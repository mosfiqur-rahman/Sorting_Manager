<p><strong>The Linux Command Line</strong><br /> Second Internet Edition<br /> William E. Shotts, Jr.<br /> A LinuxCommand.org Book<br /></p>
<hr />
<p>Copyright ©2008-2013, William E. Shotts, Jr.<br /> This work is licensed under the Creative Commons Attribution-Noncommercial-No De-<br />rivative Works 3.0 United States License. To view a copy of this license, visit the link <br />above or send a letter to Creative Commons, 171 Second Street, Suite 300, San Fran-<br />cisco, California, 94105, USA.<br />Linux®  is the registered trademark of Linus Torvalds.   All other trademarks belong to <br />their respective owners.<br />This book is part of the LinuxCommand.org project, a site for Linux education and advo-<br />cacy devoted to helping users of legacy operating systems migrate into the future.  You <br />may contact the LinuxCommand.org project at<a href="http://linuxcommand.org/"> http://linuxcommand.org.<br /></a>This book is also available in printed form, published by No Starch Press and may be <br />purchased wherever fine books are sold. No Starch Press also offers this book in elec-<br />tronic formats for most popular e-readers:<a href="http://nostarch.com/tlcl.htm"> http://nostarch.com/tlcl.htm<br /></a><strong>Release History</strong><br /> <strong>Version</strong><br /> <strong>Date</strong><br /> <strong>Description</strong><br /> 13.07<br /> July 6, 2013<br /> Second Internet Edition.<br /> 09.12<br /> December 14, 2009<br /> First Internet Edition.<br /> 09.11<br /> November 19, 2009<br /> Fourth draft with almost all reviewer feedback <br />incorporated and edited through chapter 37.<br /> 09.10<br /> October 3, 2009<br /> Third draft with revised table formatting, <br />partial application of reviewers feedback and <br />edited through chapter 18. <br /> 09.08<br /> August 12, 2009<br /> Second draft incorporating the first editing <br />pass.<br /> 09.07<br /> July 18, 2009<br /> Completed first draft.<br /></p>
<hr />
<p><em><strong>Table of Contents</strong></em><br /> <a href="news.html#18"><em><strong>Introduction.</strong></em></a><em><strong>...................................................................................................xvi</strong></em><br /> Why Use The Command Line?.....................................................................................xvi<br />What This Book Is About..............................................................................................xvi<br />Who Should Read This Book.......................................................................................xvi<br />What's In This Book.....................................................................................................xvi i<br />How To Read This Book..............................................................................................xvi i<br /> Prerequisites............................................................................................................xix<br /> Why I Don't Cal  It “GNU/Linux”...........................................................................xix<br /> Acknowledgments..........................................................................................................xx<br />Your Feedback Is Needed!............................................................................................xx<br />What's New In The Second Internet Edition.................................................................xxi<br />Further Reading............................................................................................................xxi<br />Colophon.......................................................................................................................xxi<br /> <a href="news.html#25"><strong>Part 1 – Learning The Shell.</strong></a><strong>.............................................................1</strong><br /> <a href="news.html#26"><em><strong>1 – What Is The Shell?.</strong></em></a><em><strong>....................................................................................2</strong></em><br /> Terminal Emulators..........................................................................................................2<br />Your First Keystrokes......................................................................................................2<br /> Command History.......................................................................................................3<br />Cursor Movement.......................................................................................................3<br /> A Few Words About Mice And Focus....................................................................3<br /> Try Some Simple Commands..........................................................................................4<br />Ending A Terminal Session..............................................................................................5<br /> The Console Behind The Curtain..........................................................................5<br /> Summing Up....................................................................................................................5<br />Further Reading...............................................................................................................6<br /> <a href="news.html#31"><em><strong>2 – Navigation.</strong></em></a><em><strong>..................................................................................................7</strong></em><br /> Understanding The File System Tree..............................................................................7<br />The Current Working Directory........................................................................................7<br />Listing The Contents Of A Directory................................................................................8<br />Changing The Current Working Directory.......................................................................9<br /> Absolute Pathnames..................................................................................................9<br />Relative Pathnames...................................................................................................9<br />Some Helpful Shortcuts............................................................................................11<br /> Important Facts About Filenames........................................................................11<br /> i<br /></p>
<hr />
<p>Summing Up..................................................................................................................12<br /> <a href="news.html#37"><em><strong>3 – Exploring The System.</strong></em></a><em><strong>............................................................................13</strong></em><br /> More Fun With ls...........................................................................................................13<br /> Options And Arguments............................................................................................14<br />A Longer Look At Long Format.................................................................................16<br /> Determining A File's Type With file................................................................................17<br />Viewing File Contents With less....................................................................................17<br /> What Is “Text”?.....................................................................................................17<br />Less Is More........................................................................................................19<br /> A Guided Tour................................................................................................................19<br />Symbolic Links...............................................................................................................23<br />Hard Links.....................................................................................................................24<br />Summing Up..................................................................................................................24<br />Further Reading.............................................................................................................24<br /> <a href="news.html#49"><em><strong>4 – Manipulating Files And Directories.</strong></em></a><em><strong>.......................................................25</strong></em><br /> Wildcards.......................................................................................................................25<br /> Character Ranges................................................................................................27<br />Wildcards Work In The GUI Too..........................................................................27<br /> mkdir – Create Directories.............................................................................................28<br />cp – Copy Files And Directories....................................................................................28<br /> Useful Options And Examples..................................................................................29<br /> mv – Move And Rename Files......................................................................................30<br /> Useful Options And Examples..................................................................................30<br /> rm – Remove Files And Directories...............................................................................31<br /> Useful Options And Examples..................................................................................31<br /> Be Careful With rm!.............................................................................................32<br /> ln – Create Links............................................................................................................33<br /> Hard Links................................................................................................................33<br />Symbolic Links..........................................................................................................33<br /> Let's Build A Playground................................................................................................34<br /> Creating Directories..................................................................................................34<br />Copying Files............................................................................................................34<br />Moving And Renaming Files.....................................................................................35<br />Creating Hard Links..................................................................................................37<br />Creating Symbolic Links...........................................................................................38<br />Removing Files And Directories...............................................................................39<br /> Creating Symlinks With The GUI.........................................................................40<br /> Summing Up..................................................................................................................41<br />Further Reading.............................................................................................................41<br /> <a href="news.html#66"><em><strong>5 – Working With Commands.</strong></em></a><em><strong>.......................................................................42</strong></em><br /> What Exactly Are Commands?......................................................................................42<br />Identifying Commands...................................................................................................43<br /> type – Display A Command's Type...........................................................................43<br />which – Display An Executable's Location...............................................................43<br /> Getting A Command's Documentation..........................................................................44<br /> help – Get Help For Shel  Builtins............................................................................44<br />--help – Display Usage Information..........................................................................45<br /> ii<br /></p>
<hr />
<p>man – Display A Program's Manual Page................................................................45<br />apropos – Display Appropriate Commands..............................................................47<br />whatis – Display A Very Brief Description Of A Command.......................................47<br /> The Most Brutal Man Page Of Them All..............................................................48<br /> info – Display A Program's Info Entry.......................................................................48<br />README And Other Program Documentation Files................................................49<br /> Creating Your Own Commands With alias....................................................................50<br />Summing Up..................................................................................................................52<br />Further Reading.............................................................................................................52<br /> <a href="news.html#77"><em><strong>6 – Redirection.</strong></em></a><em><strong>...............................................................................................53</strong></em><br /> Standard Input, Output, And Error.................................................................................53<br />Redirecting Standard Output.........................................................................................54<br />Redirecting Standard Error............................................................................................55<br /> Redirecting Standard Output And Standard Error To One File................................56<br />Disposing Of Unwanted Output................................................................................57<br /> /dev/nul  In Unix Culture......................................................................................57<br /> Redirecting Standard Input............................................................................................57<br /> cat – Concatenate Files............................................................................................57<br /> Pipelines........................................................................................................................59<br /> The Difference Between &gt; and |..........................................................................60<br /> Filters........................................................................................................................61<br />uniq - Report Or Omit Repeated Lines.....................................................................61<br />wc – Print Line, Word, And Byte Counts..................................................................62<br />grep – Print Lines Matching A Pattern......................................................................62<br />head / tail – Print First / Last Part Of Files................................................................63<br />tee – Read From Stdin And Output To Stdout And Files..........................................64<br /> Summing Up..................................................................................................................65<br /> Linux Is About Imagination..................................................................................65<br /> <a href="news.html#91"><em><strong>7 – Seeing The World As The Shell Sees It.</strong></em></a><em><strong>.................................................67</strong></em><br /> Expansion......................................................................................................................67<br /> Pathname Expansion...............................................................................................68<br /> Pathname Expansion Of Hidden Files.................................................................69<br /> Tilde Expansion........................................................................................................69<br />Arithmetic Expansion................................................................................................70<br />Brace Expansion......................................................................................................71<br />Parameter Expansion...............................................................................................72<br />Command Substitution.............................................................................................73<br /> Quoting..........................................................................................................................74<br /> Double Quotes..........................................................................................................75<br />Single Quotes...........................................................................................................76<br />Escaping Characters................................................................................................77<br /> Backslash Escape Sequences............................................................................77<br /> Summing Up..................................................................................................................78<br />Further Reading.............................................................................................................78<br /> <a href="news.html#103"><em><strong>8 – Advanced Keyboard Tricks.</strong></em></a><em><strong>....................................................................79</strong></em><br /> Command Line Editing..................................................................................................79<br /> Cursor Movement.....................................................................................................79<br /> iii<br /></p>
<hr />
<p>Modifying Text...........................................................................................................80<br />Cutting And Pasting (Killing And Yanking) Text........................................................80<br /> The Meta Key......................................................................................................81<br /> Completion....................................................................................................................81<br /> Programmable Completion..................................................................................83<br /> Using History.................................................................................................................83<br /> Searching History.....................................................................................................84<br />History Expansion.....................................................................................................86<br /> script....................................................................................................................86<br /> Summing Up..................................................................................................................86<br />Further Reading.............................................................................................................87<br /> <a href="news.html#112"><em><strong>9 – Permissions.</strong></em></a><em><strong>.............................................................................................88</strong></em><br /> Owners, Group Members, And Everybody Else............................................................89<br />Reading, Writing, And Executing...................................................................................90<br /> chmod – Change File Mode.....................................................................................92<br /> What The Heck Is Octal?.....................................................................................93<br /> Setting File Mode With The GUI...............................................................................95<br />umask – Set Default Permissions............................................................................96<br /> Some Special Permissions..................................................................................98<br /> Changing Identities........................................................................................................99<br /> su – Run A Shell With Substitute User And Group IDs............................................99<br />sudo – Execute A Command As Another User.......................................................101<br /> Ubuntu And sudo...............................................................................................101<br /> chown – Change File Owner And Group................................................................102<br />chgrp – Change Group Ownership.........................................................................103<br /> Exercising Our Privileges............................................................................................103<br />Changing Your Password............................................................................................106<br />Summing Up................................................................................................................107<br />Further Reading..........................................................................................................107<br /> <a href="news.html#132"><em><strong>10 – Processes.</strong></em></a><em><strong>............................................................................................108</strong></em><br /> How A Process Works.................................................................................................108<br />Viewing Processes......................................................................................................109<br /> Viewing Processes Dynamical y With top..............................................................111<br /> Controlling Processes.................................................................................................113<br /> Interrupting A Process............................................................................................114<br />Putting A Process In The Background....................................................................114<br />Returning A Process To The Foreground...............................................................115<br />Stopping (Pausing) A Process................................................................................116<br /> Signals.........................................................................................................................117<br /> Sending Signals To Processes With kil .................................................................117<br />Sending Signals To Multiple Processes With kil al ................................................120<br /> More Process Related Commands.............................................................................120<br />Summing Up................................................................................................................121<br /> <a href="news.html#147"><strong>Part 2 – Configuration And The Environment.</strong></a><strong>............................123</strong><br /> <a href="news.html#148"><em><strong>11 – The Environment.</strong></em></a><em><strong>.................................................................................124</strong></em><br /> iv<br /></p>
<hr />
<p>What Is Stored In The Environment?..........................................................................124<br /> Examining The Environment..................................................................................124<br />Some Interesting Variables.....................................................................................126<br /> How Is The Environment Established?.......................................................................127<br /> What's In A Startup File?........................................................................................128<br /> Modifying The Environment.........................................................................................130<br /> Which Files Should We Modify?.............................................................................130<br />Text Editors.............................................................................................................130<br />Using A Text Editor.................................................................................................131<br /> Why Comments Are Important..........................................................................134<br /> Activating Our Changes..........................................................................................135<br /> Summing Up................................................................................................................135<br />Further Reading..........................................................................................................135<br /> <a href="news.html#160"><em><strong>12 – A Gentle Introduction To vi.</strong></em></a><em><strong>................................................................136</strong></em><br /> Why We Should Learn vi.............................................................................................136<br />A Little Background ....................................................................................................137<br />Starting And Stopping vi..............................................................................................137<br /> Compatibility Mode............................................................................................138<br /> Editing Modes..............................................................................................................139<br /> Entering Insert Mode..............................................................................................140<br />Saving Our Work....................................................................................................140<br /> Moving The Cursor Around.........................................................................................141<br />Basic Editing................................................................................................................142<br /> Appending Text.......................................................................................................142<br />Opening A Line.......................................................................................................143<br />Deleting Text...........................................................................................................144<br />Cutting, Copying, And Pasting Text........................................................................145<br />Joining Lines...........................................................................................................147<br /> Search-And-Replace...................................................................................................147<br /> Searching Within A Line..........................................................................................147<br />Searching The Entire File.......................................................................................147<br />Global Search-And-Replace...................................................................................148<br /> Editing Multiple Files...................................................................................................150<br /> Switching Between Files.........................................................................................151<br />Opening Additional Files For Editing......................................................................151<br />Copying Content From One File Into Another........................................................152<br />Inserting An Entire File Into Another.......................................................................153<br /> Saving Our Work.........................................................................................................154<br />Summing Up................................................................................................................155<br />Further Reading..........................................................................................................155<br /> <a href="news.html#180"><em><strong>13 – Customizing The Prompt.</strong></em></a><em><strong>....................................................................156</strong></em><br /> Anatomy Of A Prompt..................................................................................................156<br />Trying Some Alternative Prompt Designs....................................................................158<br />Adding Color................................................................................................................159<br /> Terminal Confusion............................................................................................160<br /> Moving The Cursor......................................................................................................162<br />Saving The Prompt......................................................................................................163<br />Summing Up................................................................................................................164<br /> v<br /></p>
<hr />
<p>Further Reading..........................................................................................................164<br /> <a href="news.html#189"><strong>Part 3 – Common Tasks And Essential Tools.</strong></a><strong>............................165</strong><br /> <a href="news.html#190"><em><strong>14 – Package Management.</strong></em></a><em><strong>.........................................................................166</strong></em><br /> Packaging Systems.....................................................................................................166<br />How A Package System Works...................................................................................167<br /> Package Files.........................................................................................................167<br />Repositories............................................................................................................167<br />Dependencies.........................................................................................................168<br />High And Low-level Package Tools........................................................................168<br /> Common Package Management Tasks.......................................................................169<br /> Finding A Package In A Repository........................................................................169<br />Installing A Package From A Repository.................................................................169<br />Installing A Package From A Package File.............................................................170<br />Removing A Package.............................................................................................170<br />Updating Packages From A Repository..................................................................171<br />Upgrading A Package From A Package File...........................................................171<br />Listing Instal ed Packages......................................................................................172<br />Determining If A Package Is Installed.....................................................................172<br />Displaying Info About An Instal ed Package...........................................................173<br />Finding Which Package Instal ed A File.................................................................173<br /> Summing Up................................................................................................................173<br /> The Linux Software Instal ation Myth.................................................................174<br /> Further Reading..........................................................................................................175<br /> <a href="news.html#200"><em><strong>15 – Storage Media.</strong></em></a><em><strong>......................................................................................176</strong></em><br /> Mounting And Unmounting Storage Devices..............................................................176<br /> Viewing A List Of Mounted File Systems................................................................178<br /> Why Unmounting Is Important...........................................................................181<br /> Determining Device Names....................................................................................182<br /> Creating New File Systems.........................................................................................185<br /> Manipulating Partitions With fdisk..........................................................................185<br />Creating A New File System With mkfs..................................................................188<br /> Testing And Repairing File Systems............................................................................189<br /> What The fsck?..................................................................................................189<br /> Formatting Floppy Disks..............................................................................................189<br />Moving Data Directly To/From Devices.......................................................................190<br />Creating CD-ROM Images..........................................................................................191<br /> Creating An Image Copy Of A CD-ROM.................................................................191<br />Creating An Image From A Col ection Of Files.......................................................191<br /> A Program By Any Other Name.........................................................................192<br /> Writing CD-ROM Images.............................................................................................192<br /> Mounting An ISO Image Directly............................................................................192<br />Blanking A Re-Writable CD-ROM...........................................................................193<br />Writing An Image....................................................................................................193<br /> Summing Up................................................................................................................193<br />Further Reading..........................................................................................................193<br />Extra Credit..................................................................................................................193<br /> vi<br /></p>
<hr />
<p><a href="news.html#219"><em><strong>16 – Networking.</strong></em></a><em><strong>...........................................................................................195</strong></em><br /> Examining And Monitoring A Network.........................................................................196<br /> ping.........................................................................................................................196<br />traceroute...............................................................................................................197<br />netstat.....................................................................................................................198<br /> Transporting Files Over A Network..............................................................................199<br /> ftp............................................................................................................................199<br />lftp – A Better ftp.....................................................................................................202<br />wget........................................................................................................................202<br /> Secure Communication With Remote Hosts...............................................................202<br /> ssh..........................................................................................................................203<br /> Tunneling With SSH..........................................................................................206<br /> scp And sftp............................................................................................................207<br /> An SSH Client For Windows?............................................................................208<br /> Summing Up................................................................................................................208<br />Further Reading..........................................................................................................208<br /> <a href="news.html#233"><em><strong>17 – Searching For Files.</strong></em></a><em><strong>.............................................................................209</strong></em><br /> locate – Find Files The Easy Way...............................................................................209<br /> Where Does The locate Database Come From?..............................................211<br /> find – Find Files The Hard Way...................................................................................211<br /> Tests.......................................................................................................................212<br />Operators................................................................................................................214<br />Predefined Actions..................................................................................................217<br />User-Defined Actions..............................................................................................219<br />Improving Efficiency...............................................................................................220<br />xargs.......................................................................................................................220<br /> Dealing With Funny Filenames..........................................................................221<br /> A Return To The Playground..................................................................................221<br />Options...................................................................................................................224<br /> Summing Up................................................................................................................225<br />Further Reading..........................................................................................................225<br /> <a href="news.html#250"><em><strong>18 – Archiving And Backup.</strong></em></a><em><strong>........................................................................226</strong></em><br /> Compressing Files.......................................................................................................226<br /> gzip.........................................................................................................................227<br />bzip2.......................................................................................................................229<br /> Don’t Be Compressive Compulsive...................................................................230<br /> Archiving Files.............................................................................................................230<br /> tar............................................................................................................................230<br />zip...........................................................................................................................236<br /> Synchronizing Files And Directories............................................................................238<br /> Using rsync Over A Network...................................................................................240<br /> Summing Up................................................................................................................241<br />Further Reading..........................................................................................................241<br /> <a href="news.html#267"><em><strong>19 – Regular Expressions.</strong></em></a><em><strong>..........................................................................243</strong></em><br /> What Are Regular Expressions?............................................................................243<br /> grep.............................................................................................................................243<br /> vii<br /></p>
<hr />
<p>Metacharacters And Literals........................................................................................245<br />The Any Character......................................................................................................246<br />Anchors.......................................................................................................................247<br /> A Crossword Puzzle Helper...............................................................................247<br /> Bracket Expressions And Character Classes..............................................................248<br /> Negation.................................................................................................................248<br />Traditional Character Ranges.................................................................................249<br />POSIX Character Classes......................................................................................250<br /> Reverting To Traditional Col ation Order............................................................253<br /> POSIX Basic Vs. Extended Regular Expressions.......................................................254<br /> POSIX................................................................................................................254<br /> Alternation...................................................................................................................255<br />Quantifiers...................................................................................................................256<br /> ? - Match An Element Zero Or One Time...............................................................256<br />* - Match An Element Zero Or More Times............................................................257<br />+ - Match An Element One Or More Times............................................................258<br />{ } - Match An Element A Specific Number Of Times..............................................258<br /> Putting Regular Expressions To Work.........................................................................259<br /> Validating A Phone List With grep...........................................................................259<br />Finding Ugly Filenames With find...........................................................................260<br />Searching For Files With locate.............................................................................261<br />Searching For Text With less And vim....................................................................261<br /> Summing Up................................................................................................................263<br />Further Reading..........................................................................................................263<br /> <a href="news.html#288"><em><strong>20 – Text Processing.</strong></em></a><em><strong>...................................................................................264</strong></em><br /> Applications Of Text.....................................................................................................264<br /> Documents.............................................................................................................265<br />Web Pages.............................................................................................................265<br />Email.......................................................................................................................265<br />Printer Output.........................................................................................................265<br />Program Source Code............................................................................................265<br /> Revisiting Some Old Friends.......................................................................................265<br /> cat...........................................................................................................................266<br /> MS-DOS Text Vs. Unix Text...............................................................................267<br /> sort..........................................................................................................................267<br />uniq.........................................................................................................................275<br /> Slicing And Dicing........................................................................................................276<br /> cut...........................................................................................................................276<br /> Expanding Tabs.................................................................................................279<br /> paste.......................................................................................................................280<br />join..........................................................................................................................281<br /> Comparing Text...........................................................................................................283<br /> comm......................................................................................................................284<br />diff...........................................................................................................................284<br />patch.......................................................................................................................287<br /> Editing On The Fly.......................................................................................................288<br /> tr..............................................................................................................................288<br /> ROT13: The Not-So-Secret Decoder Ring........................................................290<br /> sed..........................................................................................................................290<br /> viii<br /></p>
<hr />
<p>People Who Like sed Also Like.........................................................................299<br /> aspell......................................................................................................................299<br /> Summing Up................................................................................................................303<br />Further Reading..........................................................................................................303<br />Extra Credit..................................................................................................................304<br /> <a href="news.html#329"><em><strong>21 – Formatting Output.</strong></em></a><em><strong>...............................................................................305</strong></em><br /> Simple Formatting Tools..............................................................................................305<br /> nl – Number Lines..................................................................................................305<br />fold – Wrap Each Line To A Specified Length........................................................309<br />fmt – A Simple Text Formatter................................................................................309<br />pr – Format Text For Printing..................................................................................313<br />printf – Format And Print Data................................................................................314<br /> Document Formatting Systems...................................................................................317<br /> groff.........................................................................................................................318<br /> Summing Up................................................................................................................324<br />Further Reading..........................................................................................................324<br /> <a href="news.html#350"><em><strong>22 – Printing.</strong></em></a><em><strong>.................................................................................................326</strong></em><br /> A Brief History Of Printing............................................................................................326<br /> Printing In The Dim Times......................................................................................326<br />Character-based Printers.......................................................................................327<br />Graphical Printers...................................................................................................328<br /> Printing With Linux......................................................................................................329<br />Preparing Files For Printing.........................................................................................329<br /> pr – Convert Text Files For Printing........................................................................329<br /> Sending A Print Job To A Printer..................................................................................331<br /> lpr – Print Files (Berkeley Style).............................................................................331<br />lp – Print Files (System V Style).............................................................................332<br />Another Option: a2ps..............................................................................................333<br /> Monitoring And Control ing Print Jobs.........................................................................336<br /> lpstat – Display Print System Status......................................................................336<br />lpq – Display Printer Queue Status........................................................................337<br />lprm / cancel – Cancel Print Jobs...........................................................................338<br /> Summing Up................................................................................................................338<br />Further Reading..........................................................................................................338<br /> <a href="news.html#364"><em><strong>23 – Compiling Programs.</strong></em></a><em><strong>...........................................................................340</strong></em><br /> What Is Compiling?.....................................................................................................340<br /> Are All Programs Compiled?..................................................................................341<br /> Compiling A C Program...............................................................................................342<br /> Obtaining The Source Code...................................................................................342<br />Examining The Source Tree...................................................................................344<br />Building The Program.............................................................................................346<br />Installing The Program...........................................................................................350<br /> Summing Up................................................................................................................350<br />Further Reading..........................................................................................................350<br /> <a href="news.html#377"><strong>Part 4 – Writing Shell Scripts.</strong></a><strong>......................................................353</strong><br /> ix<br /></p>
<hr />
<p><a href="news.html#378"><em><strong>24 – Writing Your First Script.</strong></em></a><em><strong>.....................................................................354</strong></em><br /> What Are Shel  Scripts?...............................................................................................354<br />How To Write A Shel  Script.........................................................................................354<br />Script File Format........................................................................................................355<br />Executable Permissions..............................................................................................356<br />Script File Location......................................................................................................356<br /> Good Locations For Scripts....................................................................................358<br /> More Formatting Tricks................................................................................................358<br /> Long Option Names................................................................................................358<br />Indentation And line-continuation...........................................................................358<br /> Configuring vim For Script Writing.....................................................................359<br /> Summing Up................................................................................................................360<br />Further Reading..........................................................................................................360<br /> <a href="news.html#385"><em><strong>25 – Starting A Project.</strong></em></a><em><strong>................................................................................361</strong></em><br /> First Stage: Minimal Document...................................................................................361<br />Second Stage: Adding A Little Data............................................................................363<br />Variables And Constants.............................................................................................364<br /> Assigning Values To Variables And Constants.......................................................367<br /> Here Documents.........................................................................................................368<br />Summing Up................................................................................................................371<br />Further Reading..........................................................................................................371<br /> <a href="news.html#396"><em><strong>26 – Top-Down Design.</strong></em></a><em><strong>................................................................................372</strong></em><br /> Shel  Functions............................................................................................................373<br />Local Variables............................................................................................................376<br />Keep Scripts Running..................................................................................................377<br /> Shel  Functions In Your .bashrc File..................................................................380<br /> Summing Up................................................................................................................380<br />Further Reading..........................................................................................................380<br /> <a href="news.html#405"><em><strong>27 – Flow Control: Branching With if.</strong></em></a><em><strong>........................................................381</strong></em><br /> if...................................................................................................................................381<br />Exit Status...................................................................................................................382<br />test...............................................................................................................................384<br /> File Expressions.....................................................................................................384<br />String Expressions..................................................................................................387<br />Integer Expressions................................................................................................388<br /> A More Modern Version Of test...................................................................................389<br />(( )) - Designed For Integers........................................................................................391<br />Combining Expressions...............................................................................................392<br /> Portability Is The Hobgoblin Of Little Minds.......................................................394<br /> Control Operators: Another Way To Branch................................................................394<br />Summing Up................................................................................................................395<br />Further Reading..........................................................................................................396<br /> <a href="news.html#421"><em><strong>28 – Reading Keyboard Input.</strong></em></a><em><strong>.....................................................................397</strong></em><br /> read – Read Values From Standard Input...................................................................398<br /> Options...................................................................................................................400<br /> x<br /></p>
<hr />
<p>IFS..........................................................................................................................402<br /> You Can’t Pipe read...........................................................................................404<br /> Validating Input............................................................................................................404<br />Menus..........................................................................................................................406<br />Summing Up................................................................................................................407<br /> Extra Credit.............................................................................................................407<br /> Further Reading..........................................................................................................408<br /> <a href="news.html#433"><em><strong>29 – Flow Control: Looping With while / until.</strong></em></a><em><strong>..........................................409</strong></em><br /> Looping........................................................................................................................409<br /> while........................................................................................................................409<br /> Breaking Out Of A Loop...............................................................................................412<br /> until.........................................................................................................................413<br /> Reading Files With Loops...........................................................................................414<br />Summing Up................................................................................................................415<br />Further Reading..........................................................................................................415<br /> <a href="news.html#440"><em><strong>30 – Troubleshooting.</strong></em></a><em><strong>..................................................................................416</strong></em><br /> Syntactic Errors...........................................................................................................416<br /> Missing Quotes.......................................................................................................417<br />Missing Or Unexpected Tokens..............................................................................417<br />Unanticipated Expansions......................................................................................418<br /> Logical Errors .............................................................................................................420<br /> Defensive Programming.........................................................................................420<br />Verifying Input.........................................................................................................422<br /> Design Is A Function Of Time............................................................................422<br /> Testing.........................................................................................................................422<br /> Test Cases..............................................................................................................423<br /> Debugging...................................................................................................................424<br /> Finding The Problem Area......................................................................................424<br />Tracing....................................................................................................................424<br />Examining Values During Execution......................................................................427<br /> Summing Up................................................................................................................427<br />Further Reading..........................................................................................................428<br /> <a href="news.html#453"><em><strong>31 – Flow Control: Branching With case.</strong></em></a><em><strong>..................................................429</strong></em><br /> case.............................................................................................................................429<br /> Patterns..................................................................................................................431<br />Performing Multiple Actions....................................................................................433<br /> Summing Up................................................................................................................434<br />Further Reading..........................................................................................................434<br /> <a href="news.html#460"><em><strong>32 – Positional Parameters.</strong></em></a><em><strong>........................................................................436</strong></em><br /> Accessing The Command Line...................................................................................436<br /> Determining The Number of Arguments.................................................................437<br />shift – Getting Access To Many Arguments............................................................438<br />Simple Applications................................................................................................439<br />Using Positional Parameters With Shel  Functions................................................440<br /> Handling Positional Parameters En Masse.................................................................441<br /> xi<br /></p>
<hr />
<p>A More Complete Application......................................................................................443<br />Summing Up................................................................................................................446<br />Further Reading..........................................................................................................449<br /> <a href="news.html#474"><em><strong>33 – Flow Control: Looping With for.</strong></em></a><em><strong>.........................................................450</strong></em><br /> for: Traditional Shel  Form...........................................................................................450<br /> Why i?................................................................................................................452<br /> for: C Language Form.................................................................................................453<br />Summing Up................................................................................................................454<br />Further Reading..........................................................................................................455<br /> <a href="news.html#480"><em><strong>34 – Strings And Numbers.</strong></em></a><em><strong>.........................................................................456</strong></em><br /> Parameter Expansion..................................................................................................456<br /> Basic Parameters...................................................................................................456<br />Expansions To Manage Empty Variables...............................................................457<br />Expansions That Return Variable Names..............................................................459<br />String Operations....................................................................................................459<br />Case Conversion....................................................................................................462<br /> Arithmetic Evaluation And Expansion.........................................................................464<br /> Number Bases........................................................................................................465<br />Unary Operators.....................................................................................................465<br />Simple Arithmetic....................................................................................................465<br />Assignment.............................................................................................................467<br />Bit Operations.........................................................................................................469<br />Logic.......................................................................................................................470<br /> bc – An Arbitrary Precision Calculator Language........................................................473<br /> Using bc..................................................................................................................474<br />An Example Script..................................................................................................475<br /> Summing Up................................................................................................................476<br />Extra Credit..................................................................................................................476<br />Further Reading..........................................................................................................476<br /> <a href="news.html#502"><em><strong>35 – Arrays.</strong></em></a><em><strong>...................................................................................................478</strong></em><br /> What Are Arrays?........................................................................................................478<br />Creating An Array........................................................................................................478<br />Assigning Values To An Array......................................................................................479<br />Accessing Array Elements...........................................................................................480<br />Array Operations.........................................................................................................482<br /> Outputting The Entire Contents Of An Array..........................................................482<br />Determining The Number Of Array Elements.........................................................482<br />Finding The Subscripts Used By An Array.............................................................483<br />Adding Elements To The End Of An Array.............................................................483<br />Sorting An Array......................................................................................................484<br />Deleting An Array....................................................................................................484<br /> Associative Arrays.......................................................................................................485<br />Summing Up................................................................................................................486<br />Further Reading..........................................................................................................486<br /> <a href="news.html#511"><em><strong>36 – Exotica.</strong></em></a><em><strong>..................................................................................................487</strong></em><br /> xii<br /></p>
<hr />
<p>Group Commands And Subshel s...............................................................................487<br /> Process Substitution...............................................................................................491<br /> Traps............................................................................................................................493<br /> Temporary Files.................................................................................................495<br /> Asynchronous Execution.............................................................................................496<br /> wait.........................................................................................................................496<br /> Named Pipes...............................................................................................................498<br /> Setting Up A Named Pipe.......................................................................................498<br />Using Named Pipes................................................................................................499<br /> Summing Up................................................................................................................499<br />Further Reading..........................................................................................................499<br /> <a href="news.html#15"><em><strong>Index.</strong></em></a><em><strong>.............................................................................................................501</strong></em><br /> xiii<br /></p>
<hr />
<p>xiv<br /></p>
<hr />
<p><em>To Karen</em><br /> xv<br /></p>
<hr />
<p><em><strong>Introduction</strong></em><br /> I want to tell you a story.<br />No, not the story of how, in 1991, Linus Torvalds wrote the first version of the Linux ker-<br />nel. You can read that story in lots of Linux books.  Nor am I going to tell you the story of <br />how, some years earlier, Richard Stallman began the GNU Project to create a free Unix-<br />like operating system. That's an important story too, but most other Linux books have that <br />one, as well.<br />No, I want to tell you the story of how you can take back control of your computer.<br />When I began working with computers as a college student in the late 1970s, there was a <br />revolution going on. The invention of the microprocessor had made it possible for ordi-<br />nary people like you and me to actually own a computer.  It's hard for many people today <br />to imagine what the world was like when only big business and big government ran all <br />the computers. Let's just say, you couldn't get much done.<br />Today, the world is very different. Computers are everywhere, from tiny wristwatches to <br />giant data centers to everything in between. In addition to ubiquitous computers, we also <br />have a ubiquitous network connecting them together. This has created a wondrous new <br />age of personal empowerment and creative freedom, but over the last couple of decades <br />something else has been happening. A few giant corporations have been imposing their <br />control over most of the world's computers and deciding what you can and cannot do <br />with them. Fortunately, people from all over the world are doing something about it. They <br />are fighting to maintain control of their computers by writing their own software. They <br />are building Linux.<br />Many people speak of “freedom” with regard to Linux, but I don't think most people <br />know what this freedom really means. Freedom is the power to decide what your com-<br />puter does, and the only way to have this freedom is to know what your computer is do-<br />ing. Freedom is a computer that is without secrets, one where everything can be known if <br />you care enough to find out.<br /> <strong>Why Use The Command Line?<br /></strong>Have you ever noticed in the movies when the “super hacker,”—<br />   you<br />  <br />  know, the guy who <br /> can break into the ultra-secure military computer in under thirty seconds—<br />   s its down at <br /> the computer, he never touches a mouse? It's because movie makers realize that we, as <br />human beings, instinctively know the only way to really get anything done on a computer <br /> xvi<br /></p>
<hr />
<p>is by typing on a keyboard!<br />Most computer users today are only familiar with the <em>graphical user interface</em> (GUI) and <br />have been taught by vendors and pundits that the <em>command line interface</em> (CLI) is a terri-<br />fying thing of the past. This is unfortunate, because a good command line interface is a <br />marvelously expressive way of communicating with a computer in much the same way <br />the written word is for human beings. It's been said that “graphical user interfaces make <br />easy tasks easy, while command line interfaces make difficult tasks possible” and this is <br />still very true today.<br />Since Linux is modeled after the  Unix  family of operating systems, it shares the same <br />rich heritage of command line tools as Unix. Unix came into prominence during the early <br />1980s (although it was first developed a decade earlier), before the widespread adoption <br />of the graphical user interface and, as a result, developed an extensive command line in-<br />terface instead. In fact, one of the strongest reasons early adopters of Linux chose it over, <br />say, Windows NT was the powerful command line interface which made the “difficult <br />tasks possible.”<br /> <strong>What This Book Is About<br /></strong>This book is a broad overview of “living” on the Linux command line. Unlike some <br />books that concentrate on just a single program, such as the shell program,  bash, this <br />book will try to convey how to get along with the command line interface in a larger <br />sense. How does it all work? What can it do? What's the best way to use it?<br /><strong>This is not a book about Linux system administration.</strong> While any serious discussion of <br />the command line will invariably lead to system administration topics, this book only <br />touches on a few administration issues. It will, however, prepare the reader for additional <br />study by providing a solid foundation in the use of the command line, an essential tool for <br />any serious system administration task.<br /><strong>This book is very Linux-centric.</strong> Many other books try to broaden their appeal by in-<br />cluding other platforms such as generic Unix and OS X. In doing so, they “water down” <br />their content to feature only general topics. This book, on the other hand, only covers <br />contemporary Linux distributions. Ninety-five percent of the content is useful for users of <br />other Unix-like systems, but this book is highly targeted at the modern Linux command <br />line user. <br /> <strong>Who Should Read This Book<br /></strong>This book is for new Linux users who have migrated from other platforms. Most likely <br />you are a “power user” of some version of Microsoft Windows. Perhaps your boss has <br />told you to administer a Linux server, or maybe you're just a desktop user who is tired of <br />all the security problems and want to give Linux a try. That's fine.  All are welcome here.<br />That being said, there is no shortcut to Linux enlightenment. Learning the command line <br />is challenging and takes real effort. It's not that it's so hard, but rather it's so <em>vast</em>. The av-<br /> xvii<br /></p>
<hr />
<p>erage Linux system has literally <em>thousands</em> of programs you can employ on the command <br />line. Consider yourself warned; learning the command line is not a casual endeavor.<br />On the other hand, learning the Linux command line is extremely rewarding. If you think <br />you're a “power user” now, just wait. You don't know what real power is—<br />   ye<br />   t. And, un-<br /> like many other computer skills, knowledge of the command line is long lasting. The <br />skills learned today will still be useful ten years from now. The command line has sur-<br />vived the test of time. <br />It is also assumed that you have no programming experience, but not to worry, we'll start <br />you down that path as well.<br /> <strong>What's In This Book<br /></strong>This material is presented in a carefully chosen sequence, much like a tutor sitting next to <br />you guiding you along. Many authors treat this material in a “systematic” fashion, which <br />makes sense from a writer’s perspective, but can be very confusing to new users.<br />Another goal is to acquaint you with the Unix way of thinking, which is different from <br />the Windows way of thinking.  Along the way, we'll go on a few side trips to help you un-<br />derstand why certain things work the way they do and how they got that way.  Linux is <br />not just a piece of software, it's also a small part of the larger Unix culture, which has its <br />own language and history. I might throw in a rant or two, as well.<br />This book is divided into four parts, each covering some aspect of the command line ex-<br />perience: <br /> ●<br /> <strong>Part 1 – Learning The Shell</strong> starts our exploration of the basic language of the <br />command line including such things as the structure of commands, file system <br />navigation, command line editing, and finding help and documentation for com-<br />mands.<br /> ●<br /> <strong>Part  2 – Configuration  And The Environment</strong>  covers editing  configuration <br />files that control the computer's operation from the command line.<br /> ●<br /> <strong>Part 3 – Common Tasks And Essential Tools</strong>  explores many of the ordinary <br />tasks that are commonly performed from the command line. Unix-like operating <br />systems, such as Linux, contain many “classic” command line programs that are <br />used to perform powerful operations on data.<br /> ●<br /> <strong>Part  4 – Writing Shell  Scripts</strong>  introduces  shell programming, an  admittedly <br />rudimentary, but easy to learn, technique for automating many common comput-<br />ing tasks. By learning shell programming, you will become familiar with concepts <br />that can be applied to many other programming languages.<br /> <strong>How To Read This Book<br /></strong>Start at the beginning of the book and follow it to the end. It isn’t written as a reference <br />work, it's really more like a story with a beginning, middle, and an end. <br /> xviii<br /></p>
<hr />
<p>Prerequisites<br />To use this book, all you will need is a working Linux installation. You can get this in one <br />of two ways:<br /> 1. <strong>Install Linux on a (not so new) computer.</strong> It doesn't matter which distribution <br /> you choose, though most people today start out with either  Ubuntu,  Fedora, or <br />OpenSUSE. If in doubt, try Ubuntu first. Installing a modern Linux distribution <br />can be ridiculously easy or ridiculously difficult depending on your hardware. I <br />suggest a desktop computer that is a couple of years old and has at least 256 <br />megabytes of RAM and 6 gigabytes of free hard disk space. Avoid laptops and <br />wireless networks if at all possible, as these are often more difficult to get work-<br />ing.<br /> 2. <strong>Use a “Live CD.”</strong> One of the cool things you can do with many Linux distribu-<br /> tions is run them directly from a CDROM (or USB flash drive) without installing <br />them at all. Just go into your BIOS setup and set your computer to “Boot from <br />CDROM,” insert the live CD, and reboot. Using a live CD is a great way to test a <br />computer for Linux compatibility prior to installation. The disadvantage of using <br />a live CD is that it may be very slow compared to having Linux installed on your <br />hard drive. Both Ubuntu and Fedora (among others) have live CD versions.<br /> Regardless of how you install Linux, you will need to have occasional superuser (i.e., ad-<br />ministrative) privileges to carry out the lessons in this book.<br />After you have a working installation, start reading and follow along with your own com-<br />puter. Most of the material in this book is “hands on,” so sit down and get typing!<br /> <strong>Why I Don't Call It “GNU/Linux”<br /></strong>In some quarters, it's politically correct to call the Linux operating system the <br />“GNU/Linux operating system.” The problem with “Linux” is that there is no <br />completely correct way to name it because it was written by many different peo-<br />ple in a vast, distributed development effort. Technically speaking, Linux is the <br />name of the operating system's kernel, nothing more. The kernel is very important <br />of course, since it makes the operating system go, but it's not enough to form a <br />complete operating system.<br />Enter  Richard Stallman, the genius-philosopher who founded the Free Software <br />movement, started the Free Software Foundation, formed the GNU Project, wrote <br />the first version of the GNU C Compiler (gcc), created the GNU General Public <br />License (the GPL), etc., etc., etc. He <em>insists</em> that you call it “GNU/Linux” to prop-<br />erly reflect the contributions of the GNU Project. While the GNU Project predates <br />the Linux kernel, and the project's contributions are extremely deserving of recog-<br />nition, placing them in the name is unfair to everyone else who made significant <br /> xix<br /></p>
<hr />
<p>contributions. Besides, I think “Linux/GNU” would be more technically accurate <br />since the kernel boots first and everything else runs on top of it.<br />In popular usage, “Linux” refers to the kernel and all the other free and open <br />source software found in the typical Linux distribution; that is, the entire Linux <br />ecosystem,   not   just   the   GNU   components.  The   operating   system   marketplace <br />seems to prefer one-word names such as DOS, Windows, Solaris, Irix, AIX. I <br />have   chosen   to   use   the   popular   format.   If,   however,   you   prefer   to   use <br />“GNU/Linux” instead, please perform a mental search-and-replace while reading <br />this book. I won't mind.<br /> <strong>Acknowledgments<br /></strong>I want to thank the following people, who helped make this book possible:<br />Jenny Watson, Acquisitions Editor at Wiley Publishing who originally suggested that I <br />write a shell scripting book.<br />John C. Dvorak, noted columnist and pundit. In an episode of his video podcast, “Cranky <br />Geeks,” Mr. Dvorak described the process of writing: “Hell. Write 200 words a day and <br />in a year, you have a novel.” This advice led me to write a page a day until I had a book.<br />Dmitri Popov wrote an article in Free Software Magazine titled, “Creating a book tem-<br />plate with Writer,” which inspired me to use  OpenOffice.org Writer  for composing the <br />text. As it turned out, it worked wonderfully.<br />Mark Polesky performed an extraordinary review and test of the text. <br />Jesse Becker, Tomasz Chrzczonowicz, Michael Levin, Spence Miner also tested and re-<br />viewed portions of the text. <br />Karen M. Shotts contributed a lot of hours, polishing my so-called English by editing the <br />text.<br />And lastly, the readers of<a href="http://linuxcommand.org/"> LinuxCommand.org,</a> who have sent me so many kind emails. <br />Their encouragement gave me the idea that I was really on to something! <br /> <strong>Your Feedback Is Needed!<br /></strong>This book is an ongoing project, like many open source software projects. If you find a <br />technical error, drop me a line at:<br /><script type="text/javascript">
<!--
h='&#x75;&#x73;&#x65;&#114;&#x73;&#46;&#x73;&#x6f;&#x75;&#114;&#x63;&#x65;&#102;&#x6f;&#114;&#x67;&#x65;&#46;&#110;&#x65;&#116;';a='&#64;';n='&#98;&#x73;&#104;&#x6f;&#116;&#116;&#x73;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'">'+'bshotts@users.sourceforge.net<br />'+'<\/'+'a'+'>');
// -->
</script><noscript>&#98;&#x73;&#104;&#x6f;&#116;&#116;&#x73;&#64;&#x75;&#x73;&#x65;&#114;&#x73;&#46;&#x73;&#x6f;&#x75;&#114;&#x63;&#x65;&#102;&#x6f;&#114;&#x67;&#x65;&#46;&#110;&#x65;&#116;&#60;&#98;&#114;&#32;&#x2f;&#62;&#32;&#40;&#98;&#x73;&#104;&#x6f;&#116;&#116;&#x73;&#32;&#x61;&#116;&#32;&#x75;&#x73;&#x65;&#114;&#x73;&#32;&#100;&#x6f;&#116;&#32;&#x73;&#x6f;&#x75;&#114;&#x63;&#x65;&#102;&#x6f;&#114;&#x67;&#x65;&#32;&#100;&#x6f;&#116;&#32;&#110;&#x65;&#116;&#x29;</noscript>Your changes and suggestions may get into future releases.<br /> xx<br /></p>
<hr />
<p><strong>What's New In The Second Internet Edition<br /></strong>This version of  <em>The Linux Command Line</em>  has undergone some additional polish and <br />modernization. In particular, bash version 4.x is assumed to be the standard version and <br />the text has been updated to reflect this. The chapter numbers in the Second Internet Edi-<br />tion now align with those in the No Starch Press edition. I also fixed a few  bugs ;-).<br />Special thanks go out to the following individuals who provided valuable feedback on the <br />first edition: Adrian Arpidez, Hu Bo, Heriberto Cantú, Joshua Escamilla, Bruce Fowler, <br />Ma Jun, Seth King, Mike O'Donnell, Parviz Rasoulipour, Gabriel Stutzman, and Chris-<br />tian Wuethrich.<br /> <strong>Further Reading</strong><br /> ●<br /> Here are some Wikipedia articles on the famous people mentioned in this chapter:<br /><a href="http://en.wikipedia.org/wiki/Linux_Torvalds">http://en.wikipedia.org/wiki/Linus_Torvalds<br /></a><a href="http://en.wikipedia.org/wiki/Richard_Stallman">http://en.wikipedia.org/wiki/Richard_Stallman</a><br /> ●<br /> The Free Software Foundation and the GNU Project:<br /><a href="http://en.wikipedia.org/wiki/Free_Software_Foundation">http://en.wikipedia.org/wiki/Free_Software_Foundation<br /></a><a href="http://www.fsf.org/">http://www.fsf.org<br /></a><a href="http://www.gnu.org/">http://www.gnu.org</a><br /> ●<br /> Richard Stallman has written extensively on the “GNU/Linux” naming issue:<br /><a href="http://www.gnu.org/gnu/why-gnu-linux.html">http://www.gnu.org/gnu/why-gnu-linux.html<br /></a><a href="http://www.gnu.org/gnu/gnu-linux-faq.html#tools">http://www.gnu.org/gnu/gnu-linux-faq.html#tools</a><br /> <strong>Colophon<br /></strong>This book was originally written using  OpenOffice.org Writer  in Liberation Serif and <br />Sans fonts on a Dell Inspiron 530N, factory configured with Ubuntu 8.04. The PDF ver-<br />sion of the text was generated directly by OpenOffice.org Writer. The Second Internet <br />Edition was produced on the same computer using LibreOffice Writer on Ubuntu 12.04.<br /> xxi<br /></p>
<hr />
<p>xxii<br /></p>
<hr />
<p>Part 1 – Learning The Shell<br /> 1<br /></p>
<hr />
<p>1 – What Is The Shell?<br /> <em><strong>1 – What Is The Shell?</strong></em><br /> When we speak of the command line, we are really referring to the <em>shell</em>. The shell is a <br />program that takes keyboard commands and passes them to the operating system to carry <br />out. Almost all Linux distributions supply a shell program from the GNU Project called <br />bash. The name “bash” is an acronym for “Bourne Again SHell”, a reference to the fact <br />bash  is an enhanced replacement for  sh, the original Unix shell program written by <br />Steve Bourne.<br /> <strong>Terminal Emulators<br /></strong>When using a graphical user interface, we need another program called a <em>terminal emula-<br />tor</em> to interact with the shell. If we look through our desktop menus, we will probably find <br />one.  KDE  uses  konsole  and  GNOME  uses  gnome-terminal,  though it's likely <br />called simply “terminal” on our menu. There are a number of other terminal emulators <br />available for Linux, but they all basically do the same thing; give us access to the shell. <br />You will probably develop a preference for one or another based on the number of bells <br />and whistles it has.<br /> <strong>Your First Keystrokes<br /></strong>So let's get started. Launch the terminal emulator! Once it comes up, we should see some-<br />thing like this:<br /> [me@linuxbox ~]$<br /> This is called a <em>shell prompt</em> and it will appear whenever the shell is ready to accept in-<br />put. While it may vary in appearance somewhat depending on the distribution, it will usu-<br />ally include your  <em>username@machinename</em>, followed by the current working directory <br />(more about that in a little bit) and a dollar sign.<br />If the last character of the prompt is a pound sign (“#”) rather than a dollar sign, the ter-<br />minal session has  <em>superuser</em>  privileges. This means either we are logged in as the root <br />user or we selected a terminal emulator that provides superuser (administrative) privi-<br /> 2<br /></p>
<hr />
<p>Your First Keystrokes<br /> leges.<br />Assuming that things are good so far, let's try some typing. Enter some gibberish at the <br />prompt like so:<br /> [me@linuxbox ~]$ <strong>kaekfjaeifj</strong><br /> Since this command makes no sense, the shell will tell us so and give us another chance:<br /> bash: kaekfjaeifj: command not found<br /> [me@linuxbox ~]$<br /> Command History<br />If we press the up-arrow key, we will see that the previous command “kaekfjaeifj” reap-<br />pears after the prompt. This is called <em>command history</em>. Most Linux distributions remem-<br />ber the last 500 commands by default. Press the down-arrow key and the previous com-<br />mand disappears.<br /> Cursor Movement<br />Recall the previous command with the up-arrow key again. Now try the left and right-ar-<br />row keys. See how we can position the cursor anywhere on the command line? This <br />makes editing commands easy.<br /> <strong>A Few Words About Mice And Focus<br /></strong>While the shell is all about the keyboard, you can also use a mouse with your ter-<br />minal emulator. There is a mechanism built into the X Window System (the un-<br />derlying engine that makes the GUI go) that supports a quick copy and paste tech-<br />nique. If you highlight some text by holding down the left mouse button and drag-<br />ging the mouse over it (or double clicking on a word), it is copied into a buffer <br />maintained by X. Pressing the middle mouse button will cause the text to be <br />pasted at the cursor location. Try it.<br /><strong>Note</strong>: Don't be tempted to use Ctrl-c and Ctrl-v to perform copy and paste <br />inside a terminal window. They don't work. These control codes have different <br />meanings to the shell and were assigned many years before Microsoft Windows.<br /> 3<br /></p>
<hr />
<p>1 – What Is The Shell?<br /> Your graphical desktop environment (most likely KDE or GNOME), in an effort <br />to behave like Windows, probably has its <em>focus policy</em> set to “click to focus.” This <br />means for a window to get focus (become active) you need to click on it. This is <br />contrary to the traditional X behavior of “focus follows mouse” which means that <br />a window gets focus just by passing the mouse over it. The window will not come <br />to the foreground until you click on it but it will be able to receive input. Setting <br />the focus policy to “focus follows mouse” will make the copy and paste technique <br />even more useful. Give it a try if you can (some desktop environments such as <br />Ubuntu's Unity no longer support it). I think if you give it a chance you will pre-<br />fer it. You will find this setting in the configuration program for your window <br />manager.<br /> <strong>Try Some Simple Commands<br /></strong>Now that we have learned to type, let's try a few simple commands. The first one is <br />date. This command displays the current time and date.<br /> [me@linuxbox ~]$ <strong>date<br /></strong>Thu Oct 25 13:51:54 EDT 2007<br /> A related command is cal which, by default, displays a calendar of the current month.<br /> [me@linuxbox ~]$ <strong>cal<br /></strong>    October 2007<br /> Su Mo Tu We Th Fr Sa<br />    1  2  3  4  5  6<br />  7  8  9 10 11 12 13<br />14 15 16 17 18 19 20<br /> 21 22 23 24 25 26 27<br />28 29 30 31<br /> To see the current amount of free space on your disk drives, enter df:<br /> [me@linuxbox ~]$ <strong>df<br /></strong>Filesystem           1K-blocks      Used Available Use% Mounted on<br /> /dev/sda2             15115452   5012392   9949716  34% /<br />/dev/sda5             59631908  26545424  30008432  47% /home<br /> /dev/sda1               147764     17370    122765  13% /boot<br /> 4<br /></p>
<hr />
<p>Try Some Simple Commands<br /> tmpfs                   256856         0    256856   0% /dev/shm<br /> Likewise, to display the amount of free memory, enter the free command.<br /> [me@linuxbox ~]$ <strong>free</strong><br />          total       used       free     shared    buffers     cached<br />Mem:    513712     503976       9736          0       5312     122916<br /> -/+ buffers/cache: 375748     137964<br />Swap:  1052248     104712     947536<br /> <strong>Ending A Terminal Session<br /></strong>We can end a terminal session by either closing the terminal emulator window, or by en-<br />tering the exit command at the shell prompt:<br /> [me@linuxbox ~]$ <strong>exit</strong><br /> <strong>The Console Behind The Curtain<br /></strong>Even if we have no terminal emulator running, several terminal sessions continue <br />to run behind the graphical desktop. Called <em>virtual terminals</em> or <em>virtual consoles</em>, <br />these sessions can be accessed on most Linux distributions by pressing  Ctrl-<br />Alt-F1 through Ctrl-Alt-F6. When a session is accessed, it presents a login <br />prompt into which we can enter our username and password. To switch from one <br />virtual console to another, press Alt and F1-F6. To return to the graphical desk-<br />top, press Alt-F7.<br /> <strong>Summing Up<br /></strong>As we begin our journey, we are introduced to the shell and see the command line for the <br />first time and learn how to start and end a terminal session. We also see how to issue <br />some simple commands and perform a little light command line editing. That wasn't so <br />scary was it?<br /> 5<br /></p>
<hr />
<p>1 – What Is The Shell?<br /> <strong>Further Reading</strong><br /> ●<br /> To learn more about Steve Bourne, father of the Bourne Shell, see this Wikipedia <br />article:<br /><a href="http://en.wikipedia.org/wiki/Steve_Bourne">http://en.wikipedia.org/wiki/Steve_Bourne</a><br /> ●<br /> Here is an article about the concept of shells in computing:<br /><a href="http://en.wikipedia.org/wiki/Shell_(computing)">http://en.wikipedia.org/wiki/Shell_(computing)</a><br /> 6<br /></p>
<hr />
<p>2 – Navigation<br /> <em><strong>2 – Navigation</strong></em><br /> The first thing we need to learn (besides just typing) is how to navigate the file system on <br />our Linux system. In this chapter we will introduce the following commands:<br /> ●<br /> pwd - Print name of current working directory<br /> ●<br /> cd - Change directory<br /> ●<br /> ls - List directory contents<br /> <strong>Understanding The File System Tree<br /></strong>Like Windows, a Unix-like operating system such as Linux organizes its files in what is <br />called a <em>hierarchical directory structure</em>. This means that they are organized in a tree-like <br />pattern of directories (sometimes called folders in other systems), which may contain <br />files and other directories. The first directory in the file system is called the <em>root direc-<br />tory</em>. The root directory contains files and subdirectories, which contain more files and <br />subdirectories and so on and so on.<br />Note that unlike Windows, which has a separate file system tree for each storage device, <br />Unix-like systems such as Linux always have a single file system tree, regardless of how <br />many drives or storage devices are attached to the computer. Storage devices are attached <br />(or more correctly, <em>mounted</em>) at various points on the tree according to the whims of the <br /><em>system administrator</em>, the person (or persons) responsible for the maintenance of the sys-<br />tem.<br /> <strong>The Current Working Directory<br /></strong>Most of us are probably familiar with a graphical file manager which represents the file <br />system tree as in Figure 1. Notice that the tree is usually shown upended, that is, with the <br />root at the top and the various branches descending below.<br />However, the command line has no pictures, so to navigate the file system tree we need <br />to think of it in a different way.<br /> 7<br /></p>
<hr />
<p>2 – Navigation<br /> Imagine that the file system is a maze shaped like an upside-down tree and we are able to <br /> <em>Figure 1: File system tree as shown by a <br />graphical file manager</em><br /> stand in the middle of it. At any given time, we are inside a single directory and we can <br />see the files contained in the directory and the pathway to the directory above us (called <br />the <em>parent directory</em>) and any subdirectories below us. The directory we are standing in is <br />called the <em>current working directory</em>. To display the current working directory, we use the <br />pwd (print working directory) command.<br /> [me@linuxbox ~]$ <strong>pwd</strong><br /> /home/me<br /> When we first log in to our system (or start a terminal emulator session) our current <br />working directory is set to our <em>home directory</em>. Each user account is given its own home <br />directory and it is the only place a regular user is allowed to write files.<br /> <strong>Listing The Contents Of A Directory<br /></strong>To list the files and directories in the current working directory, we use the ls command.<br /> [me@linuxbox ~]$ <strong>ls</strong><br /> Desktop  Documents  Music  Pictures  Public  Templates  Videos<br /> 8<br /></p>
<hr />
<p>Listing The Contents Of A Directory<br /> Actually, we can use the ls command to list the contents of any directory, not just the <br />current working directory, and there are many other fun things it can do as well. We'll <br />spend more time with ls in the next chapter.<br /> <strong>Changing The Current Working Directory<br /></strong>To change your working directory (where we are standing in our tree-shaped maze) we <br />use the cd command. To do this, type cd followed by the <em>pathname</em> of the desired work-<br />ing directory. A pathname is the route we take along the branches of the tree to get to the <br />directory we want. Pathnames can be specified in one of two different ways; as <em>absolute <br />pathnames</em> or as <em>relative pathnames</em>. Let's deal with absolute pathnames first.<br /> Absolute Pathnames<br />An  absolute  pathname begins with the root directory and follows the tree branch by <br />branch until the path to the desired directory or file is completed. For example, there is a <br />directory on your system in which most of your system's programs are installed. The <br />pathname of the directory is /usr/bin. This means from the root directory (represented <br />by the leading slash in the pathname) there is a directory called &quot;usr&quot; which contains a di-<br />rectory called &quot;bin&quot;.<br /> [me@linuxbox ~]$ <strong>cd /usr/bin<br /></strong>[me@linuxbox bin]$ <strong>pwd</strong><br /> /usr/bin<br />[me@linuxbox bin]$ <strong>ls</strong><br /> ...Listing of many, many files ...<br /> Now we can see that we have changed the current working directory to /usr/bin and <br />that it is full of files. Notice how the shell prompt has changed? As a convenience, it is <br />usually set up to automatically display the name of the working directory.<br /> Relative Pathnames<br />Where an absolute pathname starts from the root directory and leads to its destination, a <br />relative pathname starts from the working directory. To do this, it uses a couple of special <br />symbols to represent relative positions in the file system tree. These special symbols are <br />&quot;.&quot; (dot) and &quot;..&quot; (dot dot).<br />The &quot;.&quot; symbol refers to the working directory and the &quot;..&quot; symbol refers to the working <br />directory's parent directory. Here is how it works. Let's change the working directory to <br /> 9<br /></p>
<hr />
<p>2 – Navigation<br /> /usr/bin again:<br /> [me@linuxbox ~]$ <strong>cd /usr/bin<br /></strong>[me@linuxbox bin]$ <strong>pwd</strong><br /> /usr/bin<br /> Okay, now let's say that we wanted to change the working directory to the parent of <br />/usr/bin which is /usr. We could do that two different ways. Either with an absolute <br />pathname:<br /> [me@linuxbox bin]$ <strong>cd /usr</strong><br /> [me@linuxbox usr]$ <strong>pwd<br /></strong>/usr<br /> Or, with a relative pathname:<br /> [me@linuxbox bin]$ <strong>cd ..<br /></strong>[me@linuxbox usr]$ <strong>pwd</strong><br /> /usr<br /> Two different methods with identical results. Which one should we use? The one that <br />requires the least typing!<br />Likewise, we can change the working directory from /usr to /usr/bin in two <br />different ways. Either using an absolute pathname:<br /> [me@linuxbox usr]$ <strong>cd /usr/bin</strong><br /> [me@linuxbox bin]$ <strong>pwd<br /></strong>/usr/bin<br /> Or, with a relative pathname:<br /> [me@linuxbox usr]$ <strong>cd ./bin<br /></strong>[me@linuxbox bin]$ <strong>pwd</strong><br /> /usr/bin<br /> Now, there is something important that I must point out here. In almost all cases, you can <br /> 10<br /></p>
<hr />
<p>Changing The Current Working Directory<br /> omit the &quot;./&quot;. It is implied. Typing:<br /> [me@linuxbox usr]$ <strong>cd bin</strong><br /> does the same thing. In general, if you do not specify a pathname to something, the work-<br />ing directory will be assumed.<br /> Some Helpful Shortcuts<br />In Table 2-1 we see some useful ways the current working directory can be quickly <br />changed.<br /> <em>Table 2-1: cd Shortcuts</em><br /> <strong>Shortcut</strong><br /> <strong>Result</strong><br /> cd<br /> Changes the working directory to your home directory.<br /> cd -<br /> Changes the working directory to the previous working directory.<br /> cd ~<em>user_name </em>Changes the working directory to the home directory of <br /> <em>user_name</em>. For example, cd ~bob will change the directory to <br />the home directory of user “bob.”<br /> <strong>Important Facts About Filenames<br /></strong>1. Filenames that begin with a period character are hidden. This only means that <br /> ls will not list them unless you say ls -a. When your account was created, <br />several  hidden files  were placed in your home directory to configure things <br />for your account. Later on we will take a closer look at some of these files to <br />see how you can customize your environment. In addition, some applications <br />place their configuration and settings files in your home directory as hidden <br />files.<br /> 2. Filenames and commands in Linux, like Unix, are  case sensitive. The file-<br /> names “File1” and “file1” refer to different files.<br /> 3. Linux has no concept of a “file extension” like some other operating systems. <br /> You may name files any way you like. The contents and/or purpose of a file is <br />determined by other means. Although Unix-like operating system don’t use <br /> 11<br /></p>
<hr />
<p>2 – Navigation<br /> file  extensions  to determine the contents/purpose of files, some application <br />programs do.<br /> 4. Though Linux supports long filenames which may contain embedded spaces <br /> and punctuation characters, limit the punctuation characters in the names of <br />files you create to period, dash, and underscore. <em>Most importantly, do not em-<br />bed spaces in filenames.</em> If you want to represent spaces between words in a <br />filename, use underscore characters. You will thank yourself later.<br /> <strong>Summing Up<br /></strong>In this chapter we saw how the shell treats the directory structure of the system. We <br />learned about absolute and relative pathnames and the basic commands that are used to <br />move about that structure. In the next chapter we will use this knowledge to go on a tour <br />of a modern Linux system.<br /> 12<br /></p>
<hr />
<p>3 – Exploring The System<br /> <em><strong>3 – Exploring The System</strong></em><br /> Now that we know how to move around the file system, it's time for a guided tour of our <br />Linux system. Before we start however, we’re going to learn some more commands that <br />will be useful along the way:<br /> ●<br /> ls – List directory contents<br /> ●<br /> file – Determine file type<br /> ●<br /> less – View file contents<br /> <strong>More Fun With ls<br /></strong>The ls command is probably the most used command, and for good reason. With it, we <br />can see directory contents and determine a variety of important file and directory at-<br />tributes. As we have seen, we can simply enter ls to see a list of files and subdirectories <br />contained in the current working directory:<br /> [me@linuxbox ~]$ <strong>ls</strong><br /> Desktop  Documents  Music  Pictures  Public  Templates  Videos<br /> Besides the current working directory, we can specify the directory to list, like so:<br /> me@linuxbox ~]$ <strong>ls /usr</strong><br /> bin  games    kerberos  libexec  sbin   src<br />etc  include  lib       local    share  tmp<br /> Or even specify multiple directories. In this example we will list both the user's home di-<br />rectory (symbolized by the “~” character) and the /usr directory:<br /> [me@linuxbox ~]$ <strong>ls ~ /usr<br /></strong>/home/me:<br /> 13<br /></p>
<hr />
<p>3 – Exploring The System<br /> Desktop  Documents  Music  Pictures  Public  Templates  Videos<br /> /usr:<br /> bin  games    kerberos  libexec  sbin   src<br />etc  include  lib       local    share  tmp<br /> We can also change the format of the output to reveal more detail:<br /> [me@linuxbox ~]$ <strong>ls -l<br /></strong>total 56<br /> drwxrwxr-x 2 me me 4096 2007-10-26 17:20 Desktop<br />drwxrwxr-x 2 me me 4096 2007-10-26 17:20 Documents<br /> drwxrwxr-x 2 me me 4096 2007-10-26 17:20 Music<br />drwxrwxr-x 2 me me 4096 2007-10-26 17:20 Pictures<br /> drwxrwxr-x 2 me me 4096 2007-10-26 17:20 Public<br />drwxrwxr-x 2 me me 4096 2007-10-26 17:20 Templates<br /> drwxrwxr-x 2 me me 4096 2007-10-26 17:20 Videos<br /> By adding “-l” to the command, we changed the output to the long format.<br /> Options And Arguments<br />This brings us to a very important point about how most commands work. Commands are <br />often followed by one or more <em>options</em> that modify their behavior, and further, by one or <br />more <em>arguments</em>, the items upon which the command acts. So most commands look kind <br />of like this:<br /> <strong>command -options arguments</strong><br /> Most commands use options consisting of a single character preceded by a dash, for ex-<br />ample, “-l”, but many commands, including those from the  GNU Project, also support <br /><em>long options</em>, consisting of a word preceded by two dashes. Also, many commands allow <br />multiple short options to be strung together. In this example, the ls command is given <br />two options, the “l” option to produce long format output, and the “t” option to sort the <br />result by the file's modification time.<br /> [me@linuxbox ~]$ <strong>ls -lt</strong><br /> 14<br /></p>
<hr />
<p>More Fun With ls<br /> We'll add the long option “--reverse” to reverse the order of the sort:<br /> [me@linuxbox ~]$ <strong>ls -lt --reverse</strong><br /> Note that command options, like filenames in Linux, are case-sensitive.<br /> The ls command has a large number of possible options. The most common are listed in <br />Table 3-1.<br /> <em>Table 3- 1: Common ls Options</em><br /> <strong>Option</strong><br /> <strong>Long Option</strong><br /> <strong>Description</strong><br /> -a<br /> --all<br /> List all files, even those with names that begin <br />with a period, which are normally not listed <br />(i.e., hidden).<br /> -A<br /> --almost-all<br /> Like the -a option above except it does not <br />list  . (current directory) and .. (parent <br />directory).<br /> -d<br /> --directory<br /> Ordinarily, if a directory is specified, ls will <br />list the contents of the directory, not the <br />directory itself. Use this option in conjunction <br />with the -l option to see details about the <br />directory rather than its contents.<br /> -F<br /> --classify<br /> This option will append an indicator character <br />to the end of each listed name. For example, a <br />“/” if the name is a directory. <br /> -h<br /> --human-readable<br /> In long format listings, display file sizes in <br />human readable format rather than in bytes.<br /> -l<br /> Display results in long format.<br /> -r<br /> --reverse<br /> Display the results in reverse order. Normally, <br />ls displays its results in ascending <br />alphabetical order.<br /> -S<br /> Sort results by file size.<br /> -t<br /> Sort by modification time.<br /> 15<br /></p>
<hr />
<p>3 – Exploring The System<br /> A Longer Look At Long Format<br />As we saw before, the “-l” option causes ls to display its results in long format. This for-<br />mat contains a great deal of useful information. Here is the Examples directory from an <br />Ubuntu system:<br /> -rw-r--r-- 1 root root 3576296 2007-04-03 11:05 Experience ubuntu.ogg<br />-rw-r--r-- 1 root root 1186219 2007-04-03 11:05 kubuntu-leaflet.png<br /> -rw-r--r-- 1 root root   47584 2007-04-03 11:05 logo-Edubuntu.png<br />-rw-r--r-- 1 root root   44355 2007-04-03 11:05 logo-Kubuntu.png<br /> -rw-r--r-- 1 root root   34391 2007-04-03 11:05 logo-Ubuntu.png<br />-rw-r--r-- 1 root root   32059 2007-04-03 11:05 oo-cd-cover.odf<br /> -rw-r--r-- 1 root root  159744 2007-04-03 11:05 oo-derivatives.doc<br />-rw-r--r-- 1 root root   27837 2007-04-03 11:05 oo-maxwell.odt<br /> -rw-r--r-- 1 root root   98816 2007-04-03 11:05 oo-trig.xls<br />-rw-r--r-- 1 root root  453764 2007-04-03 11:05 oo-welcome.odt<br /> -rw-r--r-- 1 root root  358374 2007-04-03 11:05 ubuntu Sax.ogg<br /> Let's look at the different fields from one of the files and examine their meanings:<br /> <em>Table 3-2: ls Long Listing Fields</em><br /> <strong>Field</strong><br /> <strong>Meaning</strong><br /> -rw-r--r--<br /> Access rights to the file. The first character indicates the <br />type of file. Among the different types, a leading dash <br />means a regular file, while a “d” indicates a directory. <br />The next three characters are the access rights for the <br />file's owner, the next three are for members of the file's <br />group, and the final three are for everyone else. The full <br />meaning of this is discussed in Chapter 9 – Permissions.<br /> 1<br /> File's number of hard links. See the discussion of links <br />later in this chapter.<br /> root<br /> The username of the file's owner.<br /> root<br /> The name of the group which owns the file.<br /> 32059<br /> Size of the file in bytes.<br /> 2007-04-03 11:05<br /> Date and time of the file's last modification.<br /> oo-cd-cover.odf<br /> Name of the file.<br /> 16<br /></p>
<hr />
<p>Determining A File's Type With file<br /> <strong>Determining A File's Type With file<br /></strong>As we explore the system it will be useful to know what files contain. To do this we will <br />use the file command to determine a file's type. As we discussed earlier, filenames in <br />Linux are not required to reflect a file's contents. While a filename like “picture.jpg” <br />would normally be expected to contain a JPEG compressed image, it is not required to in <br />Linux.  We can invoke the file command this way:<br /> <strong>file <em>filename</em></strong><br /> When invoked, the  file  command will print a brief description of the file's contents. <br />For example:<br /> [me@linuxbox ~]$ <strong>file picture.jpg<br /></strong>picture.jpg: JPEG image data, JFIF standard 1.01<br /> There are many kinds of files. In fact, one of the common ideas in Unix-like operating <br />systems such as Linux is that “everything is a file.” As we proceed with our lessons, we <br />will see just how true that statement is.<br />While many of the files on your system are familiar, for example MP3 and JPEG, there <br />are many kinds that are a little less obvious and a few that are quite strange.<br /> <strong>Viewing File Contents With less<br /></strong>The less command is a program to view text files. Throughout our Linux system, there <br />are many files that contain human-readable text. The less program provides a conve-<br />nient way to examine them.<br /> <strong>What Is “Text”?<br /></strong>There are many ways to represent information on a computer. All methods in-<br />volve defining a relationship between the information and some numbers that will <br />be used to represent it. Computers, after all, only understand numbers and all data <br />is converted to numeric representation.<br />Some   of  these  representation   systems  are  very  complex   (such   as  compressed <br />video files), while others are rather simple. One of the earliest and simplest is <br />called <em>ASCII text</em>. ASCII (pronounced &quot;As-Key&quot;) is short for American Standard <br /> 17<br /></p>
<hr />
<p>3 – Exploring The System<br /> Code for Information Interchange. This is a simple encoding scheme that was first <br />used on Teletype machines to map keyboard characters to numbers.<br />Text is a simple one-to-one mapping of characters to numbers. It is very compact. <br />Fifty characters of text translates to fifty bytes of data. It is important to under-<br />stand that text only contains a simple mapping of characters to numbers. It is not <br />the same as a word processor document such as one created by Microsoft Word or <br />OpenOffice.org  Writer.  Those   files,   in   contrast   to   simple  ASCII   text,   contain <br />many non-text elements that are used to describe its structure and formatting. <br />Plain ASCII text files contain only the characters themselves and a few rudimen-<br />tary control codes like tabs, carriage returns and line feeds.<br />Throughout a Linux system, many files are stored in text format and there are <br />many Linux tools that work with text files. Even Windows recognizes the impor-<br />tance of this format. The well-known NOTEPAD.EXE program is an editor for <br />plain ASCII text files.<br /> Why would we want to examine text files? Because many of the files that contain system <br />settings (called <em>configuration files</em>) are stored in this format, and being able to read them <br />gives us insight about how the system works. In addition, many of the actual programs <br />that the system uses (called <em>scripts</em>) are stored in this format. In later chapters, we will <br />learn how to edit text files in order to modify systems settings and write our own scripts, <br />but for now we will just look at their contents.<br />The less command is used like this:<br /> <strong>less <em>filename</em></strong><br /> Once started, the  less program allows you to scroll forward and backward through a <br />text file. For example, to examine the file that defines all the system's user accounts, enter <br />the following command:<br /> [me@linuxbox ~]$ <strong>less /etc/passwd</strong><br /> Once the less program starts, we can view the contents of the file. If the file is longer <br />than one page, we can scroll up and down. To exit less, press the “q” key.<br />The table below lists the most common keyboard commands used by less.<br /> 18<br /></p>
<hr />
<p>Viewing File Contents With less<br /> <em>Table 3-3: less Commands</em><br /> <strong>Command</strong><br /> <strong>Action</strong><br /> Page Up or b<br /> Scroll back one page<br /> Page Down or space<br /> Scroll forward one page<br /> Up Arrow<br /> Scroll up one line<br /> Down Arrow<br /> Scroll down one line<br /> G<br /> Move to the end of the text file<br /> 1G or g<br /> Move to the beginning of the text file<br /> /<em>characters</em><br /> Search forward to the next occurrence of <em>characters</em><br /> n<br /> Search for the next occurrence of the previous search<br /> h<br /> Display help screen<br /> q<br /> Quit less<br /> <strong>Less Is More<br /></strong>The less program was designed as an improved replacement of an earlier Unix <br />program called more. The name “less” is a play on the phrase “less is more”—<br />   a  <br /> motto of modernist architects and designers.<br />less  falls into the class of programs called “pagers,” programs that allow the <br />easy viewing of long text documents in a page by page manner. Whereas the <br />more program could only page forward, the less program allows paging both <br />forward and backward and has many other features as well. <br /> <strong>A Guided Tour<br /></strong>The file system layout on your Linux system is much like that found on other Unix-like <br />systems. The design is actually specified in a published standard called the <em>Linux Filesys-<br />tem Hierarchy Standard</em>. Not all Linux distributions conform to the standard exactly but <br />most come pretty close.<br />Next, we are going to wander around the file system ourselves to see what makes our <br />Linux system tick. This will give you a chance to practice your navigation skills. One of <br />the things we will discover is that many of the interesting files are in plain human-read-<br />able text. As we go about our tour, try the following:<br /> 19<br /></p>
<hr />
<p>3 – Exploring The System<br /> 1. cd into a given directory<br />2. List the directory contents with ls -l<br />3. If you see an interesting file, determine its contents with file<br />4. If it looks like it might be text, try viewing it with less<br /> <strong>Remember the copy and paste trick! </strong>If you are using a mouse, you can double <br />click on a filename to copy it and middle click to paste it into commands.<br /> As we wander around, don't be afraid to look at stuff. Regular users are largely prohibited <br />from messing things up. That's the system administrators job! If a command complains <br />about something, just move on to something else. Spend some time looking around. The <br />system is ours to explore. Remember, in Linux, there are no secrets!<br />Table 3-4 lists just a few of the directories we can explore. Feel free to try more!<br /> <em>Table 3-4: Directories Found On Linux Systems</em><br /> <strong>Directory</strong><br /> <strong>Comments</strong><br /> /<br /> The root directory. Where everything begins.<br /> /bin<br /> Contains binaries (programs) that must be present for the <br />system to boot and run.<br /> /boot<br /> Contains the Linux kernel, initial RAM disk image (for <br />drivers needed at boot time), and the boot loader.<br /> Interesting files:<br /> ●<br /> /boot/grub/grub.conf or menu.lst, which <br />are used to configure the boot loader.<br /> ●<br /> /boot/vmlinuz, the Linux kernel<br /> /dev<br /> This is a special directory which contains <em>device nodes</em>. <br />“Everything is a file” also applies to devices. Here is where <br />the kernel maintains a list of all the devices it understands.<br /> 20<br /></p>
<hr />
<p>A Guided Tour<br /> <strong>Directory</strong><br /> <strong>Comments</strong><br /> /etc<br /> The /etc directory contains all of the system-wide <br />configuration files. It also contains a collection of shell <br />scripts which start each of the system services at boot time. <br />Everything in this directory should be readable text.<br /> Interesting files: While everything in /etc is interesting, <br />here are some of my all-time favorites:<br /> ●<br /> /etc/crontab, a file that defines when <br />automated jobs will run.<br /> ●<br /> /etc/fstab, a table of storage devices and their <br />associated mount points.<br /> ●<br /> /etc/passwd, a list of the user accounts.<br /> /home<br /> In normal configurations, each user is given a directory in <br />/home. Ordinary users can only write files in their home <br />directories. This limitation protects the system from errant <br />user activity.<br /> /lib<br /> Contains shared library files used by the core system <br />programs. These are similar to DLLs in Windows.<br /> /lost+found<br /> Each formatted partition or device using a Linux file system, <br />such as ext3, will have this directory. It is used in the case of <br />a partial recovery from a file system corruption event. <br />Unless something really bad has happened to your system, <br />this directory will remain empty.<br /> /media<br /> On modern Linux systems the /media directory will <br />contain the mount points for removable media such as USB <br />drives, CD-ROMs, etc. that are mounted automatically at <br />insertion.<br /> /mnt<br /> On older Linux systems, the /mnt directory contains mount <br />points for removable devices that have been mounted <br />manually.<br /> /opt<br /> The /opt directory is used to install “optional” software. <br />This is mainly used to hold commercial software products <br />that may be installed on your system.<br /> 21<br /></p>
<hr />
<p>3 – Exploring The System<br /> <strong>Directory</strong><br /> <strong>Comments</strong><br /> /proc<br /> The /proc directory is special. It's not a real file system in <br />the sense of files stored on your hard drive. Rather, it is a <br />virtual file system maintained by the Linux kernel. The <br />“files” it contains are peepholes into the kernel itself. The <br />files are readable and will give you a picture of how the <br />kernel sees your computer.<br /> /root<br /> This is the home directory for the root account.<br /> /sbin<br /> This directory contains “system” binaries. These are <br />programs that perform vital system tasks that are generally <br />reserved for the superuser.<br /> /tmp<br /> The /tmp directory is intended for storage of temporary, <br />transient files created by various programs. Some <br />configurations cause this directory to be emptied each time <br />the system is rebooted.<br /> /usr<br /> The /usr directory tree is likely the largest one on a Linux <br />system. It contains all the programs and support files used <br />by regular users.<br /> /usr/bin<br /> /usr/bin contains the executable programs installed by <br />your Linux distribution. It is not uncommon for this <br />directory to hold thousands of programs.<br /> /usr/lib<br /> The shared libraries for the programs in /usr/bin.<br /> /usr/local<br /> The /usr/local tree is where programs that are not <br />included with your distribution but are intended for system-<br />wide use are installed. Programs compiled from source code <br />are normally installed in /usr/local/bin. On a newly <br />installed Linux system, this tree exists, but it will be empty <br />until the system administrator puts something in it.<br /> /usr/sbin<br /> Contains more system administration programs.<br /> /usr/share<br /> /usr/share contains all the shared data used by <br />programs in /usr/bin. This includes things like default <br />configuration files, icons, screen backgrounds, sound files, <br />etc.<br /> /usr/share/doc<br /> Most packages installed on the system will include some <br />kind of documentation. In /usr/share/doc, we will find <br />documentation files organized by package.<br /> 22<br /></p>
<hr />
<p>A Guided Tour<br /> <strong>Directory</strong><br /> <strong>Comments</strong><br /> /var<br /> With the exception of /tmp and /home, the directories we <br />have looked at so far remain relatively static, that is, their <br />contents don't change. The /var directory tree is where <br />data that is likely to change is stored. Various databases, <br />spool files, user mail, etc. are located here.<br /> /var/log<br /> /var/log contains <em>log files</em>, records of various system <br />activity. These are very important and should be monitored <br />from time to time. The most useful one is <br />/var/log/messages. Note that for security reasons on <br />some systems, you must be the superuser to view log files .<br /> <strong>Symbolic Links<br /></strong>As we look around, we are likely to see a directory listing with an entry like this:<br /> lrwxrwxrwx 1 root root   11 2007-08-11 07:34 libc.so.6 -&gt; libc-2.6.so<br /> Notice how the first letter of the listing is “l” and the entry seems to have two filenames? <br />This is a special kind of a file called a <em>symbolic link</em> (also known as a <em>soft link</em> or <em>sym-<br />link</em>.) In most Unix-like systems it is possible to have a file referenced by multiple names. <br />While the value of this may not be obvious, it is really a useful feature.<br />Picture this scenario: A program requires the use of a shared resource of some kind con-<br />tained in a file named “foo,” but “foo” has frequent version changes. It would be good to <br />include the version number in the filename so the administrator or other interested party <br />could see what version of “foo” is installed. This presents a problem. If we change the <br />name of the shared resource, we have to track down every program that might use it and <br />change it to look for a new resource name every time a new version of the resource is in-<br />stalled. That doesn't sound like fun at all.<br />Here is where symbolic links save the day. Let's say we install version 2.6 of “foo,” <br />which has the filename “foo-2.6” and then create a symbolic link simply called “foo” that <br />points to “foo-2.6.” This means that when a program opens the file “foo”, it is actually <br />opening the file “foo-2.6”. Now everybody is happy. The programs that rely on “foo” can <br />find it and we can still see what actual version is installed. When it is time to upgrade to <br />“foo-2.7,” we just add the file to our system, delete the symbolic link “foo” and create a <br />new one that points to the new version. Not only does this solve the problem of the ver-<br />sion upgrade, but it also allows us to keep both versions on our machine. Imagine that <br />“foo-2.7” has a bug (damn those developers!) and we need to revert to the old version. <br />Again, we just delete the symbolic link pointing to the new version and create a new <br /> 23<br /></p>
<hr />
<p>3 – Exploring The System<br /> symbolic link pointing to the old version. <br />The directory listing above (from the /lib directory of a Fedora system) shows a sym-<br />bolic link called “libc.so.6” that points to a shared library file called “libc-2.6.so.” This <br />means that programs looking for “libc.so.6” will actually get the file “libc-2.6.so.” We <br />will learn how to create symbolic links in the next chapter.<br /> <strong>Hard Links<br /></strong>While we are on the subject of links, we need to mention that there is a second type of <br />link called a <em>hard link</em>. Hard links also allow files to have multiple names, but they do it <br />in a different way. We’ll talk more about the differences between symbolic and hard links <br />in the next chapter.<br /> <strong>Summing Up<br /></strong>With our tour behind us, we have learned a lot about our system. We've seen various files <br />and directories and their contents. One thing you should take away from this is how open <br />the system is. In Linux there are many important files that are plain human-readable text. <br />Unlike many proprietary systems, Linux makes everything available for examination and <br />study. <br /> <strong>Further Reading</strong><br /> ●<br /> The full version of the <em>Linux Filesystem Hierarchy Standard</em> can be found here:<br /><a href="http://www.pathname.com/fhs/">http://www.pathname.com/fhs/</a><br /> ●<br /> An article about the directory structure of Unix and Unix-like systems: <br /><a href="http://en.wikipedia.org/wiki/Unix_directory_structure">http://en.wikipedia.org/wiki/Unix_directory_structure</a><br /> ●<br /> A detailed description of the ASCII text format: <br /><a href="http://en.wikipedia.org/wiki/ASCII">http://en.wikipedia.org/wiki/ASCII</a><br /> 24<br /></p>
<hr />
<p>4 – Manipulating Files And Directories<br /> <em><strong>4 – Manipulating Files And Directories</strong></em><br /> At this point, we are ready for some real work! This chapter will introduce the following <br />commands:<br /> ●<br /> cp – Copy files and directories<br /> ●<br /> mv – Move/rename files and directories<br /> ●<br /> mkdir – Create directories<br /> ●<br /> rm – Remove files and directories<br /> ●<br /> ln – Create hard and symbolic links<br /> These five commands are among the most frequently used Linux commands. They are <br />used for manipulating both files and directories.<br />Now, to be frank, some of the tasks performed by these commands are more easily done <br />with a graphical file manager. With a file manager, we can drag and drop a file from one <br />directory to another, cut and paste files, delete files, etc. So why use these old command <br />line programs?<br />The answer is power and flexibility. While it is easy to perform simple file manipulations <br />with a graphical file manager, complicated tasks can be easier with the command line <br />programs. For example, how could we copy all the HTML files from one directory to an-<br />other, but only copy files that do not exist in the destination directory or are newer than <br />the versions in the destination directory? Pretty hard with a file manager. Pretty easy with <br />the command line:<br /> <strong>cp -u *.html destination</strong><br /> <strong>Wildcards<br /></strong>Before we begin using our commands, we need to talk about a shell feature that makes <br />these commands so powerful. Since the shell uses filenames so much, it provides special <br />characters to help you rapidly specify groups of filenames. These special characters are <br /> 25<br /></p>
<hr />
<p>4 – Manipulating Files And Directories<br /> called <em>wildcards</em>. Using wildcards (which is also known as <em>globbing</em>) allow you to select <br />filenames based on patterns of characters. The table below lists the wildcards and what <br />they select:<br /> <em>Table 4-1: Wildcards</em><br /> <strong>Wildcard</strong><br /> <strong>Meaning</strong><br /> *<br /> Matches any characters<br /> ?<br /> Matches any single character<br /> [<em>characters</em>]<br /> Matches any character that is a member of the set <em>characters</em> <br /> [!<em>characters</em>]<br /> Matches any character that is not a member of the set <br /><em>characters</em><br /> [[:<em>class</em>:]]<br /> Matches any character that is a member of the specified <br /><em>class</em><br /> Table 4-2 lists the most commonly used character classes:<br /> <em>Table 4-2: Commonly Used Character Classes</em><br /> <strong>Character Class</strong><br /> <strong>Meaning</strong><br /> [:alnum:]<br /> Matches any alphanumeric character<br /> [:alpha:]<br /> Matches any alphabetic character<br /> [:digit:]<br /> Matches any numeral<br /> [:lower:]<br /> Matches any lowercase letter<br /> [:upper:]<br /> Matches any uppercase letter<br /> Using wildcards makes it possible to construct very sophisticated selection criteria for <br />filenames. Here are some examples of patterns and what they match:<br /> <em>Table 4-3: Wildcard Examples</em><br /> <strong>Pattern</strong><br /> <strong>Matches</strong><br /> *<br /> All files<br /> g*<br /> Any file beginning with “g”<br /> b*.txt<br /> Any file beginning with “b” followed by <br />any characters and ending with “.txt”<br /> 26<br /></p>
<hr />
<p>Wildcards<br /> Data???<br /> Any file beginning with “Data” followed <br />by exactly three characters<br /> [abc]*<br /> Any file beginning with either an “a”, a <br />“b”, or a “c”<br /> BACKUP.[0-9][0-9][0-9]<br /> Any file beginning with “BACKUP.” <br />followed by exactly three numerals<br /> [[:upper:]]*<br /> Any file beginning with an uppercase letter<br /> [![:digit:]]*<br /> Any file not beginning with a numeral<br /> *[[:lower:]123]<br /> Any file ending with a lowercase letter or <br />the numerals “1”, “2”, or “3”<br /> Wildcards can be used with any command that accepts filenames as arguments, but we’ll <br />talk more about that in Chapter 7.<br /> <strong>Character Ranges<br /></strong>If you are coming from another Unix-like environment or have been reading <br />some other books on this subject, you may have encountered the [A-Z] or the <br />[a-z]  character   range   notations.   These   are   traditional   Unix   notations   and <br />worked in older versions of Linux as well. They can still work, but you have to be <br />very careful with them because they will not produce the expected results unless <br />properly configured. For now, you should avoid using them and use  character <br />classes instead.<br /> <strong>Wildcards Work In The GUI Too<br /></strong>Wildcards are especially valuable not only because they are used so frequently on <br />the command line, but are also supported by some graphical file managers.<br />●<br /> In  <strong>Nautilus</strong>  (the file manager for  GNOME), you can select files using the <br />Edit/Select Pattern menu item. Just enter a file selection pattern with wild-<br />cards and the files in the currently viewed directory will be highlighted for se-<br />lection.<br /> ●<br /> In some versions of  <strong>Dolphin</strong>  and  <strong>Konqueror</strong>  (the file managers for  KDE), <br />you can enter wildcards directly on the location bar. For example, if you want <br />to see all the files starting with a lowercase “u” in the /usr/bin directory, enter <br />“/usr/bin/u*” in the location bar and it will display the result.<br /> 27<br /></p>
<hr />
<p>4 – Manipulating Files And Directories<br /> Many ideas originally found in the command line interface make their way into <br />the graphical interface, too. It is one of the many things that make the Linux desk-<br />top so powerful.<br /> <strong>mkdir – Create Directories<br /></strong>The mkdir command is used to create directories. It works like this:<br /> <strong>mkdir <em>directory...</em></strong><br /> <strong>A note on notation:</strong> When three periods follow an argument in the description of a com-<br />mand (as above), it means that the argument can be repeated, thus:<br /> <strong>mkdir dir1</strong><br /> would create a single directory named “dir1”, while<br /> <strong>mkdir dir1 dir2 dir3</strong><br /> would create three directories named “dir1”, “dir2”, and “dir3”.<br /> <strong>cp – Copy Files And Directories<br /></strong>The cp command copies files or directories. It can be used two different ways:<br /> <strong>cp <em>item1</em></strong><strong> <em>item2</em></strong><br /> to copy the single file or directory “item1” to file or directory “item2” and:<br /> <strong>cp <em>item</em></strong><strong>... <em>directory</em></strong><br /> to copy multiple items (either files or directories) into a directory.<br /> 28<br /></p>
<hr />
<p>cp – Copy Files And Directories<br /> Useful Options And Examples<br />Here are some of the commonly used options (the short option and the equivalent long <br />option) for cp:<br /> <em>Table 4-4: cp Options</em><br /> <strong>Option</strong><br /> <strong>Meaning</strong><br /> -a, --archive<br /> Copy the files and directories and all of their attributes, <br />including ownerships and permissions. Normally, <br />copies take on the default attributes of the user <br />performing the copy. <br /> -i, --interactive<br /> Before overwriting an existing file, prompt the user for <br />confirmation. <strong>If this option is not specified, cp will <br />silently overwrite files.</strong> <br /> -r, --recursive<br /> Recursively copy directories and their contents. This <br />option (or the -a option) is required when copying <br />directories.<br /> -u, --update<br /> When copying files from one directory to another, only <br />copy files that either don't exist, or are newer than the <br />existing corresponding files, in the destination <br />directory.<br /> -v, --verbose<br /> Display informative messages as the copy is <br />performed.<br /> <em>Table 4-5: cp Examples</em><br /> <strong>Command</strong><br /> <strong>Results</strong><br /> cp <em>file1</em> <em>file2</em><br /> Copy <em>file1</em> to <em>file2</em>. <strong>If <em>file2</em></strong><strong> exists, it is overwritten <br />with the contents of <em>file1</em></strong><strong>.</strong> If <em>file2</em> does not exist, it <br />is created.<br /> cp -i <em>file1</em> <em>file2</em><br /> Same as above, except that if <em>file2</em> exists, the user is <br />prompted before it is overwritten.<br /> cp <em>file1</em> <em>file2</em> <em>dir1</em><br /> Copy <em>file1</em> and <em>file2</em> into directory <em>dir1</em>. <em>dir1</em> must <br />already exist.<br /> cp dir1/* dir2<br /> Using a wildcard, all the files in <em>dir1</em> are copied <br />into <em>dir2</em>. <em>dir2</em> must already exist.<br /> 29<br /></p>
<hr />
<p>4 – Manipulating Files And Directories<br /> cp -r <em>dir1</em> <em>dir2</em><br /> Copy the contents of directory <em>dir1</em> to directory <br /><em>dir2</em>. If directory <em>dir2</em> does not exist, it is created <br />and, after the copy, will contain the same contents <br />as directory <em>dir1</em>.<br />If directory <em>dir2</em> does exist, then directory <em>dir1</em> (and <br />its contents) will be copied into <em>dir2</em>. <br /> <strong>mv – Move And Rename Files<br /></strong>The mv command performs both file moving and file renaming, depending on how it is <br />used. In either case, the original filename no longer exists after the operation. mv is used <br />in much the same way as cp:<br /> <strong>mv <em>item1</em></strong><strong> <em>item2</em></strong><br /> to move or rename file or directory “item1” to “item2” or:<br /> <strong>mv <em>item</em></strong><strong>... <em>directory</em></strong><br /> to move one or more items from one directory to another.<br /> Useful Options And Examples<br />mv shares many of the same options as cp:<br /> <em>Table 4-6: mv Options</em><br /> <strong>Option</strong><br /> <strong>Meaning</strong><br /> -i, --interactive<br /> Before overwriting an existing file, prompt the user for <br />confirmation. <strong>If this option is not specified, mv will <br />silently overwrite files.</strong> <br /> -u, --update<br /> When moving files from one directory to another, only <br />move files that either don't exist, or are newer than the <br />existing corresponding files in the destination <br />directory.<br /> -v, --verbose<br /> Display informative messages as the move is <br /> 30<br /></p>
<hr />
<p>mv – Move And Rename Files<br /> performed.<br /> <em>Table 4-7: mv Examples</em><br /> <strong>Command</strong><br /> <strong>Results</strong><br /> mv <em>file1</em> <em>file2</em><br /> Move <em>file1</em> to <em>file2</em>. <strong>If <em>file2</em></strong><strong> exists, it is overwritten <br />with the contents of <em>file1</em></strong><strong>.</strong> If <em>file2</em> does not exist, it <br />is created. <strong>In either case, <em>file1</em></strong><strong> ceases to exist.</strong><br /> mv -i <em>file1</em> <em>file2</em><br /> Same as above, except that if <em>file2</em> exists, the user is <br />prompted before it is overwritten.<br /> mv <em>file1</em> <em>file2</em> <em>dir1</em><br /> Move <em>file1</em> and <em>file2</em> into directory <em>dir1</em>. <em>dir1</em> must <br />already exist.<br /> mv <em>dir1</em> <em>dir2</em><br /> If directory <em>dir2</em> does not exist, create directory <br /><em>dir2</em> and move the contents of directory <em>dir1</em> into <br /><em>dir2</em> and delete directory <em>dir1</em>.<br />If directory <em>dir2</em> does exist, move directory <em>dir1</em> <br />(and its contents) into directory <em>dir2</em>.<br /> <strong>rm – Remove Files And Directories<br /></strong>The rm command is used to remove (delete) files and directories:<br /> <strong>rm <em>item</em></strong><strong>...</strong><br /> where “item” is one or more files or directories.<br /> Useful Options And Examples<br />Here are some of the common options for rm:<br /> <em>Table 4-8: rm Options</em><br /> <strong>Option</strong><br /> <strong>Meaning</strong><br /> -i, --interactive<br /> Before deleting an existing file, prompt the user for <br />confirmation. <strong>If this option is not specified, rm will <br />silently delete files.</strong> <br /> 31<br /></p>
<hr />
<p>4 – Manipulating Files And Directories<br /> -r, --recursive<br /> Recursively delete directories. This means that if a <br />directory being deleted has subdirectories, delete them <br />too. To delete a directory, this option must be specified.<br /> -f, --force<br /> Ignore nonexistent files and do not prompt. This <br />overrides the --interactive option. <br /> -v, --verbose<br /> Display informative messages as the deletion is <br />performed.<br /> <em>Table 4-9: rm Examples</em><br /> <strong>Command</strong><br /> <strong>Results</strong><br /> rm <em>file1</em><br /> Delete <em>file1</em> silently.<br /> rm -i <em>file1</em><br /> Same as above, except that the user is prompted for <br />confirmation before the deletion is performed.<br /> rm -r <em>file1</em> <em>dir1</em><br /> Delete<em> file1</em> and <em>dir1</em> and its contents.<br /> rm -rf <em>file1</em> <em>dir1</em><br /> Same as above, except that if either <em>file1</em> or <em>dir1</em> do <br />not exist, rm will continue silently.<br /> <strong>Be Careful With rm!<br /></strong>Unix-like operating systems such as Linux do not have an undelete command. <br />Once you delete something with  rm, it's gone. Linux assumes you're smart and <br />you know what you're doing.<br />Be particularly careful with wildcards. Consider this classic example. Let's say <br />you want to delete just the HTML files in a directory. To do this, you type:<br />rm *.html<br />which is correct, but if you accidentally place a space between the “*” and the <br />“.html” like so:<br />rm * .html<br />the rm command will delete all the files in the directory and then complain that <br />there is no file called “.html”.<br /><strong>Here is a useful tip.</strong>  Whenever you use wildcards with  rm  (besides carefully <br />checking your typing!), test the wildcard first with ls. This will let you see the <br /> 32<br /></p>
<hr />
<p>rm – Remove Files And Directories<br /> files that will be deleted. Then press the up arrow key to recall the command and <br />replace the ls with rm.<br /> <strong>ln – Create Links<br /></strong>The ln command is used to create either hard or symbolic links. It is used in one of two <br />ways:<br /> <strong>ln <em>file</em></strong><strong> <em>link</em></strong><br /> to create a hard link, and:<br /> <strong>ln -s <em>item</em></strong><strong> <em>link</em></strong><br /> to create a symbolic link where “item” is either a file or a directory.<br /> Hard Links<br />Hard links are the original Unix way of creating links, compared to symbolic links, which <br />are more modern. By default, every file has a single hard link that gives the file its name. <br />When we create a hard link, we create an additional directory entry for a file.  Hard links <br />have two important limitations:<br /> 1. A hard link cannot reference a file outside its own file system. This means a link <br /> cannot reference a file that is not on the same disk partition as the link itself.<br /> 2. A hard link may not reference a directory.<br /> A hard link is indistinguishable from the file itself. Unlike a symbolic link, when you list <br />a directory containing a hard link you will see no special indication of the link. When a <br />hard link is deleted, the link is removed but the contents of the file itself continue to exist <br />(that is, its space is not deallocated) until all links to the file are deleted.<br />It is important to be aware of hard links because you might encounter them from time to <br />time, but modern practice prefers symbolic links, which we will cover next.<br /> Symbolic Links<br />Symbolic links were created to overcome the limitations of hard links. Symbolic links <br />work by creating a special type of file that contains a text pointer to the referenced file or <br /> 33<br /></p>
<hr />
<p>4 – Manipulating Files And Directories<br /> directory. In this regard, they operate in much the same way as a Windows shortcut <br />though of course, they predate the Windows feature by many years ;-)<br />A file pointed to by a symbolic link, and the symbolic link itself are largely indistinguish-<br />able from one another. For example, if you write something to the symbolic link, the ref-<br />erenced file is written to. However when you delete a symbolic link, only the link is <br />deleted, not the file itself. If the file is deleted before the symbolic link, the link will con-<br />tinue to exist, but will point to nothing. In this case, the link is said to be <em>broken</em>. In many <br />implementations, the  ls  command will display broken links in a distinguishing color, <br />such as red, to reveal their presence.<br />The concept of links can seem very confusing, but hang in there. We're going to try all <br />this stuff and it will, hopefully, become clear. <br /> <strong>Let's Build A Playground<br /></strong>Since we are going to do some real file manipulation, let's build a safe place to “play” <br />with our file manipulation commands. First we need a directory to work in. We'll create <br />one in our home directory and call it “playground.”<br /> Creating Directories<br />The mkdir command is used to create a directory. To create our playground directory we <br />will first make sure we are in our home directory and will then create the new directory:<br /> [me@linuxbox ~]$ <strong>cd<br /></strong>[me@linuxbox ~]$ <strong>mkdir playground</strong><br /> To make our playground a little more interesting, let's create a couple of directories inside <br />it called “dir1” and “dir2”. To do this, we will change our current working directory to <br />playground and execute another mkdir:<br /> [me@linuxbox ~]$ <strong>cd playground<br /></strong>[me@linuxbox playground]$ <strong>mkdir dir1 dir2</strong><br /> Notice that the  mkdir  command will accept multiple arguments allowing us to create <br />both directories with a single command.<br /> Copying Files<br />Next, let's get some data into our playground. We'll do this by copying a file. Using the <br /> 34<br /></p>
<hr />
<p>Let's Build A Playground<br /> cp command, we'll copy the passwd file from the /etc directory to the current work-<br />ing directory:<br /> [me@linuxbox playground]$ <strong>cp /etc/passwd .</strong><br /> Notice how we used the shorthand for the current working directory, the single trailing <br />period. So now if we perform an ls, we will see our file:<br /> [me@linuxbox playground]$ <strong>ls -l</strong><br /> total 12<br />drwxrwxr-x 2 me  me 4096 2008-01-10 16:40 dir1<br /> drwxrwxr-x 2 me  me 4096 2008-01-10 16:40 dir2<br />-rw-r--r-- 1 me  me 1650 2008-01-10 16:07 passwd<br /> Now, just for fun, let's repeat the copy using the “-v” option (verbose) to see what it does:<br /> [me@linuxbox playground]$ <strong>cp -v /etc/passwd .<br /></strong>`/etc/passwd' -&gt; `./passwd'<br /> The cp command performed the copy again, but this time displayed a concise message <br />indicating what operation it was performing. Notice that  cp  overwrote the first copy <br />without any warning. Again this is a case of cp assuming that you know what you’re are <br />doing. To get a warning, we'll include the “-i” (interactive) option:<br /> [me@linuxbox playground]$ <strong>cp -i /etc/passwd .<br /></strong>cp: overwrite `./passwd'?<br /> Responding to the prompt by entering a “y” will cause the file to be overwritten, any <br />other character (for example, “n”) will cause cp to leave the file alone.<br /> Moving And Renaming Files<br />Now, the name “passwd” doesn't seem very playful and this is a playground, so let's <br />change it to something else:<br /> [me@linuxbox playground]$ <strong>mv passwd fun</strong><br /> 35<br /></p>
<hr />
<p>4 – Manipulating Files And Directories<br /> Let's pass the fun around a little by moving our renamed file to each of the directories and <br />back again:<br /> [me@linuxbox playground]$ <strong>mv fun dir1</strong><br /> to move it first to directory dir1, then:<br /> [me@linuxbox playground]$ <strong>mv dir1/fun dir2</strong><br /> to move it from dir1 to dir2, then:<br /> [me@linuxbox playground]$ <strong>mv dir2/fun .</strong><br /> to finally bring it back to the current working directory. Next, let's see the effect of mv on <br />directories. First we will move our data file into dir1 again:<br /> [me@linuxbox playground]$ <strong>mv fun dir1</strong><br /> then move dir1 into dir2 and confirm it with ls:<br /> [me@linuxbox playground]$ <strong>mv dir1 dir2<br /></strong>[me@linuxbox playground]$ <strong>ls -l dir2</strong><br /> total 4<br />drwxrwxr-x 2 me  me   4096 2008-01-11 06:06 dir1<br /> [me@linuxbox playground]$ <strong>ls -l dir2/dir1<br /></strong>total 4<br /> -rw-r--r-- 1 me  me   1650 2008-01-10 16:33 fun<br /> Note that since dir2 already existed, mv moved dir1 into dir2. If dir2 had not ex-<br />isted, mv would have renamed dir1 to dir2. Lastly, let's put everything back:<br /> [me@linuxbox playground]$ <strong>mv dir2/dir1 .</strong><br /> [me@linuxbox playground]$ <strong>mv dir1/fun .</strong><br /> 36<br /></p>
<hr />
<p>Let's Build A Playground<br /> Creating Hard Links<br />Now we'll try some links. First the hard links. We’ll create some links to our data file like <br />so:<br /> [me@linuxbox playground]$ <strong>ln fun fun-hard<br /></strong>[me@linuxbox playground]$ <strong>ln fun dir1/fun-hard</strong><br /> [me@linuxbox playground]$ <strong>ln fun dir2/fun-hard</strong><br /> So now we have four instances of the file “fun”. Let's take a look our playground direc-<br />tory:<br /> [me@linuxbox playground]$ <strong>ls -l</strong><br /> total 16<br />drwxrwxr-x 2 me   me   4096 2008-01-14 16:17 dir1<br /> drwxrwxr-x 2 me   me   4096 2008-01-14 16:17 dir2<br />-rw-r--r-- 4 me   me   1650 2008-01-10 16:33 fun<br /> -rw-r--r-- 4 me   me   1650 2008-01-10 16:33 fun-hard<br /> One thing you notice is that the second field in the listing for fun and fun-hard both <br />contain a “4” which is the number of hard links that now exist for the file. You'll remem-<br />ber that a file will aways have at least one link because the file's name is created by a <br />link. So, how do we know that fun and fun-hard are, in fact, the same file? In this <br />case,  ls  is not very helpful. While we can see that  fun  and  fun-hard  are both the <br />same size (field 5), our listing provides no way to be sure. To solve this problem, we're <br />going to have to dig a little deeper.<br />When thinking about hard links, it is helpful to imagine that files are made up of two <br />parts: the data part containing the file's contents and the name part which holds the file's <br />name. When we create hard links, we are actually creating additional name parts that all <br />refer to the same data part. The system assigns a chain of disk blocks to what is called an <br /><em>inode</em>, which is then associated with the name part. Each hard link therefore refers to a <br />specific inode containing the file's contents.<br />The ls command has a way to reveal this information. It is invoked with the “-i” option:<br /> [me@linuxbox playground]$ <strong>ls -li</strong><br /> total 16<br />12353539 drwxrwxr-x 2 me   me   4096 2008-01-14 16:17 dir1<br /> 12353540 drwxrwxr-x 2 me   me   4096 2008-01-14 16:17 dir2<br />12353538 -rw-r--r-- 4 me   me   1650 2008-01-10 16:33 fun<br /> 37<br /></p>
<hr />
<p>4 – Manipulating Files And Directories<br /> 12353538 -rw-r--r-- 4 me   me   1650 2008-01-10 16:33 fun-hard<br /> In this version of the listing, the first field is the inode number and, as we can see, both <br />fun  and  fun-hard  share the same inode number, which confirms they are the same <br />file.<br /> Creating Symbolic Links<br />Symbolic links were created to overcome the two disadvantages of hard links: Hard links <br />cannot span physical devices and hard links cannot reference directories, only files. Sym-<br />bolic links are a special type of file that contains a text pointer to the target file or direc-<br />tory.<br />Creating symbolic links is similar to creating hard links:<br /> [me@linuxbox playground]$ <strong>ln -s fun fun-sym</strong><br /> [me@linuxbox playground]$ <strong>ln -s ../fun dir1/fun-sym<br /></strong>[me@linuxbox playground]$ <strong>ln -s ../fun dir2/fun-sym</strong><br /> The first example is pretty straightforward, we simply add the “-s” option to create a <br />symbolic link rather than a hard link. But what about the next two? Remember, when we <br />create a symbolic link, we are creating a text description of where the target file is rela-<br />tive to the symbolic link. It's easier to see if we look at the ls output:<br /> [me@linuxbox playground]$ <strong>ls -l dir1<br /></strong>total 4<br /> -rw-r--r-- 4 me   me   1650 2008-01-10 16:33 fun-hard<br />lrwxrwxrwx 1 me   me      6 2008-01-15 15:17 fun-sym -&gt; ../fun<br /> The listing for fun-sym in dir1 shows that it is a symbolic link by the leading “l” in <br />the first field and that it points to “../fun”, which is correct. Relative to the location of <br />fun-sym, fun is in the directory above it. Notice too, that the length of the symbolic <br />link file is 6, the number of characters in the string “../fun” rather than the length of the <br />file to which it is pointing.<br />When creating symbolic links, you can either use absolute pathnames:<br /> <strong>ln -s /home/me/playground/fun dir1/fun-sym</strong><br /> 38<br /></p>
<hr />
<p>Let's Build A Playground<br /> or relative pathnames, as we did in our earlier example. Using relative pathnames is more <br />desirable because it allows a directory containing symbolic links to be renamed and/or <br />moved without breaking the links.<br />In addition to regular files, symbolic links can also reference directories:<br /> [me@linuxbox playground]$ <strong>ln -s dir1 dir1-sym<br /></strong>[me@linuxbox playground]$ <strong>ls -l</strong><br /> total 16<br />drwxrwxr-x 2 me   me   4096 2008-01-15 15:17 dir1<br /> lrwxrwxrwx 1 me   me      4 2008-01-16 14:45 dir1-sym -&gt; dir1<br />drwxrwxr-x 2 me   me   4096 2008-01-15 15:17 dir2<br /> -rw-r--r-- 4 me   me   1650 2008-01-10 16:33 fun<br />-rw-r--r-- 4 me   me   1650 2008-01-10 16:33 fun-hard<br /> lrwxrwxrwx 1 me   me      3 2008-01-15 15:15 fun-sym -&gt; fun<br /> Removing Files And Directories<br />As we covered earlier, the rm command is used to delete files and directories. We are go-<br />ing to use it to clean up our playground a little bit. First, let's delete one of our hard links:<br /> [me@linuxbox playground]$ <strong>rm fun-hard</strong><br /> [me@linuxbox playground]$ <strong>ls -l<br /></strong>total 12<br /> drwxrwxr-x 2 me   me   4096 2008-01-15 15:17 dir1<br />lrwxrwxrwx 1 me   me      4 2008-01-16 14:45 dir1-sym -&gt; dir1<br /> drwxrwxr-x 2 me   me   4096 2008-01-15 15:17 dir2<br />-rw-r--r-- 3 me   me   1650 2008-01-10 16:33 fun<br /> lrwxrwxrwx 1 me   me      3 2008-01-15 15:15 fun-sym -&gt; fun<br /> That worked as expected. The file fun-hard is gone and the link count shown for fun <br />is reduced from four to three, as indicated in the second field of the directory listing. <br />Next, we'll delete the file  fun, and just for enjoyment, we'll include the “-i” option to <br />show what that does:<br /> [me@linuxbox playground]$ <strong>rm -i fun</strong><br /> rm: remove regular file `fun'?<br /> Enter “y” at the prompt and the file is deleted. But let's look at the output of ls now. No-<br />ticed what happened to fun-sym? Since it's a symbolic link pointing to a now-nonexis-<br />tent file, the link is <em>broken</em>:<br /> 39<br /></p>
<hr />
<p>4 – Manipulating Files And Directories<br /> [me@linuxbox playground]$ <strong>ls -l<br /></strong>total 8<br /> drwxrwxr-x 2 me   me   4096 2008-01-15 15:17 dir1<br />lrwxrwxrwx 1 me   me      4 2008-01-16 14:45 dir1-sym -&gt; dir1<br /> drwxrwxr-x 2 me   me   4096 2008-01-15 15:17 dir2<br />lrwxrwxrwx 1 me   me      3 2008-01-15 15:15 fun-sym -&gt; fun<br /> Most Linux distributions configure ls to display broken links. On a Fedora box, broken <br />links are displayed in blinking red text! The presence of a broken link is not, in and of it-<br />self dangerous but it is rather messy. If we try to use a broken link we will see this:<br /> [me@linuxbox playground]$ <strong>less fun-sym<br /></strong>fun-sym: No such file or directory<br /> Let's clean up a little. We'll delete the symbolic links:<br /> [me@linuxbox playground]$ <strong>rm fun-sym dir1-sym<br /></strong>[me@linuxbox playground]$ <strong>ls -l</strong><br /> total 8<br />drwxrwxr-x 2 me   me   4096 2008-01-15 15:17 dir1<br /> drwxrwxr-x 2 me   me   4096 2008-01-15 15:17 dir2<br /> One thing to remember about symbolic links is that most file operations are carried out <br />on the link's target, not the link itself. rm is an exception. When you delete a link, it is the <br />link that is deleted, not the target.<br />Finally, we will remove our playground. To do this, we will return to our home directory <br />and use rm with the recursive option (-r) to delete playground and all of its contents, in-<br />cluding its subdirectories:<br /> [me@linuxbox playground]$ <strong>cd</strong><br /> [me@linuxbox ~]$ <strong>rm -r playground</strong><br /> <strong>Creating Symlinks With The GUI<br /></strong>The file managers in both  GNOME  and  KDE  provide an easy and automatic <br />method of  creating  symbolic links. With GNOME, holding the Ctrl+Shift keys <br /> 40<br /></p>
<hr />
<p>Let's Build A Playground<br /> while dragging a file will create a link rather than copying (or moving) the file. In <br />KDE, a small menu appears whenever a file is dropped, offering a choice of copy-<br />ing, moving, or linking the file.<br /> <strong>Summing Up<br /></strong>We've covered a lot of ground here and it will take a while to fully sink in. Perform the <br />playground exercise over and over until it makes sense. It is important to get a good un-<br />derstanding of basic file manipulation commands and wildcards. Feel free to expand on <br />the playground exercise by adding more files and directories, using wildcards to specify <br />files for various operations. The concept of links is a little confusing at first, but take the <br />time to learn how they work. They can be a real lifesaver.<br /> <strong>Further Reading</strong><br /> ●<br /> A discussion of symbolic links:<a href="http://en.wikipedia.org/wiki/Symbolic_link"> http://en.wikipedia.org/wiki/Symbolic_link</a><br /> 41<br /></p>
<hr />
<p>5 – Working With Commands<br /> <em><strong>5 – Working With Commands</strong></em><br /> Up to this point, we have seen a series of mysterious commands, each with its own mys-<br />terious options and arguments. In this chapter, we will attempt to remove some of that <br />mystery and even create some of our own commands. The commands introduced in this <br />chapter are:<br /> ●<br /> type – Indicate how a command name is interpreted<br /> ●<br /> which – Display which executable program will be executed<br /> ●<br /> help – Get help for shell builtins<br /> ●<br /> man – Display a command's manual page<br /> ●<br /> apropos – Display a list of appropriate commands<br /> ●<br /> info – Display a command's info entry<br /> ●<br /> whatis – Display a very brief description of a command<br /> ●<br /> alias – Create an alias for a command<br /> <strong>What Exactly Are Commands?<br /></strong>A command can be one of four different things:<br /> 1. <strong>An executable program</strong>  like all those files we saw in  /usr/bin. Within this <br /> category, programs can be <em>compiled binaries</em> such as programs written in C and <br />C++, or programs written in <em>scripting languages</em> such as the shell, perl, python, <br />ruby, etc.<br /> 2. <strong>A command built into the shell itself</strong>. bash supports a number of commands in-<br /> ternally called <em>shell builtins</em>. The cd command, for example, is a shell builtin.<br /> 3. <strong>A shell function.</strong> These are miniature shell scripts incorporated into the <em>environ-</em><br /> <em>ment</em>. We will cover configuring the environment and writing shell functions in <br />later chapters, but for now, just be aware that they exist.<br /> 4. <strong>An alias.</strong> Commands that we can define ourselves, built from other commands.<br /> 42<br /></p>
<hr />
<p>Identifying Commands<br /> <strong>Identifying Commands<br /></strong>It is often useful to know exactly which of the four kinds of commands is being used and <br />Linux provides a couple of ways to find out.<br /> type – Display A Command's Type<br />The type command is a shell builtin that displays the kind of command the shell will <br />execute, given a particular command name. It works like this:<br /> <strong>type <em>command</em></strong><br /> where “command” is the name of the command you want to examine. Here are some ex-<br />amples:<br /> [me@linuxbox ~]$ <strong>type type<br /></strong>type is a shell builtin<br /> [me@linuxbox ~]$ <strong>type ls<br /></strong>ls is aliased to `ls --color=tty'<br /> [me@linuxbox ~]$ <strong>type cp<br /></strong>cp is /bin/cp<br /> Here we see the results for three different commands. Notice that the one for ls (taken <br />from a Fedora system) and how the ls command is actually an alias for the ls command <br />with the “-- color=tty” option added. Now we know why the output from ls is displayed <br />in color!<br /> which – Display An Executable's Location<br />Sometimes there is more than one version of an executable program installed on a sys-<br />tem. While this is not very common on desktop systems, it's not unusual on large servers. <br />To determine the exact location of a given executable, the which command is used:<br /> [me@linuxbox ~]$ <strong>which ls</strong><br /> /bin/ls<br /> which only works for executable programs, not builtins nor aliases that are substitutes <br />for actual executable programs. When we try to use which on a shell builtin, for exam-<br />ple, cd, we either get no response or an error message:<br /> 43<br /></p>
<hr />
<p>5 – Working With Commands<br /> [me@linuxbox ~]$ <strong>which cd<br /></strong>/usr/bin/which: no cd in (/opt/jre1.6.0_03/bin:/usr/lib/qt-<br /> 3.3/bin:/usr/kerberos/bin:/opt/jre1.6.0_03/bin:/usr/lib/ccache:/usr/l<br />ocal/bin:/usr/bin:/bin:/home/me/bin)<br /> which is a fancy way of saying “command not found.”<br /> <strong>Getting A Command's Documentation<br /></strong>With this knowledge of what a command is, we can now search for the documentation <br />available for each kind of command.<br /> help – Get Help For Shell Builtins<br />bash has a built-in help facility available for each of the shell builtins. To use it, type <br />“help” followed by the name of the shell builtin. For example:<br /> [me@linuxbox ~]$ <strong>help cd</strong><br /> cd: cd [-L|[-P [-e]]] [dir] <br />Change the shell working directory. <br /> Change the current directory to DIR.  The default DIR is the value of <br /> the HOME shell variable. <br /> The variable CDPATH defines the search path for the directory <br />containing DIR.  Alternative directory names in CDPATH are separated <br /> by a colon (:). A null directory name is the same as the current <br />directory.  If DIR begins with a slash (/), then CDPATH is not used. <br /> If the directory is not found, and the shell option `cdable_vars' is <br /> set, the word is assumed to be  a variable name.  If that variable <br />has a value, its value is used for DIR. <br /> Options: <br /> -L<br /> force symbolic links to be followed <br /> -P<br /> use the physical directory structure without following symbolic <br /> links <br /> -e<br /> if the -P option is supplied, and the current working directory <br /> cannot be determined successfully, exit with a non-zero status <br /> The default is to follow symbolic links, as if `-L' were specified. <br /> Exit Status: <br />Returns 0 if the directory is changed, and if $PWD is set <br /> successfully when -P is used; non-zero otherwise.<br /> 44<br /></p>
<hr />
<p>Getting A Command's Documentation<br /> <strong>A note on notation:</strong> When square brackets appear in the description of a command's syn-<br />tax, they indicate optional items. A vertical bar character indicates mutually exclusive <br />items. In the case of the cd command above:<br />cd [-L|[-P[-e]]] [dir]<br />This notation says that the command cd may be followed optionally by either a “-L” or a <br />“-P” and further, if the “-P” option is specified the “-e” option may also be included fol-<br />lowed by the optional argument “dir”.<br />While the output of  help  for the  cd  commands is concise and accurate, it is by no <br />means tutorial and as we can see, it also seems to mention a lot of things we haven't <br />talked about yet! Don't worry. We'll get there.<br /> --help – Display Usage Information<br />Many executable programs support a “--help” option that displays a description of the <br />command's supported syntax and options. For example:<br /> [me@linuxbox ~]$ <strong>mkdir --help</strong><br /> Usage: mkdir [OPTION] DIRECTORY...<br />Create the DIRECTORY(ies), if they do not already exist.<br />   -Z, --context=CONTEXT (SELinux) set security context to CONTEXT<br /> Mandatory arguments to long options are mandatory for short options <br />too.<br />   -m, --mode=MODE   set file mode (as in chmod), not a=rwx – umask<br />  -p, --parents     no error if existing, make parent directories as<br />                     needed<br />  -v, --verbose     print a message for each created directory<br />       --help        display this help and exit<br />      --version     output version information and exit<br /> Report bugs to &lt;bug-coreutils@gnu.org&gt;.<br /> Some programs don't support the “--help” option, but try it anyway. Often it results in an <br />error message that will reveal the same usage information.<br /> man – Display A Program's Manual Page<br />Most executable programs intended for command line use provide a formal piece of doc-<br />umentation called a <em>manual</em> or <em>man page</em>. A special paging program called man is used to <br />view them. It is used like this:<br /> 45<br /></p>
<hr />
<p>5 – Working With Commands<br /> <strong>man <em>program</em></strong><br /> where “program” is the name of the command to view.<br />Man pages vary somewhat in format but generally contain a title, a synopsis of the com-<br />mand's syntax, a description of the command's purpose, and a listing and description of <br />each of the command's options. Man pages, however, do not usually include examples, <br />and are intended as a reference, not a tutorial. As an example, let's try viewing the man <br />page for the ls command:<br /> [me@linuxbox ~]$ <strong>man ls</strong><br /> On most Linux systems, man uses less to display the manual page, so all of the familiar <br />less commands work while displaying the page.<br />The “manual” that man displays is broken into sections and not only covers user com-<br />mands but also system administration commands, programming interfaces, file formats <br />and more. The table below describes the layout of the manual:<br /> <em>Table 5-1: Man Page Organization</em><br /> <strong>Section</strong><br /> <strong>Contents</strong><br /> 1<br /> User commands<br /> 2<br /> Programming interfaces kernel system calls<br /> 3<br /> Programming interfaces to the C library<br /> 4<br /> Special files such as device nodes and drivers<br /> 5<br /> File formats<br /> 6<br /> Games and amusements such as screen savers<br /> 7<br /> Miscellaneous <br /> 8<br /> System administration commands<br /> Sometimes we need to look in a specific section of the manual to find what we are look-<br />ing for. This is particularly true if we are looking for a file format that is also the name of <br />a command. Without specifying a section number, we will always get the first instance of <br />a match, probably in section 1. To specify a section number, we use man like this:<br /> 46<br /></p>
<hr />
<p>Getting A Command's Documentation<br /> <strong>man <em>section</em></strong><strong> <em>search_term</em></strong> <br /> For example:<br /> [me@linuxbox ~]$ <strong>man 5 passwd</strong><br /> This will display the man page describing the file format of the /etc/passwd file. <br /> apropos – Display Appropriate Commands<br />It is also possible to search the list of man pages for possible matches based on a search <br />term. It's very crude but sometimes helpful. Here is an example of a search for man pages <br />using the search term “floppy”:<br /> [me@linuxbox ~]$ <strong>apropos floppy</strong><br /> create_floppy_devices (8)  - udev callout to create all possible<br />                             floppy device based on the CMOS type<br /> fdformat             (8)  - Low-level formats a floppy disk<br />floppy               (8)  - format floppy disks<br /> gfloppy              (1)  - a simple floppy formatter for the GNOME<br />mbadblocks           (1)  - tests a floppy disk, and marks the bad<br />                             blocks in the FAT<br />mformat              (1)  - add an MSDOS filesystem to a low-level<br />                             formatted floppy disk<br /> The first field in each line of output is the name of the man page, the second field shows <br />the section. Note that the man command with the “-k” option performs the exact same <br />function as apropos.<br /> whatis – Display A Very Brief Description Of A Command<br />The whatis program displays the name and a one line description of a man page match-<br />ing a specified keyword:<br /> [me@linuxbox ~]$ <strong>whatis ls<br /></strong>ls                   (1)  - list directory contents<br /> 47<br /></p>
<hr />
<p>5 – Working With Commands<br /> <strong>The Most Brutal Man Page Of Them All<br /></strong>As we have seen, the manual pages supplied with Linux and other Unix-like sys-<br />tems are intended as reference documentation and not as tutorials. Many man <br />pages are hard to read, but I think that the grand prize for difficulty has got to go <br />to the man page for bash. As I was doing my research for this book, I gave it <br />careful review to ensure that I was covering most of its topics. When printed, it's <br />over 80 pages long and extremely dense, and its structure makes absolutely no <br />sense to a new user.<br />On the other hand, it is very accurate and concise, as well as being extremely <br />complete. So check it out if you dare and look forward to the day when you can <br />read it and it all makes sense.<br /> info – Display A Program's Info Entry<br />The GNU Project provides an alternative to man pages for their programs, called “info.” <br />Info pages are displayed with a reader program named, appropriately enough, info. Info <br />pages are <em>hyperlinked</em> much like web pages. Here is a sample:<br /> File: coreutils.info,  Node: ls invocation,  Next: dir invocation, <br />Up: Directory listing<br /> 10.1 `ls': List directory contents<br />==================================<br /> The `ls' program lists information about files (of any type, <br />including directories).  Options and file arguments can be intermixed <br /> arbitrarily, as usual.<br />    For non-option command-line arguments that are directories, by <br /> default `ls' lists the contents of directories, not recursively, and <br />omitting files with names beginning with `.'.  For other non-option <br /> arguments, by default `ls' lists just the filename.  If no non-option <br />argument is specified, `ls' operates on the current directory, acting <br /> as if it had been invoked with a single argument of `.'.<br /> 48<br /></p>
<hr />
<p>Getting A Command's Documentation<br />    By default, the output is sorted alphabetically, according to the<br />--zz-Info: (coreutils.info.gz)ls invocation, 63 lines --Top----------<br /> The info program reads <em>info files</em>, which are tree structured into individual <em>nodes</em>, each <br />containing a single topic. Info files contain hyperlinks that can move you from node to <br />node. A hyperlink can be identified by its leading asterisk, and is activated by placing the <br />cursor upon it and pressing the enter key.<br />To invoke info, type “info” followed optionally by the name of a program. Below is a <br />table of commands used to control the reader while displaying an info page:<br /> <em>Table 5-2: info Commands</em><br /> <strong>Command</strong><br /> <strong>Action</strong><br /> ?<br /> Display command help<br /> PgUp or Backspace<br /> Display previous page<br /> PgDn or Space<br /> Display next page<br /> n<br /> Next - Display the next node<br /> p<br /> Previous - Display the previous node<br /> u<br /> Up - Display the parent node of the currently displayed <br />node, usually a menu.<br /> Enter<br /> Follow the hyperlink at the cursor location<br /> q<br /> Quit<br /> Most of the command line programs we have discussed so far are part of the GNU <br />Project's “coreutils” package, so typing:<br /> [me@linuxbox ~]$ <strong>info coreutils</strong><br /> will display a menu page with hyperlinks to each program contained in the coreutils <br />package.<br /> README And Other Program Documentation Files<br />Many software packages installed on your system have documentation files residing in <br />the /usr/share/doc directory. Most of these are stored in plain text format and can <br /> 49<br /></p>
<hr />
<p>5 – Working With Commands<br /> be viewed with less. Some of the files are in HTML format and can be viewed with a <br />web browser. We may encounter some files ending with a “.gz” extension. This indicates <br />that they have been compressed with the gzip compression program. The gzip package <br />includes a special version of less called zless that will display the contents of gzip-<br />compressed text files. <br /> <strong>Creating Your Own Commands With alias<br /></strong>Now for our very first experience with programming! We will create a command of our <br />own using the  alias  command. But before we start, we need to reveal a small com-<br />mand line trick. It's possible to put more than one command on a line by separating each <br />command with a semicolon character. It works like this:<br /> <em>command1</em>; <em>command2</em>; <em>command3</em>...<br /> Here's the example we will use:<br /> [me@linuxbox ~]$ <strong>cd /usr; ls; cd -<br /></strong>bin  games    kerberos  lib64    local  share  tmp<br /> etc  include  lib       libexec  sbin   src<br />/home/me<br /> [me@linuxbox ~]$<br /> As we can see, we have combined three commands on one line. First we change directory <br />to /usr then list the directory and finally return to the original directory (by using 'cd <br />-') so we end up where we started. Now let's turn this sequence into a new command us-<br />ing  alias. The first thing we have to do is dream up a name for our new command. <br />Let's try “test”. Before we do that, it would be a good idea to find out if the name “test” is <br />already being used. To find out, we can use the type command again:<br /> [me@linuxbox ~]$ <strong>type test</strong><br /> test is a shell builtin<br />  Oops! The name “test” is already taken. Let's try “foo”:<br /> [me@linuxbox ~]$ <strong>type foo</strong><br /> bash: type: foo: not found<br /> 50<br /></p>
<hr />
<p>Creating Your Own Commands With alias<br /> Great! “foo” is not taken. So let's create our alias:<br /> [me@linuxbox ~]$ <strong>alias foo=</strong>'<strong>cd /usr; ls; cd -'</strong><br /> Notice the structure of this command:<br /> <strong>alias <em>name</em></strong><strong>='<em>string</em></strong><strong>'</strong><br /> After the command “alias” we give alias a name followed immediately (no whitespace al-<br />lowed) by an equals sign, followed immediately by a quoted string containing the mean-<br />ing to be assigned to the name. After we define our alias, it can be used anywhere the <br />shell would expect a command. Let's try it:<br /> [me@linuxbox ~]$ <strong>foo<br /></strong>bin  games    kerberos  lib64    local  share  tmp<br /> etc  include  lib       libexec  sbin   src<br />/home/me<br /> [me@linuxbox ~]$<br /> We can also use the type command again to see our alias:<br /> [me@linuxbox ~]$ <strong>type foo</strong><br /> foo is aliased to `cd /usr; ls ; cd -'<br /> To remove an alias, the unalias command is used, like so:<br /> [me@linuxbox ~]$ <strong>unalias foo</strong><br /> [me@linuxbox ~]$ <strong>type foo<br /></strong>bash: type: foo: not found<br /> While we purposefully avoided naming our alias with an existing command name, it is <br />not uncommon to do so. This is often done to apply a commonly desired option to each <br />invocation of a common command. For instance, we saw earlier how the ls command is <br />often aliased to add color support:<br /> 51<br /></p>
<hr />
<p>5 – Working With Commands<br /> [me@linuxbox ~]$ <strong>type ls<br /></strong>ls is aliased to `ls --color=tty'<br /> To see all the aliases defined in the environment, use the alias command without argu-<br />ments. Here are some of the aliases defined by default on a Fedora system. Try and figure <br />out what they all do:<br /> [me@linuxbox ~]$ <strong>alias<br /></strong>alias l.='ls -d .* --color=tty'<br /> alias ll='ls -l --color=tty'<br />alias ls='ls --color=tty'<br /> There is one tiny problem with defining aliases on the command line. They vanish when <br />your shell session ends. In a later chapter, we will see how to add our own aliases to the <br />files that establish the environment each time we log on, but for now, enjoy the fact that <br />we have taken our first, albeit tiny, step into the world of shell programming!<br /> <strong>Summing Up<br /></strong>Now that we have learned how to find the documentation for commands, go and look up <br />the documentation for all the commands we have encountered so far. Study what addi-<br />tional options are available and try them out!<br /> <strong>Further Reading<br /></strong>There are many online sources of documentation for Linux and the command line. Here <br />are some of the best:<br /> ●<br /> The <em>Bash Reference Manual</em> is a reference guide to the bash shell. It’s still a ref-<br />erence work but contains examples and is easier to read than the bash man page.<br /><a href="http://www.gnu.org/software/bash/manual/bashref.html">http://www.gnu.org/software/bash/manual/bashref.html</a><br /> ●<br /> The  <em>Bash FAQ</em> contains answers to frequently asked questions regarding  bash. <br />This list is aimed at intermediate to advanced users, but contains a lot of good in-<br />formation.<br /><a href="http://mywiki.wooledge.org/BashFAQ">http://mywiki.wooledge.org/BashFAQ</a><br /> ●<br /> The GNU Project provides extensive documentation for its programs, which form <br />the core of the Linux command line experience. You can see a complete list here:<br /><a href="http://www.gnu.org/manual/manual.html">http://www.gnu.org/manual/manual.html</a><br /> ●<br /> Wikipedia has an interesting article on man pages:<br /><a href="http://en.wikipedia.org/wiki/Man_page">http://en.wikipedia.org/wiki/Man_page</a><br /> 52<br /></p>
<hr />
<p>6 – Redirection<br /> <em><strong>6 – Redirection</strong></em><br /> In this lesson we are going to unleash what may be the coolest feature of the command <br />line. It's called  <em>I/O redirection</em>. The “I/O” stands for  <em>input/output</em>  and with this facility <br />you can redirect the input and output of commands to and from files, as well as connect <br />multiple commands together into powerful command <em>pipelines</em>. To show off this facility, <br />we will introduce the following commands:<br /> ●<br /> cat - Concatenate files<br /> ●<br /> sort - Sort lines of text<br /> ●<br /> uniq - Report or omit repeated lines<br /> ●<br /> grep - Print lines matching a pattern<br /> ●<br /> wc - Print newline, word, and byte counts for each file<br /> ●<br /> head - Output the first part of a file<br /> ●<br /> tail - Output the last part of a file<br /> ●<br /> tee - Read from standard input and write to standard output and files<br /> <strong>Standard Input, Output, And Error<br /></strong>Many of the programs that we have used so far produce output of some kind. This output <br />often consists of two types. First, we have the program's results; that is, the data the pro-<br />gram is designed to produce, and second, we have status and error messages that tell us <br />how the program is getting along. If we look at a command like ls, we can see that it <br />displays its results and its error messages on the screen.<br />Keeping with the Unix theme of “everything is a file,” programs such as ls actually send <br />their results to a special file called <em>standard output</em> (often expressed as <em>stdout</em>) and their <br />status messages to another file called s<em>tandard error</em> (<em>stderr</em>). By default, both standard <br />output and standard error are linked to the screen and not saved into a disk file.<br />In addition, many programs take input from a facility called <em>standard input</em> (<em>stdin</em>) which <br />is, by default, attached to the keyboard.<br /> 53<br /></p>
<hr />
<p>6 – Redirection<br /> I/O redirection allows us to change where output goes and where input comes from. Nor-<br />mally, output goes to the screen and input comes from the keyboard, but with I/O redi-<br />rection, we can change that.<br /> <strong>Redirecting Standard Output<br /></strong>I/O redirection allows us to redefine where standard output goes. To redirect standard <br />output to another file instead of the screen, we use the “&gt;” redirection operator followed <br />by the name of the file. Why would we want to do this? It's often useful to store the out-<br />put of a command in a file. For example, we could tell the shell to send the output of the <br />ls command to the file ls-output.txt instead of the screen:<br /> [me@linuxbox ~]$ <strong>ls -l /usr/bin &gt; ls-output.txt</strong><br /> Here, we created a long listing of the /usr/bin directory and sent the results to the file <br />ls-output.txt. Let's examine the redirected output of the command:<br /> [me@linuxbox ~]$ <strong>ls -l ls-output.txt</strong><br /> -rw-rw-r-- 1 me   me   167878 2008-02-01 15:07 ls-output.txt<br /> Good; a nice, large, text file. If we look at the file with less, we will see that the file <br />ls-output.txt does indeed contain the results from our ls command:<br /> [me@linuxbox ~]$ <strong>less ls-output.txt</strong><br /> Now, let's repeat our redirection test, but this time with a twist. We'll change the name of <br />the directory to one that does not exist:<br /> [me@linuxbox ~]$ <strong>ls -l /bin/usr &gt; ls-output.txt<br /></strong>ls: cannot access /bin/usr: No such file or directory<br /> We received an error message. This makes sense since we specified the non-existent di-<br />rectory /bin/usr, but why was the error message displayed on the screen rather than <br />being redirected to the file ls-output.txt? The answer is that the ls program does <br />not send its error messages to standard output. Instead, like most well-written Unix pro-<br />grams, it sends its error messages to  standard error. Since we only redirected standard <br />output and not standard error, the error message was still sent to the screen. We'll see how <br /> 54<br /></p>
<hr />
<p>Redirecting Standard Output<br /> to redirect standard error in just a minute, but first, let's look at what happened to our out-<br />put file:<br /> [me@linuxbox ~]$ <strong>ls -l ls-output.txt<br /></strong>-rw-rw-r-- 1 me   me   0 2008-02-01 15:08 ls-output.txt<br /> The file now has zero length! This is because, when we redirect output with the “&gt;” redi-<br />rection operator, the destination file is always rewritten from the beginning. Since our ls <br />command   generated   no   results   and   only   an   error   message,   the   redirection   operation <br />started to rewrite the file and then stopped because of the error, resulting in its truncation. <br />In fact, if we ever need to actually truncate a file (or create a new, empty file) we can use <br />a trick like this:<br /> [me@linuxbox ~]$ <strong>&gt; ls-output.txt</strong><br /> Simply using the redirection operator with no command preceding it will truncate an ex-<br />isting file or create a new, empty file.<br />So, how can we append redirected output to a file instead of overwriting the file from the <br />beginning? For that, we use the “&gt;&gt;” redirection operator, like so:<br /> [me@linuxbox ~]$ <strong>ls -l /usr/bin &gt;&gt; ls-output.txt</strong><br /> Using the “&gt;&gt;” operator will result in the output being appended to the file. If the file <br />does not already exist, it is created just as though the “&gt;” operator had been used. Let's <br />put it to the test:<br /> [me@linuxbox ~]$ <strong>ls -l /usr/bin &gt;&gt; ls-output.txt<br /></strong>[me@linuxbox ~]$ <strong>ls -l /usr/bin &gt;&gt; ls-output.txt</strong><br /> [me@linuxbox ~]$ <strong>ls -l /usr/bin &gt;&gt; ls-output.txt<br /></strong>[me@linuxbox ~]$ <strong>ls -l ls-output.txt</strong><br /> -rw-rw-r-- 1 me   me   503634 2008-02-01 15:45 ls-output.txt<br /> We repeated the command three times resulting in an output file three times as large.<br /> <strong>Redirecting Standard Error<br /></strong>Redirecting standard error lacks the ease of a dedicated redirection operator. To redirect <br /> 55<br /></p>
<hr />
<p>6 – Redirection<br /> standard error we must refer to its <em>file descriptor</em>. A program can produce output on any <br />of several numbered file streams. While we have referred to the first three of these file <br />streams as standard input, output and error, the shell references them internally as file de-<br />scriptors 0, 1 and 2, respectively. The shell provides a notation for redirecting files using <br />the file descriptor number. Since standard error is the same as file descriptor number 2, <br />we can redirect standard error with this notation:<br /> [me@linuxbox ~]$ <strong>ls -l /bin/usr 2&gt; ls-error.txt</strong><br /> The file descriptor “2” is placed immediately before the redirection operator to perform <br />the redirection of standard error to the file ls-error.txt.<br /> Redirecting Standard Output And Standard Error To One File<br />There are cases in which we may wish to capture all of the output of a command to a sin-<br />gle file. To do this, we must redirect both standard output and standard error at the same <br />time. There are two ways to do this. First, the traditional way, which works with old ver-<br />sions of the shell:<br /> [me@linuxbox ~]$ <strong>ls -l /bin/usr &gt; ls-output.txt 2&gt;&amp;1</strong><br /> Using this method, we perform two redirections. First we redirect standard output to the <br />file ls-output.txt and then we redirect file descriptor 2 (standard error) to file de-<br />scriptor one (standard output) using the notation 2&gt;&amp;1.<br /> <strong>Notice that the order of the redirections is significant.</strong> The redirection of stan-<br />dard error must always occur <em>after</em> redirecting standard output or it doesn't work. In <br />the example above,<br /> &gt;ls-output.txt 2&gt;&amp;1<br /> redirects standard error to the file ls-output.txt, but if the order is changed to<br />  2&gt;&amp;1 &gt;ls-output.txt<br /> standard error is directed to the screen.<br /> Recent versions of bash provide a second, more streamlined method for performing this <br /> 56<br /></p>
<hr />
<p>Redirecting Standard Error<br /> combined redirection:<br /> [me@linuxbox ~]$ <strong>ls -l /bin/usr &amp;&gt; ls-output.txt</strong><br /> In this example, we use the single notation &amp;&gt; to redirect both standard output and stan-<br />dard error to the file ls-output.txt. You may also append the standard output and <br />standard error streams to a single file like so:<br /> [me@linuxbox ~]$ <strong>ls -l /bin/usr &amp;&gt;&gt; ls-output.txt</strong><br /> Disposing Of Unwanted Output<br />Sometimes “silence is golden,” and we don't want output from a command, we just want <br />to throw it away. This applies particularly to error and status messages. The system pro-<br />vides a way to do this by redirecting output to a special file called “/dev/null”. This file is <br />a system device called a <em>bit bucket</em> which accepts input and does nothing with it. To sup-<br />press error messages from a command, we do this:<br /> [me@linuxbox ~]$ <strong>ls -l /bin/usr 2&gt; /dev/null</strong><br /> <strong>/dev/null In Unix Culture<br /></strong>The bit bucket is an ancient Unix concept and due to its universality, it has ap-<br />peared in many parts of Unix culture. When someone says he/she is sending your <br />comments to  /dev/null, now you know what it means. For more examples, <br />see the<a href="http://en.wikipedia.org/wiki//dev/null"> Wikipedia article on “/dev/null”.</a><br /> <strong>Redirecting Standard Input<br /></strong>Up to now, we haven't encountered any commands that make use of standard input (actu-<br />ally we have, but we’ll reveal that surprise a little bit later), so we need to introduce one.<br /> cat – Concatenate Files<br />The cat command reads one or more files and copies them to standard output like so:<br /> 57<br /></p>
<hr />
<p>6 – Redirection<br /> <strong>cat [<em>file...</em></strong><strong>]</strong><br /> In most cases, you can think of cat as being analogous to the TYPE command in DOS. <br />You can use it to display files without paging, for example:<br /> [me@linuxbox ~]$ <strong>cat</strong> <strong>ls-output.txt</strong><br /> will display the contents of the file ls-output.txt. cat is often used to display short <br />text files. Since cat can accept more than one file as an argument, it can also be used to <br />join files together. Say we have downloaded a large file that has been split into multiple <br />parts (multimedia files are often split this way on Usenet), and we want to join them back <br />together. If the files were named:<br />movie.mpeg.001 movie.mpeg.002 ... movie.mpeg.099<br />we could join them back together with this command:<br /> <strong>cat movie.mpeg.0* &gt; movie.mpeg</strong><br /> Since wildcards always expand in sorted order, the arguments will be arranged in the cor-<br />rect order.<br />This is all well and good, but what does this have to do with standard input? Nothing yet, <br />but let's try something else. What happens if we enter “cat” with no arguments:<br /> [me@linuxbox ~]$ <strong>cat</strong><br /> Nothing happens, it just sits there like it's hung. It may seem that way, but it's really doing <br />exactly what it's supposed to.<br />If cat is not given any arguments, it reads from standard input and since standard input <br />is, by default, attached to the keyboard, it's waiting for us to type something! Try adding <br />the following text and pressing Enter:<br /> [me@linuxbox ~]$ <strong>cat<br />The quick brown fox jumped over the lazy dog.</strong><br /> Next, type a Ctrl-d (i.e., hold down the Ctrl key and press “d”) to tell cat that it has <br /> 58<br /></p>
<hr />
<p>Redirecting Standard Input<br /> reached <em>end of file</em> (EOF) on standard input:<br /> [me@linuxbox ~]$ <strong>cat<br />The quick brown fox jumped over the lazy dog.</strong><br /> The quick brown fox jumped over the lazy dog.<br /> In the absence of filename arguments, cat copies standard input to standard output, so <br />we see our line of text repeated. We can use this behavior to create short text files. Let's <br />say that we wanted to create a file called “lazy_dog.txt” containing the text in our exam-<br />ple. We would do this:<br /> [me@linuxbox ~]$ <strong>cat &gt; lazy_dog.txt</strong><br /> <strong>The quick brown fox jumped over the lazy dog.</strong><br /> Type the command followed by the text we want in to place in the file. Remember to type <br />Ctrl-d at the end. Using the command line, we have implemented the world's dumbest <br />word processor! To see our results, we can use cat to copy the file to stdout again:<br /> [me@linuxbox ~]$ <strong>cat lazy_dog.txt</strong><br /> The quick brown fox jumped over the lazy dog.<br /> Now that we know how cat accepts standard input, in addition to filename arguments, <br />let's try redirecting standard input:<br /> [me@linuxbox ~]$ <strong>cat &lt; lazy_dog.txt</strong><br /> The quick brown fox jumped over the lazy dog.<br /> Using the “&lt;” redirection operator, we change the source of standard input from the key-<br />board to the file lazy_dog.txt. We see that the result is the same as passing a single <br />filename argument. This is not particularly useful compared to passing a filename argu-<br />ment, but it serves to demonstrate using a file as a source of standard input. Other com-<br />mands make better use of standard input, as we shall soon see.<br />Before we move on, check out the man page for cat, as it has several interesting options.<br /> <strong>Pipelines<br /></strong>The ability of commands to read data from standard input and send to standard output is <br /> 59<br /></p>
<hr />
<p>6 – Redirection<br /> utilized by a shell feature called <em>pipelines</em>. Using the pipe operator “|” (vertical bar), the <br />standard output of one command can be <em>piped</em> into the standard input of another:<br /> <em>command1</em> | <em>command2</em><br /> To fully demonstrate this, we are going to need some commands. Remember how we said <br />there was one we already knew that accepts standard input? It's less. We can use less <br />to display, page-by-page, the output of any command that sends its results to standard <br />output:<br /> [me@linuxbox ~]$ <strong>ls -l /usr/bin | less</strong><br /> This is extremely handy! Using this technique, we can conveniently examine the output <br />of any command that produces standard output.<br /> <strong>The Difference Between &gt; and |<br /></strong>At first glance, it may be hard to understand the redirection performed by the <br />pipeline operator | versus the redirection operator &gt;. Simply put, the redirection <br />operator connects a command with a file while the pipeline operator connects the <br />output of one command with the input of a second command.<br /> <em>command1</em> &gt; <em>file1<br />command1</em> | <em>command2</em><br /> A lot of people will try the following when they are learning about pipelines, “just <br />to see what happens.”<br /> <em>command1</em> &gt; <em>command2</em><br /> Answer: Sometimes something really bad.<br /> Here is an actual example submitted by a reader who was administering a Linux-<br />based server appliance.  As the superuser, he did this:<br /> # cd /usr/bin<br /># ls &gt; less<br /> 60<br /></p>
<hr />
<p>Pipelines<br /> The first command put him in the directory where most programs are stored and <br />the second command told the shell to overwrite the file less with  the output of <br />the ls command. Since the /usr/bin directory already contained a file named <br />“less” (the less program), the second command overwrote the less program <br />file with the text from ls thus destroying the less program on his system.<br /> The lesson here is that the redirection operator silently creates or overwrites files, <br />so you need to treat it with a lot of respect. <br /> Filters<br />Pipelines are often used to perform complex operations on data. It is possible to put sev-<br />eral commands together into a pipeline. Frequently, the commands used this way are re-<br />ferred to as <em>filters</em>.  Filters take input, change it somehow and then output it. The first one <br />we will try is sort. Imagine we wanted to make a combined list of all of the executable <br />programs in /bin and /usr/bin, put them in sorted order and view it:<br /> [me@linuxbox ~]$ <strong>ls /bin /usr/bin | sort | less</strong><br /> Since we specified two directories (/bin and /usr/bin), the output of ls would have <br />consisted of two sorted lists, one for each directory. By including sort in our pipeline, <br />we changed the data to produce a single, sorted list.<br /> uniq - Report Or Omit Repeated Lines<br />The uniq command is often used in conjunction with sort. uniq accepts a sorted list <br />of data from either standard input or a single filename argument (see the uniq man page <br />for details) and, by default, removes any duplicates from the list. So, to make sure our list <br />has no duplicates (that is, any programs of the same name that appear in both the /bin <br />and /usr/bin directories) we will add uniq to our pipeline:<br /> [me@linuxbox ~]$ <strong>ls /bin /usr/bin | sort | uniq | less</strong><br /> In this example, we use  uniq  to remove any duplicates from the output of the  sort <br />command. If we want to see the list of duplicates instead, we add the “-d” option to uniq <br />like so:<br /> 61<br /></p>
<hr />
<p>6 – Redirection<br /> [me@linuxbox ~]$ <strong>ls /bin /usr/bin | sort | uniq -d | less</strong><br /> wc – Print Line, Word, And Byte Counts<br />The wc (word count) command is used to display the number of lines, words, and bytes <br />contained in files. For example:<br /> [me@linuxbox ~]$ <strong>wc ls-output.txt<br /></strong> 7902  64566 503634 ls-output.txt<br /> In this case it prints out three numbers: lines, words, and bytes contained in ls-out-<br />put.txt. Like our previous commands, if executed without command line arguments, <br />wc accepts standard input. The “-l” option limits its output to only report lines.  Adding it <br />to a pipeline is a handy way to count things. To see the number of items we have in our <br />sorted list, we can do this:<br /> [me@linuxbox ~]$ <strong>ls /bin /usr/bin | sort | uniq | wc -l<br /></strong>2728<br /> grep – Print Lines Matching A Pattern<br />grep is a powerful program used to find text patterns within files. It's used like this:<br /> grep <em>pattern</em> [<em>file...</em>]<br /> When  grep encounters a “pattern” in the file, it prints out the lines containing it. The <br />patterns that grep can match can be very complex, but for now we will concentrate on <br />simple text matches. We'll cover the advanced patterns, called  <em>regular expressions</em>  in a <br />later chapter.<br />Let's say we wanted to find all the files in our list of programs that had the word “zip” <br />embedded in the name. Such a search might give us an idea of some of the programs on <br />our system that had something to do with file compression. We would do this:<br /> [me@linuxbox ~]$ <strong>ls /bin /usr/bin | sort | uniq | grep zip</strong><br /> 62<br /></p>
<hr />
<p>Pipelines<br /> bunzip2<br />bzip2<br /> gunzip<br />gzip<br /> unzip<br />zip<br /> zipcloak<br />zipgrep<br /> zipinfo<br />zipnote<br /> zipsplit<br /> There are a couple of handy options for grep: “-i” which causes grep to ignore case <br />when performing the search (normally searches are case sensitive) and “-v” which tells <br />grep to only print lines that do not match the pattern.<br /> head / tail – Print First / Last Part Of Files<br />Sometimes you don't want all the output from a command. You may only want the first <br />few lines or the last few lines. The head command prints the first ten lines of a file and <br />the tail command prints the last ten lines. By default, both commands print ten lines of <br />text, but this can be adjusted with the “-n” option:<br /> [me@linuxbox ~]$ <strong>head -n 5 ls-output.txt<br /></strong>total 343496<br /> -rwxr-xr-x 1 root root       31316 2007-12-05 08:58 [<br />-rwxr-xr-x 1 root root        8240 2007-12-09 13:39 411toppm<br /> -rwxr-xr-x 1 root root      111276 2007-11-26 14:27 a2p<br />-rwxr-xr-x 1 root root       25368 2006-10-06 20:16 a52dec<br /> [me@linuxbox ~]$ <strong>tail -n 5 ls-output.txt<br /></strong>-rwxr-xr-x 1 root root        5234 2007-06-27 10:56 znew<br /> -rwxr-xr-x 1 root root         691 2005-09-10 04:21 zonetab2pot.py<br />-rw-r--r-- 1 root root         930 2007-11-01 12:23 zonetab2pot.pyc<br /> -rw-r--r-- 1 root root         930 2007-11-01 12:23 zonetab2pot.pyo<br />lrwxrwxrwx 1 root root           6 2008-01-31 05:22 zsoelim -&gt; soelim<br /> These can be used in pipelines as well:<br /> [me@linuxbox ~]$ <strong>ls /usr/bin | tail -n 5<br /></strong>znew<br /> zonetab2pot.py<br />zonetab2pot.pyc<br /> zonetab2pot.pyo<br /> 63<br /></p>
<hr />
<p>6 – Redirection<br /> zsoelim<br /> tail has an option which allows you to view files in real-time. This is useful for watch-<br />ing the progress of log files as they are being written. In the following example, we will <br />look at the  messages  file in  /var/log  (or the  /var/log/syslog  file if  mes-<br />sages is missing). Superuser privileges are required to do this on some Linux distribu-<br />tions, since the /var/log/messages file may contain security information:<br /> [me@linuxbox ~]$ <strong>tail -f /var/log/messages</strong><br /> Feb  8 13:40:05 twin4 dhclient: DHCPACK from 192.168.1.1<br />Feb  8 13:40:05 twin4 dhclient: bound to 192.168.1.4 -- renewal in <br /> 1652 seconds.<br />Feb  8 13:55:32 twin4 mountd[3953]: /var/NFSv4/musicbox exported to <br /> both 192.168.1.0/24 and twin7.localdomain in <br />192.168.1.0/24,twin7.localdomain<br /> Feb  8 14:07:37 twin4 dhclient: DHCPREQUEST on eth0 to 192.168.1.1 <br />port 67<br /> Feb  8 14:07:37 twin4 dhclient: DHCPACK from 192.168.1.1<br />Feb  8 14:07:37 twin4 dhclient: bound to 192.168.1.4 -- renewal in <br /> 1771 seconds.<br />Feb  8 14:09:56 twin4 smartd[3468]: Device: /dev/hda, SMART <br /> Prefailure Attribute: 8 Seek_Time_Performance changed from 237 to 236<br />Feb  8 14:10:37 twin4 mountd[3953]: /var/NFSv4/musicbox exported to <br /> both 192.168.1.0/24 and twin7.localdomain in <br />192.168.1.0/24,twin7.localdomain<br /> Feb  8 14:25:07 twin4 sshd(pam_unix)[29234]: session opened for user <br />me by (uid=0)<br /> Feb  8 14:25:36 twin4 su(pam_unix)[29279]: session opened for user <br />root by me(uid=500)<br /> Using the “-f” option,  tail  continues to monitor the file and when new lines are ap-<br />pended, they immediately appear on the display. This continues until you type Ctrl-c.<br /> tee – Read From Stdin And Output To Stdout And Files<br />In keeping with our plumbing metaphor, Linux provides a command called tee which <br />creates a “tee” fitting on our pipe. The tee program reads standard input and copies it to <br />both standard output (allowing the data to continue down the pipeline) and to one or more <br />files. This is useful for capturing a pipeline's contents at an intermediate stage of process-<br />ing.  Here we repeat one of our earlier examples, this time including tee to capture the <br />entire directory listing to the file ls.txt before grep filters the pipeline's contents:<br /> 64<br /></p>
<hr />
<p>Pipelines<br /> [me@linuxbox ~]$ <strong>ls /usr/bin | tee ls.txt | grep zip<br /></strong>bunzip2<br /> bzip2<br />gunzip<br /> gzip<br />unzip<br /> zip<br />zipcloak<br /> zipgrep<br />zipinfo<br /> zipnote<br />zipsplit<br /> <strong>Summing Up<br /></strong>As always, check out the documentation of each of the commands we have covered in <br />this chapter. We have only seen their most basic usage. They all have a number of inter-<br />esting options. As we gain Linux experience, we will see that the redirection feature of <br />the command line is extremely useful for solving specialized problems. There are many <br />commands that make use of standard input and output, and almost all command line pro-<br />grams use standard error to display their informative messages.<br /> <strong>Linux Is About Imagination<br /></strong>When I am asked to explain the difference between Windows and Linux, I often <br />use a toy analogy.<br />Windows is like a Game Boy. You go to the store and buy one all shiny new in the <br />box. You take it home, turn it on and play with it. Pretty graphics, cute sounds. <br />After a while though, you get tired of the game that came with it so you go back <br />to the store and buy another one. This cycle repeats over and over. Finally, you go <br />back to the store and say to the person behind the counter, “I want a game that <br />does this!” only to be told that no such game exists because there is no “market <br />demand” for it. Then you say, “But I only need to change this one thing!” The <br />person behind the counter says you can't change it. The games are all sealed up in <br />their cartridges. You discover that your toy is limited to the games that others <br />have decided that you need and no more.<br />Linux, on the other hand, is like the world's largest Erector Set. You open it up <br />and it's just a huge collection of parts. A lot of steel struts, screws, nuts, gears, <br />pulleys, motors, and a few suggestions on what to build. So you start to play with <br />it. You build one of the suggestions and then another. After a while you discover <br /> 65<br /></p>
<hr />
<p>6 – Redirection<br /> that you have your own ideas of what to make. You don't ever have to go back to <br />the store, as you already have everything you need. The Erector Set takes on the <br />shape of your imagination. It does what you want.<br />Your choice of toys is, of course, a personal thing, so which toy would you find <br />more satisfying? <br /> 66<br /></p>
<hr />
<p>7 – Seeing The World As The Shell Sees It<br /> <em><strong>7 – Seeing The World As The Shell Sees It</strong></em><br /> In this chapter we are going to look at some of the “magic” that occurs on the command <br />line when you press the enter key. While we will examine several interesting and com-<br />plex features of the shell, we will do it with just one new command:<br /> ●<br /> echo – Display a line of text<br /> <strong>Expansion<br /></strong>Each time you type a command line and press the enter key, bash performs several pro-<br />cesses upon the text before it carries out your command. We have seen a couple of cases <br />of how a simple character sequence, for example “*”, can have a lot of meaning to the <br />shell. The process that makes this happen is called <em>expansion</em>. With expansion, you enter <br />something and it is expanded into something else before the shell acts upon it. To demon-<br />strate what we mean by this, let's take a look at the  echo  command.  echo  is a shell <br />builtin that performs a very simple task. It prints out its text arguments on standard out-<br />put:<br /> [me@linuxbox ~]$ <strong>echo this is a test<br /></strong>this is a test<br /> That's pretty straightforward. Any argument passed to echo gets displayed. Let's try an-<br />other example:<br /> [me@linuxbox ~]$ <strong>echo *<br /></strong>Desktop Documents ls-output.txt Music Pictures Public Templates <br /> Videos<br /> So what just happened? Why didn't echo print “*”? As you recall from our work with <br />wildcards, the “*” character means match any characters in a filename, but what we didn't <br />see in our original discussion was how the shell does that. The simple answer is that the <br />shell expands the “*” into something else (in this instance, the names of the files in the <br /> 67<br /></p>
<hr />
<p>7 – Seeing The World As The Shell Sees It<br /> current working directory) before the echo command is executed. When the enter key is <br />pressed, the shell automatically expands any qualifying characters on the command line <br />before the command is carried out, so the echo command never saw the “*”, only its ex-<br />panded result. Knowing this, we can see that echo behaved as expected.<br /> Pathname Expansion<br />The mechanism by which wildcards work is called <em>pathname expansion</em>. If we try some <br />of the techniques that we employed in our earlier chapters, we will see that they are really <br />expansions. Given a home directory that looks like this:<br /> [me@linuxbox ~]$ <strong>ls<br /></strong>Desktop    ls-output.txt  Pictures  Templates<br /> Documents  Music          Public    Videos<br /> we could carry out the following expansions:<br /> [me@linuxbox ~]$ <strong>echo D*</strong><br /> Desktop Documents<br /> and:<br /> [me@linuxbox ~]$ <strong>echo *s</strong><br /> Documents Pictures Templates Videos<br /> or even:<br /> [me@linuxbox ~]$ <strong>echo [[:upper:]]*</strong><br /> Desktop Documents Music Pictures Public Templates Videos<br /> and looking beyond our home directory:<br /> [me@linuxbox ~]$ <strong>echo /usr/*/share</strong><br /> /usr/kerberos/share /usr/local/share<br /> 68<br /></p>
<hr />
<p>Expansion<br /> <strong>Pathname Expansion Of Hidden Files<br /></strong>As we know, filenames that begin with a period character are hidden. Pathname <br />expansion also respects this behavior. An expansion such as:<br />echo *<br />does not reveal hidden files.<br />It might appear at first glance that we could include hidden files in an expansion <br />by starting the pattern with a leading period, like this:<br />echo .*<br />It almost works. However, if we examine the results closely, we will see that the <br />names “.” and “..” will also appear in the results. Since these names refer to the <br />current working directory and its parent directory, using this pattern will likely <br />produce an incorrect result. We can see this if we try the command:<br />ls -d .* | less<br />To better perform pathname expansion in this situation, we have to employ a <br />more specific pattern:<br />echo .[!.]*<br />This pattern expands into every filename that begins with a period, does not in-<br />clude a second period, and followed by any other characters. This will work cor-<br />rectly with most hidden files (though it still won't include filenames with multiple <br />leading periods). The ls command with the -A option (“almost all”) will provide <br />a correct listing of hidden files: <br />ls -A<br /> Tilde Expansion<br />As you may recall from our introduction to the cd command, the tilde character (“~”) has <br />a special meaning. When used at the beginning of a word, it expands into the name of the <br />home directory of the named user, or if no user is named, the home directory of the cur-<br />rent user:<br /> [me@linuxbox ~]$ <strong>echo ~</strong><br /> /home/me<br /> If user “foo” has an account, then:<br /> [me@linuxbox ~]$ <strong>echo ~foo</strong><br /> /home/foo<br /> 69<br /></p>
<hr />
<p>7 – Seeing The World As The Shell Sees It<br /> Arithmetic Expansion<br />The shell allows arithmetic to be performed by expansion. This allow us to use the shell <br />prompt as a calculator:<br /> [me@linuxbox ~]$ <strong>echo $((2 + 2))<br /></strong>4<br /> Arithmetic expansion uses the form:<br />$((<em>expression</em>))<br />where <em>expression</em> is an arithmetic expression consisting of values and arithmetic opera-<br />tors.<br />Arithmetic expansion only supports integers (whole numbers, no decimals), but can per-<br />form quite a number of different operations. Here are a few of the supported operators:<br /> <em>Table 7-1: Arithmetic Operators</em><br /> <strong>Operator</strong><br /> <strong>Description</strong><br /> +<br /> Addition<br /> -<br /> Subtraction<br /> *<br /> Multiplication<br /> /<br /> Division (but remember, since expansion only supports integer <br />arithmetic, results are integers.)<br /> %<br /> Modulo, which simply means, “ remainder.”<br /> **<br /> Exponentiation<br /> Spaces are not significant in arithmetic expressions and expressions may be nested. For <br />example, to multiply 5 squared by 3:<br /> [me@linuxbox ~]$ <strong>echo $(($((5**2)) * 3))<br /></strong>75<br /> Single parentheses may be used to group multiple subexpressions. With this technique, <br />we can rewrite the example above and get the same result using a single expansion in-<br />stead of two:<br /> 70<br /></p>
<hr />
<p>Expansion<br /> [me@linuxbox ~]$ <strong>echo $(((5**2) * 3))<br /></strong>75<br /> Here is an example using the division and remainder operators. Notice the effect of inte-<br />ger division:<br /> [me@linuxbox ~]$ <strong>echo Five divided by two equals $((5/2))<br /></strong>Five divided by two equals 2<br /> [me@linuxbox ~]$ <strong>echo with $((5%2)) left over.<br /></strong>with 1 left over.<br /> Arithmetic expansion is covered in greater detail in Chapter 34.<br /> Brace Expansion<br />Perhaps the strangest expansion is called <em>brace expansion</em>. With it, you can create multi-<br />ple text strings from a pattern containing braces. Here's an example:<br /> [me@linuxbox ~]$ <strong>echo Front-{A,B,C}-Back<br /></strong>Front-A-Back Front-B-Back Front-C-Back<br /> Patterns to be brace expanded may contain a leading portion called a  <em>preamble</em>  and a <br />trailing   portion   called   a  <em>postscript</em>.  The   brace   expression   itself   may   contain   either   a <br />comma-separated list of strings, or a range of integers or single characters.  The pattern <br />may not contain embedded whitespace. Here is an example using a range of integers:<br /> [me@linuxbox ~]$ <strong>echo Number_{1..5}<br /></strong>Number_1 Number_2 Number_3 Number_4 Number_5<br /> Integers may also be <em>zero-padded</em> like so:<br /> [me@linuxbox ~]$ <strong>echo {01..15}<br /></strong>01 02 03 04 05 06 07 08 09 10 11 12 13 14 15<br /> [me@linuxbox ~]$ <strong>echo {001..15}<br /></strong>001 002 003 004 005 006 007 008 009 010 011 012 013 014 015<br /> A range of letters in reverse order:<br /> 71<br /></p>
<hr />
<p>7 – Seeing The World As The Shell Sees It<br /> [me@linuxbox ~]$ <strong>echo {Z..A}<br /></strong>Z Y X W V U T S R Q P O N M L K J I H G F E D C B A<br /> Brace expansions may be nested:<br /> [me@linuxbox ~]$ <strong>echo a{A{1,2},B{3,4}}b<br /></strong>aA1b aA2b aB3b aB4b<br /> So what is this good for? The most common application is to make lists of files or direc-<br />tories to be created. For example, if we were photographers and had a large collection of <br />images that we wanted to organize into years and months, the first thing we might do is <br />create a series of directories named in numeric “Year-Month” format. This way, the direc-<br />tory names will sort in chronological order. We could type out a complete list of directo-<br />ries, but that's a lot of work and it's error-prone too. Instead, we could do this:<br /> [me@linuxbox ~]$ <strong>mkdir Photos<br /></strong>[me@linuxbox ~]$ <strong>cd Photos</strong><br /> [me@linuxbox Photos]$ <strong>mkdir {2007..2009}-{01..12}<br /></strong>[me@linuxbox Photos]$ <strong>ls</strong><br /> 2007-01  2007-07  2008-01  2008-07  2009-01  2009-07<br />2007-02  2007-08  2008-02  2008-08  2009-02  2009-08<br /> 2007-03  2007-09  2008-03  2008-09  2009-03  2009-09<br />2007-04  2007-10  2008-04  2008-10  2009-04  2009-10<br /> 2007-05  2007-11  2008-05  2008-11  2009-05  2009-11<br />2007-06  2007-12  2008-06  2008-12  2009-06  2009-12<br /> Pretty slick!<br /> Parameter Expansion<br />We're only going to touch briefly on  parameter expansion  in this chapter, but we'll be <br />covering it extensively later. It's a feature that is more useful in shell scripts than directly <br />on the command line. Many of its capabilities have to do with the system's ability to store <br />small chunks of data and to give each chunk a name. Many such chunks, more properly <br />called  <em>variables</em>, are available for your examination. For example, the variable named <br />“USER” contains your username. To invoke parameter expansion and reveal the contents <br />of USER you would do this:<br /> [me@linuxbox ~]$ <strong>echo $USER</strong><br /> 72<br /></p>
<hr />
<p>Expansion<br /> me<br /> To see a list of available variables, try this:<br /> [me@linuxbox ~]$ <strong>printenv | less</strong><br /> You may have noticed that with other types of expansion, if you mistype a pattern, the <br />expansion will not take place and the echo command will simply display the mistyped <br />pattern. With parameter expansion, if you misspell the name of a variable, the expansion <br />will still take place, but will result in an empty string:<br /> [me@linuxbox ~]$ <strong>echo $SUER</strong><br /> [me@linuxbox ~]$ <br /> Command Substitution<br />Command substitution allows us to use the output of a command as an expansion:<br /> [me@linuxbox ~]$ <strong>echo $(ls)</strong><br /> Desktop Documents ls-output.txt Music Pictures Public Templates <br />Videos<br /> One of my favorites goes something like this:<br /> [me@linuxbox ~]$ <strong>ls -l $(which cp)<br /></strong>-rwxr-xr-x 1 root root 71516 2007-12-05 08:58 /bin/cp<br /> Here we passed the results of which cp as an argument to the ls command, thereby <br />getting the listing of of the cp program without having to know its full pathname. We are <br />not limited to just simple commands. Entire  pipelines can be used (only partial output <br />shown):<br /> [me@linuxbox ~]$ <strong>file $(ls -d /usr/bin/* | grep zip)<br /></strong>/usr/bin/bunzip2:      symbolic link to `bzip2'<br /> 73<br /></p>
<hr />
<p>7 – Seeing The World As The Shell Sees It<br /> /usr/bin/bzip2:        ELF 32-bit LSB executable, Intel 80386, <br />version 1 (SYSV), dynamically linked (uses shared libs), for <br /> GNU/Linux 2.6.9, stripped<br />/usr/bin/bzip2recover: ELF 32-bit LSB executable, Intel 80386, <br /> version 1 (SYSV), dynamically linked (uses shared libs), for <br />GNU/Linux 2.6.9, stripped<br /> /usr/bin/funzip:       ELF 32-bit LSB executable, Intel 80386, <br />version 1 (SYSV), dynamically linked (uses shared libs), for <br /> GNU/Linux 2.6.9, stripped<br />/usr/bin/gpg-zip:      Bourne shell script text executable<br /> /usr/bin/gunzip:       symbolic link to `../../bin/gunzip'<br />/usr/bin/gzip:         symbolic link to `../../bin/gzip'<br /> /usr/bin/mzip:         symbolic link to `mtools'<br /> In this example, the results of the pipeline became the argument list of the file com-<br />mand.<br />There is an alternate syntax for command substitution in older shell programs which is <br />also supported in bash. It uses <em>back-quotes</em> instead of the dollar sign and parentheses:<br /> [me@linuxbox ~]$ <strong>ls -l `which cp`</strong><br /> -rwxr-xr-x 1 root root 71516 2007-12-05 08:58 /bin/cp<br /> <strong>Quoting<br /></strong>Now that we've seen how many ways the shell can perform expansions, it's time to learn <br />how we can control it. Take for example:<br /> [me@linuxbox ~]$ <strong>echo this is a     test</strong><br /> this is a test<br /> or:<br /> [me@linuxbox ~]$ <strong>echo The total is $100.00</strong><br /> The total is 00.00<br /> In the first example, <em>word-splitting</em> by the shell removed extra whitespace from the echo <br />command's list of arguments. In the second example, parameter expansion substituted an <br />empty string for the value of “$1” because it was an undefined variable. The shell pro-<br />vides a mechanism called <em>quoting</em> to selectively suppress unwanted expansions.<br /> 74<br /></p>
<hr />
<p>Quoting<br /> Double Quotes<br />The first type of quoting we will look at is <em>double quotes</em>. If you place text inside double <br />quotes, all the special characters used by the shell lose their special meaning and are <br />treated as ordinary characters. The exceptions are “$”, “\” (backslash), and “`” (back-<br />quote). This means that word-splitting, pathname expansion, tilde expansion, and  brace <br />expansion are suppressed, but parameter expansion, arithmetic expansion, and command <br />substitution are still carried out. Using double quotes, we can cope with filenames con-<br />taining   embedded   spaces.   Say   we   were   the   unfortunate   victim   of   a   file   called <br />two words.txt. If we tried to use this on the command line, word-splitting would <br />cause this to be treated as two separate arguments rather than the desired single argument:<br /> [me@linuxbox ~]$ <strong>ls -l two words.txt<br /></strong>ls: cannot access two: No such file or directory<br /> ls: cannot access words.txt: No such file or directory<br /> By using double quotes, we stop the word-splitting and get the desired result; further, we <br />can even repair the damage:<br /> [me@linuxbox ~]$ <strong>ls -l &quot;two words.txt&quot;</strong><br /> -rw-rw-r-- 1 me   me   18 2008-02-20 13:03 two words.txt<br />[me@linuxbox ~]$ <strong>mv &quot;two words.txt&quot; two_words.txt</strong><br /> There! Now we don't have to keep typing those pesky double quotes.<br />Remember,  parameter  expansion,  arithmetic  expansion, and  command substitution  still <br />take place within double quotes:<br /> [me@linuxbox ~]$ <strong>echo &quot;$USER $((2+2)) $(cal)&quot;<br /></strong>me 4    February 2008<br /> Su Mo Tu We Th Fr Sa<br />                1  2<br />  3  4  5  6  7  8  9<br />10 11 12 13 14 15 16<br /> 17 18 19 20 21 22 23<br />24 25 26 27 28 29<br /> We should take a moment to look at the effect of double quotes on command substitution. <br />First let's look a little deeper at how word splitting works. In our earlier example, we saw <br />how word-splitting appears to remove extra spaces in our text:<br /> 75<br /></p>
<hr />
<p>7 – Seeing The World As The Shell Sees It<br /> [me@linuxbox ~]$ <strong>echo this is a     test<br /></strong>this is a test<br /> By default, word-splitting looks for the presence of spaces, tabs, and newlines (linefeed <br />characters) and treats them as <em>delimiters</em> between words. This means that unquoted spa-<br />ces, tabs, and newlines are not considered to be part of the text. They only serve as sepa-<br />rators. Since they separate the words into different arguments, our example command line <br />contains a command followed by four distinct arguments. If we add double quotes:<br /> [me@linuxbox ~]$ <strong>echo &quot;this is a     test&quot;<br /></strong>this is a     test<br /> word-splitting is suppressed and the embedded spaces are not treated as delimiters, rather <br />they become part of the argument. Once the double quotes are added, our command line <br />contains a command followed by a single argument.<br />The fact that newlines are considered delimiters by the word-splitting mechanism causes <br />an interesting, albeit subtle, effect on command substitution. Consider the following:<br /> [me@linuxbox ~]$ <strong>echo $(cal)<br /></strong>February 2008 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 <br /> 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29<br />[me@linuxbox ~]$ <strong>echo &quot;$(cal)&quot;</strong><br />    February 2008<br />Su Mo Tu We Th Fr Sa<br />                 1  2<br /> 3  4  5  6  7  8  9<br /> 10 11 12 13 14 15 16<br />17 18 19 20 21 22 23<br /> 24 25 26 27 28 29<br /> In the first instance, the unquoted command substitution resulted in a command line con-<br />taining 38 arguments. In the second, a command line with one argument that includes the <br />embedded spaces and newlines.<br /> Single Quotes<br />If we need to suppress <em>all</em> expansions, we use <em>single quotes</em>. Here is a comparison of un-<br />quoted, double quotes, and single quotes:<br /> 76<br /></p>
<hr />
<p>Quoting<br /> [me@linuxbox ~]$ <strong>echo text ~/*.txt {a,b} $(echo foo) $((2+2)) $USER<br /></strong>text /home/me/ls-output.txt a b foo 4 me<br /> [me@linuxbox ~]$ <strong>echo &quot;text ~/*.txt {a,b} $(echo foo) $((2+2)) $USER&quot;<br /></strong>text ~/*.txt {a,b} foo 4 me<br /> [me@linuxbox ~]$ <strong>echo 'text ~/*.txt {a,b} $(echo foo) $((2+2)) $USER'<br /></strong>text ~/*.txt {a,b} $(echo foo) $((2+2)) $USER<br /> As we can see, with each succeeding level of quoting, more and more of the expansions <br />are suppressed.<br /> Escaping Characters<br />Sometimes we only want to quote a single character. To do this, we can precede a charac-<br />ter with a backslash, which in this context is called the  <em>escape character</em>. Often this is <br />done inside double quotes to selectively prevent an expansion:<br /> [me@linuxbox ~]$ <strong>echo &quot;The balance for user $USER is: \$5.00&quot;<br /></strong>The balance for user me is: $5.00<br /> It is also common to use escaping to eliminate the special meaning of a character in a <br />filename. For example, it is possible to use characters in filenames that normally have <br />special meaning to the shell. These would include “$”, “!”, “&amp;”, “ “, and others. To in-<br />clude a special character in a filename you can to this:<br /> [me@linuxbox ~]$ <strong>mv bad\&amp;filename good_filename</strong><br /> To allow a backslash character to appear, escape it by typing “\\”. Note that within single <br />quotes, the backslash loses its special meaning and is treated as an ordinary character.<br /> <strong>Backslash Escape Sequences<br /></strong>In addition to its role as the escape character, the backslash is also used as part of <br />a notation to represent certain special characters called <em>control codes</em>. The first 32 <br />characters in the  ASCII  coding scheme are used to transmit commands to tele-<br />type-like devices. Some of these codes are familiar (tab, backspace, linefeed, and <br />carriage return), while others are not (null, end-of-transmission, and acknowl-<br />edge).<br /> 77<br /></p>
<hr />
<p>7 – Seeing The World As The Shell Sees It<br /> <strong>Escape Sequence</strong><br /> <strong>Meaning</strong><br /> \a<br /> Bell (“Alert” - causes the computer to beep)<br /> \b<br /> Backspace<br /> \n<br /> Newline.  On Unix-like systems, this <br />produces a linefeed. <br /> \r<br /> Carriage return<br /> \t<br /> Tab<br /> The table above lists some of the common backslash escape sequences. The idea <br />behind this representation using the backslash originated in the C programming <br />language and has been adopted by many others, including the shell.<br />Adding the “-e” option to echo will enable interpretation of escape sequences. <br />You may also place them inside $' '. Here, using the sleep command, a sim-<br />ple program that just waits for the specified number of seconds and then exits, we <br />can create a primitive countdown timer:<br /> <strong>sleep 10; echo -e &quot;Time's up\a&quot;<br /></strong>We could also do this:<br /><strong>sleep 10; echo &quot;Time's up&quot; $'\a'</strong><br /> <strong>Summing Up<br /></strong>As we move forward with using the shell, we will find that expansions and quoting will <br />be used with increasing frequency, so it makes sense to get a good understanding of the <br />way they work. In fact, it could be argued that they are the most important subjects to <br />learn about the shell. Without a proper understanding of expansion, the shell will always <br />be a source of mystery and confusion, and much of it potential power wasted.<br /> <strong>Further Reading</strong><br /> ●<br /> The  bash  man page has major sections on both expansion and quoting which <br />cover these topics in a more formal manner.<br /> ●<br /> The <em>Bash Reference Manual</em> also contains chapters on expansion and quoting:<br /><a href="http://www.gnu.org/software/bash/manual/bashref.html">http://www.gnu.org/software/bash/manual/bashref.html </a><br /> 78<br /></p>
<hr />
<p>8 – Advanced Keyboard Tricks<br /> <em><strong>8 – Advanced Keyboard Tricks</strong></em><br /> I often kiddingly describe Unix as “the operating system for people who like to type.” Of <br />course, the fact that it even has a command line is a testament to that. But command line <br />users don't like to type <em>that</em> much. Why else would so many commands have such short <br />names like cp, ls, mv, and rm? In fact, one of the most cherished goals of the command <br />line is laziness; doing the most work with the fewest number of keystrokes. Another goal <br />is never having to lift your fingers from the keyboard, never reaching for the mouse. In <br />this chapter, we will look at bash features that make keyboard use faster and more effi-<br />cient.<br />The following commands will make an appearance:<br /> ●<br /> clear – Clear the screen<br /> ●<br /> history – Display the contents of the history list<br /> <strong>Command Line Editing<br /></strong>bash  uses a library (a shared collection of routines that different programs can use) <br />called <em>Readline</em> to implement command line editing. We have already seen some of this. <br />We know, for example, that the arrow keys move the cursor but there are many more fea-<br />tures. Think of these as additional tools that we can employ in our work. It’s not impor-<br />tant to learn all of them, but many of them are very useful. Pick and choose as desired.<br /> <strong>Note:</strong> Some of the key sequences below (particularly those which use the Alt key) <br />may be intercepted by the GUI for other functions. All of the key sequences should <br />work properly when using a virtual console.<br /> Cursor Movement<br />The following table lists the keys used to move the cursor:<br /> 79<br /></p>
<hr />
<p>8 – Advanced Keyboard Tricks<br /> <em>Table 8-1: Cursor Movement Commands</em><br /> <strong>Key</strong><br /> <strong>Action</strong><br /> Ctrl-a<br /> Move cursor to the beginning of the line.<br /> Ctrl-e<br /> Move cursor to the end of the line.<br /> Ctrl-f<br /> Move cursor forward one character; same as the right arrow key.<br /> Ctrl-b<br /> Move cursor backward one character; same as the left arrow key.<br /> Alt-f<br /> Move cursor forward one word.<br /> Alt-b<br /> Move cursor backward one word.<br /> Ctrl-l<br /> Clear the screen and move the cursor to the top left corner. The <br />clear command does the same thing.<br /> Modifying Text<br />Table 8-2 lists keyboard commands that are used to edit characters on the command line.<br /> <em>Table 8-2: Text Editing Commands</em><br /> <strong>Key</strong><br /> <strong>Action</strong><br /> Ctrl-d<br /> Delete the character at the cursor location<br /> Ctrl-t<br /> Transpose (exchange) the character at the cursor location with the <br />one preceding it.<br /> Alt-t<br /> Transpose the word at the cursor location with the one preceding it.<br /> Alt-l<br /> Convert the characters from the cursor location to the end of the <br />word to lowercase.<br /> Alt-u<br /> Convert the characters from the cursor location to the end of the <br />word to uppercase.<br /> Cutting And Pasting (Kil ing And Yanking) Text<br />The Readline documentation uses the terms <em>killing</em> and <em>yanking</em> to refer to what we would <br />commonly call cutting and pasting. Items that are cut are stored in a buffer called the <em>kill-<br />ring</em>.<br /> 80<br /></p>
<hr />
<p>Command Line Editing<br /> <em>Table 8-3: Cut And Paste Commands</em><br /> <strong>Key</strong><br /> <strong>Action</strong><br /> Ctrl-k<br /> Kill text from the cursor location to the end of line.<br /> Ctrl-u<br /> Kill text from the cursor location to the beginning of the line.<br /> Alt-d<br /> Kill text from the cursor location to the end of the current word.<br /> Alt-<br /> Kill text from the cursor location to the beginning of the current <br /> Backspace<br /> word. If the cursor is at the beginning of a word, kill the previous <br />word.<br /> Ctrl-y<br /> Yank text from the kill-ring and insert it at the cursor location.<br /> <strong>The Meta Key<br /></strong>If   you   venture   into   the   Readline   documentation,   which   can   be   found   in   the <br />READLINE section of the  bash man page, you will encounter the term “meta <br />key.” On modern keyboards this maps to the Alt key but it wasn't always so.<br />Back in the dim times (before PCs but after Unix) not everybody had their own <br />computer. What they might have had was a device called a <em>terminal</em>. A terminal <br />was a communication device that featured a text display screen and a keyboard <br />and just enough electronics inside to display text characters and move the cursor <br />around. It was attached (usually by serial cable) to a larger computer or the com-<br />munication network of a larger computer. There were many different brands of <br />terminals and they all had different keyboards and display feature sets. Since they <br />all tended to at least understand ASCII, software developers wanting portable ap-<br />plications wrote to the lowest common denominator. Unix systems have a very <br />elaborate way of dealing with terminals and their different display features. Since <br />the developers of Readline could not be sure of the presence of a dedicated extra <br />control key, they invented one and called it “meta.” While the Alt key serves as <br />the meta key on modern keyboards, you can also press and release the Esc key to <br />get the same effect as holding down the Alt key if you're still using a terminal <br />(which you can still do in Linux!).<br /> <strong>Completion<br /></strong>Another way that the shell can help you is through a mechanism called <em>completion</em>. Com-<br />pletion occurs when you press the tab key while typing a command. Let's see how this <br />works. Given a home directory that looks like this:<br /> 81<br /></p>
<hr />
<p>8 – Advanced Keyboard Tricks<br /> [me@linuxbox ~]$ <strong>ls<br /></strong>Desktop    ls-output.txt  Pictures  Templates      Videos<br /> Documents  Music          Public<br /> Try typing the following but <strong>don't press the Enter key</strong>:<br /> [me@linuxbox ~]$ <strong>ls l</strong><br /> Now press the tab key:<br /> [me@linuxbox ~]$ <strong>ls ls-output.txt</strong><br /> See how the shell completed the line for you? Let's try another one. Again, don't press <br />Enter:<br /> [me@linuxbox ~]$ <strong>ls D</strong><br /> Press tab:<br /> [me@linuxbox ~]$ <strong>ls D</strong><br /> No completion, just a beep. This happened because “D” matches more than one entry in <br />the directory. For completion to be successful, the “clue” you give it has to be unambigu-<br />ous. If we go further:<br /> [me@linuxbox ~]$ <strong>ls Do</strong><br />  Then press tab:<br /> [me@linuxbox ~]$ <strong>ls Documents</strong><br /> The completion is successful.<br />While this example shows completion of pathnames, which is its most common use, <br /> 82<br /></p>
<hr />
<p>Completion<br /> completion will also work on variables (if the beginning of the word is a “$”), user names <br />(if the word begins with “~”), commands (if the word is the first word on the line.) and <br />hostnames (if the beginning of the word is “@”). Hostname completion only works for <br />hostnames listed in /etc/hosts.<br />There are a number of control and meta key sequences that are associated with comple-<br />tion:<br /> <em>Table 8-4: Completion Commands</em><br /> <strong>Key</strong><br /> <strong>Action</strong><br /> Alt-?<br /> Display list of possible completions. <em>On most systems you can also <br />do this by pressing the tab key a second time, which is much easier.</em><br /> Alt-*<br /> Insert all possible completions. This is useful when you want to use <br />more than one possible match.<br /> There quite a few more that I find rather obscure. You can see a list in the  bash man <br />page under “READLINE”.<br /> <strong>Programmable Completion<br /></strong>Recent versions of  bash have a facility called  <em>programmable completion</em>. Pro-<br />grammable completion allows you (or more likely, your distribution provider) to <br />add additional completion rules. Usually this is done to add support for specific <br />applications. For example it is possible to add completions for the option list of a <br />command or match particular file types that an application supports. Ubuntu has a <br />fairly large set defined by default. Programmable completion is implemented by <br />shell functions, a kind of mini shell script that we will cover in later chapters. If <br />you are curious, try:<br /><strong>set | less<br /></strong>and see if you can find them. Not all distributions include them by default.<br /> <strong>Using History<br /></strong>As we discovered in Chapter 1, bash maintains a history of commands that have been <br />entered.   This   list   of   commands   is   kept   in   your   home   directory   in   a   file   called <br />.bash_history. The history facility is a useful resource for reducing the amount of <br />typing you have to do, especially when combined with command line editing.<br /> 83<br /></p>
<hr />
<p>8 – Advanced Keyboard Tricks<br /> Searching History<br />At any time, we can view the contents of the history list by:<br /> [me@linuxbox ~]$ <strong>history | less</strong><br /> By default, bash stores the last 500 commands you have entered. We will see how to ad-<br />just this value in a later chapter. Let's say we want to find the commands we used to list <br />/usr/bin. One way we could do this:<br /> [me@linuxbox ~]$ <strong>history | grep /usr/bin</strong><br /> And let's say that among our results we got a line containing an interesting command like <br />this:<br />   88  ls -l /usr/bin &gt; ls-output.txt<br />The number “88” is the line number of the command in the history list. We could use this <br />immediately using another type of expansion called <em>history expansion</em>. To use our discov-<br />ered line we could do this:<br /> [me@linuxbox ~]$ <strong>!88</strong><br /> bash  will expand “!88” into the contents of the eighty-eighth line in the history list. <br />There are other forms of history expansion that we will cover a little later.<br /> bash also provides the ability to search the history list incrementally. This means that we <br />can tell bash to search the history list as we enter characters, with each additional char-<br />acter further refining our search. To start incremental search press Ctrl-r followed by <br />the text you are looking for. When you find it, you can either press Enter to execute the <br />command or press Ctrl-j to copy the line from the history list to the current command <br />line. To find the next occurrence of the text (moving “up” the history list), press Ctrl-r <br />again. To quit searching, press either Ctrl-g or Ctrl-c. Here we see it in action:<br /> [me@linuxbox ~]$ <br /> First press Ctrl-r:<br /> 84<br /></p>
<hr />
<p>Using History<br /> (reverse-i-search)`': <br /> The prompt changes to indicate that we are performing a reverse incremental search. It is <br />“reverse” because we are searching from “now” to some time in the past. Next, we start <br />typing our search text. In this example “/usr/bin”:<br /> (reverse-i-search)`<strong>/usr/bin</strong>': ls -l /usr/bin &gt; ls-output.txt<br /> Immediately, the search returns our result. With our result, we can execute the command <br />by pressing Enter, or we can copy the command to our current command line for fur-<br />ther editing by pressing Ctrl-j. Let's copy it. Press Ctrl-j:<br /> [me@linuxbox ~]$ <strong>ls -l /usr/bin &gt; ls-output.txt</strong><br /> Our shell prompt returns and our command line is loaded and ready for action!<br />The table below lists some of the keystrokes used to manipulate the history list:<br /> <em>Table 8-5: History Commands</em><br /> <strong>Key</strong><br /> <strong>Action</strong><br /> Ctrl-p<br /> Move to the previous history entry. Same action as the up arrow.<br /> Ctrl-n<br /> Move to the next history entry. Same action as the down arrow.<br /> Alt-&lt;<br /> Move to the beginning (top) of the history list.<br /> Alt-&gt;<br /> Move to the end (bottom) of the history list, i.e., the current <br />command line.<br /> Ctrl-r<br /> Reverse incremental search. Searches incrementally from the <br />current command line up the history list.<br /> Alt-p<br /> Reverse search, non-incremental. With this key, type in the search <br />string and press enter before the search is performed.<br /> Alt-n<br /> Forward search, non-incremental.<br /> Ctrl-o<br /> Execute the current item in the history list and advance to the next <br />one. This is handy if you are trying to re-execute a sequence of <br />commands in the history list.<br /> 85<br /></p>
<hr />
<p>8 – Advanced Keyboard Tricks<br /> History Expansion<br />The shell offers a specialized type of expansion for items in the history list by using the <br />“!” character. We have already seen how the exclamation point can be followed by a <br />number to insert an entry from the history list. There are a number of other expansion fea-<br />tures:<br /> <em>Table 8-6: History Expansion Commands</em><br /> <strong>Sequence</strong><br /> <strong>Action</strong><br /> !!<br /> Repeat the last command. It is probably easier to press up arrow and <br />enter.<br /> !<em>number</em><br /> Repeat history list item <em>number</em>.<br /> !string<br /> Repeat last history list item starting with string. <br /> !?string<br /> Repeat last history list item containing string.<br /> I would caution against using the “!string” and “!?string” forms unless you are absolutely <br />sure of the contents of the history list items.<br />There are many more elements available in the history expansion mechanism, but this <br />subject is already too arcane and our heads may explode if we continue. The HISTORY <br />EXPANSION section of the bash man page goes into all the gory details. Feel free to <br />explore!<br /> <strong>script<br /></strong>In addition to the command history feature in bash, most Linux distributions in-<br />clude a program called script that can be used to record an entire shell session <br />and store it in a file. The basic syntax of the command is:<br />script [<em>file</em>]<br />where <em>file</em> is the name of the file used for storing the recording. If no file is speci-<br />fied, the file typescript is used. See the script man page for a complete <br />list of the program’s options and features.<br /> <strong>Summing Up<br /></strong>In this chapter we have covered  <em>some</em>  of the keyboard tricks that the shell provides to <br />help hardcore typists reduce their workloads. I suspect that as time goes by and you be-<br />come more involved with the command line, you will refer back to this chapter to pick up <br /> 86<br /></p>
<hr />
<p>Summing Up<br /> more of these tricks. For now, consider them optional and potentially helpful.<br /> <strong>Further Reading</strong><br /> ●<br /> The Wikipedia has a good article on computer terminals:<br /><a href="http://en.wikipedia.org/wiki/Computer_terminal">http://en.wikipedia.org/wiki/Computer_terminal</a><br /> 87<br /></p>
<hr />
<p>9 – Permissions<br /> <em><strong>9 – Permissions</strong></em><br /> Operating systems in the Unix tradition differ from those in the MS-DOS tradition in that <br />they are not only <em>multitasking</em> systems, but also <em>multi-user</em> systems, as well.<br />What exactly does this mean? It means that more than one person can be using the com-<br />puter at the same time. While a typical computer will likely have only one keyboard and <br />monitor, it can still be used by more than one user. For example, if a computer is attached <br />to a network or the Internet, remote users can log in via ssh (secure shell) and operate <br />the   computer.   In   fact,   remote   users   can   execute   graphical   applications   and   have   the <br />graphical output appear on a remote display. The X Window System supports this as part <br />of its basic design.<br />The multiuser capability of Linux is not a recent &quot;innovation,&quot; but rather a feature that is <br />deeply embedded into the design of the operating system. Considering the environment in <br />which Unix was created, this makes perfect sense. Years ago, before computers were <br />&quot;personal,&quot; they were large, expensive, and centralized. A typical university computer <br />system, for example, consisted of a large central computer located in one building and <br />terminals which were located throughout the campus, each connected to the large central <br />computer. The computer would support many users at the same time.<br />In order to make this practical, a method had to be devised to protect the users from each <br />other. After all, the actions of one user could not be allowed to crash the computer, nor <br />could one user interfere with the files belonging to another user.<br />In this chapter we are going to look at this essential part of system security and introduce <br />the following commands:<br /> ●<br /> id – Display user identity<br /> ●<br /> chmod – Change a file's mode<br /> ●<br /> umask – Set the default file permissions<br /> ●<br /> su – Run a shell as another user<br /> ●<br /> sudo – Execute a command as another user <br /> ●<br /> chown – Change a file's owner<br /> 88<br /></p>
<hr />
<p>9 – Permissions<br /> ●<br /> chgrp – Change a file's group ownership<br /> ●<br /> passwd – Change a user's password<br /> <strong>Owners, Group Members, And Everybody Else<br /></strong>When we were exploring the system back in Chapter 3, we may have encountered a prob-<br />lem when trying to examine a file such as /etc/shadow:<br /> [me@linuxbox ~]$ <strong>file /etc/shadow<br /></strong>/etc/shadow: regular file, no read permission<br /> [me@linuxbox ~]$ <strong>less /etc/shadow<br /></strong>/etc/shadow: Permission denied<br /> The reason for this error message is that, as regular users, we do not have permission to <br />read this file.<br />In the Unix security model, a user may <em>own</em> files and directories. When a user owns a file <br />or directory, the user has control over its access. Users can, in turn, belong to a  <em>group <br /></em>consisting of one or more users who are given access to files and directories by their <br />owners. In addition to granting access to a group, an owner may also grant some set of <br />access rights to everybody, which in Unix terms is referred to as the <em>world</em>. To find out in-<br />formation about your identity, use the id command:<br /> [me@linuxbox ~]$ <strong>id<br /></strong>uid=500(me) gid=500(me) groups=500(me)<br /> Let's look at the output. When user  accounts  are created, users are assigned a number <br />called a <em>user ID</em> or <em>uid</em> which is then, for the sake of the humans, mapped to a username. <br />The user is assigned a <em>primary group ID</em> or <em>gid</em> and may belong to additional groups. The <br />above example is from a Fedora system. On other systems, such as Ubuntu, the output <br />may look a little different:<br /> [me@linuxbox ~]$ <strong>id<br /></strong>uid=1000(me) gid=1000(me) <br /> groups=4(adm),20(dialout),24(cdrom),25(floppy),29(audio),30(dip),44(v<br />ideo),46(plugdev),108(lpadmin),114(admin),1000(me)<br /> As we can see, the uid and gid numbers are different. This is simply because Fedora starts <br />its numbering of regular user accounts at 500, while Ubuntu starts at 1000. We can also <br /> 89<br /></p>
<hr />
<p>9 – Permissions<br /> see that the Ubuntu user belongs to a lot more groups. This has to do with the way <br />Ubuntu manages privileges for system devices and services.<br />So where does this information come from? Like so many things in Linux, from a couple <br />of text files. User accounts are defined in the /etc/passwd file and groups are defined <br />in the  /etc/group  file. When user accounts and groups are created, these files are <br />modified along with /etc/shadow which holds information about the user's password. <br />For each user account, the /etc/passwd file defines the user (login) name, uid, gid, <br />the account's real name, home directory, and login shell. If you examine the contents of <br />/etc/passwd  and  /etc/group, you will notice that besides the regular user ac-<br />counts, there are accounts for the superuser (uid 0) and various other system users.<br />In the next chapter, when we cover processes, you will see that some of these other <br />“users” are, in fact, quite busy.<br />While many Unix-like systems assign regular users to a common group such as “users”, <br />modern Linux practice is to create a unique, single-member group with the same name as <br />the user. This makes certain types of permission assignment easier.<br /> <strong>Reading, Writing, And Executing<br /></strong>Access rights to files and directories are defined in terms of read access, write access, and <br />execution access. If we look at the output of the ls command, we can get some clue as to <br />how this is implemented:<br /> [me@linuxbox ~]$ <strong>&gt; foo.txt<br /></strong>[me@linuxbox ~]$ <strong>ls -l foo.txt</strong><br /> -rw-rw-r-- 1 me    me   0 2008-03-06 14:52 foo.txt<br /> The first ten characters of the listing are the <em>file attributes</em>. The first of these characters is <br />the <em>file type</em>. Here are the file types you are most likely to see (there are other, less com-<br />mon types too):<br /> <em>Table 9-1: File Types</em><br /> <strong>Attribute</strong><br /> <strong>File Type</strong><br /> -<br /> A regular file.<br /> d<br /> A directory.<br /> l<br /> A symbolic link. Notice that with symbolic links, the remaining file <br />attributes are always “rwxrwxrwx” and are dummy values. The real <br />file attributes are those of the file the symbolic link points to.<br /> 90<br /></p>
<hr />
<p>Reading, Writing, And Executing<br /> c<br /> A <em>character special file</em>. This file type refers to a device that <br />handles data as a stream of bytes, such as a terminal or modem.<br /> b<br /> A <em>block special file</em>. This file type refers to a device that handles <br />data in blocks, such as a hard drive or CD-ROM drive.<br /> The remaining nine characters of the file attributes, called the <em>file mode,</em> represent the <br />read, write, and execute permissions for the file's owner, the file's group owner, and <br />everybody else:<br /> <strong>Owner</strong><br /> <strong>Group</strong><br /> <strong>World</strong><br /> rwx<br /> rwx<br /> rwx<br /> When set, the r, w, and x mode attributes have the following effect on files and directo-<br />ries:<br /> <em>Table 9-2: Permission Attributes</em><br /> <strong>Attribute</strong><br /> <strong>Files</strong><br /> <strong>Directories</strong><br /> r<br /> Allows a file to be opened and <br /> Allows a directory's contents to <br /> read. <br /> be listed if the execute attribute <br />is also set.<br /> w<br /> Allows a file to be written to or <br /> Allows files within a directory <br /> truncated, however this attribute <br /> to be created, deleted, and <br /> does not allow files to be <br /> renamed if the execute attribute <br /> renamed or deleted. The ability <br /> is also set.<br /> to delete or rename files is <br />determined by directory <br />attributes.<br /> x<br /> Allows a file to be treated as a <br /> Allows a directory to be <br /> program and executed. Program <br /> entered, e.g., cd <em>directory</em>.<br /> files written in scripting <br />languages must also be set as <br />readable to be executed.<br /> Here are some examples of file attribute settings:<br /> 91<br /></p>
<hr />
<p>9 – Permissions<br /> <em>Table 9-3: Permission Attribute Examples</em><br /> <strong>File Attributes</strong><br /> <strong>Meaning</strong><br /> -rwx------<br /> A regular file that is readable, writable, and executable by the <br />file's owner. No one else has any access.<br /> -rw-------<br /> A regular file that is readable and writable by the file's owner. <br />No one else has any access.<br /> -rw-r--r--<br /> A regular file that is readable and writable by the file's owner. <br />Members of the file's owner group may read the file. The file is <br />world-readable.<br /> -rwxr-xr-x<br /> A regular file that is readable, writable, and executable by the <br />file's owner. The file may be read and executed by everybody <br />else. <br /> -rw-rw----<br /> A regular file that is readable and writable by the file's owner <br />and members of the file's group owner only.<br /> lrwxrwxrwx<br /> A symbolic link. All symbolic links have “dummy” <br />permissions. The real permissions are kept with the actual file <br />pointed to by the symbolic link.<br /> drwxrwx---<br /> A directory. The owner and the members of the owner group <br />may enter the directory and, create, rename and remove files <br />within the directory.<br /> drwxr-x---<br /> A directory. The owner may enter the directory and create, <br />rename and delete files within the directory. Members of the <br />owner group may enter the directory but cannot create, delete <br />or rename files.<br /> chmod – Change File Mode<br />To change the mode (permissions) of a file or directory, the chmod command is used. Be <br />aware that only the file’s owner or the superuser can change the mode of a file or direc-<br />tory. chmod supports two distinct ways of specifying mode changes: octal number repre-<br />sentation, or symbolic representation. We will cover octal number representation first.<br /> 92<br /></p>
<hr />
<p>Reading, Writing, And Executing<br /> <strong>What The Heck Is Octal?<br /></strong><em>Octal</em> (base 8), and its cousin, <em>hexadecimal</em> (base 16) are number systems often <br />used to express numbers on computers. We humans, owing to the fact that we (or <br />at least most of us) were born with ten fingers, count using a base 10 number sys-<br />tem. Computers, on the other the other hand, were born with only one finger and <br />thus do all all their counting in <em>binary</em> (base 2). Their number system only has two <br />numerals, 0 and 1. So in binary, counting looks like this:<br />0, 1, 10, 11, 100, 101, 110, 111, 1000, 1001, 1010, 1011...<br />In octal, counting is done with the numerals zero through seven, like so:<br />0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21...<br />Hexadecimal counting uses the numerals zero through nine plus the letters “A” <br />through “F”:<br />0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F, 10, 11, 12, 13...<br />While we can see the sense in binary (since computers only have one finger), <br />what are octal and hexadecimal good for? The answer has to do with human con-<br />venience. Many times, small portions of data are represented on computers as <em>bit <br />patterns</em>. Take for example an RGB color. On most computer displays, each pixel <br />is composed of three color components: eight bits of red, eight bits of green, and <br />eight bits of blue. A lovely medium blue would be a 24 digit number:<br />010000110110111111001101<br />How would you like to read and write those kinds of numbers all day? I didn't <br />think so. Here's where another number system would help. Each digit in a hexa-<br />decimal number represents four digits in binary. In octal, each digit represents <br />three binary digits. So our 24 digit medium blue could be condensed down to a <br />six digit hexadecimal number:<br />436FCD<br />Since the digits in the hexadecimal number “line up” with the bits in the binary <br />number we can see that the red component of our color is 43, the green 6F, and <br />the blue CD.<br />These days, hexadecimal notation (often spoken as “hex”) is more common than <br />octal, but as we shall soon see, octal's ability to express three bits of binary will <br />be very useful... <br /> With octal notation we use octal numbers to set the pattern of desired permissions. Since <br />each digit in an  octal  number represents three  binary  digits, this maps nicely to  the <br />scheme used to store the file mode. This table shows what we mean:<br /> <em>Table 9-4: File Modes In Binary And Octal</em><br /> <strong>Octal</strong><br /> <strong>Binary</strong><br /> <strong>File Mode</strong><br /> 93<br /></p>
<hr />
<p>9 – Permissions<br /> 0<br /> 000<br /> ---<br /> 1<br /> 001<br /> --x<br /> 2<br /> 010<br /> -w-<br /> 3<br /> 011<br /> -wx<br /> 4<br /> 100<br /> r--<br /> 5<br /> 101<br /> r-x<br /> 6<br /> 110<br /> rw-<br /> 7<br /> 111<br /> rwx<br /> By using three octal digits, we can set the file mode for the owner, group owner, and <br />world:<br /> [me@linuxbox ~]$ <strong>&gt; foo.txt<br /></strong>[me@linuxbox ~]$ <strong>ls -l foo.txt</strong><br /> -rw-rw-r-- 1 me    me   0 2008-03-06 14:52 foo.txt<br />[me@linuxbox ~]$ <strong>chmod 600 foo.txt</strong><br /> [me@linuxbox ~]$ <strong>ls -l foo.txt<br /></strong>-rw------- 1 me    me   0 2008-03-06 14:52 foo.txt<br /> By passing the argument “600”, we were able to set the permissions of the owner to read <br />and write while removing all permissions from the group owner and world. Though re-<br />membering the octal to binary mapping may seem inconvenient, you will usually only <br />have to use a few common ones: 7 (rwx), 6 (rw-), 5 (r-x), 4 (r--), and 0 (---).<br /> chmod also supports a symbolic notation for specifying file modes. Symbolic notation is <br />divided into three parts: who the change will affect, which operation will be performed, <br />and what permission will be set. To specify who is affected, a combination of the charac-<br />ters “u”, “g”, “o”, and “a” is used as follows:<br /> <em>Table 9-5: chmod Symbolic Notation</em><br /> <strong>Symbol</strong><br /> <strong>Meaning</strong><br /> u<br /> Short for “user” but means the file or directory owner.<br /> g<br /> Group owner.<br /> o<br /> Short for “others,” but means world.<br /> a<br /> Short for “all.” The combination of “u”, “g”, and “o”.<br /> 94<br /></p>
<hr />
<p>Reading, Writing, And Executing<br /> If no character is specified, “all” will be assumed. The operation may be a “+” indicating <br />that a permission is to be added, a “-” indicating that a permission is to be taken away, or <br />a “=” indicating that only the specified permissions are to be applied and that all others <br />are to be removed.<br />Permissions are specified with the “r”, “w”, and “x” characters. Here are some examples <br />of symbolic notation:<br /> <em>Table 9-6: chmod Symbolic Notation Examples</em><br /> <strong>Notation</strong><br /> <strong>Meaning</strong><br /> u+x<br /> Add execute permission for the owner.<br /> u-x<br /> Remove execute permission from the owner.<br /> +x<br /> Add execute permission for the owner, group, and world. <br />Equivalent to a+x.<br /> o-rw<br /> Remove the read and write permission from anyone besides the <br />owner and group owner.<br /> go=rw<br /> Set the group owner and anyone besides the owner to have read and <br />write permission. If either the group owner or world previously had <br />execute permissions, they are removed.<br /> u+x,go=rx<br /> Add execute permission for the owner and set the permissions for <br />the group and others to read and execute. Multiple specifications <br />may be separated by commas.<br /> Some people prefer to use octal notation, some folks really like the symbolic. Symbolic <br />notation does offer the advantage of allowing you to set a single attribute without disturb-<br />ing any of the others.<br />Take a look at the chmod man page for more details and a list of options. A word of cau-<br />tion regarding the “--recursive” option: it acts on both files and directories, so it's not as <br />useful as one would hope since, we rarely want files and directories to have the same per-<br />missions.<br /> Setting File Mode With The GUI<br />Now that we have seen how the permissions on files and directories are set, we can better <br />understand the permission dialogs in the GUI. In both  Nautilus  (GNOME) and  Kon-<br />queror (KDE), right-clicking a file or directory icon will expose a properties dialog. Here <br />is an example from KDE 3.5:<br /> 95<br /></p>
<hr />
<p>9 – Permissions<br /> <em>Figure 2: KDE 3.5 File <br />Properties Dialog</em><br /> Here we can see the settings for the owner, group, and world. In KDE, clicking the “Ad-<br />vanced Permissions” button brings up another dialog that allows you to set each of the <br />mode attributes individually. Another victory for understanding brought to us by the com-<br />mand line!<br /> umask – Set Default Permissions<br />The umask command controls the default permissions given to a file when it is created. <br />It uses octal notation to express a  <em>mask</em>  of bits to be removed from a file's mode at-<br />tributes. Let's take a look:<br /> [me@linuxbox ~]$ <strong>rm -f foo.txt<br /></strong>[me@linuxbox ~]$ <strong>umask</strong><br /> 0002<br />[me@linuxbox ~]$ <strong>&gt; foo.txt</strong><br /> [me@linuxbox ~]$ <strong>ls -l foo.txt<br /></strong>-rw-rw-r-- 1 me    me   0 2008-03-06 14:53 foo.txt<br /> We first removed any old copy of foo.txt to make sure we were starting fresh. Next, <br />we ran the umask command without an argument to see the current value. It responded <br /> 96<br /></p>
<hr />
<p>Reading, Writing, And Executing<br /> with the value 0002 (the value 0022 is another common default value), which is the oc-<br />tal representation of our mask. We next create a new instance of the file foo.txt and <br />observe its permissions.<br />We can see that both the owner and group get read and write permission, while everyone <br />else only gets read permission. The reason that world does not have write permission is <br />because of the value of the mask. Let's repeat our example, this time setting the mask our-<br />selves:<br /> [me@linuxbox ~]$ <strong>rm foo.txt<br /></strong>[me@linuxbox ~]$ <strong>umask 0000</strong><br /> [me@linuxbox ~]$ <strong>&gt; foo.txt<br /></strong>[me@linuxbox ~]$ <strong>ls -l foo.txt</strong><br /> -rw-rw-rw- 1 me    me   0 2008-03-06 14:58 foo.txt<br /> When we set the mask to  0000 (effectively turning it off), we see that the file is now <br />world writable. To understand how this works, we have to look at octal numbers again. If <br />we take the mask and expand it into binary, and then compare it to the attributes we can <br />see what happens:<br /> <strong>Original file mode</strong><br /> --- rw- rw- rw-<br /> <strong>Mask</strong><br /> 000 000 000 010<br /> <strong>Result</strong><br /> --- rw- rw- r--<br /> Ignore for the moment the leading zeros (we'll get to those in a minute) and observe that <br />where the 1 appears in our mask, an attribute was removed—<br />   i n this case, the world write <br /> permission. That's what the mask does. Everywhere a 1 appears in the binary value of the <br />mask, an attribute is unset. If we look at a mask value of 0022, we can see what it does:<br /> <strong>Original file mode</strong><br /> --- rw- rw- rw-<br /> <strong>Mask</strong><br /> 000 000 010 010<br /> <strong>Result</strong><br /> --- rw- r-- r--<br /> Again, where a 1 appears in the binary value, the corresponding attribute is unset. Play <br />with some values (try some sevens) to get used to how this works. When you're done, re-<br />member to clean up:<br /> 97<br /></p>
<hr />
<p>9 – Permissions<br /> [me@linuxbox ~]$ <strong>rm foo.txt; umask 0002</strong><br /> Most of the time you won't have to change the mask; the default provided by your distri-<br />bution will be fine. In some high-security situations, however, you will want to control it.<br /> <strong>Some Special Permissions<br /></strong>Though we usually see an octal permission mask expressed as a three digit num-<br />ber, it is more technically correct to express it in four digits. Why? Because, in ad-<br />dition to read, write, and execute permission, there are some other, less used, per-<br />mission settings.<br />The first of these is the <em>setuid bit</em> (octal 4000). When applied to an executable file, <br />it sets the <em>effective user ID</em> from that of the real user (the user actually running the <br />program) to that of the program's owner. Most often this is given to a few pro-<br />grams owned by the superuser. When an ordinary user runs a program that is “<em>se-<br />tuid root</em>” , the program runs with the effective privileges of the superuser. This <br />allows the program to access files and directories that an ordinary user would nor-<br />mally be prohibited from accessing. Clearly, because this raises security concerns, <br />the number of setuid programs must be held to an absolute minimum.<br />The second less-used setting is the <em>setgid bit</em> (octal 2000) which, like the setuid <br />bit, changes the <em>effective group ID</em> from the <em>real group ID</em> of the real user to that <br />of the file owner. If the setgid bit is set on a directory, newly created files in the <br />directory will be given the group ownership of the directory rather the group own-<br />ership of the file's creator. This is useful in a shared directory when members of a <br />common group need access to all the files in the directory, regardless of the file <br />owner's primary group.<br />The third is called the  <em>sticky bit</em>  (octal 1000). This is a holdover from ancient <br />Unix, where it was possible to mark an executable file as “not swappable.” On <br />files, Linux ignores the sticky bit, but if applied to a directory, it prevents users <br />from deleting or renaming files unless the user is either the owner of the directory, <br />the owner of the file, or the superuser. This is often used to control access to a <br />shared directory, such as /tmp. <br />Here are some examples of using chmod with symbolic notation to set these spe-<br />cial permissions. First assigning setuid to a program:<br />chmod u+s <em>program<br /></em>Next, assigning setgid to a directory:<br />chmod g+s <em>dir<br /></em>Finally, assigning the sticky bit to a directory:<br />chmod +t <em>dir</em><br /> 98<br /></p>
<hr />
<p>Reading, Writing, And Executing<br /> When viewing the output from  ls, you can determine the special permissions. <br />Here are some examples. First, a program that is setuid:<br />-rw<strong>s</strong>r-xr-x<br />A directory that has the setgid attribute:<br />drwxrw<strong>s</strong>r-x<br />A directory with the sticky bit set:<br />drwxrwxrw<strong>t</strong><br /> <strong>Changing Identities<br /></strong>At various times, we may find it necessary to take on the identity of another user. Often <br />we want to gain superuser privileges to carry out some administrative task, but it is also <br />possible to “become” another regular user for such things as testing an account. There are <br />three ways to take on an alternate identity:<br /> 1. Log out and log back in as the alternate user.<br />2. Use the su command.<br />3. Use the sudo command.<br /> We will skip the first technique since we know how to do it and it lacks the convenience <br />of the other two. From within our own shell session, the su command allows you to as-<br />sume the identity of another user, and either start a new shell session with that user's IDs, <br />or to issue a single command as that user. The sudo command allows an administrator to <br />set up a configuration file called  /etc/sudoers, and define specific commands that <br />particular users are permitted to execute under an assumed identity. The choice of which <br />command to use is largely determined by which Linux distribution you use. Your distri-<br />bution probably includes both commands, but its configuration will favor either one or <br />the other. We'll start with su.<br /> su – Run A Shell With Substitute User And Group IDs<br />The su command is used to start a shell as another user. The command syntax looks like <br />this:<br /> <strong>su [-[l]] [<em>user</em></strong><strong>]</strong><br /> If the “-l” option is included, the resulting shell session is a <em>login shell</em> for the specified <br />user.  This  means  that  the   user's  environment  is  loaded  and  the   working  directory  is <br /> 99<br /></p>
<hr />
<p>9 – Permissions<br /> changed to the user's home directory. This is usually what we want. If the user is not <br />specified, the superuser is assumed. Notice that (strangely) the “-l” may be abbreviated <br />“-”, which is how it is most often used. To start a shell for the superuser, we would do <br />this:<br /> [me@linuxbox ~]$ <strong>su -<br /></strong>Password:<br /> [root@linuxbox ~]#<br /> After entering the command, we are prompted for the superuser's password. If it is suc-<br />cessfully entered, a new shell prompt appears indicating that this shell has superuser priv-<br />ileges (the trailing “#” rather than a “$”) and the current working directory is now the <br />home directory for the superuser (normally /root.) Once in the new shell, we can carry <br />out commands as the superuser. When finished, enter “exit” to return to the previous <br />shell:<br /> [root@linuxbox ~]# <strong>exit</strong><br /> [me@linuxbox ~]$<br /> It is also possible to execute a single command rather than starting a new interactive com-<br />mand by using su this way:<br /> su -c '<em>command</em>'<br /> Using this form, a single command line is passed to the new shell for execution. It is im-<br />portant to enclose the command in quotes, as we do not want expansion to occur in our <br />shell, but rather in the new shell:<br /> [me@linuxbox ~]$ <strong>su -c 'ls -l /root/*'<br /></strong>Password:<br /> -rw------- 1 root root     754 2007-08-11 03:19 /root/anaconda-ks.cfg<br /> /root/Mail:<br />total 0<br /> [me@linuxbox ~]$<br /> 100<br /></p>
<hr />
<p>Changing Identities<br /> sudo – Execute A Command As Another User<br />The sudo command is like su in many ways, but has some important additional capabil-<br />ities. The administrator can configure  sudo to allow an ordinary user to execute com-<br />mands as a different user (usually the superuser) in a very controlled way. In particular, a <br />user may be restricted to one or more specific commands and no others. Another impor-<br />tant difference is that the use of  sudo  does not require access to the superuser's pass-<br />word. To authenticate using sudo, the user uses his/her own password. Let's say, for ex-<br />ample, that  sudo  has been configured to allow us to run a fictitious backup program <br />called “backup_script”, which requires superuser privileges. With sudo it would be done <br />like this:<br /> [me@linuxbox ~]$ <strong>sudo backup_script<br /></strong>Password:<br /> System Backup Starting...<br /> After entering the command, we are prompted for our password (not the superuser's) and <br />once the authentication is complete, the specified command is carried out. One important <br />difference between su and sudo is that sudo does not start a new shell, nor does it load <br />another user's environment. This means that commands do not need to be quoted any dif-<br />ferently than they would be without using sudo. Note that this behavior can be overrid-<br />den by specifying various options. See the sudo man page for details.<br />To see what privileges are granted by sudo, use the “-l” option to list them:<br /> [me@linuxbox ~]$ <strong>sudo -l</strong><br /> User me may run the following commands on this host:<br />    (ALL) ALL<br /> <strong>Ubuntu And sudo<br /></strong>One of the recurrent problems for regular users is how to perform certain tasks <br />that require superuser privileges. These tasks include installing and updating soft-<br />ware, editing system configuration files, and accessing devices. In the Windows <br />world, this is often done by giving users administrative privileges. This allows <br />users to perform these tasks. However, it also enables programs executed by the <br /> 101<br /></p>
<hr />
<p>9 – Permissions<br /> user to have the same abilities. This is desirable in most cases, but it also permits <br /><em>malware</em> (malicious software) such as viruses to have free reign of the computer.<br />In the Unix world, there has always been a larger division between regular users <br />and administrators, owing to the multiuser heritage of Unix. The approach taken <br />in Unix is to grant superuser privileges only when needed. To do this, the su and <br />sudo commands are commonly used.<br />Up until a few of years ago, most Linux distributions relied on su for this pur-<br />pose. su didn't require the configuration that sudo required, and having a root <br />account is traditional in Unix. This introduced a problem. Users were tempted to <br />operate as root unnecessarily. In fact, some users operated their systems as the <br />root user exclusively, since it does away with all those annoying “permission de-<br />nied” messages. This is how you reduce the security of a Linux system to that of a <br />Windows system. Not a good idea.<br />When  Ubuntu  was   introduced,   its   creators   took   a   different   tack.   By   default, <br />Ubuntu disables logins to the root account (by failing to set a password for the ac-<br />count), and instead uses sudo to grant superuser privileges. The initial user ac-<br />count is granted full access to superuser privileges via sudo and may grant simi-<br />lar powers to subsequent user accounts.<br /> chown – Change File Owner And Group<br />The chown command is used to change the owner and group owner of a file or directory. <br />Superuser privileges are required to use this command. The syntax of chown looks like <br />this:<br /> <strong>chown [owner][:[group]] file...</strong><br /> chown can change the file owner and/or the file group owner depending on the first ar-<br />gument of the command. Here are some examples:<br /> <em>Table 9-7: chown Argument Examples</em><br /> <strong>Argument</strong><br /> <strong>Results</strong><br /> bob<br /> Changes the ownership of the file from its current owner to user <br />bob.<br /> bob:users<br /> Changes the ownership of the file from its current owner to user <br />bob and changes the file group owner to group users.<br /> 102<br /></p>
<hr />
<p>Changing Identities<br /> :admins<br /> Changes the group owner to the group admins. The file owner is <br />unchanged.<br /> bob:<br /> Change the file owner from the current owner to user bob and <br />changes the group owner to the login group of user bob.<br /> Let's say that we have two users;  janet, who has access to superuser privileges and <br />tony, who does not. User janet wants to copy a file from her home directory to the <br />home directory of user tony. Since user janet wants tony to be able to edit the file, <br />janet changes the ownership of the copied file from janet to tony:<br /> [janet@linuxbox ~]$ <strong>sudo cp myfile.txt ~tony<br /></strong>Password:<br /> [janet@linuxbox ~]$ <strong>sudo ls -l ~tony/myfile.txt<br /></strong> -rw-r--r-- 1 root  root  8031 2008-03-20 14:30 /home/tony/myfile.txt<br /> [janet@linuxbox ~]$ <strong>sudo chown tony: ~tony/myfile.txt<br /></strong>[janet@linuxbox ~]$ <strong>sudo ls -l ~tony/myfile.txt</strong><br />  -rw-r--r-- 1 tony  tony  8031 2008-03-20 14:30 /home/tony/myfile.txt<br /> Here we see user janet copy the file from her directory to the home directory of user <br />tony. Next,  janet  changes the ownership of the file from  root  (a result of using <br />sudo) to tony. Using the trailing colon in the first argument, janet also changed the <br />group ownership of the file to the login group of  tony, which happens to be group <br />tony.<br />Notice that after the first use of sudo, janet was not prompted for her password? This <br />is because sudo, in most configurations, “trusts” you for several minutes until its timer <br />runs out.<br /> chgrp – Change Group Ownership<br />In older versions of Unix, the chown command only changed file ownership, not group <br />ownership. For that purpose, a separate command, chgrp was used. It works much the <br />same way as chown, except for being more limited.<br /> <strong>Exercising Our Privileges<br /></strong>Now that we have learned how this permissions thing works, it's time to show it off. We <br />are going to demonstrate the solution to a common problem—<br />   s etting up a shared direc-<br /> tory. Let's imagine that we have two users named “bill” and “karen.” They both have mu-<br />sic CD collections and wish to set up a shared directory, where they will each store their <br /> 103<br /></p>
<hr />
<p>9 – Permissions<br /> music files as  Ogg Vorbis  or  MP3. User  bill  has access to superuser privileges via <br />sudo. <br />The first thing that needs to happen is creating a group that will have both  bill  and <br />karen  as members. Using the graphical user management tool,  bill  creates a group <br />called music and adds users bill and karen to it:<br /> <em>Figure 3: Creating A New Group With GNOME</em><br /> Next, bill creates the directory for the music files:<br /> [bill@linuxbox ~]$ <strong>sudo mkdir /usr/local/share/Music</strong><br /> Password:<br /> Since bill is manipulating files outside his home directory, superuser privileges are re-<br />quired. After the directory is created, it has the following ownerships and permissions:<br /> [bill@linuxbox ~]$ <strong>ls -ld /usr/local/share/Music</strong><br /> drwxr-xr-x 2 root root 4096 2008-03-21 18:05 /usr/local/share/Music<br /> As we can see, the directory is owned by root and has 755 permissions. To make this <br />directory sharable, bill needs to change the group ownership and the group permissions <br />to allow writing:<br /> 104<br /></p>
<hr />
<p>Exercising Our Privileges<br /> [bill@linuxbox ~]$ <strong>sudo chown :music /usr/local/share/Music<br /></strong>[bill@linuxbox ~]$ <strong>sudo chmod 775 /usr/local/share/Music</strong><br /> [bill@linuxbox ~]$ <strong>ls -ld /usr/local/share/Music<br /></strong>drwxrwxr-x 2 root music 4096 2008-03-21 18:05 /usr/local/share/Music<br /> So   what   does   this   all   mean?   It   means   that   we   now   have   a   directory, <br />/usr/local/share/Music  that is owned by  root  and allows read and write ac-<br />cess to group  music. Group music has members bill and  karen, thus bill and <br />karen can create files in directory /usr/local/share/Music. Other users can list <br />the contents of the directory but cannot create files there.<br />But we still have a problem. With the current permissions, files and directories created <br />within the Music directory will have the normal permissions of the users  bill  and <br />karen:<br /> [bill@linuxbox ~]$ <strong>&gt; /usr/local/share/Music/test_file<br /></strong>[bill@linuxbox ~]$ <strong>ls -l /usr/local/share/Music</strong><br /> -rw-r--r-- 1 bill   bill   0 2008-03-24 20:03 test_file<br /> Actually there are two problems. First, the default umask on this system is 0022 which <br />prevents group members from writing files belonging to other members of the group. <br />This would not be a problem if the shared directory only contained files, but since this di-<br />rectory will store music, and music is usually organized in a hierarchy of artists and al-<br />bums, members of the group will need the ability to create files and directories inside di-<br />rectories created by other members. We need to change the umask used by bill and <br />karen to 0002 instead.<br />Second, each file and directory created by one member will be set to the primary group of <br />the user rather than the group music. This can be fixed by setting the setgid bit on the <br />directory:<br /> [bill@linuxbox ~]$ <strong>sudo chmod g+s /usr/local/share/Music</strong><br /> [bill@linuxbox ~]$ <strong>ls -ld /usr/local/share/Music<br /></strong>drwxrwsr-x 2 root music 4096 2008-03-24 20:03 /usr/local/share/Music<br /> Now we test to see if the new permissions fix the problem.  bill  sets his  umask  to <br />0002, removes the previous test file, and creates a new test file and directory:<br /> [bill@linuxbox ~]$ <strong>umask 0002</strong><br /> 105<br /></p>
<hr />
<p>9 – Permissions<br /> [bill@linuxbox ~]$ <strong>rm /usr/local/share/Music/test_file<br /></strong>[bill@linuxbox ~]$ <strong>&gt; /usr/local/share/Music/test_file</strong><br /> [bill@linuxbox ~]$ <strong>mkdir /usr/local/share/Music/test_dir<br /></strong>[bill@linuxbox ~]$ <strong>ls -l /usr/local/share/Music</strong><br /> drwxrwsr-x 2 bill   music 4096 2008-03-24 20:24 test_dir<br />-rw-rw-r-- 1 bill   music 0 2008-03-24 20:22 test_file<br /> [bill@linuxbox ~]$ <br /> Both files and directories are now created with the correct permissions to allow all mem-<br />bers of the group music to create files and directories inside the Music directory.<br />The one remaining issue is umask. The necessary setting only lasts until the end of ses-<br />sion and must be reset. In Chapter 11, we'll look at making the change to umask perma-<br />nent.<br /> <strong>Changing Your Password<br /></strong>The last topic we'll cover in this chapter is setting passwords for yourself (and for other <br />users   if   you   have   access   to   superuser   privileges.)  To   set   or   change   a   password,   the <br />passwd command is used. The command syntax looks like this:<br /> <strong>passwd [<em>user</em></strong><strong>]</strong><br /> To change your password, just enter the  passwd command. You will be prompted for <br />your old password and your new password:<br /> [me@linuxbox ~]$ <strong>passwd<br /></strong>(current) UNIX password:<br /> New UNIX password:<br /> The passwd command will try to enforce use of “strong” passwords. This means it will <br />refuse to accept passwords that are too short, too similar to previous passwords, are dic-<br />tionary words, or are too easily guessed:<br /> [me@linuxbox ~]$ <strong>passwd</strong><br /> (current) UNIX password:<br />New UNIX password:<br /> BAD PASSWORD: is too similar to the old one<br />New UNIX password:<br /> BAD PASSWORD: it is WAY too short<br /> 106<br /></p>
<hr />
<p>Changing Your Password<br /> New UNIX password:<br />BAD PASSWORD: it is based on a dictionary word<br /> If you have  superuser  privileges, you can specify a username as an argument to the <br />passwd  command to set the password for another user. Other options are available to <br />the superuser to allow account locking, password expiration, etc. See the passwd man <br />page for details.<br /> <strong>Summing Up<br /></strong>In this chapter we have seen how Unix-like systems such as Linux manage user permis-<br />sions to allow the read, write, and execution access to files and directories. The basic <br />ideas of this system of permissions date back to the early days of Unix and have stood up <br />pretty well to the test of time. But the native permissions mechanism in Unix-like sys-<br />tems lacks the fine granularity of more modern systems.<br /> <strong>Further Reading</strong><br /> ●<br /> Wikipedia has a good article on malware:<br /><a href="http://en.wikipedia.org/wiki/Malware">http://en.wikipedia.org/wiki/Malware</a><br /> There are number of command line programs used to create and maintain users and <br />groups. For more information, see the man pages for the following commands:<br /> ●<br /> adduser<br /> ●<br /> useradd<br /> ●<br /> groupadd<br /> 107<br /></p>
<hr />
<p>10 – Processes<br /> <em><strong>10 – Processes</strong></em><br /> Modern operating systems are usually <em>multitasking</em>, meaning that they create the illusion <br />of doing more than one thing at once by rapidly switching from one executing program to <br />another. The Linux kernel manages this through the use of <em>processes</em>. Processes are how <br />Linux organizes the different programs waiting for their turn at the CPU.<br />Sometimes a computer will become sluggish or an application will stop responding. In <br />this chapter, we will look at some of the tools available at the command line that let us <br />examine what programs are doing, and how to terminate processes that are misbehaving. <br />This chapter will introduce the following commands:<br /> ●<br /> ps – Report a snapshot of current processes<br /> ●<br /> top – Display tasks<br /> ●<br /> jobs – List active jobs<br /> ●<br /> bg – Place a job in the background<br /> ●<br /> fg – Place a job in the foreground<br /> ●<br /> kill – Send a signal to a process<br /> ●<br /> killall – Kill processes by name<br /> ●<br /> shutdown – Shutdown or reboot the system<br /> <strong>How A Process Works<br /></strong>When a system starts up, the kernel initiates a few of its own activities as processes and <br />launches a program called init. init, in turn, runs a series of shell scripts (located in <br />/etc) called <em>init scripts</em>, which start all the system services. Many of these services are <br />implemented as <em>daemon programs</em>, programs that just sit in the background and do their <br />thing without having any user interface. So even if we are not logged in, the system is at <br />least a little busy performing routine stuff.<br />The fact that a program can launch other programs is expressed in the process scheme as <br />a <em>parent process</em> producing a <em>child process</em>.<br /> 108<br /></p>
<hr />
<p>How A Process Works<br /> The kernel maintains information about each process to help keep things organized. For <br />example, each process is assigned a number called a  <em>process ID</em>  or  <em>PID</em>. PIDs are as-<br />signed in ascending order, with init always getting PID 1. The kernel also keeps track <br />of the memory assigned to each process, as well as the processes' readiness to resume ex-<br />ecution. Like files, processes also have owners and user IDs, effective user IDs, etc.<br /> <strong>Viewing Processes<br /></strong>The most commonly used command to view processes (there are several) is ps. The ps <br />program has a lot of options, but in it simplest form it is used like this:<br /> [me@linuxbox ~]$ <strong>ps<br /></strong>  PID TTY          TIME CMD<br />  5198 pts/1    00:00:00 bash<br />10129 pts/1    00:00:00 ps<br /> The result in this example lists two processes, process 5198 and process 10129, which are <br />bash and ps respectively. As we can see, by default, ps doesn't show us very much, just <br />the processes associated with the current terminal session. To see more, we need to add <br />some options, but before we do that, let's look at the other fields produced by ps. TTY is <br />short for “Teletype,” and refers to the <em>controlling terminal</em> for the process. Unix is show-<br />ing its age here. The TIME field is the amount of CPU time consumed by the process. As <br />we can see, neither process makes the computer work very hard.<br />If we add an option, we can get a bigger picture of what the system is doing:<br /> [me@linuxbox ~]$ <strong>ps x<br /></strong>  PID TTY      STAT   TIME COMMAND<br />  2799 ?        Ssl    0:00 /usr/libexec/bonobo-activation-server –ac<br /> 2820 ?        Sl     0:01 /usr/libexec/evolution-data-server-1.10 --<br /> 15647 ?        Ss     0:00 /bin/sh /usr/bin/startkde<br />15751 ?        Ss     0:00 /usr/bin/ssh-agent /usr/bin/dbus-launch --<br /> 15754 ?        S      0:00 /usr/bin/dbus-launch --exit-with-session<br />15755 ?        Ss     0:01 /bin/dbus-daemon --fork --print-pid 4 –pr<br /> 15774 ?        Ss     0:02 /usr/bin/gpg-agent -s –daemon<br />15793 ?        S      0:00 start_kdeinit --new-startup +kcminit_start<br /> 15794 ?        Ss     0:00 kdeinit Running...<br />15797 ?        S      0:00 dcopserver –nosid<br /> and many more...<br /> 109<br /></p>
<hr />
<p>10 – Processes<br /> Adding the “x” option (note that there is no leading dash) tells ps to show all of our pro-<br />cesses regardless of what terminal (if any) they are controlled by. The presence of a “?” in <br />the TTY column indicates no controlling terminal. Using this option, we see a list of ev-<br />ery process that we own.<br />Since the system is running a lot of processes, ps produces a long list. It is often helpful <br />to pipe the output from ps into less for easier viewing. Some option combinations also <br />produce long lines of output, so maximizing the terminal emulator window may be a <br />good idea, too.<br />A new column titled STAT has been added to the output. STAT is short for “state” and re-<br />veals the current status of the process:<br /> <em>Table 10-1: Process States</em><br /> <strong>State</strong><br /> <strong>Meaning</strong><br /> R<br /> Running. This means that the process is running or ready to run.<br /> S<br /> Sleeping. The process is not running; rather, it is waiting for an <br />event, such as a keystroke or network packet.<br /> D<br /> Uninterruptible Sleep. Process is waiting for I/O such as a disk <br />drive.<br /> T<br /> Stopped. Process has been instructed to stop. More on this later.<br /> Z<br /> A defunct or “zombie” process. This is a child process that has <br />terminated, but has not been cleaned up by its parent.<br /> &lt;<br /> A high priority process. It's possible to grant more importance to a <br />process, giving it more time on the CPU. This property of a process <br />is called <em>niceness</em>. A process with high priority is said to be less <em>nice <br /></em>because it's taking more of the CPU's time, which leaves less for <br />everybody else.<br /> N<br /> A low priority process. A process with low priority (a “nice” <br />process) will only get processor time after other processes with <br />higher priority have been serviced.<br /> The process state may be followed by other characters. These indicate various exotic <br />process characteristics. See the ps man page for more detail.<br />Another popular set of options is “aux” (without a leading dash). This gives us even more <br />information:<br /> 110<br /></p>
<hr />
<p>Viewing Processes<br /> [me@linuxbox ~]$ <strong>ps aux<br /></strong>USER    PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND<br /> root      1  0.0  0.0   2136   644 ?        Ss   Mar05   0:31 init<br />root      2  0.0  0.0      0     0 ?        S&lt;   Mar05   0:00 [kt]<br /> root      3  0.0  0.0      0     0 ?        S&lt;   Mar05   0:00 [mi]<br />root      4  0.0  0.0      0     0 ?        S&lt;   Mar05   0:00 [ks]<br /> root      5  0.0  0.0      0     0 ?        S&lt;   Mar05   0:06 [wa]<br />root      6  0.0  0.0      0     0 ?        S&lt;   Mar05   0:36 [ev]<br /> root      7  0.0  0.0      0     0 ?        S&lt;   Mar05   0:00 [kh]<br /> and many more...<br /> This set of options displays the processes belonging to every user. Using the options <br />without the leading dash invokes the command with “BSD style” behavior. The Linux <br />version of  ps  can emulate the behavior of the  ps  program found in several different <br />Unix implementations. With these options, we get these additional columns:<br /> <em>Table 10-2: BSD Style ps Column Headers</em><br /> <strong>Header</strong><br /> <strong>Meaning</strong><br /> USER<br /> User ID. This is the owner of the process.<br /> %CPU<br /> CPU usage in percent.<br /> %MEM<br /> Memory usage in percent.<br /> VSZ<br /> Virtual memory size.<br /> RSS<br /> Resident Set Size. The amount of physical memory (RAM) the <br />process is using in kilobytes.<br /> START<br /> Time when the process started. For values over 24 hours, a date is <br />used.<br /> Viewing Processes Dynamically With top<br />While the ps command can reveal a lot about what the machine is doing, it provides only <br />a snapshot of the machine's state at the moment the ps command is executed. To see a <br />more dynamic view of the machine's activity, we use the top command:<br /> [me@linuxbox ~]$ <strong>top</strong><br /> 111<br /></p>
<hr />
<p>10 – Processes<br /> The top program displays a continuously updating (by default, every 3 seconds) display <br />of the system processes listed in order of process activity. The name “top” comes from <br />the fact that the top program is used to see the “top” processes on the system. The top <br />display consists of two parts: a system summary at the top of the display, followed by a <br />table of processes sorted by CPU activity:<br /> top - 14:59:20 up  6:30,  2 users,  load average: 0.07, 0.02, 0.00<br />Tasks: 109 total,   1 running, 106 sleeping,   0 stopped,   2 zombie<br /> Cpu(s):  0.7%us,  1.0%sy,  0.0%ni, 98.3%id,  0.0%wa,  0.0%hi,  0.0%si<br />Mem:    319496k total,   314860k used,     4636k free,    19392k buff<br /> Swap:   875500k total,   149128k used,   726372k free,   114676k cach<br />   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND<br /> 6244 me        39  19 31752 3124 2188 S  6.3  1.0  16:24.42 trackerd<br /> 11071 me        20   0  2304 1092  840 R  1.3  0.3   0:00.14 top<br /> 6180 me        20   0  2700 1100  772 S  0.7  0.3   0:03.66 dbus-dae<br />  6321 me        20   0 20944 7248 6560 S  0.7  2.3   2:51.38 multiloa<br /> 4955 root      20   0  104m 9668 5776 S  0.3  3.0   2:19.39 Xorg<br />     1 root      20   0  2976  528  476 S  0.0  0.2   0:03.14 init<br />    2 root      15  -5     0    0    0 S  0.0  0.0   0:00.00 kthreadd<br />     3 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 migratio<br />    4 root      15  -5     0    0    0 S  0.0  0.0   0:00.72 ksoftirq<br />     5 root      RT  -5     0    0    0 S  0.0  0.0   0:00.04 watchdog<br />    6 root      15  -5     0    0    0 S  0.0  0.0   0:00.42 events/0<br />     7 root      15  -5     0    0    0 S  0.0  0.0   0:00.06 khelper<br />   41 root      15  -5     0    0    0 S  0.0  0.0   0:01.08 kblockd/<br />    67 root      15  -5     0    0    0 S  0.0  0.0   0:00.00 kseriod<br />  114 root      20   0     0    0    0 S  0.0  0.0   0:01.62 pdflush<br />   116 root      15  -5     0    0    0 S  0.0  0.0   0:02.44 kswapd0<br /> The system summary contains a lot of good stuff. Here's a rundown:<br /> <em>Table 10-3: top Information Fields</em><br /> <strong>Row</strong><br /> <strong>Field</strong><br /> <strong>Meaning</strong><br /> 1<br /> top<br /> Name of the program.<br /> 14:59:20<br /> Current time of day.<br /> up 6:30<br /> This is called <em>uptime</em>. It is the amount of time <br />since the machine was last booted. In this <br />example, the system has been up for six and a <br />half hours.<br /> 2 users<br /> There are two users logged in.<br /> load average:<br /> <em>Load average</em> refers to the number of processes <br /> 112<br /></p>
<hr />
<p>Viewing Processes<br /> that are waiting to run, that is, the number of <br />processes that are in a runnable state and are <br />sharing the CPU. Three values are shown, each <br />for a different period of time. The first is the <br />average for the last 60 seconds, the next the <br />previous 5 minutes, and finally the previous 15 <br />minutes. Values under 1.0 indicate that the <br />machine is not busy.<br /> 2<br /> Tasks:<br /> This summarizes the number of processes and <br />their various process states.<br /> 3<br /> Cpu(s):<br /> This row describes the character of the <br />activities that the CPU is performing.<br /> 0.7%us<br /> 0.7% of the CPU is being used for <em>user <br />processes</em>. This means processes outside of the <br />kernel itself.<br /> 1.0%sy<br /> 1.0% of the CPU is being used for <em>system</em> <br />(kernel) processes.<br /> 0.0%ni<br /> 0.0% of the CPU is being used by “nice” (low <br />priority) processes.<br /> 98.3%id<br /> 98.3% of the CPU is idle.<br /> 0.0%wa<br /> 0.0% of the CPU is waiting for I/O.<br /> 4<br /> Mem:<br /> Shows how physical RAM is being used.<br /> 5<br /> Swap:<br /> Shows how swap space (virtual memory) is <br />being used.<br /> The top program accepts a number of keyboard commands. The two most interesting are <br />h, which displays the program's help screen, and q, which quits top.<br />Both major desktop environments provide graphical applications that display information <br />similar to top (in much the same way that Task Manager in Windows works), but I find <br />that  top  is better than the graphical versions because it is faster and it consumes far <br />fewer system resources. After all, our system monitor program shouldn't be the source of <br />the system slowdown that we are trying to track.<br /> <strong>Controlling Processes<br /></strong>Now that we can see and monitor processes, let's gain some control over them. For our <br /> 113<br /></p>
<hr />
<p>10 – Processes<br /> experiments, we're going to use a little program called  xlogo  as our guinea pig. The <br />xlogo program is a sample program supplied with the X Window System (the underly-<br />ing engine that makes the graphics on our display go) which simply displays a re-sizable <br />window containing the X logo. First, we'll get to know our test subject:<br /> [me@linuxbox ~]$ <strong>xlogo</strong><br /> After entering the command, a small window containing the logo should appear some-<br />where on the screen. On some systems, xlogo may print a warning message, but it may <br />be safely ignored.<br /> <strong>Tip:</strong>  If your system does not include the  xlogo  program, try using  gedit  or <br />kwrite instead.<br /> We can verify that xlogo is running by resizing its window. If the logo is redrawn in the <br />new size, the program is running.<br />Notice how our shell prompt has not returned? This is because the shell is waiting for the <br />program to finish, just like all the other programs we have used so far. If we close the <br />xlogo window, the prompt returns.<br /> Interrupting A Process<br />Let's observe what happens when we run xlogo again. First, enter the xlogo command <br />and verify that the program is running. Next, return to the terminal window and press <br />Ctrl-c.<br /> [me@linuxbox ~]$ <strong>xlogo</strong><br /> [me@linuxbox ~]$<br /> In a terminal, pressing Ctrl-c, <em>interrupts</em> a program. This means that we politely asked <br />the program to terminate. After we pressed Ctrl-c, the xlogo window closed and the <br />shell prompt returned.<br />Many (but not all) command-line programs can be interrupted by using this technique. <br /> Putting A Process In The Background<br />Let's say we wanted to get the shell prompt back without terminating the  xlogo  pro-<br /> 114<br /></p>
<hr />
<p>Controlling Processes<br /> gram. We’ll do this by placing the program in the <em>background</em>. Think of the terminal as <br />having a <em>foreground</em> (with stuff visible on the surface like the shell prompt) and a back-<br />ground (with hidden stuff behind the surface.) To launch a program so that it is immedi-<br />ately placed in the background, we follow the command with an- “&amp;” character:<br /> [me@linuxbox ~]$ <strong>xlogo &amp;<br /></strong>[1] 28236<br /> [me@linuxbox ~]$<br /> After entering the command, the xlogo window appeared and the shell prompt returned, <br />but some funny numbers were printed too. This message is part of a shell feature called <br /><em>job control</em>. With this message, the shell is telling us that we have started job number 1 <br />(“[1]”) and that it has PID 28236. If we run ps, we can see our process:<br /> [me@linuxbox ~]$ <strong>ps</strong><br />  PID TTY          TIME CMD<br />10603 pts/1    00:00:00 bash<br /> 28236 pts/1    00:00:00 xlogo<br />28239 pts/1    00:00:00 ps<br /> The shell's job control facility also gives us a way to list the jobs that have been launched <br />from our terminal. Using the jobs command, we can see this list:<br /> [me@linuxbox ~]$ <strong>jobs<br /></strong>[1]+  Running                 xlogo &amp;<br /> The results show that we have one job, numbered “1”, that it is running, and that the com-<br />mand was xlogo &amp;.<br /> Returning A Process To The Foreground<br />A process in the background is immune from keyboard input, including any attempt inter-<br />rupt it with a Ctrl-c. To return a process to the foreground, use the fg command, this <br />way:<br /> [me@linuxbox ~]$ <strong>jobs<br /></strong>[1]+  Running                 xlogo &amp;<br /> [me@linuxbox ~]$ <strong>fg %1</strong><br /> 115<br /></p>
<hr />
<p>10 – Processes<br /> xlogo<br /> The command fg followed by a percent sign and the job number (called a <em>jobspec</em>) does <br />the trick. If we only have one background job, the jobspec is optional. To terminate xl-<br />ogo, press Ctrl-c.<br /> Stopping (Pausing) A Process<br />Sometimes we'll want to stop a process without terminating it. This is often done to allow <br />a foreground process to be moved to the background. To stop a foreground process, press <br />Ctrl-z. Let's try it. At the command prompt, type xlogo, the Enter key, then Ctrl-<br />z:<br /> [me@linuxbox ~]$ <strong>xlogo</strong><br /> [1]+  Stopped                 xlogo<br />[me@linuxbox ~]$<br /> After stopping xlogo, we can verify that the program has stopped by attempting to re-<br />size the xlogo window. We will see that it appears quite dead. We can either restore the <br />program to the foreground, using the  fg  command, or move the program to the back-<br />ground with the bg command:<br /> [me@linuxbox ~]$ <strong>bg %1<br /></strong>[1]+ xlogo &amp;<br /> [me@linuxbox ~]$<br /> As with the fg command, the jobspec is optional if there is only one job.<br />Moving a process from the foreground to the background is handy if we launch a graphi-<br />cal program from the command, but forget to place it in the background by appending the <br />trailing “&amp;”.<br />Why would you want to launch a graphical program from the command line? There are <br />two reasons. First, the program you wish to run might not be listed on the window man-<br />ager's menus (such as  xlogo). Secondly, by launching a program from the command <br />line, you might be able to see error messages that would otherwise be invisible if the pro-<br />gram   were   launched   graphically.   Sometimes,   a   program   will   fail   to   start   up   when <br />launched from the graphical menu. By launching it from the command line instead, we <br />may see an error message that will reveal the problem. Also, some graphical programs <br />have many interesting and useful command line options. <br /> 116<br /></p>
<hr />
<p>Signals<br /> <strong>Signals<br /></strong>The  kill  command  is used to “kill” processes. This allows us to terminate programs <br />that need killing. Here's an example:<br /> [me@linuxbox ~]$ xlogo &amp;<br />[1] 28401<br /> [me@linuxbox ~]$ kill 28401<br />[1]+  Terminated              xlogo<br /> We first launch xlogo in the background. The shell prints the jobspec and the PID of the <br />background process. Next, we use the kill command and specify the PID of the process <br />we want to terminate. We could have also specified the process using a jobspec (for ex-<br />ample, “%1”) instead of a PID.<br />While this is all very straightforward, there is more to it than that. The kill command <br />doesn't exactly “kill” processes, rather it sends them <em>signals</em>. Signals are one of several <br />ways that the operating system communicates with programs. We have already seen sig-<br />nals in action with the use of Ctrl-c and Ctrl-z. When the terminal receives one of <br />these keystrokes, it sends a signal to the program in the foreground. In the case of Ctrl-<br />c, a signal called INT (Interrupt) is sent; with Ctrl-z, a signal called TSTP (Terminal <br />Stop). Programs, in turn, “listen” for signals and may act upon them as they are received. <br />The fact that a program can listen and act upon signals allows a program to do things like <br />save work in progress when it is sent a termination signal.<br /> Sending Signals To Processes With kill<br />The kill command is used to send signals to programs. Its most common syntax looks <br />like this:<br /> <strong>kill [-<em>signal</em></strong><strong>] PID...</strong><br /> If no signal is specified on the command line, then the TERM (Terminate) signal is sent by <br />default. The kill command is most often used to send the following signals:<br /> <em>Table 10-4: Common Signals</em><br /> <strong>Number</strong><br /> <strong>Name</strong><br /> <strong>Meaning</strong><br /> 1<br /> HUP<br /> Hangup. This is a vestige of the good old days <br />when terminals were attached to remote <br /> 117<br /></p>
<hr />
<p>10 – Processes<br /> computers with phone lines and modems. The <br />signal is used to indicate to programs that the <br />controlling terminal has “hung up.” The effect of <br />this signal can be demonstrated by closing a <br />terminal session. The foreground program <br />running on the terminal will be sent the signal and <br />will terminate.<br /> This signal is also used by many daemon <br />programs to cause a reinitialization. This means <br />that when a daemon is sent this signal, it will <br />restart and re-read its configuration file. The <br />Apache web server is an example of a daemon <br />that uses the HUP signal in this way.<br /> 2<br /> INT<br /> Interrupt. Performs the same function as the <br />Ctrl-c key sent from the terminal. It will <br />usually terminate a program.<br /> 9<br /> KILL<br /> Kill. This signal is special. Whereas programs <br />may choose to handle signals sent to them in <br />different ways, including ignoring them all <br />together, the KILL signal is never actually sent to <br />the target program. Rather, the kernel <br />immediately terminates the process. When a <br />process is terminated in this manner, it is given no <br />opportunity to “clean up” after itself or save its <br />work. For this reason, the KILL signal should <br />only be used as a last resort when other <br />termination signals fail.<br /> 15<br /> TERM<br /> Terminate. This is the default signal sent by the <br />kill command. If a program is still “alive” <br />enough to receive signals, it will terminate.<br /> 18<br /> CONT<br /> Continue. This will restore a process after a STOP <br />signal.<br /> 19<br /> STOP<br /> Stop. This signal causes a process to pause <br />without terminating. Like the KILL signal, it is <br />not sent to the target process, and thus it cannot be <br />ignored.<br />  <br /> 118<br /></p>
<hr />
<p>Signals<br /> Let's try out the kill command:<br /> [me@linuxbox ~]$ <strong>xlogo &amp;<br /></strong>[1] 13546<br /> [me@linuxbox ~]$ <strong>kill -1 13546<br /></strong>[1]+  Hangup                  xlogo<br /> In this example, we start the xlogo program in the background and then send it a HUP <br />signal with kill. The xlogo program terminates and the shell indicates that the back-<br />ground process has received a hangup signal. You may need to press the enter key a cou-<br />ple of times before you see the message. Note that signals may be specified either by <br />number or by name, including the name prefixed with the letters “SIG”:<br /> [me@linuxbox ~]$ <strong>xlogo &amp;<br /></strong>[1] 13601<br /> [me@linuxbox ~]$ <strong>kill -INT 13601<br /></strong>[1]+  Interrupt               xlogo<br /> [me@linuxbox ~]$ <strong>xlogo &amp;<br /></strong>[1] 13608<br /> [me@linuxbox ~]$ <strong>kill -SIGINT 13608<br /></strong>[1]+  Interrupt               xlogo<br /> Repeat the example above and try out the other signals. Remember, you can also use job-<br />specs in place of PIDs.<br />Processes, like files, have owners, and you must be the owner of a process (or the supe-<br />ruser) in order to send it signals with kill.<br />In addition to the list of signals above, which are most often used with kill, there are <br />other signals frequently used by the system. Here is a list of other common signals:<br /> <em>Table 10-5: Other Common Signals</em><br /> <strong>Number</strong><br /> <strong>Name</strong><br /> <strong>Meaning</strong><br /> 3<br /> QUIT<br /> Quit.<br /> 11<br /> SEGV<br /> Segmentation Violation. This signal is sent if a <br />program makes illegal use of memory, that is, it <br />tried to write somewhere it was not allowed to.<br /> 20<br /> TSTP<br /> Terminal Stop. This is the signal sent by the <br />terminal when the Ctrl-z key is pressed. Unlike <br />the STOP signal, the TSTP signal is received by <br /> 119<br /></p>
<hr />
<p>10 – Processes<br /> the program but the program may choose to <br />ignore it.<br /> 28<br /> WINCH<br /> Window Change. This is a signal sent by the <br />system when a window changes size. Some <br />programs , like top and less will respond to <br />this signal by redrawing themselves to fit the new <br />window dimensions.<br /> For the curious, a complete list of signals can be seen with the following command:<br /> [me@linuxbox ~]$ kill -l<br /> Sending Signals To Multiple Processes With killall<br />It's also possible to send signals to multiple processes matching a specified program or <br />username by using the killall command. Here is the syntax:<br /> <strong>killall [-u <em>user</em></strong><strong>] [-<em>signal</em></strong><strong>] <em>name</em></strong><strong>...</strong><br /> To demonstrate, we will start a couple of instances of the xlogo program and then ter-<br />minate them:<br /> [me@linuxbox ~]$ <strong>xlogo &amp;</strong><br /> [1] 18801<br />[me@linuxbox ~]$ <strong>xlogo &amp;</strong><br /> [2] 18802<br />[me@linuxbox ~]$ <strong>killall xlogo</strong><br /> [1]-  Terminated              xlogo<br />[2]+  Terminated              xlogo<br /> Remember, as with  kill, you must have  superuser  privileges to send signals to pro-<br />cesses that do not belong to you.<br /> <strong>More Process Related Commands<br /></strong>Since monitoring processes is an important system administration task, there are a lot of <br />commands for it. Here are some to play with:<br /> 120<br /></p>
<hr />
<p>More Process Related Commands<br /> <em>Table 10-6: Other Process Related Commands</em><br /> <strong>Command</strong><br /> <strong>Description</strong><br /> pstree<br /> Outputs a process list arranged in a tree-like pattern showing the <br />parent/child relationships between processes.<br /> vmstat<br /> Outputs a snapshot of system resource usage including, memory, <br />swap and disk I/O. To see a continuous display, follow the <br />command with a time delay (in seconds) for updates. For example: <br />vmstat 5. Terminate the output with Ctrl-c.<br /> xload<br /> A graphical program that draws a graph showing system load over <br />time.<br /> tload<br /> Similar to the xload program, but draws the graph in the terminal. <br />Terminate the output with Ctrl-c.<br /> <strong>Summing Up<br /></strong>Most modern systems feature a mechanism for managing multiple processes. Linux pro-<br />vides a rich set of tools for this purpose. Given that Linux is the world's most deployed <br />server operating system, this makes a lot of sense. However, unlike some other systems, <br />Linux relies primarily on command line tools for process management. Though there are <br />graphical process tools for Linux, the command line tools are greatly preferred because of <br />their speed and light footprint. While the GUI tools may look pretty, they often create a <br />lot of system load themselves, which somewhat defeats the purpose.<br /> 121<br /></p>
<hr />
<hr />
<p>Part 2 – Configuration And The Environment<br /> Part 2 – Configuration And The <br /> Environment<br /> 123<br /></p>
<hr />
<p>11 – The Environment<br /> <em><strong>11 – The Environment</strong></em><br /> As we discussed earlier, the shell maintains a body of information during our shell ses-<br />sion called the <em>environment</em>. Data stored in the environment is used by programs to deter-<br />mine facts about our configuration. While most programs use <em>configuration files</em> to store <br />program settings, some programs will also look for values stored in the environment to <br />adjust their behavior. Knowing this, we can use the environment to customize our shell <br />experience.<br />In this chapter, we will work with the following commands:<br /> ●<br /> printenv – Print part or all of the environment<br /> ●<br /> set – Set shell options<br /> ●<br /> export – Export environment to subsequently executed programs<br /> ●<br /> alias – Create an alias for a command<br /> <strong>What Is Stored In The Environment?<br /></strong>The shell stores two basic types of data in the environment, though, with  bash,  the <br />types are largely indistinguishable. They are  <em>environment variables</em> and <em>shell variables</em>. <br />Shell variables are bits of data placed there by bash, and environment variables are basi-<br />cally everything else. In addition to variables, the shell also stores some programmatic <br />data, namely <em>aliases</em> and <em>shell functions</em>. We covered aliases in Chapter 5, and shell func-<br />tions (which are related to shell scripting) will be covered in Part 4.<br /> Examining The Environment<br />To see what is stored in the environment, we can use either the set builtin in bash or <br />the printenv program. The set command will show both the shell and environment <br />variables, while  printenv  will only display the latter. Since the list of environment <br />contents will be fairly long, it is best to pipe the output of either command into less:<br /> [me@linuxbox ~]$ <strong>printenv | less</strong><br /> 124<br /></p>
<hr />
<p>What Is Stored In The Environment?<br /> Doing so, we should get something that looks like this:<br /> KDE_MULTIHEAD=false<br />SSH_AGENT_PID=6666<br /> HOSTNAME=linuxbox<br />GPG_AGENT_INFO=/tmp/gpg-PdOt7g/S.gpg-agent:6689:1<br /> SHELL=/bin/bash<br />TERM=xterm<br /> XDG_MENU_PREFIX=kde-<br />HISTSIZE=1000<br /> XDG_SESSION_COOKIE=6d7b05c65846c3eaf3101b0046bd2b00-<br />1208521990.996705-1177056199<br /> GTK2_RC_FILES=/etc/gtk-2.0/gtkrc:/home/me/.gtkrc-<br />2.0:/home/me/.kde/share/config/gtkrc-2.0<br /> GTK_RC_FILES=/etc/gtk/gtkrc:/home/me/.gtkrc:/home/me/.kde/share/confi<br />g/gtkrc<br /> GS_LIB=/home/me/.fonts<br />WINDOWID=29360136<br /> QTDIR=/usr/lib/qt-3.3<br />QTINC=/usr/lib/qt-3.3/include<br /> KDE_FULL_SESSION=true<br />USER=me<br /> LS_COLORS=no=00:fi=00:di=00;34:ln=00;36:pi=40;33:so=00;35:bd=40;33;01<br />:cd=40;33;01:or=01;05;37;41:mi=01;05;37;41:ex=00;32:*.cmd=00;32:*.exe<br /> :<br /> What we see is a list of environment variables and their values. For example, we see a <br />variable called  USER, which contains the value “me”. The  printenv  command can <br />also list the value of a specific variable:<br /> [me@linuxbox ~]$ <strong>printenv USER</strong><br /> me<br /> The set command, when used without options or arguments, will display both the shell <br />and environment variables, as well as any defined shell functions. Unlike printenv, its <br />output is courteously sorted in alphabetical order:<br /> [me@linuxbox ~]$ <strong>set | less</strong><br /> It is also possible to view the contents of a variable using the echo command, like this:<br /> 125<br /></p>
<hr />
<p>11 – The Environment<br /> [me@linuxbox ~]$ <strong>echo $HOME<br /></strong>/home/me<br /> One element of the environment that neither set nor printenv displays is aliases. To <br />see them, enter the alias command without arguments:<br /> [me@linuxbox ~]$ <strong>alias<br /></strong>alias l.='ls -d .* --color=tty'<br /> alias ll='ls -l --color=tty'<br />alias ls='ls --color=tty'<br /> alias vi='vim'<br />alias which='alias | /usr/bin/which --tty-only --read-alias --show-<br /> dot --show-tilde'<br /> Some Interesting Variables<br />The environment contains quite a few variables, and though your environment may differ <br />from the one presented here, you will likely see the following variables in your environ-<br />ment:<br /> <em>Table 11-1: Environment Variables</em><br /> <strong>Variable</strong><br /> <strong>Contents</strong><br /> DISPLAY<br /> The name of your display if you are running a graphical <br />environment. Usually this is “:0”, meaning the first display <br />generated by the X server.<br /> EDITOR<br /> The name of the program to be used for text editing.<br /> SHELL<br /> The name of your shell program.<br /> HOME<br /> The pathname of your home directory.<br /> LANG<br /> Defines the character set and collation order of your language.<br /> OLD_PWD<br /> The previous working directory.<br /> PAGER<br /> The name of the program to be used for paging output. This is often <br />set to /usr/bin/less.<br /> PATH<br /> A colon-separated list of directories that are searched when you <br />enter the name of a executable program.<br /> PS1<br /> Prompt String 1. This defines the contents of your shell prompt. As <br />we will later see, this can be extensively customized.<br /> 126<br /></p>
<hr />
<p>What Is Stored In The Environment?<br /> PWD<br /> The current working directory.<br /> TERM<br /> The name of your terminal type. Unix-like systems support many <br />terminal protocols; this variable sets the protocol to be used with <br />your terminal emulator. <br /> TZ<br /> Specifies your timezone. Most Unix-like systems maintain the <br />computer’s internal clock in <em>Coordinated Universal Time</em> (UTC) <br />and then displays the local time by applying an offset specified by <br />this variable.<br /> USER<br /> Your username.<br /> Don't worry if some of these values are missing. They vary by distribution.<br /> <strong>How Is The Environment Established?<br /></strong>When we log on to the system, the bash program starts, and reads a series of configura-<br />tion scripts called <em>startup files</em>, which define the default environment shared by all users. <br />This is followed by more startup files in our home directory that define our personal envi-<br />ronment. The exact sequence depends on the type of shell session being started. There are <br />two kinds: a login shell session and a non-login shell session.<br />A login shell session is one in which we are prompted for our username and password; <br />when we start a virtual console session, for example. A non-login shell session typically <br />occurs when we launch a terminal session in the GUI.<br />Login shells read one or more startup files as shown in Table 11-2:<br /> <em>Table 11-2: Startup Files For Login Shell Sessions</em><br /> <strong>File</strong><br /> <strong>Contents</strong><br /> /etc/profile<br /> A global configuration script that applies to all users.<br /> ~/.bash_profile<br /> A user's personal startup file. Can be used to extend or <br />override settings in the global configuration script.<br /> ~/.bash_login<br /> If ~/.bash_profile is not found, bash attempts to <br />read this script.<br /> ~/.profile<br /> If neither ~/.bash_profile nor ~/.bash_login <br />is found, bash attempts to read this file. This is the <br />default in Debian-based distributions, such as Ubuntu.<br /> Non-login shell sessions read the following startup files:<br /> 127<br /></p>
<hr />
<p>11 – The Environment<br /> <em>Table 11-3: Startup Files For Non-Login Shell Sessions</em><br /> <strong>File</strong><br /> <strong>Contents</strong><br /> /etc/bash.bashrc<br /> A global configuration script that applies to all users.<br /> ~/.bashrc<br /> A user's personal startup file. Can be used to extend or <br />override settings in the global configuration script.<br /> In addition to reading the startup files above, non-login shells also inherit the environ-<br />ment from their parent process, usually a login shell.<br />Take a look at your system and see which of these startup files you have. Remember—<br />    <br /> since most of the filenames listed above start with a period (meaning that they are hid-<br />den), you will need to use the “-a” option when using ls.<br />The ~/.bashrc file is probably the most important startup file from the ordinary user’s <br />point of view, since it is almost always read. Non-login shells read it by default and most <br />startup files for login shells are written in such a way as to read the ~/.bashrc file as <br />well.<br /> What's In A Startup File?<br />If we take a look inside a typical .bash_profile (taken from a CentOS 4 system), it <br />looks something like this:<br /> # .bash_profile<br /> # Get the aliases and functions<br />if [ -f ~/.bashrc ]; then<br />         . ~/.bashrc<br />fi<br /> # User specific environment and startup programs<br /> PATH=$PATH:$HOME/bin<br /> export PATH<br /> Lines that begin with a “#” are <em>comments</em> and are not read by the shell. These are there <br />for human readability. The first interesting thing occurs on the fourth line, with the fol-<br />lowing code:<br /> if [ -f ~/.bashrc ]; then<br /> 128<br /></p>
<hr />
<p>How Is The Environment Established?<br />         . ~/.bashrc<br />fi<br /> This is called an <em>if compound command</em>, which we will cover fully when we get to shell <br />scripting in Part 4, but for now we will translate:<br /> If the file &quot;~/.bashrc&quot; exists, then<br /> read the &quot;~/.bashrc&quot; file.<br /> We can see that this bit of code is how a login shell gets the contents of .bashrc. The <br />next thing in our startup file has to do with the PATH variable.<br />Ever wonder how the shell knows where to find commands when we enter them on the <br />command line? For example, when we enter ls, the shell does not search the entire com-<br />puter to find /bin/ls (the full pathname of the ls command), rather, it searches a list <br />of directories that are contained in the PATH variable.<br />The  PATH  variable is often (but not always, depending on the distribution) set by the <br />/etc/profile startup file and with this code:<br /> PATH=$PATH:$HOME/bin<br /> PATH is modified to add the directory $HOME/bin to the end of the list. This is an ex-<br />ample of parameter expansion, which we touched on in Chapter 7. To demonstrate how <br />this works, try the following:<br /> [me@linuxbox ~]$ <strong>foo=&quot;This is some &quot;</strong><br /> [me@linuxbox ~]$ <strong>echo $foo<br /></strong>This is some<br /> [me@linuxbox ~]$ <strong>foo=$foo&quot;text.&quot;<br /></strong>[me@linuxbox ~]$ <strong>echo $foo</strong><br /> This is some text.<br /> Using this technique, we can append text to the end of a variable's contents.<br />By adding the string $HOME/bin to the end of the PATH variable's contents, the direc-<br />tory $HOME/bin is added to the list of directories searched when a command is entered. <br />This means that when we want to create a directory within our home directory for storing <br />our own private programs, the shell is ready to accommodate us. All we have to do is call <br /> 129<br /></p>
<hr />
<p>11 – The Environment<br /> it bin, and we’re ready to go.<br /> <strong>Note</strong>: Many distributions provide this PATH setting by default. Some Debian based <br />distributions, such as Ubuntu, test for the existence of the ~/bin directory at lo-<br />gin, and dynamically add it to the PATH variable if the directory is found.<br /> Lastly, we have:<br /> export PATH<br /> The export command tells the shell to make the contents of PATH available to child <br />processes of this shell.<br /> <strong>Modifying The Environment<br /></strong>Since we know where the startup files are and what they contain, we can modify them to <br />customize our environment.<br /> Which Files Should We Modify?<br />As a general rule, to add directories to your PATH, or define additional environment vari-<br />ables, place those changes in .bash_profile (or equivalent, according to your distri-<br />bution. For example, Ubuntu uses .profile.) For everything else, place the changes in <br />.bashrc. Unless you are the system administrator and need to change the defaults for <br />all users of the system, restrict your modifications to the files in your home directory. It is <br />certainly possible to change the files in /etc such as profile, and in many cases it <br />would be sensible to do so, but for now, let's play it safe.<br /> Text Editors<br />To edit (i.e., modify) the shell's startup files, as well as most of the other configuration <br />files on the system, we use a program called a <em>text editor</em>. A text editor is a program that <br />is, in some ways, like a word processor in that it allows you to edit the words on the <br />screen with a moving cursor. It differs from a word processor by only supporting pure <br />text, and often contains features designed for writing programs. Text editors are the cen-<br />tral tool used by software developers to write code, and by system administrators to man-<br />age the configuration files that control the system.<br />There are a lot of different text editors available for Linux; your system probably has sev-<br />eral installed. Why so many different ones? Probably because programmers like writing <br /> 130<br /></p>
<hr />
<p>Modifying The Environment<br /> them, and since programmers use them extensively, they write editors to express their <br />own desires as to how they should work.<br />Text editors fall into two basic categories: graphical and text based. GNOME and KDE <br />both include some popular graphical editors. GNOME ships with an editor called gedit, <br />which is usually called “Text Editor” in the GNOME menu. KDE usually ships with three <br />which are (in order of increasing complexity) kedit, kwrite, and kate.<br />There are many text-based editors. The popular ones you will encounter are nano, vi, <br />and emacs. The nano editor is a simple, easy-to-use editor designed as a replacement <br />for the pico editor supplied with the PINE email suite. The vi editor (on most Linux <br />systems replaced by a program named vim, which is short for “Vi IMproved”) is the tra-<br />ditional editor for Unix-like systems. It will be the subject of our next chapter. The <br />emacs  editor was originally written by  Richard Stallman. It is a gigantic, all-purpose, <br />does-everything programming environment. While readily available, it is seldom installed <br />on most Linux systems by default.<br /> Using A Text Editor<br />All text editors can be invoked from the command line by typing the name of the editor <br />followed by the name of the file you want to edit. If the file does not already exist, the ed-<br />itor will assume that you want to create a new file. Here is an example using gedit:<br /> [me@linuxbox ~]$ <strong>gedit some_file</strong><br /> This command will start the gedit text editor and load the file named “some_file”, if it <br />exists.<br />All graphical text editors are pretty self-explanatory, so we won't cover them here. In-<br />stead, we will concentrate on our first text-based text editor, nano. Let's fire up nano <br />and edit the .bashrc file. But before we do that, let's practice some “safe computing.” <br />Whenever we edit an important configuration file, it is always a good idea to create a <br />backup copy of the file first. This protects us in case we mess the file up while editing. To <br />create a backup of the .bashrc file, do this:<br /> [me@linuxbox ~]$ cp .bashrc .bashrc.bak<br /> It doesn't matter what you call the backup file, just pick an understandable name. The ex-<br />tensions “.bak”, “.sav”, “.old”, and “.orig” are all popular ways of indicating a backup <br />file. Oh, and remember that cp will <em>overwrite existing files</em> silently.<br /> 131<br /></p>
<hr />
<p>11 – The Environment<br /> Now that we have a backup file, we'll start the editor:<br /> [me@linuxbox ~]$ <strong>nano .bashrc</strong><br /> Once nano starts, we’ll get a screen like this:<br />   GNU nano 2.0.3           File: .bashrc<br /> # .bashrc<br /> # Source global definitions<br /> if [ -f /etc/bashrc ]; then<br />        . /etc/bashrc<br /> fi<br /> # User specific aliases and functions<br />                           [ Read 8 lines ]<br />^G Get Help^O WriteOut^R Read Fil^Y Prev Pag^K Cut Text^C Cur Pos<br /> ^X Exit    ^J Justify ^W Where Is^V Next Pag^U UnCut Te^T To Spell<br /> <strong>Note:</strong> If your system does not have nano installed, you may use a graphical editor <br />instead.<br /> The screen consists of a header at the top, the text of the file being edited in the middle  <br />and a menu of commands at the bottom. Since nano was designed to replace the text edi-<br />tor supplied with an email client, it is rather short on editing features.<br />The first command you should learn in any text editor is how to exit the program. In the <br />case of nano, you type Ctrl-x to exit. This is indicated in the menu at the bottom of <br />the screen. The notation “^X” means  Ctrl-x. This is a common notation for control <br />characters used by many programs.<br />The second command we need to know is how to save our work. With nano it's Ctrl-<br /> 132<br /></p>
<hr />
<p>Modifying The Environment<br /> o. With this knowledge under our belts, we're ready to do some editing. Using the down <br />arrow key and/or the PageDown key, move the cursor to the end of the file, then add the <br />following lines to the .bashrc file:<br /> <strong>umask 0002<br />export HISTCONTROL=ignoredups</strong><br /> <strong>export HISTSIZE=1000<br />alias l.='ls -d .* --color=auto'</strong><br /> <strong>alias ll='ls -l --color=auto'</strong><br /> <strong>Note:</strong> Your distribution may already include some of these, but duplicates won't <br />hurt anything.<br /> Here is the meaning of our additions:<br /> <em>Table 11-4: Additions to our .bashrc</em><br /> <strong>Line</strong><br /> <strong>Meaning</strong><br /> umask 0002<br /> Sets the umask to solve the <br />problem with shared directories <br />we discussed in Chapter 9.<br /> export HISTCONTROL=ignoredups<br /> Causes the shell's history <br />recording feature to ignore a <br />command if the same command <br />was just recorded.<br /> export HISTSIZE=1000<br /> Increases the size of the command <br />history from the default of 500 <br />lines to 1000 lines.<br /> alias l.='ls -d .* --color=auto'<br /> Creates a new command called <br />“l.” which displays all directory <br />entries that begin with a dot.<br /> alias ll='ls -l --color=auto'<br /> Creates a new command called <br />“ll” which displays a long <br />format directory listing.<br /> As we can see, many of our additions are not intuitively obvious, so it would be a good <br />idea to add some comments to our .bashrc file to help explain things to the humans. <br /> 133<br /></p>
<hr />
<p>11 – The Environment<br /> Using the editor, change our additions to look like this:<br /> <strong># Change umask to make directory sharing easier<br /></strong>umask 0002<br /> <strong># Ignore duplicates in command history and increase</strong><br /> <strong># history size to 1000 lines<br /></strong>export HISTCONTROL=ignoredups<br /> export HISTSIZE=1000<br /> <strong># Add some helpful aliases<br /></strong>alias l.='ls -d .* --color=auto'<br /> alias ll='ls -l --color=auto'<br /> Ah,   much   better!   With   our   changes   complete,   press  Ctrl-o  to   save   our   modified <br />.bashrc file, and Ctrl-x to exit nano. <br /> <strong>Why Comments Are Important<br /></strong>Whenever you modify configuration files it's a good idea to add some comments <br />to document your changes. Sure, you will remember what you changed tomorrow, <br />but what about six months from now? Do yourself a favor and add some com-<br />ments. While you're at it, it’s not a bad idea to keep a log of what changes you <br />make.<br />Shell scripts and bash startup files use a “#” symbol to begin a comment. Other <br />configuration files may use other symbols. Most configuration files will have <br />comments. Use them as a guide.<br />You will often see lines in configuration files that are <em>commented out</em> to prevent <br />them from being used by the affected program. This is done to give the reader <br />suggestions for possible configuration choices or examples of correct configura-<br />tion syntax. For example, the .bashrc file of Ubuntu 8.04 contains these lines:<br /># some more ls aliases<br />#alias ll='ls -l'<br />#alias la='ls -A'<br />#alias l='ls -CF'<br />The last three lines are valid alias definitions that have been commented out. If <br />you remove the leading “#” symbols from these three lines, a technique called <em>un-<br />commenting</em>, you will activate the aliases. Conversely, if you add a “#” symbol to <br />the beginning of a line, you can deactivate a configuration line while preserving <br />the information it contains.<br /> 134<br /></p>
<hr />
<p>Modifying The Environment<br /> Activating Our Changes<br />The changes we have made to our .bashrc will not take affect until we close our termi-<br />nal session and start a new one, since the .bashrc file is only read at the beginning of a <br />session. However, we can force bash to re-read the modified .bashrc file with the fol-<br />lowing command:<br /> [me@linuxbox ~]$ <strong>source .bashrc</strong><br /> After doing this, we should be able to see the effect of our changes. Try out one of the <br />new aliases:<br /> [me@linuxbox ~]$ <strong>ll</strong><br /> <strong>Summing Up<br /></strong>In this chapter we learned an essential skill—<br />   e diting configuration files with a text edi-<br /> tor. Moving forward, as we read man pages for commands, take note of the environment <br />variables that commands support. There may be a gem or two. In later chapters, we will <br />learn about shell functions, a powerful feature that you can also include in the  bash <br />startup files to add to your arsenal of custom commands.<br /> <strong>Further Reading</strong><br /> ●<br /> The INVOCATION section of the bash man page covers the bash startup files <br />in gory detail.<br /> 135<br /></p>
<hr />
<p>12 – A Gentle Introduction To vi<br /> <em><strong>12 – A Gentle Introduction To vi</strong></em><br /> There is an old joke about a visitor to New York City asking a passerby for directions to <br />the city's famous classical music venue:<br />Visitor: Excuse me, how do I get to Carnegie Hall?<br />Passerby: Practice, practice, practice!<br />Learning the Linux command line, like becoming an accomplished pianist, is not some-<br />thing that we pick up in an afternoon. It takes years of practice. In this chapter, we will <br />introduce the  vi  (pronounced “vee eye”) text editor, one of the core programs in the <br />Unix tradition. vi is somewhat notorious for its difficult user interface, but when we see <br />a master sit down at the keyboard and begin to “play,” we will indeed be witness to some <br />great art. We won't become masters in this chapter, but when we are done, we will know <br />how to play “chopsticks” in vi.<br /> <strong>Why We Should Learn vi<br /></strong>In this modern age of graphical editors and easy-to-use text-based editors such as nano, <br />why should we learn vi? There are three good reasons:<br /> ●<br /> vi is always available. This can be a lifesaver if we have a system with no graph-<br />ical interface, such as a remote server or a local system with a broken X configu-<br />ration. nano, while increasingly popular is still not universal. POSIX, a standard <br />for program compatibility on Unix systems, requires that vi be present.<br /> ●<br /> vi is lightweight and fast. For many tasks, it's easier to bring up vi than it is to <br />find the graphical text editor in the menus and wait for its multiple megabytes to <br />load. In addition, vi is designed for typing speed. As we shall see, a skilled vi <br />user never has to lift his or her fingers from the keyboard while editing.<br /> ●<br /> We don't want other Linux and Unix users to think we are sissies.<br /> Okay, maybe two good reasons.<br /> 136<br /></p>
<hr />
<p>A Little Background <br /> <strong>A Little Background <br /></strong>The first version of  vi  was written in 1976 by Bill  Joy, a University of California at <br />Berkley student who later went on to co-found Sun Microsystems. vi derives its name <br />from the word “visual,” because it was intended to allow editing on a video terminal with <br />a moving cursor. Previous to <em>visual editors</em>, there were <em>line editors</em> which operated on a <br />single line of text at a time. To specify a change, we tell a line editor to go to a particular <br />line and describe what change to make, such as adding or deleting text. With the advent <br />of video terminals (rather than printer-based terminals like teletypes) visual editing be-<br />came possible. vi actually incorporates a powerful line editor called ex, and we can use <br />line editing commands while using vi.<br />Most Linux distributions don't include real  vi; rather, they ship with an enhanced re-<br />placement called  vim  (which is short for “vi improved”) written by Bram  Moolenaar. <br />vim is a substantial improvement over traditional Unix vi and is usually symbolically <br />linked (or aliased) to the name “vi” on Linux systems. In the discussions that follow, we <br />will assume that we have a program called “vi” that is really vim.<br /> <strong>Starting And Stopping vi<br /></strong>To start vi, we simply enter the following:<br /> [me@linuxbox ~]$ <strong>vi</strong><br /> And a screen like this should appear:<br /> ~<br /> ~<br />~                         VIM - Vi Improved<br /> ~<br />~                          version 7.1.138<br /> ~                     by Bram Moolenaar et al.<br />~            Vim is open source and freely distributable<br /> ~<br />~                     Sponsor Vim development!<br /> ~          type  :help sponsor&lt;Enter&gt;    for information<br />~<br /> ~          type  :q&lt;Enter&gt;               to exit<br />~          type  :help&lt;Enter&gt;  or  &lt;F1&gt;  for on-line help<br /> ~          type  :help version7&lt;Enter&gt;   for version info<br />~<br /> ~                   Running in Vi compatible mode<br />~          type  :set nocp&lt;Enter&gt;        for Vim defaults<br /> 137<br /></p>
<hr />
<p>12 – A Gentle Introduction To vi<br /> ~          type  :help cp-default&lt;Enter&gt; for info on this<br />~<br /> ~<br />~<br /> Just as we did with nano earlier, the first thing to learn is how to exit. To exit, we enter <br />the following command (note that the colon character is part of the command):<br /> <strong>:q</strong><br /> The shell prompt should return. If, for some reason, vi will not quit (usually because we <br />made a change to a file that has not yet been saved), we can tell vi that we really mean it <br />by adding an exclamation point to the command:<br /> <strong>:q!</strong><br /> <strong>Tip:</strong> If you get “lost” in vi, try pressing the Esc key twice to find your way again.<br /> <strong>Compatibility Mode<br /></strong>In the example startup screen above (taken from Ubuntu 8.04), we see the text <br />“Running in Vi compatible mode.” This means that vim will run in a mode that is <br />closer to the normal behavior of vi rather than the enhanced behavior of vim. <br />For purposes of this chapter, we will want to run vim with its enhanced behavior. <br />To do this, you have a few options:<br />Try running vim instead of vi.<br />If that works, consider adding alias vi='vim' to your .bashrc file.<br />Alternatively, use this command to add a line to your vim configuration file:<br />echo &quot;set nocp&quot; &gt;&gt; ~/.vimrc<br />Different Linux distributions package vim in different ways. Some distributions <br />install a minimal version of  vim  by default that only supports a limited set of <br />vim features. While preforming the lessons that follow, you may encounter miss-<br />ing features. If this is the case, install the full version of vim.<br /> 138<br /></p>
<hr />
<p>Editing Modes<br /> <strong>Editing Modes<br /></strong>Let's start up vi again, this time passing to it the name of a nonexistent file. This is how <br />we can create a new file with vi:<br /> [me@linuxbox ~]$ <strong>rm -f foo.txt<br /></strong>[me@linuxbox ~]$ <strong>vi foo.txt</strong><br /> If all goes well, we should get a screen like this:<br /> ~<br /> ~<br />~<br /> ~<br />~<br /> ~<br />~<br /> ~<br />~<br /> ~<br />~<br /> ~<br />~<br /> ~<br />~<br /> ~<br />~<br /> ~<br />~<br /> ~<br />~<br /> &quot;foo.txt&quot; [New File] <br /> The leading tilde characters (”~”) indicate that no text exists on that line. This shows that <br />we have an empty file. <strong>Do not type anything yet!<br /></strong>The second most important thing to learn about vi (after learning how to exit) is that vi <br />is a <em>modal editor</em>. When vi starts up, it begins in <em>command mode</em>. In this mode, almost <br />every key is a command, so if we were to start typing, vi would basically go crazy and <br />make a big mess.<br /> 139<br /></p>
<hr />
<p>12 – A Gentle Introduction To vi<br /> Entering Insert Mode<br />In order to add some text to our file, we must first enter <em>insert mode</em>. To do this, we press <br />the “i” key. Afterward, we should see the following at the bottom of the screen if vim is <br />running in its usual enhanced mode (this will not appear in vi compatible mode):<br /> <strong>-- INSERT --</strong><br /> Now we can enter some text. Try this:<br /> <strong>The quick brown fox jumped over the lazy dog.</strong><br /> To exit insert mode and return to command mode, press the Esc key.<br /> Saving Our Work<br />To save the change we just made to our file, we must enter an <em>ex command</em> while in com-<br />mand mode. This is easily done by pressing the “:” key. After doing this, a colon charac-<br />ter should appear at the bottom of the screen:<br /> :<br /> To write our modified file, we follow the colon with a “w” then Enter:<br /> :<strong>w</strong><br /> The file will be written to the hard drive and we should get a confirmation message at the <br />bottom of the screen, like this:<br /> &quot;foo.txt&quot; [New] 1L, 46C written<br /> <strong>Tip:</strong> If you read the vim documentation, you will notice that (confusingly) com-<br />mand mode is called <em>normal mode</em> and ex commands are called <em>command mode</em>. <br /> 140<br /></p>
<hr />
<p>Editing Modes<br /> Beware.<br /> <strong>Moving The Cursor Around<br /></strong>While in command mode,  vi offers a large number of movement commands, some of <br />which it shares with less. Here is a subset:<br /> <em>Table 12-1: Cursor Movement Keys</em><br /> <strong>Key</strong><br /> <strong>Moves The Cursor</strong><br /> l or Right Arrow<br /> Right one character.<br /> h or Left Arrow<br /> Left one character.<br /> j or Down Arrow<br /> Down one line.<br /> k or Up Arrow<br /> Up one line.<br /> 0 (zero)<br /> To the beginning of the current line.<br /> ^<br /> To the first non-whitespace character on the current <br />line.<br /> $<br /> To the end of the current line.<br /> w<br /> To the beginning of the next word or punctuation <br />character.<br /> W<br /> To the beginning of the next word, ignoring <br />punctuation characters.<br /> b<br /> To the beginning of the previous word or punctuation <br />character.<br /> B<br /> To the beginning of the previous word, ignoring <br />punctuation characters.<br /> Ctrl-f or Page Down<br /> Down one page.<br /> Ctrl-b or Page Up<br /> Up one page.<br /> <em>number</em>G<br /> To line <em>number</em>. For example, 1G moves to the first <br />line of the file.<br /> G<br /> To the last line of the file.<br /> Why are the h, j, k, and l keys used for cursor movement? Because when vi was origi-<br /> 141<br /></p>
<hr />
<p>12 – A Gentle Introduction To vi<br /> nally written, not all video terminals had arrow keys, and skilled typists could use regular <br />keyboard keys to move the cursor without ever having to lift their fingers from the key-<br />board.<br />Many commands in vi can be prefixed with a number, as with the “G” command listed <br />above. By prefixing a command with a number, we may specify the number of times a <br />command is to be carried out. For example, the command “5j” causes vi to move the <br />cursor down five lines.<br /> <strong>Basic Editing<br /></strong>Most editing consists of a few basic operations such as inserting text, deleting text, and <br />moving text around by cutting and pasting. vi, of course, supports all of these operations <br />in its own unique way. vi also provides a limited form of undo. If we press the “u” key <br />while in command mode, vi will undo the last change that you made. This will come in <br />handy as we try out some of the basic editing commands.<br /> Appending Text<br />vi has several different ways of entering insert mode. We have already used the i com-<br />mand to insert text.<br />Let's go back to our foo.txt file for a moment:<br /> The quick brown fox jumped over the lazy dog.<br /> If we wanted to add some text to the end of this sentence, we would discover that the i <br />command will not do it, since we can't move the cursor beyond the end of the line. vi <br />provides a command to append text, the sensibly named “a” command. If we move the <br />cursor to the end of the line and type “a”, the cursor will move past the end of the line <br />and vi will enter insert mode. This will allow us to add some more text:<br /> The quick brown fox jumped over the lazy dog.<strong> It was cool.</strong><br /> Remember to press the Esc key to exit insert mode.<br />Since we will almost always want to append text to the end of a line, vi offers a shortcut <br />to move to the end of the current line and start appending. It's the “A” command. Let's try <br />it and add some more lines to our file.<br />First, we'll move the cursor to the beginning of the line using the “0” (zero) command. <br /> 142<br /></p>
<hr />
<p>Basic Editing<br /> Now we type “A” and add the following lines of text:<br /> The quick brown fox jumped over the lazy dog. It was cool.<br /><strong>Line 2</strong><br /> <strong>Line 3<br />Line 4</strong><br /> <strong>Line 5</strong><br /> Again, press the Esc key to exit insert mode.<br />As we can see, the “A” command is more useful as it moves the cursor to the end of the <br />line before starting insert mode.<br /> Opening A Line<br />Another way we can insert text is by “opening” a line. This inserts a blank line between <br />two existing lines and enters insert mode. This has two variants:<br /> <em>Table 12-2: Line Opening Keys</em><br /> <strong>Command</strong><br /> <strong>Opens</strong><br /> o<br /> The line below the current line.<br /> O<br /> The line above the current line.<br /> We can demonstrate this as follows: place the cursor on “Line 3” then press the o key.<br /> The quick brown fox jumped over the lazy dog. It was cool.<br /> Line 2<br />Line 3<br /> Line 4<br /> Line 5<br /> A new line was opened below the third line and we entered insert mode. Exit insert mode <br />by pressing the Esc key. Press the u key to undo our change.<br />Press the O key to open the line above the cursor:<br /> The quick brown fox jumped over the lazy dog. It was cool.<br /> Line 2<br /> 143<br /></p>
<hr />
<p>12 – A Gentle Introduction To vi<br /> Line 3<br /> Line 4<br />Line 5<br /> Exit insert mode by pressing the Esc key and undo our change by pressing u.<br /> Deleting Text<br />As we might expect, vi offers a variety of ways to delete text, all of which contain one <br />of two keystrokes. First, the x key will delete a character at the cursor location. x may be <br />preceded by a number specifying how many characters are to be deleted. The d key is <br />more general purpose. Like x, it may be preceded by a number specifying the number of <br />times the deletion is to be performed. In addition, d is always followed by a movement <br />command that controls the size of the deletion. Here are some examples: <br /> <em>Table 12-3: Text Deletion Commands</em><br /> <strong>Command</strong><br /> <strong>Deletes</strong><br /> x<br /> The current character.<br /> 3x<br /> The current character and the next two characters.<br /> dd<br /> The current line.<br /> 5dd<br /> The current line and the next four lines.<br /> dW<br /> From the current cursor position to the beginning of <br />the next word.<br /> d$<br /> From the current cursor location to the end of the <br />current line.<br /> d0<br /> From the current cursor location to the beginning of <br />the line.<br /> d^<br /> From the current cursor location to the first non-<br />whitespace character in the line.<br /> dG<br /> From the current line to the end of the file.<br /> d20G<br /> From the current line to the twentieth line of the file.<br /> Place the cursor on the word “It” on the first line of our text. Press the x key repeatedly <br />until the rest of the sentence is deleted. Next, press the u key repeatedly until the deletion <br /> 144<br /></p>
<hr />
<p>Basic Editing<br /> is undone.<br /> <strong>Note:</strong> Real vi only supports a single level of undo. vim supports multiple levels.<br /> Let's try the deletion again, this time using the d command. Again, move the cursor to the <br />word “It” and press dW to delete the word:<br /> The quick brown fox jumped over the lazy dog. was cool.<br />Line 2<br /> Line 3<br />Line 4<br /> Line 5<br /> Press d$ to delete from the cursor position to the end of the line:<br /> The quick brown fox jumped over the lazy dog.<br /> Line 2<br />Line 3<br /> Line 4<br />Line 5<br /> Press dG to delete from the current line to the end of the file:<br /> ~<br />~<br /> ~<br />~<br /> ~<br /> Press u three times to undo the deletion.<br /> Cutting, Copying, And Pasting Text<br />The d command not only deletes text, it also “cuts” text. Each time we use the d com-<br />mand the deletion is copied into a paste buffer (think clipboard) that we can later recall <br />with the p command to paste the contents of the buffer after the cursor or the P command <br />to paste the contents before the cursor.<br />The y command is used to “yank” (copy) text in much the same way the d command is <br /> 145<br /></p>
<hr />
<p>12 – A Gentle Introduction To vi<br /> used to cut text. Here are some examples combining the y command with various move-<br />ment commands:<br /> <em>Table13- 4: Yanking Commands</em><br /> <strong>Command</strong><br /> <strong>Copies</strong><br /> yy<br /> The current line.<br /> 5yy<br /> The current line and the next four lines.<br /> yW<br /> From the current cursor position to the beginning of <br />the next word.<br /> y$<br /> From the current cursor location to the end of the <br />current line.<br /> y0<br /> From the current cursor location to the beginning of <br />the line.<br /> y^<br /> From the current cursor location to the first non-<br />whitespace character in the line.<br /> yG<br /> From the current line to the end of the file.<br /> y20G<br /> From the current line to the twentieth line of the file.<br /> Let's try some copy and paste. Place the cursor on the first line of the text and type yy to <br />copy the current line. Next, move the cursor to the last line (G) and type p to paste the <br />line below the current line:<br /> The quick brown fox jumped over the lazy dog. It was cool.<br />Line 2<br /> Line 3<br />Line 4<br /> Line 5<br /><strong>The quick brown fox jumped over the lazy dog. It was cool.</strong><br /> Just as before, the u command will undo our change. With the cursor still positioned on <br />the last line of the file, type P to paste the text above the current line:<br /> The quick brown fox jumped over the lazy dog. It was cool.<br />Line 2<br /> Line 3<br />Line 4<br /> 146<br /></p>
<hr />
<p>Basic Editing<br /> <strong>The quick brown fox jumped over the lazy dog. It was cool.<br /></strong>Line 5<br /> Try out some of the other y commands in the table above and get to know the behavior of <br />both the p and P commands. When you are done, return the file to its original state.<br /> Joining Lines<br />vi is rather strict about its idea of a line. Normally, it is not possible to move the cursor <br />to the end of a line and delete the end-of-line character to join one line with the one be-<br />low it. Because of this, vi provides a specific command, J (not to be confused with j, <br />which is for cursor movement) to join lines together.<br />If we place the cursor on line 3 and type the J command, here's what happens:<br /> The quick brown fox jumped over the lazy dog. It was cool.<br />Line 2<br /> <strong>Line 3 Line 4<br /></strong>Line 5<br /> <strong>Search-And-Replace<br /></strong>vi has the ability to move the cursor to locations based on searches. It can do this on ei-<br />ther a single line or over an entire file. It can also perform text replacements with or with-<br />out confirmation from the user.<br /> Searching Within A Line<br />The f command searches a line and moves the cursor to the next instance of a specified <br />character. For example, the command fa would move the cursor to the next occurrence <br />of the character “a” within the current line. After performing a character search within a <br />line, the search may be repeated by typing a semicolon.<br /> Searching The Entire File<br />To move the cursor to the next occurrence of a word or phrase, the / command is used. <br />This works the same way as we learned earlier in the less program. When you type the <br />/ command a “/” will appear at the bottom of the screen. Next, type the word or phrase to <br />be searched for, followed by the Enter key. The cursor will move to the next location <br />containing the search string. A search may be repeated using the previous search string <br /> 147<br /></p>
<hr />
<p>12 – A Gentle Introduction To vi<br /> with the n command. Here's an example:<br /> The quick brown fox jumped over the lazy dog. It was cool.<br />Line 2<br /> Line 3<br />Line 4<br /> Line 5<br /> Place the cursor on the first line of the file. Type:<br />  <strong>/Line</strong><br /> followed by the Enter key. The cursor will move to line 2. Next, type n and the cursor <br />will move to line 3. Repeating the n command will move the cursor down the file until it <br />runs out of matches. While we have so far only used words and phrases for our search <br />patterns, vi allows the use of <em>regular expressions</em>, a powerful method of expressing com-<br />plex text patterns. We will cover regular expressions in some detail in a later chapter.<br /> Global Search-And-Replace<br />vi uses an ex command to perform search-and-replace operations (called “substitution” <br />in vi) over a range of lines or the entire file. To change the word “Line” to “line” for the <br />entire file, we would enter the following command:<br /> <strong>:%s/Line/line/g</strong><br /> Let's break this command down into separate items and see what each one does:<br /> <em>Table12- 5:An example of global search-and-replace syntax</em><br /> <strong>Item</strong><br /> <strong>Meaning</strong><br /> :<br /> The colon character starts an ex command.<br /> %<br /> Specifies the range of lines for the operation. % is a shortcut <br />meaning from the first line to the last line. Alternately, the <br />range could have been specified 1,5 (since our file is five <br />lines long), or 1,$ which means “from line 1 to the last line in <br />the file.” If the range of lines is omitted, the operation is only <br />performed on the current line.<br /> 148<br /></p>
<hr />
<p>Search-And-Replace<br /> s<br /> Specifies the operation. In this case, substitution (search-and-<br />replace).<br /> /Line/line/<br /> The search pattern and the replacement text.<br /> g<br /> This means “global” in the sense that the search-and-replace is <br />performed on every instance of the search string in the line. If <br />omitted, only the first instance of the search string on each line <br />is replaced.<br /> After executing our search-and-replace command our file looks like this:<br /> The quick brown fox jumped over the lazy dog. It was cool.<br />line 2<br /> line 3<br />line 4<br /> line 5<br /> We can also specify a substitution command with user confirmation. This is done by <br />adding a “c” to the end of the command. For example:<br /> <strong>:%s/line/Line/gc</strong><br /> This command will change our file back to its previous form; however, before each sub-<br />stitution, vi stops and asks us to confirm the substitution with this message:<br /> replace with Line (y/n/a/q/l/^E/^Y)?<br /> Each of the characters within the parentheses is a possible choice as follows:<br /> <em>Table 12-6: Replace Confirmation Keys</em><br /> <strong>Key</strong><br /> <strong>Action</strong><br /> y<br /> Perform the substitution.<br /> n<br /> Skip this instance of the pattern.<br /> a<br /> Perform the substitution on this and all subsequent instances <br />of the pattern.<br /> 149<br /></p>
<hr />
<p>12 – A Gentle Introduction To vi<br /> q or Esc<br /> Quit substituting.<br /> l<br /> Perform this substitution and then quit. Short for “last.”<br /> Ctrl-e, Ctrl-y<br /> Scroll down and scroll up, respectively. Useful for viewing <br />the context of the proposed substitution.<br />  <br />If you type y, the substitution will be performed, n will cause vi to skip this instance and <br />move on to the next one. <br /> <strong>Editing Multiple Files<br /></strong>It's often useful to edit more than one file at a time. You might need to make changes to <br />multiple files or you may need to copy content from one file into another. With vi we <br />can open multiple files for editing by specifying them on the command line:<br /> vi <em>file1 file2 file3...</em><br /> Let's exit our existing vi session and create a new file for editing. Type :wq to exit vi, <br />saving our modified text. Next, we'll create an additional file in our home directory that <br />we can play with. We'll create the file by capturing some output from the ls command:<br /> [me@linuxbox ~]$ <strong>ls -l /usr/bin &gt; ls-output.txt</strong><br /> Let's edit our old file and our new one with vi:<br /> [me@linuxbox ~]$ <strong>vi foo.txt ls-output.txt</strong><br /> vi will start up and we will see the first file on the screen:<br /> The quick brown fox jumped over the lazy dog. It was cool.<br /> Line 2<br />Line 3<br /> Line 4<br />Line 5<br /> 150<br /></p>
<hr />
<p>Editing Multiple Files<br /> Switching Between Files<br />To switch from one file to the next, use this ex command:<br /> <strong>:n</strong><br /> To move back to the previous file use:<br /> <strong>:N</strong><br /> While we can move from one file to another, vi enforces a policy that prevents us from <br />switching files if the current file has unsaved changes. To force  vi to switch files and <br />abandon your changes, add an exclamation point (!) to the command.<br />In addition to the switching method described above, vim (and some versions of vi) also <br />provide some ex commands that make multiple files easier to manage. We can view a list <br />of files being edited with the :buffers command. Doing so will display a list of the <br />files at the bottom of the display:<br /> <strong>:buffers<br /></strong>  1 %a   &quot;foo.txt&quot;                      line 1<br />   2      &quot;ls-output.txt&quot;                line 0<br />Press ENTER or type command to continue <br /> To switch to another buffer (file), type :buffer followed by the number of the buffer <br />you wish to edit. For example, to switch from buffer 1 which contains the file foo.txt <br />to buffer 2 containing the file ls-output.txt we would type this:<br /> <strong>:buffer 2</strong><br /> and our screen now displays the second file.<br /> Opening Additional Files For Editing<br />It's also possible to add files to our current editing session. The ex command :e (short for <br />“edit”) followed by a filename will open an additional file. Let's end our current editing <br />session and return to the command line.<br /> 151<br /></p>
<hr />
<p>12 – A Gentle Introduction To vi<br /> Start vi again with just one file:<br /> [me@linuxbox ~]$ <strong>vi foo.txt</strong><br /> To add our second file, enter:<br /> <strong>:e ls-output.txt</strong><br /> And it should appear on the screen. The first file is still present as we can verify:<br /> <strong>:buffers<br /></strong>  1 #    &quot;foo.txt&quot;                      line 1<br />   2 %a   &quot;ls-output.txt&quot;                line 0<br />Press ENTER or type command to continue <br /> <strong>Note:</strong> You cannot switch to files loaded with the :e command using either the :n <br />or :N command. To switch files, use the :buffer command followed by the buf-<br />fer number.<br /> Copying Content From One File Into Another<br />Often while editing multiple files, we will want to copy a portion of one file into another <br />file that we are editing. This is easily done using the usual yank and paste commands we <br />used earlier. We can demonstrate as follows. First, using our two files, switch to buffer 1 <br />(foo.txt) by entering:<br /> <strong>:buffer 1</strong><br /> which should give us this:<br /> 152<br /></p>
<hr />
<p>Editing Multiple Files<br /> The quick brown fox jumped over the lazy dog. It was cool.<br />Line 2<br /> Line 3<br />Line 4<br /> Line 5<br /> Next, move the cursor to the first line, and type yy to yank (copy) the line.<br />Switch to the second buffer by entering:<br /> <strong>:buffer 2</strong><br /> The screen will now contain some file listings like this (only a portion is shown here):<br /> total 343700<br />-rwxr-xr-x 1 root root       31316 2007-12-05 08:58 [<br /> -rwxr-xr-x 1 root root        8240 2007-12-09 13:39 411toppm<br />-rwxr-xr-x 1 root root      111276 2008-01-31 13:36 a2p<br /> -rwxr-xr-x 1 root root       25368 2006-10-06 20:16 a52dec<br />-rwxr-xr-x 1 root root       11532 2007-05-04 17:43 aafire<br /> -rwxr-xr-x 1 root root        7292 2007-05-04 17:43 aainfo<br /> Move the cursor to the first line and paste the line we copied from the preceding file by <br />typing the p command:<br /> total 343700<br /> <strong>The quick brown fox jumped over the lazy dog. It was cool.<br /></strong>-rwxr-xr-x 1 root root       31316 2007-12-05 08:58 [<br /> -rwxr-xr-x 1 root root        8240 2007-12-09 13:39 411toppm<br />-rwxr-xr-x 1 root root      111276 2008-01-31 13:36 a2p<br /> -rwxr-xr-x 1 root root       25368 2006-10-06 20:16 a52dec<br />-rwxr-xr-x 1 root root       11532 2007-05-04 17:43 aafire<br /> -rwxr-xr-x 1 root root        7292 2007-05-04 17:43 aainfo<br /> Inserting An Entire File Into Another<br />It's also possible to insert an entire file into one that we are editing. To see this in action, <br />let's end our vi session and start a new one with just a single file:<br /> 153<br /></p>
<hr />
<p>12 – A Gentle Introduction To vi<br /> [me@linuxbox ~]$ <strong>vi ls-output.txt</strong><br /> We will see our file listing again:<br /> total 343700<br /> -rwxr-xr-x 1 root root       31316 2007-12-05 08:58 [<br />-rwxr-xr-x 1 root root        8240 2007-12-09 13:39 411toppm<br /> -rwxr-xr-x 1 root root      111276 2008-01-31 13:36 a2p<br />-rwxr-xr-x 1 root root       25368 2006-10-06 20:16 a52dec<br /> -rwxr-xr-x 1 root root       11532 2007-05-04 17:43 aafire<br />-rwxr-xr-x 1 root root        7292 2007-05-04 17:43 aainfo<br /> Move the cursor to the third line, then enter the following ex command:<br /> <strong>:r foo.txt</strong><br /> The :r command (short for “read”) inserts the specified file before the cursor position. <br />Our screen should now look like this:<br /> total 343700<br /> -rwxr-xr-x 1 root root       31316 2007-12-05 08:58 [<br />-rwxr-xr-x 1 root root        8240 2007-12-09 13:39 411toppm<br /> <strong>The quick brown fox jumped over the lazy dog. It was cool.<br />Line 2</strong><br /> <strong>Line 3<br />Line 4</strong><br /> <strong>Line 5<br /></strong>-rwxr-xr-x 1 root root      111276 2008-01-31 13:36 a2p<br /> -rwxr-xr-x 1 root root       25368 2006-10-06 20:16 a52dec<br />-rwxr-xr-x 1 root root       11532 2007-05-04 17:43 aafire<br /> -rwxr-xr-x 1 root root        7292 2007-05-04 17:43 aainfo<br /> <strong>Saving Our Work<br /></strong>Like everything else in vi, there are several different ways to save our edited files. We <br />have already covered the ex command :w, but there are some others we may also find <br />helpful.<br />In command mode, typing  ZZ  will save the current file and exit  vi. Likewise, the ex <br />command :wq will combine the :w and :q commands into one that will both save the <br /> 154<br /></p>
<hr />
<p>Saving Our Work<br /> file and exit.<br />The :w command may also specify an optional filename. This acts like “Save As...” For <br />example, if we were editing  foo.txt  and wanted to save an alternate version called <br />foo1.txt, we would enter the following:<br /> <strong>:w foo1.txt</strong><br /> <strong>Note:</strong>  While the command above saves the file under a new name, it does not <br />change the name of the file you are editing. As you continue to edit, you will still <br />be editing foo.txt, not foo1.txt.<br /> <strong>Summing Up<br /></strong>With this basic set of skills we can now perform most of the text editing needed to main-<br />tain a typical Linux system. Learning to use vim on a regular basis will pay off in the <br />long run. Since vi-style editors are so deeply embedded in Unix culture, we will see many <br />other programs that have been influenced by its design. less is a good example of this <br />influence.<br /> <strong>Further Reading<br /></strong>Even with all that we have covered in this chapter, we have barely scratched the surface <br />of what vi and vim can do. Here are a couple of on-line resources you can use to con-<br />tinue your journey towards vi mastery:<br /> ●<br /> <em>Learning The vi Editor</em> – A Wikibook from Wikipedia that offers a concise guide <br />to vi and several of its work-a-likes including vim. It's available at:<br /><a href="http://en.wikibooks.org/wiki/Vi">http://en.wikibooks.org/wiki/Vi</a><br /> ●<br /> <em>The Vim Book</em> - The vim project has a 570-page book that covers (almost) all of <br />the features in vim. You can find it at:<br /><a href="ftp://ftp.vim.org/pub/vim/doc/book/vimbook-OPL.pdf">ft</a><br /> <a href="ftp://ftp.vim.org/pub/vim/doc/book/vimbook-OPL.pdf">  p://ftp.vim.org/pub/vim/doc/book/vimbook-OPL.pdf . </a><br /> ●<br /> A Wikipedia article on Bill Joy, the creator of vi.:<br /><a href="http://en.wikipedia.org/wiki/Bill_Joy">http://en.wikipedia.org/wiki/Bill_Joy</a><br /> ●<br /> A Wikipedia article on Bram Moolenaar, the author of vim:<br /><a href="http://en.wikipedia.org/wiki/Bram_Moolenaar">http://en.wikipedia.org/wiki/Bram_Moolenaar</a><br /> 155<br /></p>
<hr />
<p>13 – Customizing The Prompt<br /> <em><strong>13 – Customizing The Prompt</strong></em><br /> In this chapter we will look at a seemingly trivial detail — our shell prompt. This exami-<br />nation will reveal some of the inner workings of the shell and the terminal emulator pro-<br />gram itself.<br />Like so many things in Linux, the shell prompt is highly configurable, and while we have <br />pretty much taken it for granted, the prompt is a really useful device once we learn how <br />to control it.<br /> <strong>Anatomy Of A Prompt<br /></strong>Our default prompt looks something like this:<br /> [me@linuxbox ~]$<br /> Notice that it contains our username, our hostname and our current working directory, but <br />how did it get that way? Very simply, it turns out. The prompt is defined by an environ-<br />ment variable named PS1 (short for “prompt string one”). We can view the contents of <br />PS1 with the echo command:<br /> [me@linuxbox ~]$ <strong>echo $PS1</strong><br /> [\u@\h \W]\$<br /> <strong>Note:</strong> Don't worry if your results are not exactly the same as the example above. <br />Every Linux distribution defines the prompt string a little differently, some quite <br />exotically.<br /> From the results, we can see that  PS1  contains a few of the characters we see in our <br />prompt such as the brackets, the at-sign, and the dollar sign, but the rest are a mystery. <br />The astute among us will recognize these as  <em>backslash-escaped special characters</em>  like <br /> 156<br /></p>
<hr />
<p>Anatomy Of A Prompt<br /> those we saw in Chapter 7. Here is a partial list of the characters that the shell treats spe-<br />cially in the prompt string: <br /> <em>Table 13-1: Escape Codes Used In Shell Prompts</em><br /> <strong>Sequence</strong><br /> <strong>Value Displayed</strong><br /> \a<br /> ASCII bell. This makes the computer beep when it is encountered.<br /> \d<br /> Current date in day, month, date format. For example, “Mon May <br />26.” <br /> \h<br /> Hostname of the local machine minus the trailing domain name.<br /> \H<br /> Full hostname.<br /> \j<br /> Number of jobs running in the current shell session.<br /> \l<br /> Name of the current terminal device.<br /> \n<br /> A newline character.<br /> \r<br /> A carriage return.<br /> \s<br /> Name of the shell program.<br /> \t<br /> Current time in 24 hour hours:minutes:seconds format.<br /> \T<br /> Current time in 12 hour format.<br /> \@<br /> Current time in 12 hour AM/PM format.<br /> \A<br /> Current time in 24 hour hours:minutes format.<br /> \u<br /> username of the current user.<br /> \v<br /> Version number of the shell.<br /> \V<br /> Version and release numbers of the shell.<br /> \w<br /> Name of the current working directory.<br /> \W<br /> Last part of the current working directory name.<br /> \!<br /> History number of the current command.<br /> \#<br /> Number of commands entered during this shell session.<br /> \$<br /> This displays a “$” character unless you have superuser privileges. <br />In that case, it displays a “#” instead.<br /> \[<br /> Signals the start of a series of one or more non-printing characters. <br />This is used to embed non-printing control characters which <br />manipulate the terminal emulator in some way, such as moving the <br /> 157<br /></p>
<hr />
<p>13 – Customizing The Prompt<br /> cursor or changing text colors.<br /> \]<br /> Signals the end of a non-printing character sequence.<br /> <strong>Trying Some Alternative Prompt Designs<br /></strong>With this list of special characters, we can change the prompt to see the effect. First, we'll <br />back up the existing string so we can restore it later. To do this, we will copy the existing <br />string into another shell variable that we create ourselves:<br /> [me@linuxbox ~]$ <strong>ps1_old=&quot;$PS1&quot;</strong><br /> We create a new variable called ps1_old and assign the value of PS1 to it. We can ver-<br />ify that the string has been copied by using the echo command:<br /> [me@linuxbox ~]$ <strong>echo $ps1_old</strong><br /> [\u@\h \W]\$<br /> We can restore the original prompt at any time during our terminal session by simply re-<br />versing the process:<br /> [me@linuxbox ~]$ <strong>PS1=&quot;$ps1_old&quot;</strong><br /> Now that we are ready to proceed, let's see what happens if we have an empty prompt <br />string:<br /> [me@linuxbox ~]$ <strong>PS1=</strong><br /> If we assign nothing to the prompt string, we get nothing. No prompt string at all! The <br />prompt is still there, but displays nothing, just as we asked it to. Since this is kind of dis-<br />concerting to look at, we'll replace it with a minimal prompt:<br /> <strong>PS1=&quot;\$ &quot;</strong><br /> That's better. At least now we can see what we are doing. Notice the trailing space within <br />the double quotes. This provides the space between the dollar sign and the cursor when <br /> 158<br /></p>
<hr />
<p>Trying Some Alternative Prompt Designs<br /> the prompt is displayed.<br />Let's add a bell to our prompt:<br /> $ <strong>PS1=&quot;\[\a\]\$ &quot;</strong><br /> Now we should hear a beep each time the prompt is displayed. This could get annoying, <br />but it might be useful if we needed notification when an especially long-running com-<br />mand has been executed. Note that we included the  \[  and  \]  sequences. Since the <br />ASCII bell (\a) does not “print,” that is, it does not move the cursor, we need to tell <br />bash so it can correctly determine the length of the prompt.<br />Next, let's try to make an informative prompt with some hostname and time-of-day infor-<br />mation:<br /> $ <strong>PS1=&quot;\A \h \$ &quot;</strong><br /> 17:33 linuxbox $<br /> Adding time-of-day to our prompt will be useful if we need to keep track of when we <br />perform certain tasks. Finally, we'll make a new prompt that is similar to our original:<br /> 17:37 linuxbox $ <strong>PS1=&quot;&lt;\u@\h \W&gt;\$ &quot;</strong><br /> &lt;me@linuxbox ~&gt;$<br /> Try out the other sequences listed in the table above and see if you can come up with a <br />brilliant new prompt.<br /> <strong>Adding Color<br /></strong>Most terminal emulator programs respond to certain non-printing character sequences to <br />control such things as character attributes (like color, bold text, and the dreaded blinking <br />text) and cursor position. We'll cover cursor position in a little bit, but first we'll look at <br />color.<br /> 159<br /></p>
<hr />
<p>13 – Customizing The Prompt<br /> <strong>Terminal Confusion<br /></strong>Back in ancient times, when  terminals  were hooked to remote computers, there <br />were many competing brands of terminals and they all worked differently. They <br />had different keyboards and they all had different ways of interpreting control in-<br />formation. Unix and Unix-like systems have two rather complex subsystems to <br />deal with the babel of terminal control (called termcap and terminfo). If you <br />look in the deepest recesses of your terminal emulator settings you may find a set-<br />ting for the type of terminal emulation.<br />In an effort to make terminals speak some sort of common language, the Ameri-<br />can National Standards Institute (ANSI) developed a standard set of character se-<br />quences to control video terminals. Old time DOS users will remember the AN-<br />SI.SYS file that was used to enable interpretation of these codes.<br /> Character color is controlled by sending the terminal emulator an <em>ANSI escape code</em> em-<br />bedded in the stream of characters to be displayed. The control code does not “print out” <br />on the display, rather it is interpreted by the terminal as an instruction. As we saw in the <br />table above, the \[ and \] sequences are used to encapsulate non-printing characters. An <br />ANSI escape code begins with an octal 033 (the code generated by the escape key), fol-<br />lowed by an optional character attribute, followed by an instruction. For example, the <br />code to set the text color to normal (attribute = 0), black text is:<br />\033[0;30m<br />Here is a table of available text colors. Notice that the colors are divided into two groups, <br />differentiated by the application of the bold character attribute (1) which creates the ap-<br />pearance of “light” colors:<br /> <em>Table14- 2: Escape Sequences Used To Set Text Colors</em><br /> <strong>Sequence</strong><br /> <strong>Text Color</strong><br /> <strong>Sequence</strong><br /> <strong>Text Color</strong><br /> \033[0;30m<br /> Black<br /> \033[1;30m<br /> Dark Gray<br /> \033[0;31m<br /> Red<br /> \033[1;31m<br /> Light Red<br /> \033[0;32m<br /> Green<br /> \033[1;32m<br /> Light Green<br /> \033[0;33m<br /> Brown<br /> \033[1;33m<br /> Yellow<br /> \033[0;34m<br /> Blue<br /> \033[1;34m<br /> Light Blue<br /> \033[0;35m<br /> Purple<br /> \033[1;35m<br /> Light Purple<br /> 160<br /></p>
<hr />
<p>Adding Color<br /> \033[0;36m<br /> Cyan<br /> \033[1;36m<br /> Light Cyan<br /> \033[0;37m<br /> Light Grey<br /> \033[1;37m<br /> White<br /> Let's try to make a red prompt. We'll insert the escape code at the beginning:<br /> &lt;me@linuxbox ~&gt;$ <strong>PS1=&quot;\[\033[0;31m\]&lt;\u@\h \W&gt;\$ &quot;<br /></strong>&lt;me@linuxbox ~&gt;$<br /> That works, but notice that all the text that we type after the prompt is also red. To fix <br />this, we will add another escape code to the end of the prompt that tells the terminal emu-<br />lator to return to the previous color:<br /> &lt;me@linuxbox ~&gt;$ <strong>PS1=&quot;\[\033[0;31m\]&lt;\u@\h \W&gt;\$\[\033[0m\] &quot;<br /></strong>&lt;me@linuxbox ~&gt;$<br /> That's better!<br />It's also possible to set the text background color using the codes listed below. The back-<br />ground colors do not support the bold attribute.<br /> <em>Table 13-3: Escape Sequences Used To Set Background Color</em><br /> <strong>Sequence</strong><br /> <strong>Background Color</strong><br /> <strong>Sequence</strong><br /> <strong>Background Color</strong><br /> \033[0;40m<br /> Black<br /> \033[0;44m<br /> Blue<br /> \033[0;41m<br /> Red<br /> \033[0;45m<br /> Purple<br /> \033[0;42m<br /> Green<br /> \033[0;46m<br /> Cyan<br /> \033[0;43m<br /> Brown<br /> \033[0;47m<br /> Light Grey<br /> We can create a prompt with a red background by applying a simple change to the first <br />escape code:<br /> &lt;me@linuxbox ~&gt;$ <strong>PS1=&quot;\[\033[0;41m\]&lt;\u@\h \W&gt;\$\[\033[0m\] &quot;<br /></strong>&lt;me@linuxbox ~&gt;$<br /> Try out the color codes and see what you can create!<br /> 161<br /></p>
<hr />
<p>13 – Customizing The Prompt<br /> <strong>Note:</strong>  Besides the normal (0) and bold (1) character attributes, text may also be <br />given underscore (4), blinking (5), and inverse (7) attributes as well. In the interests <br />of good taste, many terminal emulators refuse to honor the blinking attribute, how-<br />ever.<br /> <strong>Moving The Cursor<br /></strong>Escape codes can be used to position the cursor. This is commonly used to provide a <br />clock or some other kind of information at a different location on the screen, such as an <br />upper corner each time the prompt is drawn. Here is a list of the escape codes that posi-<br />tion the cursor:<br /> <em>Table 13-4: Cursor Movement Escape Sequences</em><br /> <strong>Escape Code</strong><br /> <strong>Action</strong><br /> \033[<em>l</em>;<em>c</em>H<br /> Move the cursor to line <em>l</em> and column <em>c</em><br /> \033[<em>n</em>A<br /> Move the cursor up <em>n</em> lines<br /> \033[<em>n</em>B<br /> Move the cursor down <em>n</em> lines<br /> \033[<em>n</em>C<br /> Move the cursor forward <em>n</em> characters<br /> \033[<em>n</em>D<br /> Move the cursor backward <em>n</em> characters<br /> \033[2J<br /> Clear the screen and move the cursor to the upper left corner (line <br />0, column 0)<br /> \033[K<br /> Clear from the cursor position to the end of the current line<br /> \033[s<br /> Store the current cursor position<br /> \033[u<br /> Recall the stored cursor position<br /> Using the codes above, we'll construct a prompt that draws a red bar at the top of the <br />screen containing a clock (rendered in yellow text) each time the prompt is displayed. <br />The code for the prompt is this formidable looking string:<br /> <strong>PS1=&quot;\[\033[s\033[0;0H\033[0;41m\033[K\033[1;33m\t\033[0m\033[u\]<br />&lt;\u@\h \W&gt;\$ &quot;</strong><br /> Let's take a look at each part of the string to see what it does:<br /> 162<br /></p>
<hr />
<p>Moving The Cursor<br /> <em>Table 13-5: Breakdown Of Complex Prompt String</em><br /> <strong>Sequence</strong><br /> <strong>Action</strong><br /> \[<br /> Begins a non-printing character sequence. The purpose of this <br />is to allow bash to properly calculate the size of the visible <br />prompt. Without an accurate calculation, command line editing <br />features cannot position the cursor correctly.<br /> \033[s<br /> Store the cursor position. This is needed to return to the prompt <br />location after the bar and clock have been drawn at the top of <br />the screen. <em>Be aware that some terminal emulators do not <br />honor this code.</em><br /> \033[0;0H<br /> Move the cursor to the upper left corner, which is line 0, <br />column 0.<br /> \033[0;41m<br /> Set the background color to red.<br /> \033[K<br /> Clear from the current cursor location (the top left corner) to <br />the end of the line. Since the background color is now red, the <br />line is cleared to that color creating our bar. Note that clearing <br />to the end of the line does not change the cursor position, which <br />remains at the upper left corner.<br /> \033[1;33m<br /> Set the text color to yellow.<br /> \t<br /> Display the current time. While this is a “printing” element, we <br />still include it in the non-printing portion of the prompt, since <br />we don't want bash to include the clock when calculating the <br />true size of the displayed prompt.<br /> \033[0m<br /> Turn off color. This affects both the text and background.<br /> \033[u<br /> Restore the cursor position saved earlier.<br /> \]<br /> End the non-printing characters sequence.<br /> &lt;\u@\h \W&gt;\$<br /> Prompt string.<br /> <strong>Saving The Prompt<br /></strong>Obviously, we don't want to be typing that monster all the time, so we'll want to store our <br />prompt someplace. We can make the prompt permanent by adding it to our  .bashrc <br />file. To do so, add these two lines to the file:<br /> <strong>PS1=&quot;\[\033[s\033[0;0H\033[0;41m\033[K\033[1;33m\t\033[0m\033[u\]</strong><br /> 163<br /></p>
<hr />
<p>13 – Customizing The Prompt<br /> <strong>&lt;\u@\h \W&gt;\$ &quot;</strong><br /> <strong>export PS1</strong><br /> <strong>Summing Up<br /></strong>Believe it or not, there is much more that can be done with prompts involving shell func-<br />tions and scripts that we haven't covered here, but this is a good start. Not everyone will <br />care enough to change the prompt, since the default prompt is usually satisfactory. But for <br />those of us who like to tinker, the shell provides the opportunity for many hours of trivial <br />fun.<br /> <strong>Further Reading</strong><br /> ●<br /> The <em>Bash Prompt HOWTO</em> from the<a href="http://tldp.org/"> Linux Documentation Project provi</a>des a <br />pretty complete discussion of what the shell prompt can be made to do. It is avail-<br />able at:<br /><a href="http://tldp.org/HOWTO/Bash-Prompt-HOWTO/">http://tldp.org/HOWTO/Bash-Prompt-HOWTO/</a><br /> ●<br /> Wikipedia has a good article on the ANSI Escape Codes:<br /><a href="http://en.wikipedia.org/wiki/ANSI_escape_code">http://en.wikipedia.org/wiki/ANSI_escape_code</a><br /> 164<br /></p>
<hr />
<p>Part 3 – Common Tasks And Essential Tools<br /> Part 3 – Common Tasks And Essential <br /> Tools<br /> 165<br /></p>
<hr />
<p>14 – Package Management<br /> <em><strong>14 – Package Management</strong></em><br /> If we spend any time in the Linux community, we hear many opinions as to which of the <br />many Linux distributions is “best.” Often, these discussions get really silly, focusing on <br />such things as the prettiness of the desktop background (some people won't use Ubuntu <br />because of its default color scheme!) and other trivial matters.<br />The most important determinant of distribution quality is the <em>packaging system</em> and the <br />vitality of the distribution's support community. As we spend more time with Linux, we <br />see that its software landscape is extremely dynamic. Things are constantly changing. <br />Most of the top-tier Linux distributions release new versions every six months and many <br />individual program updates every day. To keep up with this blizzard of software, we need <br />good tools for <em>package management</em>.<br />Package management is a method of installing and maintaining software on the system. <br />Today, most people can satisfy all of their software needs by installing  <em>packages</em>  from <br />their Linux distributor. This contrasts with the early days of Linux, when one had to <br />download and compile <em>source code</em> in order to install software. Not that there is anything <br />wrong with compiling source code; in fact, having access to source code is the great won-<br />der of Linux. It gives us (and everybody else) the ability to examine and improve the sys-<br />tem. It's just that having a precompiled package is faster and easier to deal with.<br />In this chapter, we will look at some of the command line tools used for package manage-<br />ment. While all of the major distributions provide powerful and sophisticated graphical <br />programs for maintaining the system, it is important to learn about the command line pro-<br />grams, too. They can perform many tasks that are difficult (or impossible) to do with their <br />graphical counterparts.<br /> <strong>Packaging Systems<br /></strong>Different distributions use different packaging systems and as a general rule, a package <br />intended for one distribution is not compatible with another distribution. Most distribu-<br />tions fall into one of two camps of packaging technologies: the Debian “.deb” camp and <br />the Red Hat “.rpm” camp. There are some important exceptions such as Gentoo, Slack-<br />ware, and Foresight, but most others use one of these two basic systems. <br /> 166<br /></p>
<hr />
<p>Packaging Systems<br /> <em>Table 14-1: Major Packaging System Families</em><br /> <strong>Packaging System</strong><br /> <strong>Distributions (Partial Listing)</strong><br /> Debian Style (.deb)<br /> Debian, Ubuntu, Xandros, Linspire<br /> Red Hat Style (.rpm)<br /> Fedora, CentOS, Red Hat Enterprise Linux, OpenSUSE, <br />Mandriva, PCLinuxOS<br /> <strong>How A Package System Works<br /></strong>The method of software distribution found in the proprietary software industry usually <br />entails buying a piece of installation media such as an “install disk” and then running an <br />“installation wizard” to install a new application on the system.<br />Linux doesn't work that way. Virtually all software for a Linux system will be found on <br />the Internet. Most of it will be provided by the distribution vendor in the form of <em>package <br />files</em>  and the rest will be available in  source code  form that can be installed manually. <br />We'll talk a little about how to install software by compiling source code in a later chap-<br />ter.<br /> Package Files<br />The basic unit of software in a packaging system is the <em>package file</em>. A package file is a <br />compressed collection of files that comprise the software package. A package may consist <br />of numerous programs and data files that support the programs. In addition to the files to <br />be installed, the package file also includes metadata about the package, such as a text de-<br />scription of the package and its contents. Additionally, many packages contain pre- and <br />post-installation scripts that perform configuration tasks before and after the package in-<br />stallation.<br />Package files are created by a person known as a <em>package maintainer</em>, often (but not al-<br />ways) an employee of the distribution vendor. The package maintainer gets the software <br />in source code form from the <em>upstream provider</em> (the author of the program), compiles it, <br />and creates the package metadata and any necessary installation scripts. Often, the pack-<br />age maintainer will apply modifications to the original source code to improve the pro-<br />gram's integration with the other parts of the Linux distribution.<br /> Repositories<br />While some software projects choose to perform their own packaging and distribution, <br />most packages today are created by the distribution vendors and interested third parties. <br />Packages are made available to the users of a distribution in central repositories that may <br />contain many thousands of packages, each specially built and maintained for the distribu-<br />tion.<br /> 167<br /></p>
<hr />
<p>14 – Package Management<br /> A distribution may maintain several different repositories for different stages of the soft-<br />ware development life cycle. For example, there will usually be a “testing” repository <br />that contains packages that have just been built and are intended for use by brave souls <br />who are looking for bugs before they are released for general distribution. A distribution <br />will often have a “development” repository where work-in-progress packages destined <br />for inclusion in the distribution's next major release are kept.<br />A distribution may also have related third-party repositories. These are often needed to <br />supply software that, for legal reasons such as patents or DRM anti-circumvention issues, <br />cannot be included with the distribution. Perhaps the best known case is that of encrypted <br />DVD support, which is not legal in the United States. The third-party repositories operate <br />in countries where software patents and anti-circumvention laws do not apply. These <br />repositories are usually wholly independent of the distribution they support and to use <br />them, one must know about them and manually include them in the configuration files for <br />the package management system.<br /> Dependencies<br />Programs seldom “standalone”; rather they rely on the presence of other software compo-<br />nents to get their work done. Common activities, such as input/output for example, are <br />handled by routines shared by many programs. These routines are stored in what are <br />called <em>shared libraries</em>, which provide essential services to more than one program. If a <br />package requires a shared resource such as a shared library, it is said to have a  <em>depen-<br />dency</em>. Modern package management systems all provide some method of  <em>dependency <br />resolution</em> to ensure that when a package is installed, all of its dependencies are installed, <br />too. <br /> High And Low-level Package Tools<br />Package management systems usually consist of two types of tools: low-level tools which <br />handle tasks such as installing and removing package files, and high-level tools that per-<br />form metadata searching and dependency resolution. In this chapter, we will look at the <br />tools supplied with Debian-style systems (such as Ubuntu and many others) and those <br />used by recent Red Hat products. While all Red Hat-style distributions rely on the same <br />low-level program (rpm), they use different high-level tools. For our discussion, we will <br />cover the high-level program yum, used by Fedora, Red Hat Enterprise Linux, and Cen-<br />tOS. Other Red Hat-style distributions provide high-level tools with comparable features.<br /> <em>Table14- 2: Packaging System Tools</em><br /> <strong>Distributions</strong><br /> <strong>Low-Level Tools</strong><br /> <strong>High-Level Tools</strong><br /> Debian-Style<br /> dpkg<br /> apt-get, aptitude<br /> 168<br /></p>
<hr />
<p>How A Package System Works<br /> Fedora, Red Hat <br /> rpm<br /> yum<br /> Enterprise Linux, CentOS<br /> <strong>Common Package Management Tasks<br /></strong>There are many operations that can be performed with the command line package man-<br />agement tools. We will look at the most common. Be aware that the low-level tools also <br />support creation of package files, an activity outside the scope of this book.<br />In the discussion below, the term “<em>package_name</em>” refers to the actual name of a pack-<br />age rather than the term “<em>package_file</em>,” which is the name of the file that contains <br />the package.<br /> Finding A Package In A Repository<br />Using the high-level tools to search repository metadata, a package can be located based <br />on its name or description.<br /> <em>Table 14-3: Package Search Commands</em><br /> <strong>Style</strong><br /> <strong>Command(s)</strong><br /> Debian<br /> apt-get update<br />apt-cache search <em>search_string</em><br /> Red Hat<br /> yum search <em>search_string</em><br /> Example: To search a yum repository for the emacs text editor, this command could be <br />used:<br /> yum search emacs<br /> Installing A Package From A Repository<br />High-level tools permit a package to be downloaded from a repository and installed with <br />full dependency resolution.<br /> <em>Table 14-4: Package Installation Commands</em><br /> <strong>Style</strong><br /> <strong>Command(s)</strong><br /> Debian<br /> apt-get update<br /> 169<br /></p>
<hr />
<p>14 – Package Management<br /> apt-get install <em>package_name</em><br /> Red Hat<br /> yum install <em>package_name</em><br /> Example: To install the emacs text editor from an apt repository:<br /> apt-get update; apt-get install emacs<br /> Installing A Package From A Package File<br />If a package file has been downloaded from a source other than a repository, it can be in-<br />stalled directly (though without dependency resolution) using a low-level tool.<br /> <em>Table 14-5: Low-Level Package Installation Commands</em><br /> <strong>Style</strong><br /> <strong>Command(s)</strong><br /> Debian<br /> dpkg --install <em>package_file</em><br /> Red Hat<br /> rpm -i <em>package_file</em><br /> Example: If the emacs-22.1-7.fc7-i386.rpm package file had been downloaded <br />from a non-repository site, it would be installed this way:<br /> rpm -i emacs-22.1-7.fc7-i386.rpm <br /> <strong>Note:</strong> Since this technique uses the low-level rpm program to perform the installa-<br />tion, no dependency resolution is performed. If  rpm  discovers a missing depen-<br />dency, rpm will exit with an error.<br /> Removing A Package<br />Packages can be uninstalled using either the high-level or low-level tools. The high-level <br />tools are shown below.<br /> 170<br /></p>
<hr />
<p>Common Package Management Tasks<br /> <em>Table15- 6: Package Removal Commands</em><br /> <strong>Style</strong><br /> <strong>Command(s)</strong><br /> Debian<br /> apt-get remove <em>package_name</em><br /> Red Hat<br /> yum erase <em>package_name</em><br /> Example: To uninstall the emacs package from a Debian-style system:<br /> apt-get remove emacs<br /> Updating Packages From A Repository<br />The most common package management task is keeping the system up-to-date with the <br />latest packages. The high-level tools can perform this vital task in one single step.<br /> <em>Table 14-7: Package Update Commands</em><br /> <strong>Style</strong><br /> <strong>Command(s)</strong><br /> Debian<br /> apt-get update; apt-get upgrade<br /> Red Hat<br /> yum update<br /> Example: To apply any available updates to the installed packages on a Debian-style sys-<br />tem:<br /> apt-get update; apt-get upgrade<br /> Upgrading A Package From A Package File<br />If an updated version of a package has been downloaded from a non-repository source, it <br />can be installed, replacing the previous version:<br /> <em>Table 14-8: Low-Level Package Upgrade Commands</em><br /> <strong>Style</strong><br /> <strong>Command(s)</strong><br /> Debian<br /> dpkg --install <em>package_file</em><br /> 171<br /></p>
<hr />
<p>14 – Package Management<br /> Red Hat<br /> rpm -U <em>package_file</em><br /> Example: Updating an existing installation of emacs to the version contained in the pack-<br />age file emacs-22.1-7.fc7-i386.rpm on a Red Hat system:<br /> rpm -U emacs-22.1-7.fc7-i386.rpm<br /> <strong>Note:</strong>  dpkg  does not have a specific option for upgrading a package versus in-<br />stalling one as rpm does.<br /> Listing Installed Packages<br />These commands can be used to display a list of all the packages installed on the system:<br /> <em>Table 14-9: Package Listing Commands</em><br /> <strong>Style</strong><br /> <strong>Command(s)</strong><br /> Debian<br /> dpkg --list<br /> Red Hat<br /> rpm -qa<br /> Determining If A Package Is Installed<br />These low-level tools can be used to display whether a specified package is installed:<br /> <em>Table 14-10: Package Status Commands</em><br /> <strong>Style</strong><br /> <strong>Command(s)</strong><br /> Debian<br /> dpkg --status <em>package_name</em><br /> Red Hat<br /> rpm -q <em>package_name</em><br /> Example: To determine if the emacs package is installed on a Debian style system:<br /> dpkg --status emacs<br /> 172<br /></p>
<hr />
<p>Common Package Management Tasks<br /> Displaying Info About An Installed Package<br />If the name of an installed package is known, the following commands can be used to <br />display a description of the package:<br /> <em>Table 14-11: Package Information Commands</em><br /> <strong>Style</strong><br /> <strong>Command(s)</strong><br /> Debian<br /> apt-cache show <em>package_name</em><br /> Red Hat<br /> yum info <em>package_name</em><br /> Example: To see a description of the emacs package on a Debian-style system:<br /> apt-cache show emacs<br /> Finding Which Package Installed A File<br />To determine what package is responsible for the installation of a particular file, the fol-<br />lowing commands can be used:<br /> <em>Table 14-12: Package File Identification Commands</em><br /> <strong>Style</strong><br /> <strong>Command(s)</strong><br /> Debian<br /> dpkg --search <em>file_name</em><br /> Red Hat<br /> rpm -qf <em>file_name</em><br /> Example: To see what package installed the /usr/bin/vim file on a Red Hat system:<br /> rpm -qf /usr/bin/vim<br /> <strong>Summing Up<br /></strong>In the chapters that follow, we will explore many different programs covering a wide <br />range of application areas. While most of these programs are commonly installed by de-<br />fault, we may need to install additional packages if necessary programs are not already <br />installed on our system. With our newfound knowledge (and appreciation) of package <br /> 173<br /></p>
<hr />
<p>14 – Package Management<br /> management, we should have no problem installing and managing the programs we need.<br /> <strong>The Linux Software Installation Myth<br /></strong>People migrating from other platforms sometimes fall victim to the myth that <br />software is somehow difficult to install under Linux and that the variety of pack-<br />aging schemes used by different distributions is a hindrance. Well, it is a hin-<br />drance, but only to proprietary software vendors who wish to distribute binary-<br />only versions of their secret software.<br />The Linux software ecosystem is based on the idea of open source code. If a pro-<br />gram developer releases source code for a product, it is likely that a person asso-<br />ciated with a distribution will package the product and include it in their reposi-<br />tory. This method ensures that the product is well integrated into the distribution <br />and the user is given the convenience of “one-stop shopping” for software, rather <br />than having to search for each product's web site.<br />Device drivers are handled in much the same way, except that instead of being <br />separate items in a distribution's repository, they become part of the Linux kernel <br />itself. Generally speaking, there is no such thing as a “driver disk” in Linux. Ei-<br />ther the kernel supports a device or it doesn't, and the Linux kernel supports a lot <br />of devices. Many more, in fact, than Windows does. Of course, this is of no con-<br />solation if the particular device you need is not supported. When that happens, <br />you need to look at the cause. A lack of driver support is usually caused by one of <br />three things:<br /><strong>1. The device is too new.</strong>  Since many hardware vendors don't actively support <br />Linux development, it falls upon a member of the Linux community to write the <br />kernel driver code. This takes time.<br /><strong>2. The device is too exotic.</strong>  Not all distributions include every possible device <br />driver. Each distribution builds their own kernels, and since kernels are very con-<br />figurable (which is what makes it possible to run Linux on everything from wrist-<br />watches to mainframes) they may have overlooked a particular device. By locat-<br />ing and downloading the source code for the driver, it is possible for you (yes, <br />you) to compile and install the driver yourself. This process is not overly difficult, <br />but it is rather involved. We'll talk about compiling software in a later chapter.<br /><strong>3. The hardware vendor is hiding something.</strong> They have neither released source <br />code for a Linux driver, nor have they released the technical documentation for <br />somebody to create one for them. This means that the hardware vendor is trying <br />to keep the programming interfaces to the device a secret. Since we don't want se-<br />cret devices in our computers, I suggest that you remove the offending hardware <br />and pitch it into the trash with your other useless items. <br /> 174<br /></p>
<hr />
<p>Further Reading<br /> <strong>Further Reading<br /></strong>Spend some time getting to know the package management system for your distribution. <br />Each distribution provides documentation for its package management tools. In addition, <br />here are some more generic sources:<br /> ●<br /> The <em>Debian GNU/Linux FAQ</em> chapter on package management provides an over-<br />view of package management on Debian systems :<br /><a href="http://www.debian.org/doc/FAQ/ch-pkgtools.en.html">http://www.debian.org/doc/FAQ/ch-pkgtools.en.html</a><br /> ●<br /> The home page for the RPM project:<br /><a href="http://www.rpm.org/">http://www.rpm.org</a><br /> ●<br /> The home page for the YUM project at Duke University:<br /><a href="http://linux.duke.edu/projects/yum/">http://linux.duke.edu/projects/yum/</a><br /> ●<br /> For a little background, the Wikipedia has an article on metadata:<br /><a href="http://en.wikipedia.org/wiki/Metadata">http://en.wikipedia.org/wiki/Metadata</a><br /> 175<br /></p>
<hr />
<p>15 – Storage Media<br /> <em><strong>15 – Storage Media</strong></em><br /> In previous chapters we’ve looked at manipulating data at the file level. In this chapter, <br />we will consider data at the device level. Linux has amazing capabilities for handling <br />storage devices, whether physical storage, such as hard disks, or network storage, or vir-<br />tual storage devices like RAID (Redundant Array of Independent Disks) and LVM (Logi-<br />cal Volume Manager).<br />However, since this is not a book about system administration, we will not try to cover <br />this entire topic in depth. What we will try to do is introduce some of the concepts and <br />key commands that are used to manage storage devices.<br />To carry out the exercises in this chapter, we will use a USB flash drive, a CD-RW disc <br />(for systems equipped with a CD-ROM burner) and a floppy disk (again, if the system is <br />so equipped.)<br />We will look at the following commands:<br /> ●<br /> mount – Mount a file system<br /> ●<br /> umount – Unmount a file system<br /> ●<br /> fsck – Check and repair a file system<br /> ●<br /> fdisk – Partition table manipulator<br /> ●<br /> mkfs – Create a file system<br /> ●<br /> fdformat – Format a floppy disk<br /> ●<br /> dd – Write block oriented data directly to a device<br /> ●<br /> genisoimage (mkisofs) – Create an ISO 9660 image file<br /> ●<br /> wodim (cdrecord) – Write data to optical storage media<br /> ●<br /> md5sum – Calculate an MD5 checksum<br /> <strong>Mounting And Unmounting Storage Devices<br /></strong>Recent advances in the Linux desktop have made storage device management extremely <br /> 176<br /></p>
<hr />
<p>Mounting And Unmounting Storage Devices<br /> easy for desktop users. For the most part, we attach a device to our system and it “just <br />works.” Back in the old days (say, 2004), this stuff had to be done manually. On non-<br />desktop systems (i.e., servers) this is still a largely manual procedure since servers often <br />have extreme storage needs and complex configuration requirements.<br />The first step in managing a storage device is attaching the device to the file system tree. <br />This process, called <em>mounting</em>, allows the device to participate with the operating system. <br />As we recall from Chapter 2, Unix-like operating systems, like Linux, maintain a single <br />file system tree with devices attached at various points. This contrasts with other operat-<br />ing systems such as MS-DOS and Windows that maintain separate file system trees for <br />each device (for example C:\, D:\, etc.).<br />A file named /etc/fstab lists the devices (typically hard disk partitions) that are to be <br />mounted at boot time. Here is an example /etc/fstab file from a Fedora 7 system:<br /> LABEL=/12         /                       ext3    defaults        1 1<br />LABEL=/home       /home                   ext3    defaults        1 2<br /> LABEL=/boot       /boot                   ext3    defaults        1 2<br />tmpfs             /dev/shm                tmpfs   defaults        0 0<br /> devpts            /dev/pts                devpts  gid=5,mode=620  0 0<br />sysfs             /sys                    sysfs   defaults        0 0<br /> proc              /proc                   proc    defaults        0 0<br />LABEL=SWAP-sda3   swap                    swap    defaults        0 0<br /> Most of the file systems listed in this example file are virtual and are not applicable to our <br />discussion. For our purposes, the interesting ones are the first three:<br /> LABEL=/12         /                       ext3    defaults        1 1<br />LABEL=/home       /home                   ext3    defaults        1 2<br /> LABEL=/boot       /boot                   ext3    defaults        1 2<br /> These are the hard disk partitions. Each line of the file consists of six fields, as follows:<br /> <em>Table 15-1: /etc/fstab Fields</em><br /> <strong>Field</strong><br /> <strong>Contents</strong><br /> <strong>Description</strong><br /> 1<br /> Device<br /> Traditionally, this field contains the actual name of a <br />device file associated with the physical device, such as <br />/dev/hda1 (the first partition of the master device <br />on the first IDE channel). But with today's computers, <br />which have many devices that are hot pluggable (like <br />USB drives), many modern Linux distributions <br /> 177<br /></p>
<hr />
<p>15 – Storage Media<br /> associate a device with a text label instead. This label <br />(which is added to the storage media when it is <br />formatted) is read by the operating system when the <br />device is attached to the system. That way, no matter <br />which device file is assigned to the actual physical <br />device, it can still be correctly identified.<br />  2<br /> Mount Point<br /> The directory where the device is attached to the file <br />system tree.<br /> 3<br /> File System Type<br /> Linux allows many file system types to be mounted. <br />Most native Linux file systems are ext3, but many <br />others are supported, such as FAT16 (msdos), FAT32 <br />(vfat), NTFS (ntfs), CD-ROM (iso9660), etc.<br /> 4<br /> Options<br /> File systems can be mounted with various options. It is <br />possible, for example, to mount file systems as read-<br />only, or to prevent any programs from being executed <br />from them (a useful security feature for removable <br />media).<br /> 5<br /> Frequency<br /> A single number that specifies if and when a file <br />system is to be backed up with the dump command.<br /> 6<br /> Order<br /> A single number that specifies in what order file <br />systems should be checked with the fsck command.<br /> Viewing A List Of Mounted File Systems<br />The mount command is used to mount file systems. Entering the command without ar-<br />guments will display a list of the file systems currently mounted:<br /> [me@linuxbox ~]$ <strong>mount<br /></strong>/dev/sda2 on / type ext3 (rw)<br /> proc on /proc type proc (rw)<br />sysfs on /sys type sysfs (rw)<br /> devpts on /dev/pts type devpts (rw,gid=5,mode=620)<br />/dev/sda5 on /home type ext3 (rw)<br /> /dev/sda1 on /boot type ext3 (rw)<br />tmpfs on /dev/shm type tmpfs (rw)<br /> none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)<br />sunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw)<br /> fusectl on /sys/fs/fuse/connections type fusectl (rw)<br />/dev/sdd1 on /media/disk type vfat (rw,nosuid,nodev,noatime,<br /> 178<br /></p>
<hr />
<p>Mounting And Unmounting Storage Devices<br /> uhelper=hal,uid=500,utf8,shortname=lower)<br />twin4:/musicbox on /misc/musicbox type nfs4 (rw,addr=192.168.1.4)<br /> The format of the listing is: <em>device</em> on <em>mount_point </em>type <em>file_system_type</em> (<em>options</em>). For <br />example, the first line shows that device /dev/sda2 is mounted as the root file system, <br />is of type ext3, and is both readable and writable (the option “rw”). This listing also has <br />two interesting entries at the bottom of the list. The next-to-last entry shows a 2 gigabyte <br />SD memory card in a card reader mounted at /media/disk, and the last entry is a net-<br />work drive mounted at /misc/musicbox.<br />For our first experiment, we will work with a CD-ROM. First, let's look at a system be-<br />fore a CD-ROM is inserted:<br /> [me@linuxbox ~]$ <strong>mount<br /></strong>/dev/mapper/VolGroup00-LogVol00 on / type ext3 (rw)<br /> proc on /proc type proc (rw)<br />sysfs on /sys type sysfs (rw)<br /> devpts on /dev/pts type devpts (rw,gid=5,mode=620)<br />/dev/hda1 on /boot type ext3 (rw)<br /> tmpfs on /dev/shm type tmpfs (rw)<br />none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)<br /> sunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw)<br /> This listing is from a CentOS 5 system, which is using LVM (Logical Volume Manager) <br />to create its root file system. Like many modern Linux distributions, this system will at-<br />tempt to automatically mount the CD-ROM after insertion. After we insert the disc, we <br />see the following: <br /> [me@linuxbox ~]$ <strong>mount</strong><br /> /dev/mapper/VolGroup00-LogVol00 on / type ext3 (rw)<br />proc on /proc type proc (rw)<br /> sysfs on /sys type sysfs (rw)<br />devpts on /dev/pts type devpts (rw,gid=5,mode=620)<br /> /dev/hda1 on /boot type ext3 (rw)<br />tmpfs on /dev/shm type tmpfs (rw)<br /> none on /proc/sys/fs/binfmt_misc type binfmt_misc (rw)<br />sunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw)<br /> /dev/hdc on /media/live-1.0.10-8 type iso9660 (ro,noexec,nosuid, <br />nodev,uid=500)<br /> After we insert the disc, we see the same listing as before with one additional entry. At <br />the end of the listing we see that the CD-ROM (which is device /dev/hdc on this sys-<br /> 179<br /></p>
<hr />
<p>15 – Storage Media<br /> tem) has been mounted on  /media/live-1.0.10-8, and is type  iso9660  (a CD-<br />ROM). For purposes of our experiment, we're interested in the name of the device. When <br />you conduct this experiment yourself, the device name will most likely be different.<br /> <strong>Warning:</strong> In the examples that follow, it is vitally important that you pay close at-<br />tention to the actual device names in use on your system and <strong>do not use the names <br />used in this text!</strong><br /> Also note that audio CDs are not the same as CD-ROMs. Audio CDs do not contain <br />file systems and thus cannot be mounted in the usual sense.<br /> Now that we have the device name of the CD-ROM drive, let's unmount the disc and re-<br />mount it at another location in the file system tree. To do this, we become the superuser <br />(using the command appropriate for our system) and unmount the disc with the umount <br />(notice the spelling) command:<br /> [me@linuxbox ~]$ <strong>su -<br /></strong>Password:<br /> [root@linuxbox ~]# <strong>umount /dev/hdc</strong><br /> The next step is to create a new <em>mount point</em> for the disk. A mount point is simply a direc-<br />tory somewhere on the file system tree. Nothing special about it. It doesn't even have to <br />be an empty directory, though if you mount a device on a non-empty directory, you will <br />not be able to see the directory's previous contents until you unmount the device. For our <br />purposes, we will create a new directory:<br /> [root@linuxbox ~]# <strong>mkdir /mnt/cdrom</strong><br /> Finally, we mount the CD-ROM at the new mount point. The -t option is used to specify <br />the file system type:<br /> [root@linuxbox ~]# <strong>mount -t iso9660 /dev/hdc /mnt/cdrom</strong><br /> Afterward, we can examine the contents of the CD-ROM via the new mount point:<br /> [root@linuxbox ~]# <strong>cd /mnt/cdrom</strong><br /> 180<br /></p>
<hr />
<p>Mounting And Unmounting Storage Devices<br /> [root@linuxbox cdrom]# <strong>ls</strong><br /> Notice what happens when we try to unmount the CD-ROM:<br /> [root@linuxbox cdrom]# <strong>umount /dev/hdc</strong><br /> umount: /mnt/cdrom: device is busy<br /> Why is this? The reason is that we cannot unmount a device if the device is being used by <br />someone or some process. In this case, we changed our working directory to the mount <br />point for the CD-ROM, which causes the device to be busy. We can easily remedy the is-<br />sue by changing the working directory to something other than the mount point:<br /> [root@linuxbox cdrom]# <strong>cd</strong><br /> [root@linuxbox ~]# <strong>umount /dev/hdc</strong><br /> Now the device unmounts successfully.<br /> <strong>Why Unmounting Is Important<br /></strong>If you look at the output of the free command, which displays statistics about <br />memory usage, you will see a statistic called “buffers.” Computer systems are de-<br />signed to go as fast as possible. One of the impediments to system speed is slow <br />devices. Printers are a good example. Even the fastest printer is extremely slow <br />by computer standards. A computer would be very slow indeed if it had to stop <br />and wait for a printer to finish printing a page. In the early days of PCs (before <br />multi-tasking), this was a real problem. If you were working on a spreadsheet or <br />text document, the computer would stop and become unavailable every time you <br />printed. The computer would send the data to the printer as fast as the printer <br />could accept it, but it was very slow since printers don't print very fast. This prob-<br />lem was solved by the advent of the  <em>printer  buffer</em>, a device containing some <br />RAM memory that would sit between the computer and the printer. With the <br />printer buffer in place, the computer would send the printer output to the buffer <br />and it would quickly be stored in the fast RAM so the computer could go back to <br />work without waiting. Meanwhile, the printer buffer would slowly <em>spool</em> the data <br />to the printer from the buffer's memory at the speed at which the printer could ac-<br />cept it.<br /> 181<br /></p>
<hr />
<p>15 – Storage Media<br /> This idea of buffering is used extensively in computers to make them faster. Don't <br />let the need to occasionally read or write data to or from slow devices impede the <br />speed of the system. Operating systems store data that has been read from, and is <br />to be written to storage devices in memory for as long as possible before actually <br />having to interact with the slower device. On a Linux system for example, you <br />will notice that the system seems to fill up memory the longer it is used. This does <br />not mean Linux is “using“ all the memory, it means that Linux is taking advan-<br />tage of all the available memory to do as much buffering as it can.<br />This buffering allows writing to storage devices to be done very quickly, because <br />the writing to the physical device is being deferred to a future time. In the mean-<br />time, the data destined for the device is piling up in memory. From time to time, <br />the operating system will write this data to the physical device.<br />Unmounting a device entails writing all the remaining data to the device so that it <br />can be safely removed. If the device is removed without unmounting it first, the <br />possibility exists that not all the data destined for the device has been transferred. <br />In some cases, this data may include vital directory updates, which will lead to <br /><em>file system corruption</em>, one of the worst things that can happen on a computer. <br /> Determining Device Names<br />It's sometimes difficult to determine the name of a device. Back in the old days, it wasn't <br />very hard. A device was always in the same place and it didn't change. Unix-like systems <br />like it that way. Back when Unix was developed, “changing a disk drive” involved using <br />a forklift to remove a washing machine-sized device from the computer room. In recent <br />years, the typical desktop hardware configuration has become quite dynamic and Linux <br />has evolved to become more flexible than its ancestors.<br />In the examples above we took advantage of the modern Linux desktop's ability to “au-<br />tomagically” mount the device and then determine the name after the fact. But what if we <br />are managing a server or some other environment where this does not occur? How can <br />we figure it out?<br />First, let's look at how the system names devices. If we list the contents of the /dev di-<br />rectory (where all devices live), we can see that there are lots and lots of devices:<br /> [me@linuxbox ~]$ <strong>ls /dev</strong><br /> The contents of this listing reveal some patterns of device naming. Here are a few:<br /> 182<br /></p>
<hr />
<p>Mounting And Unmounting Storage Devices<br /> <em>Table 15-2: Linux Storage Device Names</em><br /> <strong>Pattern</strong><br /> <strong>Device</strong><br /> /dev/fd*<br /> Floppy disk drives.<br /> /dev/hd*<br /> IDE (PATA) disks on older systems. Typical motherboards <br />contain two IDE connectors or <em>channels</em>, each with a cable with <br />two attachment points for drives. The first drive on the cable is <br />called the <em>master</em> device and the second is called the <em>slave</em> <br />device. The device names are ordered such that /dev/hda <br />refers to the master device on the first channel, /dev/hdb is the <br />slave device on the first channel; /dev/hdc, the master device <br />on the second channel, and so on. A trailing digit indicates the <br />partition number on the device. For example, /dev/hda1 refers <br />to the first partition on the first hard drive on the system while <br />/dev/hda refers to the entire drive.<br /> /dev/lp*<br /> Printers.<br /> /dev/sd*<br /> SCSI disks. On recent Linux systems, the kernel treats all disk-<br />like devices (including PATA/SATA hard disks, flash drives, and <br />USB mass storage devices such as portable music players, and <br />digital cameras) as SCSI disks. The rest of the naming system is <br />similar to the older /dev/hd* naming scheme described above.<br /> /dev/sr*<br /> Optical drives (CD/DVD readers and burners).<br /> In   addition,   we   often   see   symbolic   links   such   as  /dev/cdrom,  /dev/dvd,   and <br />/dev/floppy, which point to the actual device files, provided as a convenience.<br />If you are working on a system that does not automatically mount removable devices, <br />you can use the following technique to determine how the removable device is named <br />when   it   is   attached.   First,   start   a   real-time   view   of   the  /var/log/messages  or <br />/var/log/syslog file (you may require superuser privileges for this):<br /> [me@linuxbox ~]$ <strong>sudo tail -f /var/log/messages</strong><br /> The last few lines of the file will be displayed and then pause. Next, plug in the remov-<br />able device. In this example, we will use a 16 MB flash drive. Almost immediately, the <br />kernel will notice the device and probe it:<br /> 183<br /></p>
<hr />
<p>15 – Storage Media<br /> Jul 23 10:07:53 linuxbox kernel: usb 3-2: new full speed USB device <br />using uhci_hcd and address 2<br /> Jul 23 10:07:53 linuxbox kernel: usb 3-2: configuration #1 chosen <br />from 1 choice<br /> Jul 23 10:07:53 linuxbox kernel: scsi3 : SCSI emulation for USB Mass <br />Storage devices<br /> Jul 23 10:07:58 linuxbox kernel: scsi scan: INQUIRY result too short <br />(5), using 36<br /> Jul 23 10:07:58 linuxbox kernel: scsi 3:0:0:0: Direct-Access     Easy <br />Disk             1.00 PQ: 0 ANSI: 2<br /> Jul 23 10:07:59 linuxbox kernel: sd 3:0:0:0: [sdb] 31263 512-byte <br />hardware sectors (16 MB)<br /> Jul 23 10:07:59 linuxbox kernel: sd 3:0:0:0: [sdb] Write Protect is <br />off<br /> Jul 23 10:07:59 linuxbox kernel: sd 3:0:0:0: [sdb] Assuming drive <br />cache: write through<br /> Jul 23 10:07:59 linuxbox kernel: sd 3:0:0:0: [sdb] 31263 512-byte <br />hardware sectors (16 MB)<br /> Jul 23 10:07:59 linuxbox kernel: sd 3:0:0:0: [sdb] Write Protect is <br />off<br /> Jul 23 10:07:59 linuxbox kernel: sd 3:0:0:0: [sdb] Assuming drive <br />cache: write through<br /> Jul 23 10:07:59 linuxbox kernel:  sdb: sdb1<br />Jul 23 10:07:59 linuxbox kernel: sd 3:0:0:0: [sdb] Attached SCSI <br /> removable disk<br />Jul 23 10:07:59 linuxbox kernel: sd 3:0:0:0: Attached scsi generic <br /> sg3 type 0<br /> After the display pauses again, press Ctrl-c to get the prompt back.  The interesting parts <br />of the output are the repeated references to “[sdb]” which matches our expectation of a <br />SCSI disk device name.  Knowing this, two lines become particularly illuminating:<br /> Jul 23 10:07:59 linuxbox kernel:  sdb: sdb1<br /> Jul 23 10:07:59 linuxbox kernel: sd 3:0:0:0: [sdb] Attached SCSI <br />removable disk<br /> This tells us the device name is /dev/sdb for the entire device and /dev/sdb1 for <br />the first partition on the device.  As we have seen, working with Linux is full of interest-<br />ing detective work!<br /> <strong>Tip:</strong>  Using the  tail -f /var/log/messages  technique is a great way to <br />watch what the system is doing in near real-time.<br /> With our device name in hand, we can now mount the flash drive:<br /> 184<br /></p>
<hr />
<p>Mounting And Unmounting Storage Devices<br /> [me@linuxbox ~]$ <strong>sudo mkdir /mnt/flash<br /></strong>[me@linuxbox ~]$ <strong>sudo mount /dev/sdb1 /mnt/flash</strong><br /> [me@linuxbox ~]$ <strong>df<br /></strong>Filesystem           1K-blocks      Used Available Use% Mounted on<br /> /dev/sda2             15115452   5186944   9775164  35% /<br />/dev/sda5             59631908  31777376  24776480  57% /home<br /> /dev/sda1               147764     17277    122858  13% /boot<br />tmpfs                   776808         0    776808   0% /dev/shm<br /> /dev/sdb1                15560         0     15560   0% /mnt/flash<br /> The device name will remain the same as long as it remains physically attached to the <br />computer and the computer is not rebooted.<br /> <strong>Creating New File Systems<br /></strong>Let's say that we want to reformat the flash drive with a Linux native file system, rather <br />than the FAT32 system it has now. This involves two steps: 1. (optional) create a new par-<br />tition layout if the existing one is not to our liking, and 2. create a new, empty file system <br />on the drive.<br /> <strong>Warning!</strong>  In the following exercise, we are going to format a flash drive. Use a <br />drive that contains nothing you care about because it will be erased! Again, <strong>make <br />absolutely sure you are specifying the correct device name for your system, not <br />the one shown in the text. Failure to heed this warning could result in you for-<br />matting (i.e., erasing) the wrong drive!</strong><br /> Manipulating Partitions With fdisk<br />The  fdisk program allows us to interact directly with disk-like devices (such as hard <br />disk drives and flash drives) at a very low level. With this tool we can edit, delete, and <br />create partitions on the device. To work with our flash drive, we must first unmount it (if <br />needed) and then invoke the fdisk program as follows:<br /> [me@linuxbox ~]$ <strong>sudo umount /dev/sdb1</strong><br /> [me@linuxbox ~]$ <strong>sudo fdisk /dev/sdb</strong><br /> Notice that we must specify the device in terms of the entire device, not by partition num-<br />ber. After the program starts up, we will see the following prompt:<br /> 185<br /></p>
<hr />
<p>15 – Storage Media<br /> Command (m for help):<br /> Entering an “m” will display the program menu:<br /> Command action <br />    a   toggle a bootable flag <br />   b   edit bsd disklabel <br />    c   toggle the dos compatibility flag <br />   d   delete a partition <br />    l   list known partition types <br />   m   print this menu <br />    n   add a new partition <br />   o   create a new empty DOS partition table <br />    p   print the partition table <br />   q   quit without saving changes <br />    s   create a new empty Sun disklabel <br />   t   change a partition's system id <br />    u   change display/entry units <br />   v   verify the partition table <br />    w   write table to disk and exit <br />   x   extra functionality (experts only) <br /> Command (m for help): <br /> The first thing we want to do is examine the existing partition layout. We do this by en-<br />tering “p” to print the partition table for the device:<br /> Command (m for help): <strong>p</strong> <br /> Disk /dev/sdb: 16 MB, 16006656 bytes <br /> 1 heads, 31 sectors/track, 1008 cylinders <br />Units = cylinders of 31 * 512 = 15872 bytes <br />    Device Boot      Start         End      Blocks   Id  System <br /> /dev/sdb1               2        1008       15608+   b  W95 FAT32 <br /> In this example, we see a 16 MB device with a single partition (1) that uses 1006 of the <br />available  1008  cylinders  on  the   device.  The  partition   is  identified   as  a Windows  95 <br />FAT32 partition. Some programs will use this identifier to limit the kinds of operation <br />that can be done to the disk, but most of the time it is not critical to change it. However,  <br /> 186<br /></p>
<hr />
<p>Creating New File Systems<br /> in the interest of demonstration, we will change it to indicate a Linux partition. To do this, <br />we must first find out what ID is used to identify a Linux partition. In the listing above, <br />we see that the ID “b” is used to specify the existing partition. To see a list of the avail-<br />able partition types, we refer back to the program menu. There we can see the following <br />choice:<br />    l   list known partition types<br /> If we enter “l” at the prompt, a large list of possible types is displayed. Among them we <br />see “b” for our existing partition type and “83” for Linux.<br />Going back to the menu, we see this choice to change a partition ID:<br />    t   change a partition's system id<br /> We enter “t” at the prompt enter the new ID:<br /> Command (m for help): <strong>t <br /></strong>Selected partition 1 <br /> Hex code (type L to list codes): <strong>83</strong> <br />Changed system type of partition 1 to 83 (Linux) <br /> This completes all the changes that we need to make. Up to this point, the device has <br />been untouched (all the changes have been stored in memory, not on the physical device), <br />so we will write the modified partition table to the device and exit. To do this, we enter <br />“w” at the prompt:<br /> Command (m for help): <strong>w</strong> <br />The partition table has been altered! <br /> Calling ioctl() to re-read partition table. <br /> WARNING: If you have created or modified any DOS 6.x <br /> partitions, please see the fdisk manual page for additional <br />information. <br /> Syncing disks. <br />[me@linuxbox ~]$<br /> If we had decided to leave the device unaltered, we could have entered “q” at the prompt, <br /> 187<br /></p>
<hr />
<p>15 – Storage Media<br /> which would have exited the program without writing the changes. We can safely ignore <br />the ominous sounding warning message.<br /> Creating A New File System With mkfs<br />With our partition editing done (lightweight though it might have been) it’s time to create <br />a new file system on our flash drive. To do this, we will use mkfs (short for “make file <br />system”), which can create file systems in a variety of formats. To create an ext3 file sys-<br />tem on the device, we use the “-t” option to specify the “ext3” system type, followed by <br />the name of the device containing the partition we wish to format:<br /> [me@linuxbox ~]$ <strong>sudo mkfs -t ext3 /dev/sdb1</strong> <br /> mke2fs 1.40.2 (12-Jul-2007) <br />Filesystem label= <br /> OS type: Linux <br />Block size=1024 (log=0) <br /> Fragment size=1024 (log=0) <br />3904 inodes, 15608 blocks <br /> 780 blocks (5.00%) reserved for the super user <br />First data block=1 <br /> Maximum filesystem blocks=15990784 <br />2 block groups <br /> 8192 blocks per group, 8192 fragments per group <br />1952 inodes per group <br /> Superblock backups stored on blocks: <br /> 8193 <br /> Writing inode tables: done                            <br /> Creating journal (1024 blocks): done <br />Writing superblocks and filesystem accounting information: done <br /> This filesystem will be automatically checked every 34 mounts or <br /> 180 days, whichever comes first.  Use tune2fs -c or -i to override.<br />[me@linuxbox ~]$<br /> The program will display a lot of information when ext3 is the chosen file system type. <br />To re-format the device to its original FAT32 file system, specify “vfat” as the file system <br />type:<br /> [me@linuxbox ~]$ <strong>sudo mkfs -t vfat /dev/sdb1</strong><br /> This process of partitioning and formatting can be used anytime additional storage de-<br />vices are added to the system. While we worked with a tiny flash drive, the same process <br /> 188<br /></p>
<hr />
<p>Creating New File Systems<br /> can be applied to internal hard disks and other removable storage devices like USB hard <br />drives.<br /> <strong>Testing And Repairing File Systems<br /></strong>In our earlier discussion of the /etc/fstab file, we saw some mysterious digits at the <br />end of each line. Each time the system boots, it routinely checks the integrity of the file <br />systems before mounting them. This is done by the fsck program (short for “file system <br />check”). The last number in each fstab entry specifies the order in which the devices <br />are to be checked. In our example above, we see that the root file system is checked first, <br />followed by the home and boot file systems. Devices with a zero as the last digit are not <br />routinely checked.<br />In addition to checking the integrity of file systems, fsck can also repair corrupt file sys-<br />tems with varying degrees of success, depending on the amount of damage. On Unix-like <br />file systems, recovered portions of files are placed in the  lost+found  directory, lo-<br />cated in the root of each file system.<br />To check our flash drive (which should be unmounted first), we could do the following:<br /> [me@linuxbox ~]$ <strong>sudo fsck /dev/sdb1<br /></strong>fsck 1.40.8 (13-Mar-2008) <br /> e2fsck 1.40.8 (13-Mar-2008) <br />/dev/sdb1: clean, 11/3904 files, 1661/15608 blocks<br /> In my experience, file system corruption is quite rare unless there is a hardware problem, <br />such as a failing disk drive. On most systems, file system corruption detected at boot time <br />will cause the system to stop and direct you to run fsck before continuing.<br /> <strong>What The fsck?<br /></strong>In Unix culture, the word “fsck” is often used in place of a popular word with <br />which it shares three letters. This is especially appropriate, given that you will <br />probably be uttering the aforementioned word if you find yourself in a situation <br />where you are forced to run fsck.<br /> <strong>Formatting Floppy Disks<br /></strong>For those of us still using computers old enough to be equipped with  floppy  diskette <br /> 189<br /></p>
<hr />
<p>15 – Storage Media<br /> drives, we can manage those devices, too. Preparing a blank floppy for use is a two step <br />process. First, we perform a low-level format on the diskette, and then create a file sys-<br />tem. To accomplish the formatting, we use the fdformat program specifying the name <br />of the floppy device (usually /dev/fd0):<br /> [me@linuxbox ~]$ <strong>sudo fdformat /dev/fd0</strong> <br />Double-sided, 80 tracks, 18 sec/track. Total capacity 1440 kB. <br /> Formatting ... done <br />Verifying ... done<br /> Next, we apply a FAT file system to the diskette with mkfs:<br /> [me@linuxbox ~]$ <strong>sudo mkfs -t msdos /dev/fd0</strong><br /> Notice that we use the “msdos” file system type to get the older (and smaller) style file <br />allocation tables. After a diskette is prepared, it may be mounted like other devices.<br /> <strong>Moving Data Directly To/From Devices<br /></strong>While we usually think of data on our computers as being organized into files, it is also <br />possible to think of the data in “raw” form. If we look at a disk drive, for example, we see <br />that it consists of a large number of “blocks” of data that the operating system sees as di-<br />rectories and files. However, if we could treat a disk drive as simply a large collection of <br />data blocks, we could perform useful tasks, such as cloning devices.<br />The dd program performs this task. It copies blocks of data from one place to another. It <br />uses a unique syntax (for historical reasons) and is usually used this way:<br /> <strong>dd if=<em>input_file</em></strong><strong> of=<em>output_file</em></strong><strong> [bs=<em>block_size</em></strong><strong> [count=<em>blocks</em></strong><strong>]]</strong><br /> Let’s say we had two USB flash drives of the same size and we wanted to exactly copy <br />the first drive to the second. If we attached both drives to the computer and they are as-<br />signed to devices /dev/sdb and /dev/sdc respectively, we could copy everything on <br />the first drive to the second drive with the following:<br /> <strong>dd if=/dev/sdb of=/dev/sdc</strong><br /> 190<br /></p>
<hr />
<p>Moving Data Directly To/From Devices<br /> Alternately, if only the first device were attached to the computer, we could copy its con-<br />tents to an ordinary file for later restoration or copying:<br /> <strong>dd if=/dev/sdb of=flash_drive.img</strong><br /> <strong>Warning!</strong> The dd command is very powerful. Though its name derives from “data <br />definition,” it is sometimes called “destroy disk” because users often mistype either <br />the if or of specifications. <strong>Always double check your input and output specifi-<br />cations before pressing enter!</strong><br /> <strong>Creating CD-ROM Images<br /></strong>Writing a recordable  CD-ROM (either a CD-R or CD-RW) consists of two steps; first, <br />constructing an <em>iso image file</em> that is the exact file system image of the CD-ROM and sec-<br />ond, writing the image file onto the CD-ROM media.<br /> Creating An Image Copy Of A CD-ROM<br />If we want to make an iso image of an existing CD-ROM, we can use dd to read all the  <br />data blocks off the CD-ROM and copy them to a local file. Say we had an Ubuntu CD <br />and we wanted to make an iso file that we could later use to make more copies. After in-<br />serting the CD and determining its device name (we’ll assume /dev/cdrom), we can <br />make the iso file like so:<br /> <strong>dd if=/dev/cdrom of=ubuntu.iso</strong><br /> This technique works for data DVDs as well, but will not work for audio CDs, as they do <br />not use a file system for storage. For audio CDs, look at the cdrdao command.<br /> Creating An Image From A Collection Of Files<br />To   create   an   iso   image   file   containing   the   contents   of   a   directory,   we   use   the <br />genisoimage program. To do this, we first create a directory containing all the files <br />we wish to include in the image, and then execute the genisoimage command to cre-<br />ate the image file. For example, if we had created a directory called ~/cd-rom-files <br />and filled it with files for our CD-ROM, we could create an image file named  cd-<br />rom.iso with the following command:<br /> 191<br /></p>
<hr />
<p>15 – Storage Media<br /> <strong>genisoimage -o cd-rom.iso -R -J ~/cd-rom-files</strong><br /> The “-R” option adds metadata for the <em>Rock Ridge extensions</em>, which allows the use of <br />long filenames and POSIX style file permissions. Likewise, the “-J” option enables the <br /><em>Joliet extensions</em>, which permit long filenames for Windows.<br /> <strong>A Program By Any Other Name...<br /></strong>If you look at on-line tutorials for creating and burning optical media like CD-<br />ROMs and DVDs, you will frequently encounter two programs called mkisofs <br />and  cdrecord. These programs were part of a popular package called “cdr-<br />tools” authored by Jörg Schilling. In the summer of 2006, Mr. Schilling made a li-<br />cense change to a portion of the cdrtools package which, in the opinion of many <br />in the Linux community, created a license incompatibility with the GNU GPL. As <br />a result, a <em>fork</em> of the cdrtools project was started that now includes replacement <br />programs for cdrecord and mkisofs named wodim and genisoimage, re-<br />spectively.<br /> <strong>Writing CD-ROM Images<br /></strong>After we have an image file, we can burn it onto our optical media. Most of the com-<br />mands we will discuss below can be applied to both recordable CD-ROM and DVD me-<br />dia.<br /> Mounting An ISO Image Directly<br />There is a trick that we can use to mount an iso image while it is still on our hard disk and <br />treat it as though it were already on optical media. By adding the “-o loop” option to <br />mount (along with the required “-t iso9660” file system type), we can mount the image <br />file as though it were a device and attach it to the file system tree: <br /> <strong>mkdir /mnt/iso_image</strong><br /> <strong>mount -t iso9660 -o loop image.iso /mnt/iso_image</strong><br /> In the example above, we created a mount point named  /mnt/iso_image  and then <br />mounted the image file image.iso at that mount point. After the image is mounted, it <br />can be treated just as though it were a real CD-ROM or DVD. <em>Remember to unmount the <br />image when it is no longer needed.</em><br /> 192<br /></p>
<hr />
<p>Writing CD-ROM Images<br /> Blanking A Re-Writable CD-ROM<br />Rewritable CD-RW media needs to be erased or <em>blanked</em> before it can be reused. To do <br />this, we can use wodim, specifying the device name for the CD writer and the type of <br />blanking to be performed. The wodim program offers several types. The most minimal <br />(and fastest) is the “fast” type:<br /> <strong>wodim dev=/dev/cdrw blank=fast</strong><br /> Writing An Image<br />To write an image, we again use wodim, specifying the name of the optical media writer <br />device and the name of the image file:<br /> <strong>wodim dev=/dev/cdrw image.iso</strong><br /> In addition to the device name and image file,  wodim supports a very large set of op-<br />tions. Two common ones are “-v” for verbose output, and “-dao”, which writes the disc in <br /><em>disc-at-once</em> mode. This mode should be used if you are preparing a disc for commercial <br />reproduction. The default mode for wodim is <em>track-at-once</em>, which is useful for recording <br />music tracks.<br /> <strong>Summing Up<br /></strong>In this chapter we have looked at the basic storage management tasks. There are, of <br />course,   many   more.   Linux   supports   a   vast   array   of   storage   devices   and   file   system <br />schemes. It also offers many features for interoperability with other systems.<br /> <strong>Further Reading<br /></strong>Take a look at the man pages of the commands we have covered. Some of them support <br />huge numbers of options and operations. Also, look for on-line tutorials for adding hard <br />drives to your Linux system (there are many) and working with optical media.<br /> <strong>Extra Credit<br /></strong>It’s often useful to verify the integrity of an iso image that we have downloaded. In most <br />cases, a distributor of an iso image will also supply a <em>checksum file</em>. A checksum is the re-<br />sult of an exotic mathematical calculation resulting in a number that represents the con-<br /> 193<br /></p>
<hr />
<p>15 – Storage Media<br /> tent of the target file. If the contents of the file change by even one bit, the resulting <br />checksum will be much different. The most common method of checksum generation <br />uses the  md5sum program. When you use md5sum, it produces a unique hexadecimal <br />number:<br /> <strong>md5sum image.iso<br /></strong>34e354760f9bb7fbf85c96f6a3f94ece  image.iso<br /> After you download an image, you should run md5sum against it and compare the results <br />with the md5sum value supplied by the publisher.<br />In addition to checking the integrity of a downloaded file, we can use md5sum to verify <br />newly written optical media. To do this, we first calculate the checksum of the image file <br />and then calculate a checksum for the media. The trick to verifying the media is to limit <br />the calculation to only the portion of the optical media that contains the image. We do this <br />by determining the number of 2048 byte blocks the image contains (optical media is al-<br />ways written in 2048 byte blocks) and reading that many blocks from the media. On <br />some types of media, this is not required. A CD-R written in disc-at-once mode can be <br />checked this way:<br /> <strong>md5sum /dev/cdrom<br /></strong>34e354760f9bb7fbf85c96f6a3f94ece  /dev/cdrom<br /> Many types of media, such as DVDs, require a precise calculation of the number of <br />blocks. In the example below, we check the integrity of the image file dvd-image.iso <br />and the disc in the DVD reader /dev/dvd. Can you figure out how this works?<br /> <strong>md5sum dvd-image.iso; dd if=/dev/dvd bs=2048 count=$(( $(stat -c &quot;%s&quot; <br />dvd-image.iso) / 2048 )) | md5sum</strong><br /> 194<br /></p>
<hr />
<p>16 – Networking<br /> <em><strong>16 – Networking</strong></em><br /> When it comes to networking, there is probably nothing that cannot be done with Linux. <br />Linux is used to build all sorts of networking systems and appliances, including firewalls, <br />routers, name servers, NAS (Network Attached Storage) boxes and on and on.<br />Just as the subject of networking is vast, so are the number of commands that can be used <br />to configure and control it. We will focus our attention on just a few of the most fre-<br />quently used ones. The commands chosen for examination include those used to monitor <br />networks and those used to transfer files. In addition, we are going to explore the ssh <br />program that is used to perform remote logins. This chapter will cover:<br /> ●<br /> ping - Send an ICMP ECHO_REQUEST to network hosts<br /> ●<br /> traceroute - Print the route packets trace to a network host<br /> ●<br /> netstat  - Print network connections, routing tables, interface statistics, mas-<br />querade connections, and multicast memberships<br /> ●<br /> ftp - Internet file transfer program<br /> ●<br /> wget - Non-interactive network downloader<br /> ●<br /> ssh - OpenSSH SSH client (remote login program)<br /> We’re going to assume a little background in networking. In this, the Internet age, every-<br />one using a computer needs a basic understanding of networking concepts. To make full <br />use of this chapter we should be familiar with the following terms:<br /> ●<br /> IP (Internet Protocol) address<br /> ●<br /> Host and domain name<br /> ●<br /> URI (Uniform Resource Identifier)<br /> Please see the “Further Reading” section below for some useful articles regarding these <br />terms.<br /> <strong>Note:</strong> Some of the commands we will cover may (depending on your distribution) <br />require the installation of additional packages from your distribution’s repositories, <br /> 195<br /></p>
<hr />
<p>16 – Networking<br /> and some may require superuser privileges to execute.<br /> <strong>Examining And Monitoring A Network<br /></strong>Even if you’re not the system administrator, it’s often helpful to examine the performance <br />and operation of a network.<br /> ping<br />The most basic network command is ping. The ping command sends a special network <br />packet called an IMCP ECHO_REQUEST to a specified host. Most network devices re-<br />ceiving this packet will reply to it, allowing the network connection to be verified.<br /> <strong>Note:</strong> It is possible to configure most network devices (including Linux hosts) to <br />ignore these packets. This is usually done for security reasons, to partially obscure <br />a host from a potential attacker. It is also common for firewalls to be configured to <br />block IMCP traffic.<br /> For example, to see if we can reach linuxcommand.org (one of our favorite sites ;-), <br />we can use use ping like this:<br /> [me@linuxbox ~]$ <strong>ping linuxcommand.org</strong><br /> Once started, ping continues to send packets at a specified interval (default is one sec-<br />ond) until it is interrupted:<br /> [me@linuxbox ~]$ <strong>ping linuxcommand.org<br /></strong>PING linuxcommand.org (66.35.250.210) 56(84) bytes of data. <br /> 64 bytes from vhost.sourceforge.net (66.35.250.210): icmp_seq=1 <br />ttl=43 time=107 ms <br /> 64 bytes from vhost.sourceforge.net (66.35.250.210): icmp_seq=2 <br />ttl=43 time=108 ms <br /> 64 bytes from vhost.sourceforge.net (66.35.250.210): icmp_seq=3 <br />ttl=43 time=106 ms <br /> 64 bytes from vhost.sourceforge.net (66.35.250.210): icmp_seq=4 <br />ttl=43 time=106 ms <br /> 64 bytes from vhost.sourceforge.net (66.35.250.210): icmp_seq=5 <br />ttl=43 time=105 ms <br /> 64 bytes from vhost.sourceforge.net (66.35.250.210): icmp_seq=6 <br /> 196<br /></p>
<hr />
<p>Examining And Monitoring A Network<br /> ttl=43 time=107 ms <br /> --- linuxcommand.org ping statistics --- <br />6 packets transmitted, 6 received, 0% packet loss, time 6010ms <br /> rtt min/avg/max/mdev = 105.647/107.052/108.118/0.824 ms<br /> After it is interrupted (in this case after the sixth packet) by pressing  Ctrl-c,  ping <br />prints performance statistics. A properly performing network will exhibit zero percent <br />packet loss. A successful “ping” will indicate that the elements of the network (its inter-<br />face cards, cabling, routing, and gateways) are in generally good working order. <br /> traceroute<br />The  traceroute  program (some systems use the similar  tracepath  program in-<br />stead) displays a listing of all the “hops” network traffic takes to get from the local sys-<br />tem to a specified host. For example, to see the route taken to reach slashdot.org, <br />we would do this:<br /> [me@linuxbox ~]$ <strong>traceroute slashdot.org</strong><br /> The output looks like this:<br /> traceroute to slashdot.org (216.34.181.45), 30 hops max, 40 byte <br /> packets <br /> 1  ipcop.localdomain (192.168.1.1)  1.066 ms  1.366 ms  1.720 ms <br />  2  * * * <br /> 3  ge-4-13-ur01.rockville.md.bad.comcast.net (68.87.130.9)  14.622 <br /> ms  14.885 ms  15.169 ms <br /> 4  po-30-ur02.rockville.md.bad.comcast.net (68.87.129.154)  17.634 <br /> ms  17.626 ms  17.899 ms <br /> 5  po-60-ur03.rockville.md.bad.comcast.net (68.87.129.158)  15.992 <br /> ms  15.983 ms  16.256 ms <br /> 6  po-30-ar01.howardcounty.md.bad.comcast.net (68.87.136.5)  22.835 <br /> ms  14.233 ms  14.405 ms <br /> 7  po-10-ar02.whitemarsh.md.bad.comcast.net (68.87.129.34)  16.154 <br /> ms  13.600 ms  18.867 ms <br /> 8  te-0-3-0-1-cr01.philadelphia.pa.ibone.comcast.net (68.86.90.77)  <br /> 21.951 ms  21.073 ms  21.557 ms <br /> 9  pos-0-8-0-0-cr01.newyork.ny.ibone.comcast.net (68.86.85.10)  <br /> 22.917 ms  21.884 ms  22.126 ms <br />10  204.70.144.1 (204.70.144.1)  43.110 ms  21.248 ms  21.264 ms <br /> 11  cr1-pos-0-7-3-1.newyork.savvis.net (204.70.195.93)  21.857 ms <br />cr2-pos-0-0-3-1.newyork.savvis.net (204.70.204.238)  19.556 ms cr1-<br /> 197<br /></p>
<hr />
<p>16 – Networking<br /> pos-0-7-3-1.newyork.savvis.net (204.70.195.93)  19.634 ms <br />12  cr2-pos-0-7-3-0.chicago.savvis.net (204.70.192.109)  41.586 ms  <br /> 42.843 ms cr2-tengig-0-0-2-0.chicago.savvis.net (204.70.196.242)  <br />43.115 ms <br /> 13  hr2-tengigabitethernet-12-1.elkgrovech3.savvis.net <br />(204.70.195.122)  44.215 ms  41.833 ms  45.658 ms <br /> 14  csr1-ve241.elkgrovech3.savvis.net (216.64.194.42)  46.840 ms  <br />43.372 ms  47.041 ms <br /> 15  64.27.160.194 (64.27.160.194)  56.137 ms  55.887 ms  52.810 ms <br />16  slashdot.org (216.34.181.45)  42.727 ms  42.016 ms  41.437 ms<br /> In the output, we can see that connecting from our test system to slashdot.org re-<br />quires traversing sixteen routers. For  routers  that provided identifying information, we <br />see their hostnames, IP addresses, and performance data, which includes three samples of <br />round-trip time from the local system to the router. For routers that do not provide identi-<br />fying information (because of router configuration, network congestion, firewalls, etc.), <br />we see asterisks as in the line for hop number 2.<br /> netstat<br />The  netstat  program   is   used   to  examine   various   network   settings   and   statistics. <br />Through the use of its many options, we can look at a variety of features in our network <br />setup. Using the “-ie” option, we can examine the network interfaces in our system:<br /> [me@linuxbox ~]$ <strong>netstat -ie</strong><br /> eth0    Link encap:Ethernet  HWaddr 00:1d:09:9b:99:67  <br />        inet addr:192.168.1.2 Bcast:192.168.1.255 Mask:255.255.255.0 <br />         inet6 addr: fe80::21d:9ff:fe9b:9967/64 Scope:Link <br />        UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1 <br />         RX packets:238488 errors:0 dropped:0 overruns:0 frame:0 <br />        TX packets:403217 errors:0 dropped:0 overruns:0 carrier:0 <br />         collisions:0 txqueuelen:100 <br />        RX bytes:153098921 (146.0 MB)  TX bytes:261035246 (248.9 MB) <br />         Memory:fdfc0000-fdfe0000 <br /> lo      Link encap:Local Loopback  <br />        inet addr:127.0.0.1  Mask:255.0.0.0 <br />         inet6 addr: ::1/128 Scope:Host <br />        UP LOOPBACK RUNNING  MTU:16436  Metric:1 <br />         RX packets:2208 errors:0 dropped:0 overruns:0 frame:0 <br />        TX packets:2208 errors:0 dropped:0 overruns:0 carrier:0 <br />         collisions:0 txqueuelen:0 <br />        RX bytes:111490 (108.8 KB)  TX bytes:111490 (108.8 KB)<br /> In the example above, we see that our test system has two network interfaces. The first, <br /> 198<br /></p>
<hr />
<p>Examining And Monitoring A Network<br /> called eth0, is the Ethernet interface and the second, called lo, is the <em>loopback inter-<br />face</em>, a virtual interface that the system uses to “talk to itself.”<br />When performing causal network diagnostics, the important things to look for are the <br />presence of the word “UP” at the beginning of the fourth line for each interface, indicat-<br />ing that the network interface is enabled, and the presence of a valid IP address in the <br />inet addr field on the second line. For systems using DHCP (Dynamic Host Configu-<br />ration Protocol), a valid IP address in this field will verify that the DHCP is working.<br />Using the “-r” option will display the kernel’s network routing table. This shows how the <br />network is configured to send packets from network to network:<br /> [me@linuxbox ~]$ <strong>netstat -r<br /></strong>Kernel IP routing table <br /> Destination  Gateway     Genmask       Flags   MSS Window  irtt Iface <br /> 192.168.1.0  *           255.255.255.0 U         0 0          0 eth0  <br />default      192.168.1.1 0.0.0.0       UG        0 0          0 eth0 <br /> In this simple example, we see a typical routing table for a client machine on a LAN (Lo-<br />cal Area Network) behind a firewall/router. The first line of the listing shows the destina-<br />tion 192.168.1.0. IP addresses that end in zero refer to networks rather than individ-<br />ual hosts, so this destination means any host on the LAN. The next field, Gateway, is <br />the name or IP address of the gateway (router) used to go from the current host to the des-<br />tination network. An asterisk in this field indicates that no gateway is needed.<br />The last line contains the destination  default. This means any traffic destined for a <br />network that is not otherwise listed in the table. In our example, we see that the gateway <br />is defined as a router with the address of 192.168.1.1, which presumably knows what <br />to do with the destination traffic.<br />The netstat program has many options and we have only looked at a couple. Check <br />out the netstat man page for a complete list.<br /> <strong>Transporting Files Over A Network<br /></strong>What good is a network unless we know how to move  files  across it? There are many <br />programs that move data over networks. We will cover two of them now and several <br />more in later sections.<br /> ftp<br />One of the true “classic” programs, ftp gets it name from the protocol it uses, the <em>File <br />Transfer Protocol</em>. FTP is used widely on the Internet for file downloads. Most, if not all, <br /> 199<br /></p>
<hr />
<p>16 – Networking<br /> web browsers support it and you often see URIs starting with the protocol ftp://.<br />Before there were web browsers, there was the ftp program. ftp is used to communi-<br />cate with <em>FTP servers</em>, machines that contain files that can be uploaded and downloaded <br />over a network.<br />FTP (in its original form) is not secure, because it sends account names and passwords in <br /><em>cleartext</em>. This means that they are not encrypted and anyone <em>sniffing</em> the network can see <br />them. Because of this, almost all FTP done over the Internet is done by <em>anonymous FTP <br />servers</em>. An anonymous server allows anyone to login using the login name “anonymous” <br />and a meaningless password.<br />In the example below, we show a typical session with the ftp program downloading an <br />Ubuntu iso image located in the  /pub/cd_images/Ubuntu-8.04 directory of the <br />anonymous FTP server fileserver:<br /> [me@linuxbox ~]$ <strong>ftp fileserver <br /></strong>Connected to fileserver.localdomain. <br /> 220 (vsFTPd 2.0.1) <br />Name (fileserver:me): <strong>anonymous </strong><br /> 331 Please specify the password. <br />Password: <br /> 230 Login successful. <br />Remote system type is UNIX. <br /> Using binary mode to transfer files. <br />ftp&gt; <strong>cd pub/cd_images/Ubuntu-8.04 </strong><br /> 250 Directory successfully changed. <br />ftp&gt; <strong>ls</strong> <br /> 200 PORT command successful. Consider using PASV. <br />150 Here comes the directory listing. <br /> -rw-rw-r--    1 500      500      733079552 Apr 25 03:53 ubuntu-8.04-<br />desktop-i386.iso <br /> 226 Directory send OK. <br />ftp&gt; <strong>lcd Desktop</strong> <br /> Local directory now /home/me/Desktop <br />ftp&gt; <strong>get ubuntu-8.04-desktop-i386.iso</strong> <br /> local: ubuntu-8.04-desktop-i386.iso remote: ubuntu-8.04-desktop-<br />i386.iso <br /> 200 PORT command successful. Consider using PASV. <br />150 Opening BINARY mode data connection for ubuntu-8.04-desktop-<br /> i386.iso (733079552 bytes). <br />226 File send OK. <br /> 733079552 bytes received in 68.56 secs (10441.5 kB/s) <br />ftp&gt; <strong>bye</strong> <br /> Here is an explanation of the commands entered during this session:<br /> 200<br /></p>
<hr />
<p>Transporting Files Over A Network<br /> <strong>Command</strong><br /> <strong>Meaning</strong><br /> ftp fileserver <br /> Invoke the ftp program and have it <br />connect to the FTP server <br />fileserver.<br /> anonymous<br /> Login name. After the login prompt, a <br />password prompt will appear. Some <br />servers will accept a blank password, <br />others will require a password in the <br />form of an email address. In that case, <br />try something like <br />“user@example.com”.<br /> cd pub/cd_images/Ubuntu-8.04<br /> Change to the directory on the remote <br />system containing the desired file. <br />Note that on most anonymous FTP <br />servers, the files for public <br />downloading are found somewhere <br />under the pub directory.<br /> ls<br /> List the directory on the remote <br />system.<br /> lcd Desktop<br /> Change the directory on the local <br />system to ~/Desktop. In the <br />example, the ftp program was <br />invoked when the working directory <br />was ~. This command changes the <br />working directory to ~/Desktop.<br /> get ubuntu-8.04-desktop-<br /> Tell the remote system to transfer the <br /> i386.iso<br /> file ubuntu-8.04-desktop-<br />i386.iso to the local system. Since <br />the working directory on the local <br />system was changed to ~/Desktop, <br />the file will be downloaded there.<br /> bye<br /> Log off the remote server and end the <br />ftp program session. The commands <br />quit and exit may also be used.<br /> Typing “help” at the “ftp&gt;” prompt will display a list of the supported commands. Using <br />ftp on a server where sufficient permissions have been granted, it is possible to perform <br /> 201<br /></p>
<hr />
<p>16 – Networking<br /> many ordinary file management tasks. It’s clumsy, but it does work.<br /> lftp – A Better ftp<br />ftp is not the only command-line FTP client. In fact, there are many. One of the better <br />(and more popular) ones is lftp by Alexander Lukyanov. It works much like the tradi-<br />tional  ftp  program, but has many additional convenience features including multiple-<br />protocol support (including HTTP), automatic re-try on failed downloads, background <br />processes, tab completion of path names, and many more.<br /> wget<br />Another popular command-line program for file downloading is  wget. It is useful for <br />downloading content from both web and FTP sites. Single files, multiple files, and even <br />entire sites can be downloaded. To download the first page of linuxcommand.org we <br />could do this:<br /> [me@linuxbox ~]$ <strong>wget http://linuxcommand.org/index.php<br /></strong>--11:02:51--  http://linuxcommand.org/index.php <br />            =&gt; `index.php' <br />Resolving linuxcommand.org... 66.35.250.210 <br /> Connecting to linuxcommand.org|66.35.250.210|:80... connected. <br />HTTP request sent, awaiting response... 200 OK <br /> Length: unspecified [text/html] <br />     [ &lt;=&gt;                                 ] 3,120         --.--K/s <br /> 11:02:51 (161.75 MB/s) - `index.php' saved [3120] <br /> The program's many options allow wget to recursively download, download files in the <br />background (allowing you to log off but continue downloading), and complete the down-<br />load of a partially downloaded file. These features are well documented in its better-than-<br />average man page.<br /> <strong>Secure Communication With Remote Hosts<br /></strong>For many years, Unix-like operating systems have had the ability to be administered re-<br />motely via a network. In the early days, before the general adoption of the Internet, there <br />were   a   couple   of   popular   programs  used   to   log  in   to   remote   hosts.  These   were  the <br />rlogin and  telnet programs. These programs, however, suffer from the same fatal <br />flaw that the ftp program does; they transmit all their communications (including login <br />names and passwords) in cleartext. This makes them wholly inappropriate for use in the <br /> 202<br /></p>
<hr />
<p>Secure Communication With Remote Hosts<br /> Internet age.<br /> ssh<br />To address this problem, a new protocol called SSH (Secure Shell) was developed. SSH <br />solves the two basic problems of secure communication with a remote host. First, it au-<br />thenticates that the remote host is who it says it is (thus preventing so-called “man in the <br />middle” attacks), and second, it encrypts all of the communications between the local and <br />remote hosts.<br />SSH consists of two parts. An SSH server runs on the remote host, listening for incoming <br />connections on port 22, while an SSH client is used on the local system to communicate <br />with the remote server.<br />Most   Linux   distributions   ship   an   implementation   of   SSH   called  OpenSSH  from   the <br />OpenBSD project. Some distributions include both the client and the server packages by <br />default (for example, Red Hat), while others (such as Ubuntu) only supply the client. To <br />enable a system to receive remote connections, it must have the OpenSSH-server <br />package installed, configured and running, and (if the system is either running or is be-<br />hind a firewall) it must allow incoming network connections on TCP port 22.<br /> <strong>Tip</strong>: If you don’t have a remote system to connect to but want to try these exam-<br />ples, make sure the OpenSSH-server package is installed on your system and <br />use localhost as the name of the remote host. That way, your machine will cre-<br />ate network connections with itself.<br /> The SSH client program used to connect to remote SSH servers is called, appropriately <br />enough, ssh. To connect to a remote host named remote-sys, we would use the ssh <br />client program like so:<br /> [me@linuxbox ~]$ <strong>ssh remote-sys</strong><br /> The authenticity of host 'remote-sys (192.168.1.4)' can't be <br />established. <br /> RSA key fingerprint is <br />41:ed:7a:df:23:19:bf:3c:a5:17:bc:61:b3:7f:d9:bb. <br /> Are you sure you want to continue connecting (yes/no)?<br /> The first time the connection is attempted, a message is displayed indicating that the au-<br />thenticity of the remote host cannot be established. This is because the client program has <br />never seen this remote host before. To accept the credentials of the remote host, enter <br />“yes”   when   prompted.   Once   the   connection   is   established,   the   user   is   prompted   for <br />his/her password:<br /> 203<br /></p>
<hr />
<p>16 – Networking<br /> Warning: Permanently added 'remote-sys,192.168.1.4' (RSA) to the list <br />of known hosts. <br /> me@remote-sys's password:<br /> After the password is successfully entered, we receive the shell prompt from the remote <br />system:<br /> Last login: Sat Aug 30 13:00:48 2008<br /> [me@remote-sys ~]$ <br /> The remote shell session continues until the user enters the exit command at the remote <br />shell prompt, thereby closing the remote connection. At this point, the local shell session <br />resumes and the local shell prompt reappears.<br />It is also possible to connect to remote systems using a different username. For example, <br />if the local user “me” had an account named “bob” on a remote system, user me could log <br />in to the account bob on the remote system as follows:<br /> [me@linuxbox ~]$ <strong>ssh bob@remote-sys</strong><br /> bob@remote-sys's password:<br />Last login: Sat Aug 30 13:03:21 2008<br /> [bob@remote-sys ~]$<br /> As stated before, ssh verifies the authenticity of the remote host. If the remote host does <br />not successfully authenticate, the following message appears:<br /> [me@linuxbox ~]$ <strong>ssh remote-sys</strong><br /> @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ <br />@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @ <br /> @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ <br />IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! <br /> Someone could be eavesdropping on you right now (man-in-the-middle <br />attack)! <br /> It is also possible that the RSA host key has just been changed. <br />The fingerprint for the RSA key sent by the remote host is <br /> 41:ed:7a:df:23:19:bf:3c:a5:17:bc:61:b3:7f:d9:bb. <br />Please contact your system administrator. <br /> Add correct host key in /home/me/.ssh/known_hosts to get rid of this <br />message. <br /> Offending key in /home/me/.ssh/known_hosts:1 <br />RSA host key for remote-sys has changed and you have requested strict <br /> 204<br /></p>
<hr />
<p>Secure Communication With Remote Hosts<br /> checking. <br />Host key verification failed.<br /> This message is caused by one of two possible situations. First, an attacker may be at-<br />tempting a “man-in-the-middle” attack. This is rare, since everybody knows that  ssh <br />alerts the user to this. The more likely culprit is that the remote system has been changed <br />somehow; for example, its operating system or SSH server has been reinstalled. In the in-<br />terests of security and safety however, the first possibility should not be dismissed out of <br />hand. Always check with the administrator of the remote system when this message oc-<br />curs.<br />After it has been determined that the message is due to a benign cause, it is safe to correct <br />the problem on the client side. This is done by using a text editor (vim perhaps) to re-<br />move the obsolete key from the ~/.ssh/known_hosts file. In the example message <br />above, we see this:<br /> Offending key in /home/me/.ssh/known_hosts:1<br /> This means that line one of the known_hosts file contains the offending key. Delete <br />this line from the file, and the ssh program will be able to accept new authentication cre-<br />dentials from the remote system.<br />Besides opening a shell session on a remote system, ssh also allows us to execute a sin-<br />gle command on a remote system. For example, to execute the free command on a re-<br />mote host named remote-sys and have the results displayed on the local system:<br /> [me@linuxbox ~]$ <strong>ssh remote-sys free</strong><br /> me@twin4's password: <br />             total     used     free     shared    buffers     cached <br /> Mem:        775536   507184   268352          0     110068     154596 <br /> -/+ buffers/cache:   242520   533016 <br /> Swap:      1572856        0    1572856<br />[me@linuxbox ~]$<br /> It’s possible to use this technique in more interesting ways, such as this example in which <br />we perform an ls on the remote system and redirect the output to a file on the local sys-<br />tem:<br /> 205<br /></p>
<hr />
<p>16 – Networking<br /> [me@linuxbox ~]$ <strong>ssh remote-sys 'ls *' &gt; dirlist.txt<br /></strong>me@twin4's password:<br /> [me@linuxbox ~]$<br /> Notice the use of the single quotes in the command above. This is done because we do <br />not want the pathname expansion performed on the local machine; rather, we want it to <br />be performed on the remote system. Likewise, if we had wanted the output redirected to a <br />file on the remote machine, we could have placed the redirection operator and the file-<br />name within the single quotes:<br /> [me@linuxbox ~]$ <strong>ssh remote-sys 'ls * &gt; dirlist.txt'</strong><br /> <strong>Tunneling With SSH<br /></strong>Part of what happens when you establish a connection with a remote host via SSH <br />is that an <em>encrypted tunnel</em> is created between the local and remote systems. Nor-<br />mally, this tunnel is used to allow commands typed at the local system to be trans-<br />mitted safely to the remote system, and for the results to be transmitted safely <br />back. In addition to this basic function, the SSH protocol allows most types of <br />network traffic to be sent through the encrypted tunnel, creating a sort of  <em>VPN <br /></em>(Virtual Private Network) between the local and remote systems.<br />Perhaps the most common use of this feature is to allow X Window system traffic <br />to be transmitted. On a system running an X server (that is, a machine displaying <br />a GUI), it is possible to launch and run an X client program (a graphical applica-<br />tion) on a remote system and have its display appear on the local system. It’s easy <br />to do; here’s an example: Let’s say we are sitting at a Linux system called lin-<br />uxbox which is running an X server, and we want to run the xload program on <br />a remote system named remote-sys and see the program’s graphical output on <br />our local system. We could do this:<br />[me@linuxbox ~]$ <strong>ssh -X remote-sys<br /></strong>me@remote-sys's password:<br />Last login: Mon Sep 08 13:23:11 2008<br />[me@remote-sys ~]$ <strong>xload<br /></strong>After the xload command is executed on the remote system, its window appears <br />on the local system. On some systems, you may need to use the “-Y” option <br />rather than the “-X” option to do this.<br /> 206<br /></p>
<hr />
<p>Secure Communication With Remote Hosts<br /> scp And sftp<br />The OpenSSH package also includes two programs that can make use of an SSH-en-<br />crypted tunnel to copy files across the network. The first,  scp  (secure copy) is used <br />much like the familiar cp program to copy files. The most notable difference is that the <br />source or destination pathnames may be preceded with the name of a remote host, fol-<br />lowed by a colon character. For example, if we wanted to copy a document named doc-<br />ument.txt from our home directory on the remote system, remote-sys, to the cur-<br />rent working directory on our local system, we could do this:<br /> [me@linuxbox ~]$ <strong>scp remote-sys:document.txt .</strong><br /> me@remote-sys's password:<br />document.txt                           100% 5581     5.5KB/s   00:00<br /> [me@linuxbox ~]$<br /> As with ssh, you may apply a username to the beginning of the remote host’s name if <br />the desired remote host account name does not match that of the local system:<br /> [me@linuxbox ~]$ <strong>scp bob@remote-sys:document.txt .</strong> <br /> The second SSH file-copying program is sftp which, as its name implies, is a secure re-<br />placement for the ftp program. sftp works much like the original ftp program that <br />we used earlier; however, instead of transmitting everything in cleartext, it uses an SSH <br />encrypted tunnel. sftp has an important advantage over conventional ftp in that it does <br />not require an FTP server to be running on the remote host. It only requires the SSH <br />server. This means that any remote machine that can connect with the SSH client can also <br />be used as a FTP-like server. Here is a sample session:<br /> [me@linuxbox ~]$ <strong>sftp remote-sys<br /></strong>Connecting to remote-sys... <br /> me@remote-sys's password: <br />sftp&gt; <strong>ls</strong><br /> ubuntu-8.04-desktop-i386.iso            <br />sftp&gt; <strong>lcd Desktop</strong> <br /> sftp&gt; <strong>get ubuntu-8.04-desktop-i386.iso</strong> <br />Fetching /home/me/ubuntu-8.04-desktop-i386.iso to ubuntu-8.04-<br /> desktop-i386.iso <br />/home/me/ubuntu-8.04-desktop-i386.iso 100%  699MB   7.4MB/s   01:35<br /> sftp&gt; <strong>bye</strong><br /> 207<br /></p>
<hr />
<p>16 – Networking<br /> <strong>Tip:</strong> The SFTP protocol is supported by many of the graphical file managers found <br />in Linux distributions. Using either Nautilus (GNOME) or Konqueror (KDE), we <br />can enter a URI beginning with sftp:// into the location bar and operate on files <br />stored on a remote system running an SSH server.<br /> <strong>An SSH Client For Windows?<br /></strong>Let’s say you are sitting at a Windows machine but you need to log in to your <br />Linux server and get some real work done; what do you do? Get an SSH client <br />program for your Windows box, of course! There are a number of these. The most <br />popular one is probably PuTTY by Simon Tatham and his team. The PuTTY pro-<br />gram displays a terminal window and allow a Windows user to open an SSH (or <br />telnet) session on a remote host. The program also provides analogs for the scp <br />and sftp programs.<br />PuTTY is available at<a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/"> http://www.chiark.greenend.org.uk/~sgtatham/putty/</a><br /> <strong>Summing Up<br /></strong>In this chapter, we have surveyed the field of networking tools found on most Linux sys-<br />tems. Since Linux is so widely used in servers and networking appliances, there are many <br />more that can be added by installing additional software. But even with the basic set of <br />tools, it is possible to perform many useful network related tasks. <br /> <strong>Further Reading</strong><br /> ●<br /> For a broad (albeit dated) look at network administration, the Linux Documenta-<br />tion Project provides the <em>Linux Network Administrator’s Guide</em>:<br /><a href="http://tldp.org/LDP/nag2/index.html">http://tldp.org/LDP/nag2/index.html</a><br /> ●<br /> Wikipedia contains many good networking articles. Here are some of the basics:<br /><a href="http://en.wikipedia.org/wiki/Internet_protocol_address">http://en.wikipedia.org/wiki/Internet_protocol_address<br /></a><a href="http://en.wikipedia.org/wiki/Host_name">http://en.wikipedia.org/wiki/Host_name<br /></a><a href="http://en.wikipedia.org/wiki/Uniform_Resource_Identifier">http://en.wikipedia.org/wiki/Uniform_Resource_Identifier</a><br /> 208<br /></p>
<hr />
<p>17 – Searching For Files<br /> <em><strong>17 – Searching For Files</strong></em><br /> As we have wandered around our Linux system, one thing has become abundantly clear: <br />A typical Linux system has a lot of files! This begs the question, “How do we  find <br />things?” We already know that the Linux file system is well organized according to con-<br />ventions that have been passed down from one generation of Unix-like systems to the <br />next, but the sheer number of files can present a daunting problem.<br />In this chapter, we will look at two tools that are used to find files on a system. These <br />tools are:<br /> ●<br /> locate – Find files by name<br /> ●<br /> find – Search for files in a directory hierarchy<br /> We will also look at a command that is often used with file-search commands to process <br />the resulting list of files:<br /> ●<br /> xargs – Build and execute command lines from standard input<br /> In addition, we will introduce a couple of commands to assist us in our explorations:<br /> ●<br /> touch – Change file times<br /> ●<br /> stat – Display file or file system status<br /> <strong>locate – Find Files The Easy Way<br /></strong>The locate program performs a rapid database search of pathnames, and then outputs <br />every name that matches a given substring. Say, for example, we want to find all the pro-<br />grams with names that begin with “zip.” Since we are looking for programs, we can as-<br />sume that the name of the directory containing the programs would end with “bin/”. <br />Therefore, we could try to use locate this way to find our files:<br /> [me@linuxbox ~]$ <strong>locate bin/zip</strong><br /> locate  will search its database of pathnames and output any that contain the string <br /> 209<br /></p>
<hr />
<p>17 – Searching For Files<br /> “bin/zip”:<br /> /usr/bin/zip <br />/usr/bin/zipcloak <br /> /usr/bin/zipgrep <br />/usr/bin/zipinfo <br /> /usr/bin/zipnote <br />/usr/bin/zipsplit<br /> If the search requirement is not so simple,  locate  can be combined with other tools <br />such as grep to design more interesting searches:<br /> [me@linuxbox ~]$ <strong>locate zip | grep bin<br /></strong>/bin/bunzip2 <br /> /bin/bzip2 <br />/bin/bzip2recover <br /> /bin/gunzip <br />/bin/gzip <br /> /usr/bin/funzip <br />/usr/bin/gpg-zip <br /> /usr/bin/preunzip <br />/usr/bin/prezip <br /> /usr/bin/prezip-bin <br />/usr/bin/unzip <br /> /usr/bin/unzipsfx <br />/usr/bin/zip <br /> /usr/bin/zipcloak <br />/usr/bin/zipgrep <br /> /usr/bin/zipinfo <br />/usr/bin/zipnote <br /> /usr/bin/zipsplit <br /> The locate program has been around for a number of years, and there are several dif-<br />ferent variants in common use. The two most common ones found in modern Linux dis-<br />tributions are slocate and mlocate, though they are usually accessed by a symbolic <br />link named locate. The different versions of locate have overlapping options sets. <br />Some versions include regular expression matching (which we’ll cover in an upcoming <br />chapter) and wildcard support. Check the man page for locate to determine which ver-<br />sion of locate is installed.<br /> 210<br /></p>
<hr />
<p>locate – Find Files The Easy Way<br /> <strong>Where Does The locate Database Come From?<br /></strong>You may notice that, on some distributions, locate fails to work just after the <br />system is installed, but if you try again the next day, it works fine. What gives? <br />The  locate  database is created by another program named  updatedb. Usu-<br />ally, it is run periodically as a <em>cron job</em>; that is, a task performed at regular inter-<br />vals by the cron daemon.  Most systems equipped with locate run updatedb <br />once a day. Since the database is not updated continuously, you will notice that <br />very recent files do not show up when using locate.  To overcome this, it’s pos-<br />sible to run the  updatedb  program manually by becoming the superuser and <br />running updatedb at the prompt. <br /> <strong>find – Find Files The Hard Way<br /></strong>While the locate program can find a file based solely on its name, the find program <br />searches a given directory (and its subdirectories) for files based on a variety of at-<br />tributes. We’re going to spend a lot of time with find because it has a lot of interesting <br />features that we will see again and again when we start to cover programming concepts in <br />later chapters.<br />In its simplest use, find is given one or more names of directories to search. For exam-<br />ple, to produce a list of our home directory:<br /> [me@linuxbox ~]$ <strong>find ~</strong><br /> On most active user accounts, this will produce a large list. Since the list is sent to stan-<br />dard output, we can pipe the list into other programs. Let’s use wc to count the number of <br />files:<br /> [me@linuxbox ~]$ <strong>find ~ | wc -l<br /></strong>47068<br /> Wow, we’ve been busy! The beauty of find is that it can be used to identify files that <br />meet specific criteria. It does this through the (slightly strange) application of  <em>options</em>, <br /><em>tests</em>, and <em>actions</em>. We’ll look at the tests first.<br /> 211<br /></p>
<hr />
<p>17 – Searching For Files<br /> Tests<br />Let’s say that we want a list of directories from our search. To do this, we could add the <br />following test:<br /> [me@linuxbox ~]$ <strong>find ~ -type d | wc -l<br /></strong>1695<br /> Adding the test -type d limited the search to directories. Conversely, we could have <br />limited the search to regular files with this test:<br /> [me@linuxbox ~]$ <strong>find ~ -type f | wc -l<br /></strong>38737<br /> Here are the common file type tests supported by find:<br /> <em>Table 17-1: find File Types</em><br /> <strong>File Type</strong><br /> <strong>Description</strong><br /> b<br /> Block special device file<br /> c<br /> Character special device file<br /> d<br /> Directory<br /> f<br /> Regular file<br /> l<br /> Symbolic link<br /> We can also search by file size and filename by adding some additional tests: Let’s look <br />for all the regular files that match the wildcard pattern “*.JPG” and are larger than one <br />megabyte:<br /> [me@linuxbox ~]$ <strong>find ~ -type f -name &quot;*.JPG&quot; -size +1M | wc -l<br /></strong>840<br /> In this example, we add the -name test followed by the wildcard pattern. Notice how we <br />enclose it in quotes to prevent pathname expansion by the shell. Next, we add the -size <br />test followed by the string “+1M”. The leading plus sign indicates that we are looking for <br />files larger than the specified number. A leading minus sign would change the meaning of <br /> 212<br /></p>
<hr />
<p>find – Find Files The Hard Way<br /> the string to be smaller than the specified number. Using no sign means, “match the value <br />exactly.” The trailing letter “M” indicates that the unit of measurement is megabytes. The <br />following characters may be used to specify units:<br /> <em>Table 17-2: find Size Units</em><br /> <strong>Character</strong><br /> <strong>Unit</strong><br /> b<br /> 512-byte blocks. This is the default if no unit is specified.<br /> c<br /> Bytes<br /> w<br /> 2-byte words<br /> k<br /> Kilobytes (units of 1024 bytes)<br /> M<br /> Megabytes (units of 1048576 bytes)<br /> G<br /> Gigabytes (units of 1073741824 bytes)<br /> find  supports a large number of different tests. Below is a rundown of the common <br />ones. Note that in cases where a numeric argument is required, the same “+” and “-” no-<br />tation discussed above can be applied:<br /> <em>Table 17-3: find Tests</em><br /> <strong>Test</strong><br /> <strong>Description</strong><br /> -cmin <em>n</em><br /> Match files or directories whose content or attributes were <br />last modified exactly <em>n</em> minutes ago. To specify less than <em>n</em> <br />minutes ago, use <em>-n</em> and to specify more than <em>n</em> minutes <br />ago, use <em>+n</em>.<br /> -cnewer <em>file</em><br /> Match files or directories whose contents or attributes were <br />last modified more recently than those of <em>file</em>.<br /> -ctime <em>n</em><br /> Match files or directories whose contents or attributes were <br />last modified <em>n</em>*24 hours ago.<br /> -empty<br /> Match empty files and directories.<br /> -group <em>name</em><br /> Match file or directories belonging to <em>group</em>. <em>group</em> may <br />be expressed as either a group name or as a numeric group <br />ID.<br /> -iname <em>pattern</em><br /> Like the -name test but case insensitive.<br /> -inum <em>n</em><br /> Match files with inode number <em>n</em>. This is helpful for finding <br />all the hard links to a particular inode.<br /> 213<br /></p>
<hr />
<p>17 – Searching For Files<br /> -mmin <em>n</em><br /> Match files or directories whose contents were last <br />modified <em>n</em> minutes ago.<br /> -mtime <em>n</em><br /> Match files or directories whose contents were last <br />modified <em>n</em>*24 hours ago.<br /> -name <em>pattern</em><br /> Match files and directories with the specified wildcard <br /><em>pattern</em>.<br /> -newer <em>file</em><br /> Match files and directories whose contents were modified <br />more recently than the specified <em>file</em>. This is very useful <br />when writing shell scripts that perform file backups. Each <br />time you make a backup, update a file (such as a log), and <br />then use find to determine which files have changed since <br />the last update.<br /> -nouser<br /> Match file and directories that do not belong to a valid user. <br />This can be used to find files belonging to deleted accounts <br />or to detect activity by attackers.<br /> -nogroup<br /> Match files and directories that do not belong to a valid <br />group.<br /> -perm <em>mode</em><br /> Match files or directories that have permissions set to the <br />specified <em>mode</em>. <em>mode</em> may be expressed by either octal or <br />symbolic notation.<br /> -samefile <em>name</em><br /> Similar to the -inum test. Matches files that share the <br />same inode number as file <em>name</em>.<br /> -size <em>n</em><br /> Match files of size <em>n</em>.<br /> -type <em>c</em><br /> Match files of type <em>c</em>.<br /> -user <em>name</em><br /> Match files or directories belonging to user <em>name</em>. The user <br />may be expressed by a username or by a numeric user ID.<br /> This is not a complete list. The find man page has all the details.<br /> Operators<br />Even with all the tests that find provides, we may still need a better way to describe the <br /><em>logical relationships</em> between the tests. For example, what if we needed to determine if <br />all the files and subdirectories in a directory had secure permissions? We would look for <br />all the files with permissions that are not 0600 and the directories with permissions that <br />are not 0700. Fortunately, find provides a way to combine tests using <em>logical operators </em><br /> 214<br /></p>
<hr />
<p>find – Find Files The Hard Way<br /> to create more complex logical relationships. To express the aforementioned test, we <br />could do this:<br /> [me@linuxbox ~]$ <strong>find ~ \( -type f -not -perm 0600 \) -or \( -type d <br />-not -perm 0700 \)</strong><br /> Yikes! That sure looks weird. What is all this stuff? Actually, the operators are not that <br />complicated once you get to know them. Here is the list:<br /> <em>Table 17-4: find Logical Operators</em><br /> <strong>Operator</strong><br /> <strong>Description</strong><br /> -and<br /> Match if the tests on both sides of the operator are true. <br />May be shortened to -a. Note that when no operator is <br />present, -and is implied by default.<br /> -or<br /> Match if a test on either side of the operator is true. May be <br />shortened to -o.<br /> -not<br /> Match if the test following the operator is false. May be <br />abbreviated with an exclamation point (!).<br /> ( )<br /> Groups tests and operators together to form larger <br />expressions. This is used to control the precedence of the <br />logical evaluations. By default, find evaluates from left to <br />right. It is often necessary to override the default evaluation <br />order to obtain the desired result. Even if not needed, it is <br />helpful sometimes to include the grouping characters to <br />improve readability of the command. Note that since the <br />parentheses characters have special meaning to the shell, <br />they must be quoted when using them on the command line <br />to allow them to be passed as arguments to find. Usually <br />the backslash character is used to escape them.<br /> With this list of operators in hand, let’s deconstruct our find command. When viewed <br />from the uppermost level, we see that our tests are arranged as two groupings separated <br />by an -or operator:<br />( <em>expression 1</em> ) -or ( <em>expression 2</em> )<br />This makes sense, since we are searching for files with a certain set of permissions and <br />for directories with a different set. If we are looking for both files and directories, why do <br /> 215<br /></p>
<hr />
<p>17 – Searching For Files<br /> we use -or instead of -and? Because as find scans through the files and directories, <br />each one is evaluated to see if it matches the specified tests. We want to know if it is <em>ei-<br />ther</em> a file with bad permissions <em>or</em> a directory with bad permissions. It can’t be both at <br />the same time. So if we expand the grouped expressions, we can see it this way:<br />( file with bad perms ) -or ( directory with bad perms )<br />Our next challenge is how to test for “bad permissions.” How do we do that? Actually we <br />don’t. What we will test for is “not good permissions,” since we know what “good per-<br />missions” are. In the case of files, we define good as 0600 and for directories, as 0700. <br />The expression that will test files for “not good” permissions is:<br />-type f -and -not -perms 0600<br />and for directories:<br />-type d -and -not -perms 0700<br />As noted in the table of operators above, the -and operator can be safely removed, since <br />it is implied by default. So if we put this all back together, we get our final command:<br />find ~ ( -type f -not -perms 0600 ) -or ( -type d -not <br />-perms 0700 )<br />However, since the parentheses have special meaning to the shell, we must escape them <br />to prevent the shell from trying to interpret them. Preceding each one with a backslash <br />character does the trick.<br />There is another feature of logical operators that is important to understand. Let’s say that <br />we have two expressions separated by a logical operator:<br /><em>expr1</em> -operator <em>expr2<br /></em>In all cases,  <em>expr1</em> will always be performed; however, the operator will determine if <br /><em>expr2</em> is performed. Here’s how it works:<br /> <em>Table 17-5: find AND/OR Logic</em><br /> <strong>Results of <em>expr1</em></strong><br /> <strong>Operator</strong><br /> <em><strong>expr2</strong></em><strong> is...</strong><br /> True<br /> -and<br /> Always performed<br /> False<br /> -and<br /> Never performed<br /> True<br /> -or<br /> Never performed<br /> False<br /> -or<br /> Always performed<br /> Why does this happen? It’s done to improve performance. Take -and, for example. We <br />know that the expression <em>expr1</em> -and <em>expr2</em> cannot be true if the result of <em>expr1</em> is <br /> 216<br /></p>
<hr />
<p>find – Find Files The Hard Way<br /> false, so there is no point in performing  <em>expr2</em>. Likewise, if we have the expression <br /><em>expr1</em> -or <em>expr2</em> and the result of <em>expr1</em> is true, there is no point in performing <br /><em>expr2,</em> as we already know that the expression <em>expr1</em> -or <em>expr2</em> is true.<br />OK, so it helps it go faster. Why is this important? It’s important because we can rely on <br />this behavior to control how actions are performed, as we shall soon see.<br /> Predefined Actions<br />Let’s get some work done! Having a list of results from our find command is useful, but <br />what we really want to do is act on the items on the list. Fortunately, find allows actions <br />to be performed based on the search results. There are a set of predefined actions and sev-<br />eral ways to apply user-defined actions. First let’s look at a few of the predefined actions:<br /> <em>Table 17-6: Predefined find Actions</em><br /> <strong>Action</strong><br /> <strong>Description</strong><br /> -delete<br /> Delete the currently matching file.<br /> -ls<br /> Perform the equivalent of ls -dils on the matching file. <br />Output is sent to standard output.<br /> -print<br /> Output the full pathname of the matching file to standard <br />output. This is the default action if no other action is <br />specified.<br /> -quit<br /> Quit once a match has been made.<br /> As with the tests, there are many more actions. See the find man page for full details.<br />In our very first example, we did this:<br /> <strong>find ~</strong><br /> which produced a list of every file and subdirectory contained within our home directory. <br />It produced a list because the -print action is implied if no other action is specified. <br />Thus our command could also be expressed as:<br /> <strong>find ~ -print</strong><br /> We can use find to delete files that meet certain criteria. For example, to delete files that <br /> 217<br /></p>
<hr />
<p>17 – Searching For Files<br /> have the file extension “.BAK” (which is often used to designate backup files), we could <br />use this command:<br /> <strong>find ~ -type f -name '*.BAK' -delete</strong><br /> In this example, every file in the user’s home directory (and its subdirectories) is searched <br />for filenames ending in .BAK. When they are found, they are deleted.<br /> <strong>Warning:</strong> It should go without saying that you should <em><strong>use extreme caution</strong></em> when <br />using   the  -delete  action. Always test the command first by substituting the <br />-print action for -delete to confirm the search results.<br /> Before we go on, let’s take another look at how the logical operators affect actions. Con-<br />sider the following command:<br /> <strong>find ~ -type f -name '*.BAK' -print</strong><br /> As we have seen, this command will look for every regular file (-type f) whose name <br />ends with  .BAK  (-name<strong>  '*</strong>.BAK') and will output the relative pathname of each <br />matching file to standard output (-print). However, the reason the command performs <br />the way it does is determined by the logical relationships between each of the tests and <br />actions. Remember, there is, by default, an implied -and relationship between each test <br />and action. We could also express the command this way to make the logical relation-<br />ships easier to see:<br /> <strong>find ~ -type f -and -name '*.BAK' -and -print</strong><br /> With our command fully expressed, let’s look at how the logical operators affect its exe-<br />cution:<br /> <strong>Test/Action</strong><br /> <strong>Is Performed Only If...</strong><br /> -print<br /> -type f and -name '*.BAK' are true<br /> -name ‘*.BAK’<br /> -type f is true<br /> -type f<br /> Is always performed, since it is the first test/action in an <br />-and relationship.<br /> 218<br /></p>
<hr />
<p>find – Find Files The Hard Way<br /> Since the logical relationship between the tests and actions determines which of them are <br />performed, we can see that the order of the tests and actions is important. For instance, if <br />we were to reorder the tests and actions so that the -print action was the first one, the <br />command would behave much differently:<br /> <strong>find ~ -print -and -type f -and -name '*.BAK'</strong><br /> This version of the command will print each file (the -print action always evaluates to <br />true) and then test for file type and the specified file extension.<br /> User-Defined Actions<br />In addition to the predefined actions, we can also invoke arbitrary commands. The tradi-<br />tional way of doing this is with the -exec action. This action works like this:<br />-exec <em>command</em> {} ;<br />where <em>command</em> is the name of a command, {} is a symbolic representation of the current <br />pathname, and the semicolon is a required delimiter indicating the end of the command. <br />Here’s an example of using -exec to act like the -delete action discussed earlier:<br /> -exec rm '{}' ';'<br /> Again, since the brace and semicolon characters have special meaning to the shell, they <br />must be quoted or escaped. <br />It’s also possible to execute a user-defined action interactively. By using the -ok action <br />in place of -exec, the user is prompted before execution of each specified command:<br /> <strong>find ~ -type f -name 'foo*' -ok ls -l '{}' ';'<br /></strong>&lt; ls ... /home/me/bin/foo &gt; ? <strong>y</strong> <br /> -rwxr-xr-x 1 me   me 224 2007-10-29 18:44 /home/me/bin/foo <br />&lt; ls ... /home/me/foo.txt &gt; ? <strong>y</strong> <br /> -rw-r--r-- 1 me   me   0 2008-09-19 12:53 /home/me/foo.txt<br /> In this example, we search for files with names starting with the string “foo” and execute <br />the command ls -l each time one is found. Using the -ok action prompts the user be-<br />fore the ls command is executed.<br /> 219<br /></p>
<hr />
<p>17 – Searching For Files<br /> Improving Efficiency<br />When the  -exec action is used, it launches a new instance of the specified command <br />each time a matching file is found. There are times when we might prefer to combine all <br />of the search results and launch a single instance of the command. For example, rather <br />than executing the commands like this:<br />ls -l <em>file1<br /></em>ls -l <em>file2<br /></em>we may prefer to execute them this way:<br />ls -l <em>file1 file2<br /></em>thus causing the command to be executed only one time rather than multiple times. There <br />are two ways we can do this. The traditional way, using the external command xargs <br />and the alternate way, using a new feature in find itself. We’ll talk about the alternate <br />way first.<br />By changing the trailing semicolon character to a plus sign, we activate the ability of <br />find to combine the results of the search into an argument list for a single execution of <br />the desired command. Going back to our example, this:<br /> <strong>find ~ -type f -name 'foo*' -exec ls -l '{}' ';'<br /></strong>-rwxr-xr-x 1 me   me 224 2007-10-29 18:44 /home/me/bin/foo<br /> -rw-r--r-- 1 me   me   0 2008-09-19 12:53 /home/me/foo.txt<br /> will execute ls each time a matching file is found. By changing the command to:<br /> <strong>find ~ -type f -name 'foo*' -exec ls -l '{}' +</strong><br /> -rwxr-xr-x 1 me   me 224 2007-10-29 18:44 /home/me/bin/foo<br />-rw-r--r-- 1 me   me   0 2008-09-19 12:53 /home/me/foo.txt<br /> we get the same results, but the system only has to execute the ls command once.<br /> xargs<br />The xargs command performs an interesting function. It accepts input from standard in-<br />put and converts it into an argument list for a specified command. With our example, we <br />would use it like this:<br /> 220<br /></p>
<hr />
<p>find – Find Files The Hard Way<br /> <strong>find ~ -type f -name 'foo*' -print | xargs ls -l<br /></strong>-rwxr-xr-x 1 me   me 224 2007-10-29 18:44 /home/me/bin/foo<br /> -rw-r--r-- 1 me   me   0 2008-09-19 12:53 /home/me/foo.txt<br /> Here we see the output of the  find command piped into  xargs which, in turn, con-<br />structs an argument list for the ls command and then executes it.<br /> <strong>Note:</strong> While the number of arguments that can be placed into a command line is <br />quite large, it’s not unlimited. It is possible to create commands that are too long for <br />the shell to accept. When a command line exceeds the maximum length supported <br />by the system, xargs executes the specified command with the maximum number <br />of  arguments  possible  and then  repeats  this  process  until  standard  input  is ex-<br />hausted. To see the maximum size of the command line, execute xargs with the <br />--show-limits option.<br /> <strong>Dealing With Funny Filenames<br /></strong>Unix-like systems allow embedded  spaces (and even  newlines!) in  filenames. <br />This causes problems for programs like xargs that construct argument lists for <br />other programs. An embedded space will be treated as a delimiter, and the result-<br />ing command will interpret each space-separated word as a separate argument. To <br />overcome this, find and xarg allow the optional use of a <em>null character</em> as ar-<br />gument separator. A null character  is defined in  ASCII  as the character repre-<br />sented by the number zero (as opposed to, for example, the space character, which <br />is defined in ASCII as the character represented by the number 32). The  find <br />command provides the action  -print0, which produces null-separated output, <br />and the xargs command has the --null option, which accepts null separated <br />input. Here’s an example:<br />find ~ -iname '*.jpg' -print0 | xargs --null ls -l<br />Using this technique, we can ensure that all files, even those containing embedded <br />spaces in their names, are handled correctly.<br /> A Return To The Playground<br />It’s time to put find to some (almost) practical use. We’ll create a playground and try <br />out some of what we have learned.<br />First, let’s create a playground with lots of subdirectories and files:<br /> 221<br /></p>
<hr />
<p>17 – Searching For Files<br /> [me@linuxbox ~]$ <strong>mkdir -p playground/dir-{001..100}<br /></strong>[me@linuxbox ~]$ <strong>touch playground/dir-{001..100}/file-{A..Z}</strong><br /> Marvel in the power of the command line! With these two lines, we created a playground <br />directory containing 100 subdirectories each containing 26 empty files. Try that with the <br />GUI!<br />The   method   we   employed   to   accomplish   this   magic   involved   a   familiar   command <br />(mkdir), an exotic shell expansion (braces) and a new command, touch. By combining <br />mkdir with the -p option (which causes mkdir to create the parent directories of the <br />specified paths) with brace expansion, we were able to create 100 subdirectories.<br />The  touch  command is usually used to set or update the access, change, and modify <br />times of files. However, if a filename argument is that of a nonexistent file, an empty file <br />is created. <br />In our playground, we created 100 instances of a file named file-A. Let’s find them:<br /> [me@linuxbox ~]$ <strong>find playground -type f -name 'file-A'</strong><br /> Note that unlike  ls,  find  does not produce results in sorted order. Its order is deter-<br />mined by the layout of the storage device. We can confirm that we actually have 100 in-<br />stances of the file this way:<br /> [me@linuxbox ~]$ <strong>find playground -type f -name 'file-A' | wc -l</strong><br /> 100<br /> Next, let’s look at finding files based on their modification times. This will be helpful <br />when creating backups or organizing files in chronological order. To do this, we will first <br />create a reference file against which we will compare modification time:<br /> [me@linuxbox ~]$ <strong>touch playground/timestamp</strong><br /> This creates an empty file named timestamp and sets its modification time to the cur-<br />rent time. We can verify this by using another handy command, stat, which is a kind of <br />souped-up version of  ls. The  stat  command reveals all that the system understands <br />about a file and its attributes:<br /> 222<br /></p>
<hr />
<p>find – Find Files The Hard Way<br /> [me@linuxbox ~]$ <strong>stat playground/timestamp<br /></strong>  File: `playground/timestamp' <br />   Size: 0          Blocks: 0       IO Block: 4096 regular empty file <br />Device: 803h/2051d Inode: 14265061 Links: 1 <br /> Access: (0644/-rw-r--r--)  Uid: ( 1001/ me)   Gid: ( 1001/ me) <br />Access: 2008-10-08 15:15:39.000000000 -0400 <br /> Modify: 2008-10-08 15:15:39.000000000 -0400 <br />Change: 2008-10-08 15:15:39.000000000 -0400<br /> If we touch the file again and then examine it with stat, we will see that the file’s <br />times have been updated.:<br /> [me@linuxbox ~]$ <strong>touch playground/timestamp<br /></strong>[me@linuxbox ~]$ <strong>stat playground/timestamp</strong><br />   File: `playground/timestamp' <br />  Size: 0          Blocks: 0       IO Block: 4096 regular empty file <br /> Device: 803h/2051d Inode: 14265061 Links: 1 <br />Access: (0644/-rw-r--r--)  Uid: ( 1001/ me)   Gid: ( 1001/ me) <br /> Access: 2008-10-08 15:23:33.000000000 -0400 <br />Modify: 2008-10-08 15:23:33.000000000 -0400 <br /> Change: 2008-10-08 15:23:33.000000000 -0400<br /> Next, let’s use find to update some of our playground files:<br /> [me@linuxbox ~]$ <strong>find playground -type f -name 'file-B' -exec touch </strong><br /> <strong>'{}' ';'</strong><br /> This updates all files in the playground named file-B. Next we’ll use find to identify <br />the updated files by comparing all the files to the reference file timestamp:<br /> [me@linuxbox ~]$ <strong>find playground -type f -newer playground/timestamp</strong><br /> The results contain all 100 instances of file-B. Since we performed a touch on all the <br />files in the playground named  file-B  after we updated  timestamp, they are now <br />“newer” than timestamp and thus can be identified with the -newer test.<br />Finally, let’s go back to the bad permissions test we performed earlier and apply it to <br />playground:<br /> 223<br /></p>
<hr />
<p>17 – Searching For Files<br /> [me@linuxbox ~]$ <strong>find playground \( -type f -not -perm 0600 \) -or \( <br />-type d -not -perm 0700 \)</strong><br /> This   command   lists   all   100   directories   and   2600   files   in  playground  (as well as <br />timestamp and playground itself, for a total of 2702) because none of them meets <br />our definition of “good permissions.” With our knowledge of operators and actions, we <br />can add actions to this command to apply new permissions to the files and directories in <br />our playground:<br /> [me@linuxbox ~]$ <strong>find playground \( -type f -not -perm 0600 -exec <br />chmod 0600 '{}' ';' \) -or \( -type d -not -perm 0700 -exec chmod </strong><br /> <strong>0700 '{}' ';' \)</strong><br /> On a day-to-day basis, we might find it easier to issue two commands, one for the direc-<br />tories and one for the files, rather than this one large compound command, but it’s nice to <br />know that we can do it this way. The important point here is to understand how the opera-<br />tors and actions can be used together to perform useful tasks.<br /> Options<br />Finally, we have the options. The options are used to control the scope of a find search. <br />They may be included with other tests and actions when constructing find expressions. <br />Here is a list of the most commonly used ones:<br /> <em>Table 17-7: find Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> -depth<br /> Direct find to process a directory’s files before the <br />directory itself. This option is automatically applied when <br />the -delete action is specified.<br /> -maxdepth <em>levels</em><br /> Set the maximum number of levels that find will <br />descend into a directory tree when performing tests and <br />actions.<br /> -mindepth <em>levels</em><br /> Set the minimum number of levels that find will <br />descend into a directory tree before applying tests and <br />actions.<br /> -mount<br /> Direct find not to traverse directories that are mounted <br />on other file systems.<br /> 224<br /></p>
<hr />
<p>find – Find Files The Hard Way<br /> -noleaf<br /> Direct find not to optimize its search based on the <br />assumption that it is searching a Unix-like file system. <br />This is needed when scanning DOS/Windows file <br />systems and CD-ROMs.<br /> <strong>Summing Up<br /></strong>It's easy to see that locate is as simple as find is complicated. They both have their <br />uses. Take the time to explore the many features of find. It can, with regular use, im-<br />prove your understanding of Linux files system operations.<br /> <strong>Further Reading</strong><br /> ●<br /> The locate, updatedb, find, and xargs programs are all part the GNU <br />Project’s <em>findutils</em> package. The GNU Project provides a website with extensive <br />on-line documentation, which is quite good and should be read if you are using <br />these programs in high security environments:<br /><a href="http://www.gnu.org/software/findutils/">http://www.gnu.org/software/findutils/</a><br /> 225<br /></p>
<hr />
<p>18 – Archiving And Backup<br /> <em><strong>18 – Archiving And Backup</strong></em><br /> One of the primary tasks of a computer system’s administrator is keeping the system’s <br />data secure. One way this is done is by performing timely backups of the system’s files. <br />Even if you’re not a system administrator, it is often useful to make copies of things and <br />to move large collections of files from place to place and from device to device.<br />In this chapter, we will look at several common programs that are used to manage collec-<br />tions of files. There are the file compression programs:<br /> ●<br /> gzip – Compress or expand files<br /> ●<br /> bzip2 – A block sorting file compressor<br /> The archiving programs:<br /> ●<br /> tar – Tape archiving utility<br /> ●<br /> zip – Package and compress files<br /> And the file synchronization program:<br /> ●<br /> rsync – Remote file and directory synchronization<br /> <strong>Compressing Files<br /></strong>Throughout the history of computing, there has been a struggle to get the most data into <br />the smallest available space, whether that space be memory, storage devices, or network <br />bandwidth. Many of the data services that we take for granted today, such as portable mu-<br />sic players, high definition television, or broadband Internet, owe their existence to effec-<br />tive <em>data compression</em> techniques.<br />Data compression is the process of removing  <em>redundancy</em>  from data. Let’s consider an <br />imaginary example. Say we had an entirely black picture file with the dimensions of 100 <br />pixels by 100 pixels. In terms of data storage (assuming 24 bits, or 3 bytes per pixel), the <br />image will occupy 30,000 bytes of storage:<br />100 * 100 * 3 = 30,000<br />An image that is all one color contains entirely redundant data. If we were clever, we <br />could encode the data in such a way that we simply describe the fact that we have a block <br /> 226<br /></p>
<hr />
<p>Compressing Files<br /> of 10,000 black pixels. So, instead of storing a block of data containing 30,000 zeros <br />(black is usually represented in image files as zero), we could compress the data into the <br />number   10,000,   followed   by   a   zero   to   represent   our   data.   Such   a   data   compression <br />scheme is called  <em>run-length encoding</em>  and is one of the most rudimentary compression <br />techniques. Today’s techniques are much more advanced and complex but the basic goal <br />remains the same—<br />   ge<br />   t rid of redundant data.<br /> <em>Compression algorithms</em> (the mathematical techniques used to carry out the compression) <br />fall into two general categories, <em>lossless</em> and <em>lossy</em>. Lossless compression preserves all the <br />data contained in the original. This means that when a file is restored from a compressed <br />version, the restored file is exactly the same as the original, uncompressed version. Lossy <br />compression, on the other hand, removes data as the compression is performed, to allow <br />more compression to be applied. When a lossy file is restored, it does not match the origi-<br />nal version; rather, it is a close approximation. Examples of lossy compression are JPEG <br />(for images) and MP3 (for music). In our discussion, we will look exclusively at lossless <br />compression, since most data on computers cannot tolerate any data loss. <br /> gzip<br />The gzip program is used to compress one or more files. When executed, it replaces the <br />original file with a compressed version of the original. The corresponding gunzip pro-<br />gram is used to restore compressed files to their original, uncompressed form. Here is an <br />example:<br /> [me@linuxbox ~]$ <strong>ls -l /etc &gt; foo.txt<br /></strong>[me@linuxbox ~]$ <strong>ls -l foo.*</strong><br /> -rw-r--r-- 1 me    me    15738 2008-10-14 07:15 foo.txt<br />[me@linuxbox ~]$ <strong>gzip foo.txt</strong><br /> [me@linuxbox ~]$ <strong>ls -l foo.*<br /></strong>-rw-r--r-- 1 me    me    3230 2008-10-14 07:15 foo.txt.gz<br /> [me@linuxbox ~]$ <strong>gunzip foo.txt<br /></strong>[me@linuxbox ~]$ <strong>ls -l foo.*</strong><br /> -rw-r--r-- 1 me    me    15738 2008-10-14 07:15 foo.txt<br /> In this example, we create a text file named foo.txt from a directory listing. Next, we <br />run gzip, which replaces the original file with a compressed version named foo.tx-<br />t.gz. In the directory listing of foo.*, we see that the original file has been replaced <br />with the compressed version, and that the compressed version is about one-fifth the size <br />of the original. We can also see that the compressed file has the same permissions and <br />timestamp as the original.<br />Next, we run the gunzip program to uncompress the file. Afterward, we can see that the <br />compressed version of the file has been replaced with the original, again with the permis-<br /> 227<br /></p>
<hr />
<p>18 – Archiving And Backup<br /> sions and timestamp preserved.<br /> gzip has many options. Here are a few:<br /> <em>Table 18-1: gzip Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> -c<br /> Write output to standard output and keep original files. May also be <br />specified with --stdout and --to-stdout.<br /> -d<br /> Decompress. This causes gzip to act like gunzip. May also be <br />specified with --decompress or --uncompress.<br /> -f<br /> Force compression even if a compressed version of the original file <br />already exists. May also be specified with --force.<br /> -h<br /> Display usage information. May also be specified with --help.<br /> -l<br /> List compression statistics for each file compressed. May also be <br />specified with --list.<br /> -r<br /> If one or more arguments on the command line are directories, <br />recursively compress files contained within them. May also be <br />specified with --recursive.<br /> -t<br /> Test the integrity of a compressed file. May also be specified with <br />--test.<br /> -v<br /> Display verbose messages while compressing. May also be specified <br />with --verbose.<br /> -<em>number</em><br /> Set amount of compression. <em>number</em> is an integer in the range of 1 <br />(fastest, least compression) to 9 (slowest, most compression). The <br />values 1 and 9 may also be expressed as --fast and --best, <br />respectively. The default value is 6.<br /> Going back to our earlier example:<br /> [me@linuxbox ~]$ <strong>gzip foo.txt<br /></strong>[me@linuxbox ~]$ <strong>gzip -tv foo.txt.gz</strong><br /> foo.txt.gz:<br />  OK<br /> [me@linuxbox ~]$ <strong>gzip -d foo.txt.gz</strong><br /> Here, we replaced the file foo.txt with a compressed version named foo.txt.gz. <br />Next, we tested the integrity of the compressed version, using the -t and -v options. Fi-<br /> 228<br /></p>
<hr />
<p>Compressing Files<br /> nally, we decompressed the file back to its original form.<br /> gzip can also be used in interesting ways via standard input and output:<br /> [me@linuxbox ~]$ <strong>ls -l /etc | gzip &gt; foo.txt.gz</strong><br /> This command creates a compressed version of a directory listing.<br />The gunzip program, which uncompresses gzip files, assumes that filenames end in the <br />extension .gz, so it’s not necessary to specify it, as long as the specified name is not in <br />conflict with an existing uncompressed file:<br /> [me@linuxbox ~]$ <strong>gunzip foo.txt</strong><br /> If our goal were only to view the contents of a compressed text file, we could do this:<br /> [me@linuxbox ~]$ <strong>gunzip -c foo.txt | less</strong><br /> Alternately, there is a program supplied with  gzip, called  zcat, that is equivalent to <br />gunzip with the -c option. It can be used like the cat command on gzip compressed <br />files:<br /> [me@linuxbox ~]$ <strong>zcat foo.txt.gz | less</strong><br /> <strong>Tip:</strong> There is a zless program, too. It performs the same function as the pipeline <br />above.<br /> bzip2<br />The bzip2 program, by Julian Seward, is similar to gzip, but uses a different compres-<br />sion algorithm that achieves higher levels of compression at the cost of compression <br />speed. In most regards, it works in the same fashion as  gzip. A file compressed with <br />bzip2 is denoted with the extension .bz2:<br /> 229<br /></p>
<hr />
<p>18 – Archiving And Backup<br /> [me@linuxbox ~]$ <strong>ls -l /etc &gt; foo.txt<br /></strong>[me@linuxbox ~]$ <strong>ls -l foo.txt</strong><br /> -rw-r--r-- 1 me    me    15738 2008-10-17 13:51 foo.txt <br />[me@linuxbox ~]$ <strong>bzip2 foo.txt</strong><br /> [me@linuxbox ~]$ <strong>ls -l foo.txt.bz2<br /></strong>-rw-r--r-- 1 me    me     2792 2008-10-17 13:51 foo.txt.bz2<br /> [me@linuxbox ~]$ <strong>bunzip2 foo.txt.bz2</strong><br /> As we can see, bzip2 can be used the same way as gzip. All the options (except for <br />-r) that we discussed for gzip are also supported in  bzip2. Note, however, that the <br />compression   level   option   (-<em>number</em>) has a somewhat  different  meaning to  bzip2. <br />bzip2 comes with bunzip2 and bzcat for decompressing files.<br /> bzip2 also comes with the bzip2recover program, which will try to recover dam-<br />aged .bz2 files.<br /> <strong>Don’t Be Compressive Compulsive<br /></strong>I occasionally see people attempting to compress a file, that has already been <br />compressed with an effective compression algorithm, by doing something like <br />this:<br />$ <strong>gzip picture.jpg</strong> <br />Don’t do it. You’re probably just wasting time and space! If you apply compres-<br />sion to a file that is already compressed, you will actually end up a larger file. <br />This is because all compression techniques involve some overhead that is added <br />to the file to describe the compression. If you try to compress a file that already <br />contains no redundant information, the compression will not result in any savings <br />to offset the additional overhead.<br /> <strong>Archiving Files<br /></strong>A common file-management task often used in conjunction with compression is <em>archiv-<br />ing</em>. Archiving is the process of gathering up many files and bundling them together into a <br />single large file. Archiving is often done as a part of system backups. It is also used when <br />old data is moved from a system to some type of long-term storage. <br /> tar<br />In the Unix-like world of software, the tar program is the classic tool for archiving files. <br />Its name, short for <em>tape archive</em>, reveals its roots as a tool for making backup tapes. While <br />it is still used for that traditional task, it is equally adept on other storage devices as well. <br /> 230<br /></p>
<hr />
<p>Archiving Files<br /> We often see filenames that end with the extension  .tar  or  .tgz, which indicate a <br />“plain” tar archive and a gzipped archive, respectively. A tar archive can consist of a <br />group of separate files, one or more directory hierarchies, or a mixture of both. The com-<br />mand syntax works like this:<br />tar <em>mode</em>[<em>options</em>] <em>pathname</em>...<br />where <em>mode</em> is one of the following operating modes (only a partial list is shown here; see <br />the tar man page for a complete list):<br /> <em>Table 18-2: tar Modes</em><br /> <strong>Mode</strong><br /> <strong>Description</strong><br /> c<br /> Create an archive from a list of files and/or directories.<br /> x<br /> Extract an archive.<br /> r<br /> Append specified pathnames to the end of an archive.<br /> t<br /> List the contents of an archive.<br /> tar uses a slightly odd way of expressing options, so we’ll need some examples to show <br />how it works. First, let’s re-create our playground from the previous chapter:<br /> [me@linuxbox ~]$ <strong>mkdir -p playground/dir-{001..100}<br /></strong>[me@linuxbox ~]$ <strong>touch playground/dir-{001..100}/file-{A..Z}</strong><br /> Next, let’s create a tar archive of the entire playground:<br /> [me@linuxbox ~]$ <strong>tar cf playground.tar playground</strong><br /> This command creates a tar archive named playground.tar that contains the entire <br />playground directory hierarchy. We can see that the mode and the f option, which is used <br />to specify the name of the tar archive, may be joined together, and do not require a lead-<br />ing dash. Note, however, that the mode must always be specified first, before any other <br />option.<br />To list the contents of the archive, we can do this:<br /> [me@linuxbox ~]$ <strong>tar tf playground.tar</strong><br /> 231<br /></p>
<hr />
<p>18 – Archiving And Backup<br /> For a more detailed listing, we can add the v (verbose) option:<br /> [me@linuxbox ~]$ <strong>tar tvf playground.tar</strong><br /> Now, let’s extract the playground in a new location. We will do this by creating a new di-<br />rectory named foo, changing the directory and extracting the tar archive:<br /> [me@linuxbox ~]$ <strong>mkdir foo</strong><br /> [me@linuxbox ~]$ <strong>cd foo<br /></strong>[me@linuxbox foo]$ <strong>tar xf ../playground.tar</strong><br /> [me@linuxbox foo]$ <strong>ls<br /></strong>playground<br /> If we examine the contents of ~/foo/playground, we see that the archive was suc-<br />cessfully  installed, creating  a precise  reproduction  of the original  files. There  is one <br />caveat, however: Unless you are operating as the superuser, files and directories extracted <br />from archives take on the ownership of the user performing the restoration, rather than <br />the original owner.<br />Another interesting behavior of tar is the way it handles pathnames in archives. The de-<br />fault for pathnames is relative, rather than absolute. tar does this by simply removing <br />any leading slash from the pathname when creating the archive. To demonstrate, we will <br />re-create our archive, this time specifying an absolute pathname:<br /> [me@linuxbox foo]$ <strong>cd<br /></strong>[me@linuxbox ~]$ <strong>tar cf playground2.tar ~/playground</strong><br /> Remember,  ~/playground  will   expand   into  /home/me/playground  when   we <br />press the enter key, so we will get an absolute pathname for our demonstration. Next, we <br />will extract the archive as before and watch what happens:<br /> [me@linuxbox ~]$ <strong>cd foo<br /></strong>[me@linuxbox foo]$ <strong>tar xf ../playground2.tar</strong><br /> [me@linuxbox foo]$ <strong>ls<br /></strong>home   playground<br /> [me@linuxbox foo]$ <strong>ls home<br /></strong>me<br /> [me@linuxbox foo]$ <strong>ls home/me<br /></strong>playground<br /> 232<br /></p>
<hr />
<p>Archiving Files<br /> Here we can see that when we extracted our second archive, it re-created the directory <br />home/me/playground relative to our current working directory, ~/foo, not relative <br />to the root directory, as would have been the case with an absolute pathname. This may <br />seem like an odd way for it to work, but it’s actually more useful this way, as it allows us <br />to extract archives to any location rather than being forced to extract them to their origi-<br />nal locations. Repeating the exercise with the inclusion of the verbose option (v) will <br />give a clearer picture of what’s going on.<br />Let’s consider a hypothetical, yet practical, example of tar in action. Imagine we want <br />to copy the home directory and its contents from one system to another and we have a <br />large USB hard drive that we can use for the transfer. On our modern Linux system, the <br />drive is “automagically” mounted in the /media directory. Let’s also imagine that the <br />disk has a volume name of BigDisk when we attach it. To make the tar archive, we can <br />do the following:<br /> [me@linuxbox ~]$ <strong>sudo tar cf /media/BigDisk/home.tar /home</strong><br /> After the tar file is written, we unmount the drive and attach it to the second computer. <br />Again, it is mounted at /media/BigDisk. To extract the archive, we do this:<br /> [me@linuxbox2 ~]$ <strong>cd /</strong><br /> [me@linuxbox2 /]$ <strong>sudo tar xf /media/BigDisk/home.tar</strong><br /> What’s important to see here is that we must first change directory to /, so that the ex-<br />traction is relative to the root directory, since all pathnames within the archive are rela-<br />tive.<br />When extracting an archive, it’s possible to limit what is extracted from the archive. For <br />example, if we wanted to extract a single file from an archive, it could be done like this: <br /> <strong>tar xf <em>archive.tar</em></strong><strong> <em>pathname</em></strong><br /> By adding the trailing <em>pathname</em> to the command, tar will only restore the specified file. <br />Multiple pathnames may be specified. Note that the pathname must be the full, exact rela-<br />tive pathname as stored in the archive. When specifying pathnames, wildcards are not <br />normally supported; however, the GNU version of tar (which is the version most often <br />found in Linux distributions) supports them with the --wildcards option. Here is an <br />example using our previous playground.tar file:<br /> 233<br /></p>
<hr />
<p>18 – Archiving And Backup<br /> [me@linuxbox ~]$ <strong>cd foo<br /></strong>[me@linuxbox foo]$ <strong>tar xf ../playground2.tar --wildcards 'home/me/pla</strong><br /> <strong>yground/dir-*/file-A'</strong><br /> This command will extract only files matching the specified pathname including the <br />wildcard dir-*.<br /> tar is often used in conjunction with find to produce archives. In this example, we will <br />use find to produce a set of files to include in an archive:<br /> [me@linuxbox ~]$ <strong>find playground -name 'file-A' -exec tar rf </strong><br /> <strong>playground.tar '{}' '+'</strong><br /> Here we use find to match all the files in playground named file-A and then, us-<br />ing the -exec action, we invoke tar in the append mode (r) to add the matching files <br />to the archive playground.tar.<br />Using tar with find is a good way of creating <em>incremental backups</em> of a directory tree <br />or an entire system. By using find to match files newer than a timestamp file, we could <br />create an archive that only contains files newer than the last archive, assuming that the <br />timestamp file is updated right after each archive is created.<br /> tar can also make use of both standard input and output. Here is a comprehensive exam-<br />ple:<br /> [me@linuxbox foo]$ <strong>cd</strong><br /> [me@linuxbox ~]$ <strong>find playground -name 'file-A' | tar cf - --files-<br />from=- | gzip &gt; playground.tgz</strong><br /> In this example, we used the find program to produce a list of matching files and piped <br />them into tar. If the filename “-” is specified, it is taken to mean standard input or out-<br />put, as needed (By the way, this convention of using “-” to represent standard input/out-<br />put is used by a number of other programs, too.) The  --files-from  option (which <br />may also be specified as -T) causes tar to read its list of pathnames from a file rather <br />than the command line. Lastly, the archive produced by tar is piped into gzip to create <br />the compressed archive  playground.tgz. The  .tgz  extension is the conventional <br />extension given to gzip-compressed tar files. The extension .tar.gz is also used some-<br />times.<br />While we used the gzip program externally to produced our compressed archive, mod-<br /> 234<br /></p>
<hr />
<p>Archiving Files<br /> ern versions of GNU tar support both gzip and bzip2 compression directly, with the use <br />of the z and j options, respectively. Using our previous example as a base, we can sim-<br />plify it this way:<br /> [me@linuxbox ~]$ <strong>find playground -name 'file-A' | tar czf</strong> <br /><strong>playground.tgz -T -</strong><br /> If we had wanted to create a bzip2 compressed archive instead, we could have done this:<br /> [me@linuxbox ~]$ <strong>find playground -name 'file-A' | tar cjf <br />playground.tbz -T -</strong><br /> By simply changing the compression option from z to j (and changing the output file’s <br />extension to .tbz to indicate a bzip2 compressed file) we enabled bzip2 compression.<br />Another interesting use of standard input and output with the  tar  command involves <br />transferring files between systems over a network. Imagine that we had two machines <br />running a Unix-like system equipped with tar and ssh. In such a scenario, we could <br />transfer a directory from a remote system (named remote-sys for this example) to our <br />local system:<br /> [me@linuxbox ~]$ <strong>mkdir remote-stuff<br /></strong>[me@linuxbox ~]$ <strong>cd remote-stuff</strong><br /> [me@linuxbox remote-stuff]$ <strong>ssh remote-sys 'tar cf - Documents' | tar <br />xf -</strong><br /> me@remote-sys’s password:<br />[me@linuxbox remote-stuff]$ <strong>ls</strong><br /> Documents<br /> Here we were able to copy a directory named Documents from the remote system re-<br />mote-sys to a directory within the directory named remote-stuff on the local sys-<br />tem. How did we do this? First, we launched the tar program on the remote system us-<br />ing  ssh. You will recall that  ssh  allows us to execute a program remotely on a net-<br />worked computer and “see” the results on the local system—<br />   t he standard output pro-<br /> duced on the remote system is sent to the local system for viewing. We can take advan-<br />tage of this by having tar create an archive (the c mode) and send it to standard output, <br />rather than a file (the f option with the dash argument), thereby transporting the archive <br />over the encrypted tunnel provided by ssh to the local system. On the local system, we <br />execute tar and have it expand an archive (the x mode) supplied from standard input <br /> 235<br /></p>
<hr />
<p>18 – Archiving And Backup<br /> (again, the f option with the dash argument).<br /> zip<br />The zip program is both a compression tool and an archiver. The file format used by the <br />program is familiar to Windows users, as it reads and writes .zip files. In Linux, how-<br />ever, gzip is the predominant compression program with bzip2 being a close second.<br />In its most basic usage, zip is invoked like this:<br />zip <em>options</em> <em>zipfile</em> <em>file...<br /></em>For example, to make a zip archive of our playground, we would do this:<br /> [me@linuxbox ~]$ <strong>zip -r playground.zip playground</strong><br /> Unless we include the  -r  option for recursion, only the  playground  directory (but <br />none of its contents) is stored. Although the addition of the extension .zip is automatic, <br />we will include the file extension for clarity.<br />During the creation of the zip archive,  zip will normally display a series of messages <br />like this:<br />  adding: playground/dir-020/file-Z (stored 0%) <br />  adding: playground/dir-020/file-Y (stored 0%) <br /> adding: playground/dir-020/file-X (stored 0%) <br />  adding: playground/dir-087/ (stored 0%) <br /> adding: playground/dir-087/file-S (stored 0%) <br /> These messages show the status of each file added to the archive. zip will add files to <br />the archive using one of two storage methods: Either it will “store” a file without com-<br />pression, as shown here, or it will “deflate” the file which performs compression. The nu-<br />meric value displayed after the storage method indicates the amount of compression <br />achieved. Since our playground only contains empty files, no compression is performed <br />on its contents.<br />Extracting the contents of a zip file is straightforward when using the unzip program:<br /> [me@linuxbox ~]$ <strong>cd foo<br /></strong>[me@linuxbox foo]$ <strong>unzip ../playground.zip</strong><br /> 236<br /></p>
<hr />
<p>Archiving Files<br /> One thing to note about zip (as opposed to tar) is that if an existing archive is speci-<br />fied, it is updated rather than replaced. This means that the existing archive is preserved, <br />but new files are added and matching files are replaced.<br />Files may be listed and extracted selectively from a zip archive by specifying them to <br />unzip:<br /> [me@linuxbox ~]$ <strong>unzip -l playground.zip playground/dir-087/file-Z<br /></strong>Archive:  ../playground.zip <br />   Length     Date   Time    Name <br /> --------    ----   ----    ---- <br />         0  10-05-08 09:25   playground/dir-087/file-Z <br /> --------                   ------- <br />         0                   1 file<br />[me@linuxbox ~]$ <strong>cd foo</strong><br /> [me@linuxbox foo]$ <strong>unzip ../playground.zip playground/dir-087/file-Z<br /></strong>Archive:  ../playground.zip <br /> replace playground/dir-087/file-Z? [y]es, [n]o, [A]ll, [N]one, <br />[r]ename: <strong>y</strong> <br />  extracting: playground/dir-087/file-Z <br /> Using the -l option causes unzip to merely list the contents of the archive without ex-<br />tracting the file. If no file(s) are specified, unzip will list all files in the archive. The -v <br />option can be added to increase the verbosity of the listing. Note that when the archive <br />extraction conflicts with an existing file, the user is prompted before the file is replaced. <br />Like tar, zip can make use of standard input and output, though its implementation is <br />somewhat less useful. It is possible to pipe a list of filenames to zip via the -@ option:<br /> [me@linuxbox foo]$ <strong>cd</strong><br /> [me@linuxbox ~]$ <strong>find playground -name &quot;file-A&quot; | zip -@ file-A.zip</strong><br /> Here we use find to generate a list of files matching the test -name &quot;file-A&quot;, and <br />then pipe the list into zip, which creates the archive file-A.zip containing the se-<br />lected files.<br /> zip also supports writing its output to standard output, but its use is limited because very <br />few programs can make use of the output. Unfortunately, the unzip program does not <br />accept standard input. This prevents zip and unzip from being used together to per-<br />form network file copying like tar.<br /> zip  can, however, accept standard input, so it can be used to compress the output of <br />other programs:<br /> 237<br /></p>
<hr />
<p>18 – Archiving And Backup<br /> [me@linuxbox ~]$ <strong>ls -l /etc/ | zip ls-etc.zip -<br /></strong> adding: - (deflated 80%)<br /> In this example we pipe the output of ls into zip. Like tar, zip interprets the trailing <br />dash as “use standard input for the input file.”<br />The  unzip  program allows its output to be sent to standard output when the  -p  (for <br />pipe) option is specified:<br /> [me@linuxbox ~]$ <strong>unzip -p ls-etc.zip | less</strong><br /> We touched on some of the basic things that zip/unzip can do. They both have a lot of <br />options that add to their flexibility, though some are platform specific to other systems. <br />The man pages for both zip and unzip are pretty good and contain useful examples. <br />However, the main use of these programs is for exchanging files with Windows systems, <br />rather than performing compression and archiving on Linux, where tar and gzip are <br />greatly preferred.<br /> <strong>Synchronizing Files And Directories<br /></strong>A common strategy for maintaining a backup copy of a system involves keeping one or <br />more directories synchronized with another directory (or directories) located on either the <br />local system (usually a removable storage device of some kind) or a remote system. We <br />might, for example, have a local copy of a website under development and synchronize it <br />from time to time with the “live” copy on a remote web server.<br />In the Unix-like world, the preferred tool for this task is rsync. This program can syn-<br />chronize both local and remote directories by using the  <em>rsync remote-update protocol</em>, <br />which allows rsync to quickly detect the differences between two directories and per-<br />form the minimum amount of copying required to bring them into sync. This makes <br />rsync very fast and economical to use, compared to other kinds of copy programs.<br /> rsync is invoked like this:<br />rsync <em>options</em> <em>source</em> <em>destination<br /></em>where <em>source</em> and <em>destination</em> are one of the following:<br /> ●<br /> A local file or directory<br /> ●<br /> A remote file or directory in the form of <em>[user@]host:path</em><br /> ●<br /> A remote rsync server specified with a URI of <em>rsync://[user@]host[:port]/path</em><br /> Note that either the source or the destination must be a local file. Remote-to-remote copy-<br /> 238<br /></p>
<hr />
<p>Synchronizing Files And Directories<br /> ing is not supported.<br />Let’s try rsync out on some local files. First, let’s clean out our foo directory:<br /> [me@linuxbox ~]$ <strong>rm -rf foo/*</strong><br /> Next, we’ll synchronize the playground directory with a corresponding copy in foo:<br /> [me@linuxbox ~]$ <strong>rsync -av playground foo</strong><br /> We’ve included both the -a option (for archiving—<br />   c auses recursion and preservation of <br /> file attributes) and the -v option (verbose output) to make a <em>mirror</em> of the playground <br />directory within foo. While the command runs, we will see a list of the files and directo-<br />ries being copied. At the end, we will see a summary message like this:<br /> sent 135759 bytes  received 57870 bytes  387258.00 bytes/sec <br />total size is 3230  speedup is 0.02<br /> indicating the amount of copying performed. If we run the command again, we will see a <br />different result:<br /> [me@linuxbox ~]$ <strong>rsync -av playgound foo<br /></strong>building file list ... done <br />  sent 22635 bytes  received 20 bytes  45310.00 bytes/sec <br /> total size is 3230  speedup is 0.14<br /> Notice that there was no listing of files. This is because rsync detected that there were <br />no differences between  ~/playground  and  ~/foo/playground, and therefore it <br />didn’t need to copy anything. If we modify a file in playground and run rsync again:<br /> [me@linuxbox ~]$ <strong>touch playground/dir-099/file-Z</strong><br /> [me@linuxbox ~]$ <strong>rsync -av playground foo<br /></strong>building file list ... done <br /> playground/dir-099/file-Z <br />sent 22685 bytes  received 42 bytes  45454.00 bytes/sec <br /> total size is 3230  speedup is 0.14<br /> 239<br /></p>
<hr />
<p>18 – Archiving And Backup<br /> we see that rsync detected the change and copied only the updated file.<br />As a practical example, let’s consider the imaginary external hard drive that we used ear-<br />lier with tar. If we attach the drive to our system and, once again, it is mounted at /me-<br />dia/BigDisk, we can perform a useful system backup by first creating a directory <br />named /backup on the external drive, and then using rsync to copy the most impor-<br />tant stuff from our system to the external drive:<br /> [me@linuxbox ~]$ <strong>mkdir /media/BigDisk/backup<br /></strong>[me@linuxbox ~]$ <strong>sudo rsync -av --delete /etc /home /usr/local </strong><br /> <strong>/media/BigDisk/backup</strong><br /> In this example, we copied the /etc, /home, and /usr/local directories from our <br />system to our imaginary storage device. We included the --delete option to remove <br />files that may have existed on the backup device that no longer existed on the source de-<br />vice (this is irrelevant the first time we make a backup, but will be useful on subsequent <br />copies). Repeating the procedure of attaching the external drive and running this rsync <br />command would be a useful (though not ideal) way of keeping a small system backed up. <br />Of course, an alias would be helpful here, too. We could create an alias and add it to our <br />.bashrc file to provide this feature:<br /> alias backup='sudo rsync -av --delete /etc /home /usr/local <br /> /media/BigDisk/backup'<br /> Now all we have to do is attach our external drive and run the backup command to do <br />the job.<br /> Using rsync Over A Network<br />One of the real beauties of rsync is that it can be used to copy files over a network. Af-<br />ter all, the “r” in rsync stands for “remote.” Remote copying can be done in one of two <br />ways. The first way is with another system that has rsync installed, along with a remote <br />shell program such as ssh. Let’s say we had another system on our local network with a <br />lot of available hard drive space and we wanted to perform our backup operation using <br />the remote system instead of an external drive. Assuming that it already had a directory <br />named /backup where we could deliver our files, we could do this:<br /> [me@linuxbox ~]$ <strong>sudo rsync -av --delete --rsh=ssh /etc /home </strong><br /> 240<br /></p>
<hr />
<p>Synchronizing Files And Directories<br /> <strong>/usr/local remote-sys:/backup</strong><br /> We made two changes to our command to facilitate the network copy. First, we added the <br />--rsh=ssh option, which instructs rsync to use the ssh program as its remote shell. <br />In this way, we were able to use an ssh encrypted tunnel to securely transfer the data from <br />the local system to the remote host. Second, we specified the remote host by prefixing its <br />name (in this case the remote host is named remote-sys) to the destination pathname.<br />The second way that rsync can be used to synchronize files over a network is by using <br />an <em>rysnc server</em>. rsync can be configured to run as a daemon and listen to incoming re-<br />quests for synchronization. This is often done to allow mirroring of a remote system. For <br />example, Red Hat Software maintains a large repository of software packages under de-<br />velopment for its Fedora distribution. It is useful for software testers to mirror this collec-<br />tion during the testing phase of the distribution release cycle. Since files in the repository <br />change frequently (often more than once a day), it is desirable to maintain a local mirror <br />by periodic synchronization, rather than by bulk copying of the repository. One of these <br />repositories is kept at Georgia Tech; we could mirror it using our local copy of rsync <br />and their rsync server like this:<br /> [me@linuxbox ~]$ <strong>mkdir fedora-devel</strong><br /> [me@linuxbox ~]$ <strong>rsync -av -delete rsync://rsync.gtlib.gatech.edu/fed<br />ora-linux-core/development/i386/os fedora-devel</strong> <br /> In this example, we use the URI of the remote rsync server, which consists of a protocol <br />(rsync://), followed by the remote host-name (rsync.gtlib.gatech.edu), fol-<br />lowed by the pathname of the repository.<br /> <strong>Summing Up<br /></strong>We've looked at the common compression and archiving programs used on Linux and <br />other Unix-like operating systems. For archiving files, the tar/gzip combination is the <br />preferred method on Unix-like systems while  zip/unzip  is used for interoperability <br />with Windows systems. Finally, we looked at the rsync program (a personal favorite) <br />which is very handy for efficient synchronization of files and directories across systems.<br /> <strong>Further Reading</strong><br /> ●<br /> The man pages for all of the commands discussed here are pretty clear and con-<br />tain useful examples. In addition, the GNU Project has a good online manual for <br />its version of tar. It can be found here:<br /> 241<br /></p>
<hr />
<p>18 – Archiving And Backup<br /> <a href="http://www.gnu.org/software/tar/manual/index.html">http://www.gnu.org/software/tar/manual/index.html</a><br /> 242<br /></p>
<hr />
<p>19 – Regular Expressions<br /> <em><strong>19 – Regular Expressions</strong></em><br /> In the next few chapters, we are going to look at tools used to manipulate text. As we <br />have seen, text data plays an important role on all Unix-like systems, such as Linux. But <br />before we can fully appreciate all of the features offered by these tools, we have to first <br />examine a technology that is frequently associated with the most sophisticated uses of <br />these tools—<br />    <em>regular expressions</em>.<br /> As we have navigated the many features and facilities offered by the command line, we <br />have encountered some truly arcane shell features and commands, such as shell expan-<br />sion and quoting, keyboard shortcuts, and command history, not to mention the vi editor. <br />Regular expressions continue this “tradition” and may be (arguably) the most arcane fea-<br />ture of them all. This is not to suggest that the time it takes to learn about them is not <br />worth the effort. Quite the contrary. A good understanding will enable us to perform <br />amazing feats, though their full value may not be immediately apparent.<br /> What Are Regular Expressions?<br />Simply put, regular expressions are symbolic notations used to identify patterns in text. In <br />some ways, they resemble the shell’s wildcard method of matching file and pathnames, <br />but on a much grander scale. Regular expressions are supported by many command line <br />tools and by most programming languages to facilitate the solution of text manipulation <br />problems. However, to further confuse things, not all regular expressions are the same; <br />they vary slightly from tool to tool and from programming language to language. For our <br />discussion, we will limit ourselves to regular expressions as described in the POSIX stan-<br />dard (which will cover most of the command line tools), as opposed to many program-<br />ming languages (most notably <em>Perl</em>), which use slightly larger and richer sets of notations.<br /> <strong>grep<br /></strong>The main program we will use to work with regular expressions is our old pal,  grep. <br />The name “grep” is actually derived from the phrase “global regular expression print,” so <br />we can see that grep has something to do with regular expressions. In essence, grep <br />searches text files for the occurrence of a specified regular expression and outputs any <br />line containing a match to standard output. <br /> 243<br /></p>
<hr />
<p>19 – Regular Expressions<br /> So far, we have used grep with fixed strings, like so:<br /> [me@linuxbox ~]$ <strong>ls /usr/bin | grep zip</strong><br /> This will list all the files in the /usr/bin directory whose names contain the substring <br />“zip”.<br />The grep program accepts options and arguments this way:<br />grep [<em>options</em>] <em>regex</em> [<em>file...</em>]<br />where <em>regex</em> is a regular expression.<br />Here is a list of the commonly used grep options:<br /> <em>Table20-1: grep Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> -i<br /> Ignore case. Do not distinguish between upper and lower case <br />characters. May also be specified --ignore-case.<br /> -v<br /> Invert match. Normally, grep prints lines that contain a match. <br />This option causes grep to print every line that does not contain a <br />match. May also be specified --invert-match.<br /> -c<br /> Print the number of matches (or non-matches if the -v option is <br />also specified) instead of the lines themselves. May also be <br />specified --count.<br /> -l<br /> Print the name of each file that contains a match instead of the lines <br />themselves. May also be specified --files-with-matches.<br /> -L<br /> Like the -l option, but print only the names of files that do not <br />contain matches. May also be specified --files-without-<br />match.<br /> -n<br /> Prefix each matching line with the number of the line within the <br />file. May also be specified --line-number.<br /> -h<br /> For multi-file searches, suppress the output of filenames. May also <br />be specified --no-filename.<br /> In order to more fully explore grep, let’s create some text files to search:<br /> 244<br /></p>
<hr />
<p>grep<br /> [me@linuxbox ~]$ <strong>ls /bin &gt; dirlist-bin.txt<br /></strong>[me@linuxbox ~]$ <strong>ls /usr/bin &gt; dirlist-usr-bin.txt</strong><br /> [me@linuxbox ~]$ <strong>ls /sbin &gt; dirlist-sbin.txt<br /></strong>[me@linuxbox ~]$ <strong>ls /usr/sbin &gt; dirlist-usr-sbin.txt</strong><br /> [me@linuxbox ~]$ <strong>ls dirlist*.txt<br /></strong>dirlist-bin.txt   dirlist-sbin.txt     dirlist-usr-sbin.txt <br /> dirlist-usr-bin.txt<br /> We can perform a simple search of our list of files like this:<br /> [me@linuxbox ~]$ <strong>grep bzip dirlist*.txt</strong><br /> dirlist-bin.txt:bzip2 <br />dirlist-bin.txt:bzip2recover<br /> In this example, grep searches all of the listed files for the string bzip and finds two <br />matches, both in the file dirlist-bin.txt. If we were only interested in the list of <br />files that contained matches rather than the matches themselves, we could specify the -l <br />option:<br /> [me@linuxbox ~]$ <strong>grep -l bzip dirlist*.txt<br /></strong>dirlist-bin.txt<br /> Conversely, if we wanted only to see a list of the files that did not contain a match, we <br />could do this:<br /> [me@linuxbox ~]$ <strong>grep -L bzip dirlist*.txt<br /></strong>dirlist-sbin.txt <br /> dirlist-usr-bin.txt <br />dirlist-usr-sbin.txt<br /> <strong>Metacharacters And Literals<br /></strong>While it may not seem apparent, our grep searches have been using regular expressions <br />all along, albeit very simple ones. The regular expression “bzip” is taken to mean that a <br />match will occur only if the line in the file contains at least four characters and that some-<br />where in the line the characters “b”, “z”, “i”, and “p” are found in that order, with no <br />other characters in between. The characters in the string “bzip” are all <em>literal characters</em>, <br />in that they match themselves. In addition to literals, regular expressions may also in-<br /> 245<br /></p>
<hr />
<p>19 – Regular Expressions<br /> clude <em>metacharacters</em> that are used to specify more complex matches. Regular expression <br />metacharacters consist of the following:<br />^ $ . [ ] { } - ? * + ( ) | \<br />All other characters are considered literals, though the backslash character is used in a <br />few cases to create <em>meta sequences</em>, as well as allowing the metacharacters to be escaped <br />and treated as literals instead of being interpreted as metacharacters.<br /> <strong>Note:</strong> As we can see, many of the regular expression metacharacters are also char-<br />acters that have meaning to the shell when expansion is performed. When we pass <br />regular expressions containing metacharacters on the command line, it is vital that <br />they be enclosed in quotes to prevent the shell from attempting to expand them.<br /> <strong>The Any Character<br /></strong>The first metacharacter we will look at is the dot or period character, which is used to <br />match any character. If we include it in a regular expression, it will match any character <br />in that character position. Here’s an example:<br /> [me@linuxbox ~]$ <strong>grep -h '.zip' dirlist*.txt <br /></strong>bunzip2 <br /> bzip2 <br />bzip2recover <br /> gunzip <br />gzip <br /> funzip <br />gpg-zip <br /> preunzip <br />prezip <br /> prezip-bin <br />unzip <br /> unzipsfx<br /> We searched for any line in our files that matches the regular expression “.zip”. There are <br />a couple of interesting things to note about the results. Notice that the zip program was <br />not found. This is because the inclusion of the dot metacharacter in our regular expression <br />increased the length of the required match to four characters, and because the name “zip” <br />only contains three, it does not match. Also, if any files in our lists had contained the file <br />extension .zip, they would have been matched as well, because the period character in <br />the file extension is treated as “any character,” too.<br /> 246<br /></p>
<hr />
<p>Anchors<br /> <strong>Anchors<br /></strong>The caret (^) and dollar sign ($) characters are treated as <em>anchors</em> in regular expressions. <br />This means that they cause the match to occur only if the regular expression is found at <br />the beginning of the line (^) or at the end of the line ($):<br /> [me@linuxbox ~]$ <strong>grep -h '^zip' dirlist*.txt<br /></strong>zip <br /> zipcloak <br />zipgrep <br /> zipinfo <br />zipnote <br /> zipsplit<br />[me@linuxbox ~]$ <strong>grep -h 'zip$' dirlist*.txt</strong><br /> gunzip <br />gzip <br /> funzip <br />gpg-zip <br /> preunzip <br />prezip <br /> unzip <br />zip<br /> [me@linuxbox ~]$ <strong>grep -h '^zip$' dirlist*.txt<br /></strong>zip<br /> Here we searched the list of files for the string “zip” located at the beginning of the line, <br />the end of the line, and on a line where it is at both the beginning and the end of the line <br />(i.e., by itself on the line.) Note that the regular expression ‘^$’ (a beginning and an end <br />with nothing in between) will match blank lines.<br /> <strong>A Crossword Puzzle Helper<br /></strong>Even with our limited knowledge of regular expressions at this point, we can do <br />something useful.<br />My wife loves crossword puzzles and she will sometimes ask me for help with a <br />particular question. Something like, “What’s a five letter word whose third letter <br />is ‘j’ and last letter is ‘r’ that means...?” This kind of question got me thinking.<br />Did you know that your Linux system contains a dictionary? It does. Take a look <br />in the  /usr/share/dict  directory and you might find one, or several. The <br />dictionary files located there are just long lists of words, one per line, arranged in <br />alphabetical   order.   On   my   system,   the  words  file   contains   just  over  98,500 <br /> 247<br /></p>
<hr />
<p>19 – Regular Expressions<br /> words. To find  possible  answers  to  the  crossword  puzzle  question  above,  we <br />could do this:<br />[me@linuxbox ~]$ <strong>grep -i '^..j.r$' /usr/share/dict/words</strong><br /> Major <br />major<br />Using this regular expression, we can find all the words in our dictionary file that <br />are five letters long and have a “j” in the third position and an “r” in the last posi-<br />tion.<br /> <strong>Bracket Expressions And Character Classes<br /></strong>In addition to matching any character at a given position in our regular expression, we <br />can also match a single character from a specified set of characters by using <em>bracket ex-<br />pressions</em>. With bracket expressions, we can specify a set of characters (including charac-<br />ters that would otherwise be interpreted as metacharacters) to be matched. In this exam-<br />ple, using a two character set:<br /> [me@linuxbox ~]$ <strong>grep -h '[bg]zip' dirlist*.txt</strong><br /> bzip2 <br />bzip2recover <br /> gzip <br /> we match any line that contains the string “bzip” or “gzip”.<br />A set may contain any number of characters, and metacharacters lose their special mean-<br />ing when placed within brackets. However, there are two cases in which metacharacters <br />are used within bracket expressions, and have different meanings. The first is the caret <br />(^), which is used to indicate negation; the second is the dash (-), which is used to indi-<br />cate a character range.<br /> Negation<br />If the first character in a bracket expression is a caret (^), the remaining characters are <br />taken to be a set of characters that must not be present at the given character position. We <br />do this by modifying our previous example:<br /> [me@linuxbox ~]$ <strong>grep -h '[^bg]zip' dirlist*.txt</strong><br /> bunzip2 <br />gunzip <br /> 248<br /></p>
<hr />
<p>Bracket Expressions And Character Classes<br /> funzip <br />gpg-zip <br /> preunzip <br />prezip <br /> prezip-bin <br />unzip <br /> unzipsfx<br /> With negation activated, we get a list of files that contain the string “zip” preceded by any <br />character except “b” or “g”. Notice that the file zip was not found. A negated character <br />set still requires a character at the given position, but the character must not be a member <br />of the negated set.<br />The caret character only invokes negation if it is the first character within a bracket ex-<br />pression; otherwise, it loses its special meaning and becomes an ordinary character in the <br />set.<br /> Traditional Character Ranges<br />If we wanted to construct a regular expression that would find every file in our lists be-<br />ginning with an uppercase letter, we could do this:<br /> [me@linuxbox ~]$ <strong>grep -h '^[ABCDEFGHIJKLMNOPQRSTUVWXZY]' dirlist*.txt</strong><br /> It’s just a matter of putting all 26uppercase letters in a bracket expression. But the idea of <br />all that typing is deeply troubling, so there is another way:<br /> [me@linuxbox ~]$ <strong>grep -h '^[A-Z]' dirlist*.txt</strong> <br />MAKEDEV <br /> ControlPanel <br />GET <br /> HEAD <br />POST <br /> X <br />X11 <br /> Xorg <br />MAKEFLOPPIES <br /> NetworkManager <br />NetworkManagerDispatcher<br /> By using a three character range, we can abbreviate the 26 letters. Any range of charac-<br />ters can be expressed this way including multiple ranges, such as this expression that <br /> 249<br /></p>
<hr />
<p>19 – Regular Expressions<br /> matches all filenames starting with letters and numbers:<br /> [me@linuxbox ~]$ <strong>grep -h '^[A-Za-z0-9]' dirlist*.txt</strong><br /> In character ranges, we see that the dash character is treated specially, so how do we actu-<br />ally include a dash character in a bracket expression? By making it the first character in <br />the expression. Consider these two examples:<br /> [me@linuxbox ~]$ <strong>grep -h '[A-Z]' dirlist*.txt</strong><br /> This will match every filename containing an uppercase letter. While:<br /> [me@linuxbox ~]$ <strong>grep -h '[-AZ]' dirlist*.txt</strong><br /> will match every filename containing a dash, or a uppercase “A” or an uppercase “Z”.<br /> POSIX Character Classes<br />The traditional character ranges are an easily understood and effective way to handle the <br />problem of quickly specifying sets of characters. Unfortunately, they don’t always work. <br />While we have not encountered any problems with our use of grep so far, we might run <br />into problems using other programs.<br />Back in Chapter 4, we looked at how wildcards are used to perform pathname expansion. <br />In that discussion, we said that character ranges could be used in a manner almost identi-<br />cal to the way they are used in regular expressions, but here’s the problem:<br /> [me@linuxbox ~]$ <strong>ls /usr/sbin/[ABCDEFGHIJKLMNOPQRSTUVWXYZ]*</strong><br /> /usr/sbin/MAKEFLOPPIES<br />/usr/sbin/NetworkManagerDispatcher <br /> /usr/sbin/NetworkManager <br /> (Depending on the Linux distribution, we will get a different list of files, possibly an <br />empty list. This example is from Ubuntu). This command produces the expected result—<br />    <br /> a list of only the files whose names begin with an uppercase letter, but:<br /> 250<br /></p>
<hr />
<p>Bracket Expressions And Character Classes<br /> [me@linuxbox ~]$ <strong>ls /usr/sbin/[A-Z]*<br /></strong>/usr/sbin/biosdecode <br /> /usr/sbin/chat <br />/usr/sbin/chgpasswd <br /> /usr/sbin/chpasswd <br />/usr/sbin/chroot <br /> /usr/sbin/cleanup-info <br />/usr/sbin/complain <br /> /usr/sbin/console-kit-daemon <br /> with this command we get an entirely different result (only a partial listing of the results <br />is shown). Why is that? It’s a long story, but here’s the short version:<br />Back when Unix was first developed, it only knew about ASCII characters, and this fea-<br />ture reflects that fact. In ASCII, the first 32 characters (numbers 0-31) are control codes <br />(things like tabs, backspaces, and carriage returns). The next 32 (32-63) contain printable <br />characters, including most punctuation characters and the numerals zero through nine. <br />The next 32 (numbers 64-95) contain the uppercase letters and a few more punctuation <br />symbols. The final 31 (numbers 96-127) contain the lowercase letters and yet more punc-<br />tuation symbols. Based on this arrangement, systems using ASCII used a <em>collation order <br /></em>that looked like this:<br />ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz<br />This differs from proper dictionary order, which is like this:<br />aAbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ<br />As the popularity of Unix spread beyond the United States, there grew a need to support <br />characters not found in U.S. English. The ASCII table was expanded to use a full eight <br />bits, adding characters numbers 128-255, which accommodated many more languages. <br />To support this ability, the POSIX standards introduced a concept called a <em>locale</em>, which <br />could be adjusted to select the character set needed for a particular location. We can see <br />the language setting of our system using this command:<br /> [me@linuxbox ~]$ <strong>echo $LANG</strong><br /> en_US.UTF-8<br /> With this setting, POSIX compliant applications will use a  dictionary  collation order <br />rather than ASCII order. This explains the behavior of the commands above. A character <br />range of [A-Z] when interpreted in dictionary order includes all of the alphabetic char-<br />acters except the lowercase “a”, hence our results.<br />To partially work around this problem, the POSIX standard includes a number of charac-<br />ter classes which provide useful ranges of characters. They are described in the table be-<br /> 251<br /></p>
<hr />
<p>19 – Regular Expressions<br /> low:<br />Table 19-2: POSIX Character Classes<br /> <strong>Character Class</strong><br /> <strong>Description</strong><br /> [:alnum:]<br /> The alphanumeric characters. In ASCII, equivalent to:<br />[A-Za-z0-9]<br /> [:word:]<br /> The same as [:alnum:], with the addition of the underscore <br />(_) character.<br /> [:alpha:]<br /> The alphabetic characters. In ASCII, equivalent to:<br />[A-Za-z]<br /> [:blank:]<br /> Includes the space and tab characters.<br /> [:cntrl:]<br /> The ASCII control codes. Includes the ASCII characters 0 <br />through 31 and 127.<br /> [:digit:]<br /> The numerals zero through nine.<br /> [:graph:]<br /> The visible characters. In ASCII, it includes characters 33 <br />through 126.<br /> [:lower:]<br /> The lowercase letters.<br /> [:punct:]<br /> The punctuation characters. In ASCII, equivalent to:<br />[-!&quot;#$%&amp;'()*+,./:;&lt;=&gt;?@[\\\]_`{|}~]<br /> [:print:]<br /> The printable characters. All the characters in [:graph:] <br />plus the space character.<br /> [:space:]<br /> The whitespace characters including space, tab, carriage <br />return, newline, vertical tab, and form feed. In ASCII, <br />equivalent to:<br />[ \t\r\n\v\f]<br /> [:upper:]<br /> The uppercase characters.<br /> [:xdigit:]<br /> Characters used to express hexadecimal numbers. In ASCII, <br />equivalent to:<br />[0-9A-Fa-f]<br /> Even with the character classes, there is still no convenient way to express partial ranges, <br />such as [A-M].<br />Using character classes, we can repeat our directory listing and see an improved result:<br /> 252<br /></p>
<hr />
<p>Bracket Expressions And Character Classes<br /> [me@linuxbox ~]$ <strong>ls /usr/sbin/[[:upper:]]*<br /></strong>/usr/sbin/MAKEFLOPPIES<br /> /usr/sbin/NetworkManagerDispatcher <br />/usr/sbin/NetworkManager<br /> Remember, however, that this is not an example of a regular expression, rather it is the <br />shell performing pathname expansion. We show it here because POSIX character classes <br />can be used for both.<br /> <strong>Reverting To Traditional Collation Order<br /></strong>You can opt to have your system use the  traditional  (ASCII)  collation order  by <br />changing the value of the  LANG  environment variable. As we saw above, the <br />LANG variable contains the name of the language and character set used in your <br />locale. This value was originally determined when you selected an installation <br />language as your Linux was installed.<br />To see the locale settings, use the locale command:<br />[me@linuxbox ~]$ <strong>locale<br /></strong>LANG=en_US.UTF-8 <br />LC_CTYPE=&quot;en_US.UTF-8&quot; <br />LC_NUMERIC=&quot;en_US.UTF-8&quot; <br />LC_TIME=&quot;en_US.UTF-8&quot; <br />LC_COLLATE=&quot;en_US.UTF-8&quot; <br />LC_MONETARY=&quot;en_US.UTF-8&quot; <br />LC_MESSAGES=&quot;en_US.UTF-8&quot; <br />LC_PAPER=&quot;en_US.UTF-8&quot; <br />LC_NAME=&quot;en_US.UTF-8&quot; <br />LC_ADDRESS=&quot;en_US.UTF-8&quot; <br />LC_TELEPHONE=&quot;en_US.UTF-8&quot; <br />LC_MEASUREMENT=&quot;en_US.UTF-8&quot; <br />LC_IDENTIFICATION=&quot;en_US.UTF-8&quot; <br />LC_ALL=<br />To change the locale to use the traditional Unix behaviors, set the LANG variable <br />to POSIX:<br />[me@linuxbox ~]$ <strong>export LANG=POSIX<br /></strong>Note that this change converts the system to use U.S. English (more specifically, <br />ASCII) for its character set, so be sure if this is really what you want.<br />You can make this change permanent by adding this line to you your .bashrc <br />file:<br /> 253<br /></p>
<hr />
<p>19 – Regular Expressions<br /> export LANG=POSIX <br /> <strong>POSIX Basic Vs. Extended Regular Expressions<br /></strong>Just when we thought this couldn’t get any more confusing, we discover that POSIX also <br />splits   regular   expression   implementations   into   two   kinds:  <em>basic  regular   expressions <br />(BRE)</em> and <em>extended regular expressions (ERE)</em>. The features we have covered so far are <br />supported by any application that is POSIX compliant and implements BRE. Our grep <br />program is one such program.<br />What’s the difference between BRE and ERE? It’s a matter of metacharacters. With BRE, <br />the following metacharacters are recognized:<br />^ $ . [ ] *<br />All other characters are considered literals. With ERE, the following metacharacters (and <br />their associated functions) are added:<br />( ) { } ? + |<br />However (and this is the fun part), the “(”, “)”, “{”, and “}” characters are treated as <br />metacharacters in BRE <em>if</em> they are escaped with a backslash, whereas with ERE, preced-<br />ing any metacharacter with a backslash causes it to be treated as a literal. Any weirdness <br />that comes along will be covered in the discussions that follow.<br />Since the features we are going to discuss next are part of ERE, we are going to need to <br />use a different grep. Traditionally, this has been performed by the egrep program, but <br />the GNU version of grep also supports extended regular expressions when the -E op-<br />tion is used.<br /> <strong>POSIX<br /></strong>During the 1980’s, Unix became a very popular commercial operating system, but <br />by 1988, the Unix world was in turmoil. Many computer manufacturers had li-<br />censed the Unix source code from its creators, AT&amp;T, and were supplying various <br />versions of the operating system with their systems. However, in their efforts to <br />create product differentiation, each manufacturer added proprietary changes and <br />extensions. This started to limit the compatibility of the software. As always with <br />proprietary vendors, each was trying to play a winning game of “lock-in” with <br />their customers. This dark time in the history of Unix is known today as “<em>the <br />Balkanization</em>.”<br /> 254<br /></p>
<hr />
<p>POSIX Basic Vs. Extended Regular Expressions<br /> Enter the IEEE (Institute of Electrical and Electronics Engineers). In the mid-<br />1980s, the IEEE began developing a set of standards that would define how Unix <br />(and   Unix-like)   systems   would   perform.  These   standards,   formally   known   as <br />IEEE 1003, define the <em>application programming interfaces</em> (APIs), shell and utili-<br />ties that are to be found on a standard Unix-like system. The name “POSIX,” <br />which stands for <em>Portable Operating System Interface</em> (with the “X” added to the <br />end for extra snappiness), was suggested by Richard Stallman (yes, <em>that</em> Richard <br />Stallman), and was adopted by the IEEE.<br /> <strong>Alternation<br /></strong>The first of the extended regular expression features we will discuss is called <em>alternation</em>, <br />which is the facility that allows a match to occur from among a set of expressions. Just as <br />a bracket expression allows a single character to match from a set of specified characters, <br />alternation allows matches from a set of strings or other regular expressions.<br />To demonstrate, we’ll use  grep  in conjunction with  echo. First, let’s try a plain old <br />string match:<br /> [me@linuxbox ~]$ <strong>echo &quot;AAA&quot; | grep AAA<br /></strong>AAA<br /> [me@linuxbox ~]$ <strong>echo &quot;BBB&quot; | grep AAA<br /></strong>[me@linuxbox ~]$ <br /> A pretty straightforward example, in which we pipe the output of echo into grep and <br />see the results. When a match occurs, we see it printed out; when no match occurs, we <br />see no results.<br />Now we’ll add alternation, signified by the vertical-bar metacharacter:<br /> [me@linuxbox ~]$ <strong>echo &quot;AAA&quot; | grep -E 'AAA|BBB'<br /></strong>AAA<br /> [me@linuxbox ~]$ <strong>echo &quot;BBB&quot; | grep -E 'AAA|BBB'<br /></strong>BBB<br /> [me@linuxbox ~]$ <strong>echo &quot;CCC&quot; | grep -E 'AAA|BBB'<br /></strong>[me@linuxbox ~]$ <br /> Here we see the regular expression 'AAA|BBB', which means “match either the string <br />AAA or the string BBB.” Notice that since this is an extended feature, we added the -E <br /> 255<br /></p>
<hr />
<p>19 – Regular Expressions<br /> option to grep (though we could have just used the egrep program instead), and we <br />enclosed the regular expression in quotes to prevent the shell from interpreting the verti-<br />cal-bar metacharacter as a pipe operator. Alternation is not limited to two choices:<br /> [me@linuxbox ~]$ <strong>echo &quot;AAA&quot; | grep -E 'AAA|BBB|CCC'<br /></strong>AAA<br /> To combine alternation with other regular expression elements, we can use () to separate <br />the alternation:<br /> [me@linuxbox ~]$ <strong>grep -Eh '^(bz|gz|zip)' dirlist*.txt</strong><br /> This expression will match the filenames in our lists that start with either “bz”, “gz”, or <br />“zip”. Had we left off the parentheses, the meaning of this regular expression :<br /> [me@linuxbox ~]$ <strong>grep -Eh '^bz|gz|zip' dirlist*.txt</strong><br /> changes to match any filename that begins with “bz” <em>or contains</em> “gz” <em>or contains</em> “zip”.<br /> <strong>Quantifiers<br /></strong>Extended regular expressions support several ways to specify the number of times an ele-<br />ment is matched.<br /> ? - Match An Element Zero Or One Time<br />This quantifier means, in effect, “Make the preceding element optional.” Let’s say we <br />wanted to check a phone number for validity and we considered a phone number to be <br />valid if it matched either of these two forms:<br />(<em>nnn</em>) <em>nnn</em>-<em>nnnn</em><br /> <em>nnn</em> <em>nnn</em>-<em>nnnn</em><br /> where “<em>n</em>” is a numeral. We could construct a regular expression like this:<br />^\(?[0-9][0-9][0-9]\)?  [0-9][0-9][0-9]-[0-9][0-9][0-9][0-9]$<br /> In this expression, we follow the parentheses characters with question marks to indicate <br />that they are to be matched zero or one time. Again, since the parentheses are normally <br />metacharacters (in ERE), we precede them with backslashes to cause them to be treated <br />as literals instead.<br /> 256<br /></p>
<hr />
<p>Quantifiers<br /> Let’s try it:<br /> [me@linuxbox ~]$ <strong>echo &quot;(555) 123-4567&quot; | grep -E '^\(?[0-9][0-9][0-9]<br />\)? [0-9][0-9][0-9]-[0-9][0-9][0-9][0-9]$'</strong><br /> (555) 123-4567<br />[me@linuxbox ~]$ <strong>echo &quot;555 123-4567&quot; | grep -E '^\(?[0-9][0-9][0-9]\)</strong><br /> <strong>? [0-9][0-9][0-9]-[0-9][0-9][0-9][0-9]$'<br /></strong>555 123-4567<br /> [me@linuxbox ~]$ <strong>echo &quot;AAA 123-4567&quot; | grep -E '^\(?[0-9][0-9][0-9]\)<br />? [0-9][0-9][0-9]-[0-9][0-9][0-9][0-9]$'</strong><br /> [me@linuxbox ~]$ <br /> Here we see that the expression matches both forms of the phone number, but does not <br />match one containing non-numeric characters.<br /> * - Match An Element Zero Or More Times<br />Like the ? metacharacter, the * is used to denote an optional item; however, unlike the ?, <br />the item may occur any number of times, not just once. Let’s say we wanted to see if a <br />string was a sentence; that is, it starts with an uppercase letter, then contains any number <br />of upper and lowercase letters and spaces, and ends with a period. To match this (very <br />crude) definition of a sentence, we could use a regular expression like this:<br />[[:upper:]][[:upper:][:lower:] ]*\.<br /> The expression consists of three items: a bracket expression containing the [:upper:] <br />character class, a bracket expression containing both the [:upper:] and [:lower:] <br />character classes and a space, and a period escaped with a backslash. The second element <br />is trailed with an * metacharacter, so that after the leading uppercase letter in our sen-<br />tence, any number of upper and lowercase letters and spaces may follow it and still <br />match:<br /> [me@linuxbox ~]$ <strong>echo &quot;This works.&quot; | grep -E '[[:upper:]][[:upper:][<br />:lower:] ]*\.'</strong> <br /> This works.<br />[me@linuxbox ~]$ <strong>echo &quot;This Works.&quot; | grep -E '[[:upper:]][[:upper:][</strong><br /> <strong>:lower:] ]*\.' <br /></strong>This Works.<br /> [me@linuxbox ~]$ <strong>echo &quot;this does not&quot; | grep -E '[[:upper:]][[:upper:<br />][:lower:] ]*\.'</strong><br /> [me@linuxbox ~]$ <br /> The expression matches the first two tests, but not the third, since it lacks the required <br /> 257<br /></p>
<hr />
<p>19 – Regular Expressions<br /> leading uppercase character and trailing period.<br /> + - Match An Element One Or More Times<br />The + metacharacter works much like the *, except it requires at least one instance of the <br />preceding element to cause a match. Here is a regular expression that will only match <br />lines consisting of groups of one or more alphabetic characters separated by single spa-<br />ces:<br />^([[:alpha:]]+ ?)+$<br /> [me@linuxbox ~]$ <strong>echo &quot;This that&quot; | grep -E '^([[:alpha:]]+ ?)+$'</strong><br /> This that<br />[me@linuxbox ~]$ <strong>echo &quot;a b c&quot; | grep -E '^([[:alpha:]]+ ?)+$'</strong><br /> a b c<br />[me@linuxbox ~]$ <strong>echo &quot;a b 9&quot; | grep -E '^([[:alpha:]]+ ?)+$'</strong><br /> [me@linuxbox ~]$ <strong>echo &quot;abc  d&quot; | grep -E '^([[:alpha:]]+ ?)+$'<br /></strong>[me@linuxbox ~]$ <br /> We see that this expression does not match the line “a b 9”, because it contains a non-al-<br />phabetic character; nor does it match “abc   d”, because more than one space character <br />separates the characters “c” and “d”.<br /> { } - Match An Element A Specific Number Of Times<br />The { and } metacharacters are used to express minimum and maximum numbers of re-<br />quired matches. They may be specified in four possible ways:<br /> <em>Table 19-3: Specifying The Number Of Matches</em><br /> <strong>Specifier</strong><br /> <strong>Meaning</strong><br /> {<em>n</em>}<br /> Match the preceding element if it occurs exactly <em>n</em> times.<br /> {<em>n</em>,<em>m</em>}<br /> Match the preceding element if it occurs at least <em>n</em> times, but no <br />more than <em>m</em> times.<br /> {<em>n</em>,}<br /> Match the preceding element if it occurs <em>n</em> or more times.<br /> {,<em>m</em>}<br /> Match the preceding element if it occurs no more than <em>m</em> times.<br /> Going back to our earlier example with the phone numbers, we can use this method of <br />specifying repetitions to simplify our original regular expression from:<br />^\(?[0-9][0-9][0-9]\)?  [0-9][0-9][0-9]-[0-9][0-9][0-9][0-9]$<br /> 258<br /></p>
<hr />
<p>Quantifiers<br /> to:<br />^\(?[0-9]{3}\)?  [0-9]{3}-[0-9]{4}$<br /> Let’s try it:<br /> [me@linuxbox ~]$ <strong>echo &quot;(555) 123-4567&quot; | grep -E '^\(?[0-9]{3}\)? [0-</strong><br /> <strong>9]{3}-[0-9]{4}$' <br /></strong>(555) 123-4567<br /> [me@linuxbox ~]$ <strong>echo &quot;555 123-4567&quot; | grep -E '^\(?[0-9]{3}\)? [0-9]<br />{3}-[0-9]{4}$' </strong><br /> 555 123-4567<br />[me@linuxbox ~]$ <strong>echo &quot;5555 123-4567&quot; | grep -E '^\(?[0-9]{3}\)? [0-9</strong><br /> <strong>]{3}-[0-9]{4}$' <br /></strong>[me@linuxbox ~]$ <br /> As we can see, our revised expression can successfully validate numbers both with and <br />without the parentheses, while rejecting those numbers that are not properly formatted.<br /> <strong>Putting Regular Expressions To Work<br /></strong>Let’s look at some of the commands we already know and see how they can be used with <br />regular expressions.<br /> Validating A Phone List With grep<br />In our earlier example, we looked at single phone numbers and checked them for proper <br />formatting. A more realistic scenario would be checking a list of numbers instead, so let’s <br />make a list. We’ll do this by reciting a magical incantation to the command line. It will be <br />magic because we have not covered most of the commands involved, but worry not. We <br />will get there in future chapters. Here is the incantation:<br /> [me@linuxbox ~]$ <strong>for i in {1..10}; do echo &quot;(${RANDOM:0:3}) ${RANDO</strong><br /> <strong>M:0:3}-${RANDOM:0:4}&quot; &gt;&gt; phonelist.txt; done</strong><br /> This command will produce a file named phonelist.txt containing ten phone num-<br />bers. Each time the command is repeated, another ten numbers are added to the list. We <br />can also change the value  10  near the beginning of the command to produce more or <br />fewer phone numbers. If we examine the contents of the file, however, we see we have a <br />problem:<br /> 259<br /></p>
<hr />
<p>19 – Regular Expressions<br /> [me@linuxbox ~]$ <strong>cat phonelist.txt<br /></strong>(232) 298-2265 <br /> (624) 381-1078 <br />(540) 126-1980 <br /> (874) 163-2885 <br />(286) 254-2860 <br /> (292) 108-518 <br />(129) 44-1379 <br /> (458) 273-1642 <br />(686) 299-8268 <br /> (198) 307-2440<br /> Some of the numbers are malformed, which is perfect for our purposes, since we will use <br />grep to validate them.<br />One useful method of validation would be to scan the file for invalid numbers and display <br />the resulting list on the display:<br /> [me@linuxbox ~]$ <strong>grep -Ev '^\([0-9]{3}\) [0-9]{3}-[0-9]{4}$'</strong> <br /> phonelist.txt<br />(292) 108-518 <br /> (129) 44-1379<br />[me@linuxbox ~]$ <br /> Here we use the -v option to produce an inverse match so that we will only output the <br />lines in the list that do not match the specified expression. The expression itself includes <br />the anchor metacharacters at each end to ensure that the number has no extra characters at <br />either end. This expression also requires that the parentheses be present in a valid num-<br />ber, unlike our earlier phone number example.<br /> Finding Ugly Filenames With find<br />The find command supports a test based on a regular expression. There is an important <br />consideration to keep in mind when using regular expressions in  find  versus  grep. <br />Whereas grep will print a line when the line <em>contains</em> a string that matches an expres-<br />sion, find requires that the pathname <em>exactly match</em> the regular expression. In the fol-<br />lowing example, we will use find with a regular expression to find every pathname that <br />contains any character that is not a member of the following set:<br />[-_./0-9a-zA-Z]<br />Such a scan would reveal pathnames that contain embedded spaces and other potentially <br />offensive characters:<br /> 260<br /></p>
<hr />
<p>Putting Regular Expressions To Work<br /> [me@linuxbox ~]$ <strong>find . -regex '.*[^-_./0-9a-zA-Z].*'</strong><br /> Due to the requirement for an exact match of the entire pathname, we use .* at both ends <br />of the expression to match zero or more instances of any character. In the middle of the <br />expression, we use a negated bracket expression containing our set of acceptable path-<br />name characters.<br /> Searching For Files With locate<br />The  locate  program supports both basic (the  --regexp  option) and extended (the <br />--regex option) regular expressions. With it, we can perform many of the same opera-<br />tions that we performed earlier with our dirlist files:<br /> [me@linuxbox ~]$ <strong>locate --regex 'bin/(bz|gz|zip)'<br /></strong>/bin/bzcat <br /> /bin/bzcmp <br />/bin/bzdiff <br /> /bin/bzegrep <br />/bin/bzexe <br /> /bin/bzfgrep <br />/bin/bzgrep <br /> /bin/bzip2 <br />/bin/bzip2recover <br /> /bin/bzless <br />/bin/bzmore <br /> /bin/gzexe <br />/bin/gzip <br /> /usr/bin/zip <br />/usr/bin/zipcloak <br /> /usr/bin/zipgrep <br />/usr/bin/zipinfo <br /> /usr/bin/zipnote <br />/usr/bin/zipsplit <br /> Using   alternation,   we   perform   a   search   for   pathnames   that   contain   either  bin/bz, <br />bin/gz, or /bin/zip.<br /> Searching For Text With less And vim<br />less and vim both share the same method of searching for text. Pressing the / key fol-<br />lowed   by   a   regular   expression   will   perform   a   search.   If   we   use  less  to  view our <br />phonelist.txt file:<br /> 261<br /></p>
<hr />
<p>19 – Regular Expressions<br /> [me@linuxbox ~]$ <strong>less phonelist.txt</strong><br /> then search for our validation expression:<br /> (232) 298-2265 <br /> (624) 381-1078 <br />(540) 126-1980 <br /> (874) 163-2885 <br />(286) 254-2860 <br /> (292) 108-518 <br />(129) 44-1379 <br /> (458) 273-1642 <br />(686) 299-8268 <br /> (198) 307-2440 <br />~ <br /> ~ <br />~ <br /> <strong>/^\([0-9]{3}\) [0-9]{3}-[0-9]{4}$</strong><br /> less will highlight the strings that match, leaving the invalid ones easy to spot:<br /> (232) 298-2265<br /> (624) 381-1078 <br />(540) 126-1980 <br /> (874) 163-2885 <br />(286) 254-2860 <br /> (292) 108-518 <br />(129) 44-1379 <br /> (458) 273-1642<br />(686) 299-8268<br /> (198) 307-2440 <br />~ <br /> ~ <br />~ <br /> (END)<br /> vim, on the other hand, supports  basic  regular expressions, so our search expression <br />would look like this:<br />/([0-9]\{3\}) [0-9]\{3\}-[0-9]\{4\}<br />We can see that the expression is mostly the same; however, many of the characters that <br />are considered metacharacters in extended expressions are considered literals in basic ex-<br />pressions. They are only treated as metacharacters when escaped with a backslash. De-<br /> 262<br /></p>
<hr />
<p>Putting Regular Expressions To Work<br /> pending on the particular configuration of vim on our system, the matching will be high-<br />lighted. If not, try this command mode command:<br />:hlsearch<br />to activate search highlighting.<br /> <strong>Note:</strong>  Depending on your distribution,  vim  may or may not support text search <br />highlighting. Ubuntu, in particular, supplies a very stripped-down version of vim <br />by default. On such systems, you may want to use your package manager to install <br />a more complete version of vim.<br /> <strong>Summing Up<br /></strong>In this chapter, we’ve seen a few of the many uses of regular expressions. We can find <br />even more if we use regular expressions to search for additional applications that use <br />them. We can do that by searching the man pages:<br /> [me@linuxbox ~]$ <strong>cd /usr/share/man/man1<br /></strong>[me@linuxbox man1]$ <strong>zgrep -El 'regex|regular expression' *.gz</strong><br /> The zgrep program provides a front end for grep, allowing it to read compressed files. <br />In our example, we search the compressed section one man page files in their usual loca-<br />tion. The result of this command is a list of files containing either the string “regex” or <br />“regular expression”. As we can see, regular expressions show up in a lot of programs.<br />There is one feature found in basic regular expressions that we did not cover. Called <em>back <br />references</em>, this feature will be discussed in the next chapter.<br /> <strong>Further Reading<br /></strong>There are many online resources for learning regular expressions, including various tuto-<br />rials and cheat sheets.<br />In addition, the Wikipedia has good articles on the following background topics:<br /> ●<br /> POSIX:<a href="http://en.wikipedia.org/wiki/Posix"> http://en.wikipedia.org/wiki/Posix</a><br /> ●<br /> ASCII:<a href="http://en.wikipedia.org/wiki/Ascii"> http://en.wikipedia.org/wiki/Ascii</a><br /> 263<br /></p>
<hr />
<p>20 – Text Processing<br /> <em><strong>20 – Text Processing</strong></em><br /> All Unix-like operating systems rely heavily on text files for several types of data stor-<br />age. So it makes sense that there are many tools for manipulating text. In this chapter, we <br />will look at programs that are used to “slice and dice” text. In the next chapter, we will <br />look at more text processing, focusing on programs that are used to format text for print-<br />ing and other kinds of human consumption.<br />This chapter will revisit some old friends and introduce us to some new ones:<br /> ●<br /> cat – Concatenate files and print on the standard output<br /> ●<br /> sort – Sort lines of text files<br /> ●<br /> uniq – Report or omit repeated lines<br /> ●<br /> cut – Remove sections from each line of files<br /> ●<br /> paste – Merge lines of files<br /> ●<br /> join – Join lines of two files on a common field<br /> ●<br /> comm – Compare two sorted files line by line<br /> ●<br /> diff – Compare files line by line<br /> ●<br /> patch – Apply a diff file to an original<br /> ●<br /> tr – Translate or delete characters<br /> ●<br /> sed – Stream editor for filtering and transforming text<br /> ●<br /> aspell – Interactive spell checker<br /> <strong>Applications Of Text<br /></strong>So far, we have learned a couple of text editors (nano and vim), looked at a bunch of <br />configuration files, and have witnessed the output of dozens of commands, all in text. But <br />what else is text used for? For many things, it turns out.<br /> 264<br /></p>
<hr />
<p>Applications Of Text<br /> Documents<br />Many people write documents using plain text formats. While it is easy to see how a <br />small text file could be useful for keeping simple notes, it is also possible to write large <br />documents in text format, as well. One popular approach is to write a large document in a <br />text format and then use a  <em>markup language</em>  to describe the formatting of the finished <br />document. Many scientific papers are written using this method, as Unix-based text pro-<br />cessing systems were among the first systems that supported the advanced typographical <br />layout needed by writers in technical disciplines.<br /> Web Pages<br />The world’s most popular type of electronic document is probably the  web page. Web <br />pages are text documents that use either <em>HTML (Hypertext Markup Language)</em> or <em>XML <br />(Extensible Markup Language)</em>  as markup languages to describe the document’s visual <br />format.<br /> Email<br />Email is an intrinsically text-based medium. Even non-text attachments are converted <br />into a text representation for transmission. We can see this for ourselves by downloading <br />an email message and then viewing it in less. We will see that the message begins with <br />a <em>header</em> that describes the source of the message and the processing it received during its <br />journey, followed by the <em>body</em> of the message with its content.<br /> Printer Output<br />On Unix-like systems, output destined for a printer is sent as plain text or, if the page <br />contains graphics, is converted into a text format  <em>page description language</em>  known as <br /><em>PostScript</em>, which is then sent to a program that generates the graphic dots to be printed. <br /> Program Source Code<br />Many of the command line programs found on Unix-like systems were created to support <br />system administration and software development, and text processing programs are no <br />exception. Many of them are designed to solve software development problems. The rea-<br />son text processing is important to software developers is that all software starts out as <br />text. <em>Source code</em>, the part of the program the programmer actually writes, is always in <br />text format.<br /> <strong>Revisiting Some Old Friends<br /></strong>Back in Chapter 6 (Redirection), we learned about some commands that are able to ac-<br /> 265<br /></p>
<hr />
<p>20 – Text Processing<br /> cept standard input in addition to command line arguments. We only touched on them <br />briefly then, but now we will take a closer look at how they can be used to perform text <br />processing.<br /> cat<br />The  cat program has a number of interesting options. Many of them are used to help <br />better visualize text content. One example is the -A option, which is used to display non-<br />printing characters in the text. There are times when we want to know if control charac-<br />ters are embedded in our otherwise visible text. The most common of these are tab char-<br />acters (as opposed to spaces) and carriage returns, often present as end-of-line characters <br />in MS-DOS-style text files. Another common situation is a file containing lines of text <br />with trailing spaces.<br />Let’s create a test file using cat as a primitive word processor. To do this, we’ll just en-<br />ter the command  cat (along with specifying a file for redirected output) and type our <br />text, followed by Enter to properly end the line, then Ctrl-d, to indicate to cat that <br />we have reached end-of-file. In this example, we enter a leading tab character and follow <br />the line with some trailing spaces:<br /> [me@linuxbox ~]$ <strong>cat &gt; foo.txt</strong><br /> The quick brown fox jumped over the lazy dog.<br /> [me@linuxbox ~]$ <br /> Next, we will use cat with the -A option to display the text:<br /> [me@linuxbox ~]$ <strong>cat -A foo.txt<br /></strong>^IThe quick brown fox jumped over the lazy dog.   $<br /> [me@linuxbox ~]$ <br /> As we can see in the results, the tab character in our text is represented by ^I. This is a <br />common notation that means “Control-I” which, as it turns out, is the same as a tab char-<br />acter. We also see that a $ appears at the true end of the line, indicating that our text con-<br />tains trailing spaces.<br /> 266<br /></p>
<hr />
<p>Revisiting Some Old Friends<br /> <strong>MS-DOS Text Vs. Unix Text<br /></strong>One of the reasons you may want to use cat to look for non-printing characters <br />in text is to spot hidden carriage returns. Where do hidden carriage returns come <br />from? DOS and Windows! Unix and DOS don’t define the end of a line the same <br />way in text files. Unix ends a line with a linefeed character (ASCII 10) while MS-<br />DOS and its derivatives use the sequence carriage return (ASCII 13) and linefeed <br />to terminate each line of text.<br />There are a several ways to convert files from DOS to Unix format. On many <br />Linux systems, there are programs called dos2unix and unix2dos, which can <br />convert text files to and from DOS format. However, if you don’t have dos2u-<br />nix  on your system, don’t worry. The process of converting text from DOS to <br />Unix format is very simple; it simply involves the removal of the offending car-<br />riage returns. That is easily accomplished by a couple of the programs discussed <br />later in this chapter.<br /> cat also has options that are used to modify text. The two most prominent are -n, which <br />numbers lines, and  -s, which suppresses the output of  multiple blank lines. We can <br />demonstrate thusly:<br /> [me@linuxbox ~]$ <strong>cat &gt; foo.txt</strong><br /> The quick brown fox<br /> jumped over the lazy dog.<br /> [me@linuxbox ~]$ <strong>cat -ns foo.txt</strong> <br />     1<br /> The quick brown fox <br />      2<br />  <br />      3<br /> jumped over the lazy dog.<br /> [me@linuxbox ~]$ <br /> In this example, we create a new version of our foo.txt test file, which contains two <br />lines of text separated by two blank lines. After processing by cat with the -ns options, <br />the extra blank line is removed and the remaining lines are numbered. While this is not <br />much of a process to perform on text, it is a process.<br /> sort<br />The sort program sorts the contents of standard input, or one or more files specified on <br />the command line, and sends the results to standard output. Using the same technique that <br />we used with  cat, we can demonstrate processing of standard input directly from the <br /> 267<br /></p>
<hr />
<p>20 – Text Processing<br /> keyboard:<br /> [me@linuxbox ~]$ <strong>sort &gt; foo.txt <br /></strong>c <br /> b <br />a <br /> [me@linuxbox ~]$ <strong>cat foo.txt</strong> <br />a <br /> b <br />c <br /> After entering the command, we type the letters “c”, “b”, and “a”, followed once again by <br />Ctrl-d to indicate end-of-file. We then view the resulting file and see that the lines now <br />appear in sorted order.<br />Since sort can accept multiple files on the command line as arguments, it is possible to <br /><em>merge</em> multiple files into a single sorted whole. For example, if we had three text files and <br />wanted to combine them into a single sorted file, we could do something like this: <br /> <strong>sort file1.txt file2.txt file3.txt &gt; final_sorted_list.txt</strong><br /> sort has several interesting options. Here is a partial list:<br /> <em>Table 20-1: Common sort Options</em><br /> <strong>Option</strong><br /> <strong>Long Option</strong><br /> <strong>Description</strong><br /> -b<br /> --ignore-leading-blanks<br /> By default, sorting is performed on <br />the entire line, starting with the <br />first character in the line. This <br />option causes sort to ignore <br />leading spaces in lines and <br />calculates sorting based on the first <br />non-whitespace character on the <br />line.<br /> -f<br /> --ignore-case<br /> Makes sorting case-insensitive.<br /> -n<br /> --numeric-sort<br /> Performs sorting based on the <br />numeric evaluation of a string. <br />Using this option allows sorting to <br />be performed on numeric values <br />rather than alphabetic values.<br /> 268<br /></p>
<hr />
<p>Revisiting Some Old Friends<br /> -r<br /> --reverse<br /> Sort in reverse order. Results are in <br />descending rather than ascending <br />order.<br /> -k<br /> --key=<em>field1</em>[,<em>field2</em>]<br /> Sort based on a key field located <br />from <em>field1</em> to <em>field2</em> rather than the <br />entire line. See discussion below.<br /> -m<br /> --merge<br /> Treat each argument as the name <br />of a presorted file. Merge multiple <br />files into a single sorted result <br />without performing any additional <br />sorting.<br /> -o<br /> --output=<em>file</em><br /> Send sorted output to <em>file</em> rather <br />than standard output.<br /> -t<br /> --field-separator=<em>char</em><br /> Define the field-separator <br />character. By default fields are <br />separated by spaces or tabs.<br /> Although most of the options above are pretty self-explanatory, some are not. First, let’s <br />look at the -n option, used for numeric sorting. With this option, it is possible to sort val-<br />ues based on numeric values. We can demonstrate this by sorting the results of the  du <br />command to determine the largest users of disk space. Normally, the du command lists <br />the results of a summary in pathname order:<br /> [me@linuxbox ~]$ <strong>du -s /usr/share/* | head</strong> <br />252<br /> /usr/share/aclocal <br /> 96<br /> /usr/share/acpi-support <br /> 8<br /> /usr/share/adduser <br /> 196<br /> /usr/share/alacarte <br /> 344<br /> /usr/share/alsa <br /> 8<br /> /usr/share/alsa-base <br /> 12488<br /> /usr/share/anthy <br /> 8<br /> /usr/share/apmd <br /> 21440<br /> /usr/share/app-install <br /> 48<br /> /usr/share/application-registry <br /> In this example, we pipe the results into head to limit the results to the first ten lines. We <br />can produce a numerically sorted list to show the ten largest consumers of space this way:<br /> 269<br /></p>
<hr />
<p>20 – Text Processing<br /> [me@linuxbox ~]$ <strong>du -s /usr/share/* | sort -nr | head</strong> <br />509940<br /> /usr/share/locale-langpack <br /> 242660<br /> /usr/share/doc <br /> 197560<br /> /usr/share/fonts <br /> 179144<br /> /usr/share/gnome <br /> 146764<br /> /usr/share/myspell <br /> 144304<br /> /usr/share/gimp <br /> 135880<br /> /usr/share/dict <br /> 76508<br /> /usr/share/icons <br /> 68072<br /> /usr/share/apps <br /> 62844<br /> /usr/share/foomatic<br /> By using the -nr options, we produce a reverse numerical sort, with the largest values <br />appearing first in the results. This sort works because the numerical values occur at the <br />beginning of each line. But what if we want to sort a list based on some value found <br />within the line? For example, the results of an ls -l:<br /> [me@linuxbox ~]$ <strong>ls -l /usr/bin | head</strong><br /> total 152948 <br />-rwxr-xr-x 1 root   root      34824 2008-04-04 02:42 [ <br /> -rwxr-xr-x 1 root   root     101556 2007-11-27 06:08 a2p <br />-rwxr-xr-x 1 root   root      13036 2008-02-27 08:22 aconnect <br /> -rwxr-xr-x 1 root   root      10552 2007-08-15 10:34 acpi <br />-rwxr-xr-x 1 root   root       3800 2008-04-14 03:51 acpi_fakekey <br /> -rwxr-xr-x 1 root   root       7536 2008-04-19 00:19 acpi_listen <br />-rwxr-xr-x 1 root   root       3576 2008-04-29 07:57 addpart <br /> -rwxr-xr-x 1 root   root      20808 2008-01-03 18:02 addr2line <br />-rwxr-xr-x 1 root   root     489704 2008-10-09 17:02 adept_batch<br /> Ignoring, for the moment, that ls can sort its results by size, we could use sort to sort <br />this list by file size, as well:<br /> [me@linuxbox ~]$ <strong>ls -l /usr/bin | sort -nr -k 5 | head <br /></strong>-rwxr-xr-x 1 root   root    8234216 2008-04-07 17:42 inkscape <br /> -rwxr-xr-x 1 root   root    8222692 2008-04-07 17:42 inkview <br />-rwxr-xr-x 1 root   root    3746508 2008-03-07 23:45 gimp-2.4 <br /> -rwxr-xr-x 1 root   root    3654020 2008-08-26 16:16 quanta <br />-rwxr-xr-x 1 root   root    2928760 2008-09-10 14:31 gdbtui <br /> -rwxr-xr-x 1 root   root    2928756 2008-09-10 14:31 gdb <br />-rwxr-xr-x 1 root   root    2602236 2008-10-10 12:56 net <br /> -rwxr-xr-x 1 root   root    2304684 2008-10-10 12:56 rpcclient <br />-rwxr-xr-x 1 root   root    2241832 2008-04-04 05:56 aptitude <br /> -rwxr-xr-x 1 root   root    2202476 2008-10-10 12:56 smbcacls<br /> 270<br /></p>
<hr />
<p>Revisiting Some Old Friends<br /> Many uses of sort involve the processing of <em>tabular data</em>, such as the results of the ls <br />command above. If we apply database terminology to the table above, we would say that <br />each row is a <em>record</em> and that each record consists of multiple <em>fields</em>, such as the file at-<br />tributes, link count, filename, file size and so on.  sort  is able to process individual <br />fields. In database terms, we are able to specify one or more <em>key fields</em> to use as <em>sort keys</em>. <br />In the example above, we specify the n and r options to perform a reverse numerical sort <br />and specify -k 5 to make sort use the fifth field as the key for sorting.<br />The  k option is very interesting and has many features, but first we need to talk about <br />how sort defines fields. Let’s consider a very simple text file consisting of a single line <br />containing the author’s name:<br /> William<br /> Shotts<br /> By default, sort sees this line as having two fields. The first field contains the charac-<br />ters:<br />“William”<br />and the second field contains the characters:<br />“<br /> Shotts”<br /> meaning that whitespace characters (spaces and tabs) are used as  delimiters  between <br />fields and that the delimiters are included in the field when sorting is performed.<br />Looking again at a line from our ls output, we can see that a line contains eight fields <br />and that the fifth field is the file size:<br /> -rwxr-xr-x 1 root   root    8234216 2008-04-07 17:42 inkscape<br /> For our next series of experiments, let’s consider the following file containing the history <br />of three popular Linux distributions released from 2006 to 2008. Each line in the file has <br />three   fields:   the   distribution   name,   version   number,   and   date   of   release   in <br />MM/DD/YYYY format:<br /> SUSE<br /> 10.2<br /> 12/07/2006 <br /> Fedora<br /> 10<br /> 11/25/2008 <br /> SUSE<br /> 11.0<br /> 06/19/2008 <br /> Ubuntu<br /> 8.04<br /> 04/24/2008 <br /> Fedora<br /> 8<br /> 11/08/2007 <br /> SUSE<br /> 10.3<br /> 10/04/2007 <br /> 271<br /></p>
<hr />
<p>20 – Text Processing<br /> Ubuntu<br /> 6.10<br /> 10/26/2006 <br /> Fedora<br /> 7<br /> 05/31/2007 <br /> Ubuntu<br /> 7.10<br /> 10/18/2007 <br /> Ubuntu<br /> 7.04<br /> 04/19/2007 <br /> SUSE<br /> 10.1<br /> 05/11/2006 <br /> Fedora<br /> 6<br /> 10/24/2006 <br /> Fedora<br /> 9<br /> 05/13/2008 <br /> Ubuntu<br /> 6.06<br /> 06/01/2006 <br /> Ubuntu<br /> 8.10<br /> 10/30/2008 <br /> Fedora<br /> 5<br /> 03/20/2006<br /> Using a text editor (perhaps vim), we’ll enter this data and name the resulting file dis-<br />tros.txt.<br />Next, we’ll try sorting the file and observe the results:<br /> [me@linuxbox ~]$ <strong>sort distros.txt<br /></strong>Fedora<br /> 10<br /> 11/25/2008 <br /> Fedora<br /> 5<br /> 03/20/2006 <br /> Fedora<br /> 6<br /> 10/24/2006 <br /> Fedora<br /> 7<br /> 05/31/2007 <br /> Fedora<br /> 8<br /> 11/08/2007 <br /> Fedora<br /> 9<br /> 05/13/2008 <br /> SUSE<br /> 10.1<br /> 05/11/2006 <br /> SUSE<br /> 10.2<br /> 12/07/2006 <br /> SUSE<br /> 10.3<br /> 10/04/2007 <br /> SUSE<br /> 11.0<br /> 06/19/2008 <br /> Ubuntu<br /> 6.06<br /> 06/01/2006 <br /> Ubuntu<br /> 6.10<br /> 10/26/2006 <br /> Ubuntu<br /> 7.04<br /> 04/19/2007 <br /> Ubuntu<br /> 7.10<br /> 10/18/2007 <br /> Ubuntu<br /> 8.04<br /> 04/24/2008 <br /> Ubuntu<br /> 8.10<br /> 10/30/2008<br /> Well, it mostly worked. The problem occurs in the sorting of the Fedora version numbers. <br />Since a “1” comes before a “5” in the character set, version “10” ends up at the top while <br />version “9” falls to the bottom.<br />To fix this problem we are going to have to sort on multiple keys. We want to perform an <br />alphabetic sort on the first field and then a numeric sort on the second field. sort allows <br />multiple instances of the -k option so that multiple sort keys can be specified. In fact, a <br />key may include a range of fields. If no range is specified (as has been the case with our <br />previous examples), sort uses a key that begins with the specified field and extends to <br />the end of the line. Here is the syntax for our multi-key sort:<br /> 272<br /></p>
<hr />
<p>Revisiting Some Old Friends<br /> [me@linuxbox ~]$ <strong>sort --key=1,1 --key=2n distros.txt</strong> <br />Fedora<br /> 5<br /> 03/20/2006 <br /> Fedora<br /> 6<br /> 10/24/2006 <br /> Fedora<br /> 7<br /> 05/31/2007 <br /> Fedora<br /> 8<br /> 11/08/2007 <br /> Fedora<br /> 9<br /> 05/13/2008 <br /> Fedora<br /> 10<br /> 11/25/2008 <br /> SUSE<br /> 10.1<br /> 05/11/2006 <br /> SUSE<br /> 10.2<br /> 12/07/2006 <br /> SUSE<br /> 10.3<br /> 10/04/2007 <br /> SUSE<br /> 11.0<br /> 06/19/2008 <br /> Ubuntu<br /> 6.06<br /> 06/01/2006 <br /> Ubuntu<br /> 6.10<br /> 10/26/2006 <br /> Ubuntu<br /> 7.04<br /> 04/19/2007 <br /> Ubuntu<br /> 7.10<br /> 10/18/2007 <br /> Ubuntu<br /> 8.04<br /> 04/24/2008 <br /> Ubuntu<br /> 8.10<br /> 10/30/2008<br /> Though we used the long form of the option for clarity, -k 1,1 -k 2n would be ex-<br />actly equivalent. In the first instance of the key option, we specified a range of fields to <br />include in the first key. Since we wanted to limit the sort to just the first field, we speci -<br />fied 1,1 which means “start at field one and end at field one.” In the second instance, we <br />specified 2n, which means that field 2 is the sort key and that the sort should be numeric. <br />An option letter may be included at the end of a key specifier to indicate the type of sort <br />to be performed. These option letters are the same as the global options for the sort pro-<br />gram: b (ignore leading blanks), n (numeric sort), r (reverse sort), and so on.<br />The third field in our list contains a date in an inconvenient format for sorting. On com-<br />puters, dates are usually formatted in YYYY-MM-DD order to make chronological sort-<br />ing easy, but ours are in the American format of MM/DD/YYYY. How can we sort this <br />list in chronological order?<br />Fortunately, sort provides a way. The key option allows specification of <em>offsets</em> within <br />fields, so we can define keys within fields:<br /> [me@linuxbox ~]$ <strong>sort -k 3.7nbr -k 3.1nbr -k 3.4nbr distros.txt</strong> <br /> Fedora<br /> 10<br /> 11/25/2008 <br /> Ubuntu<br /> 8.10<br /> 10/30/2008 <br /> SUSE<br /> 11.0<br /> 06/19/2008 <br /> Fedora<br /> 9<br /> 05/13/2008 <br /> Ubuntu<br /> 8.04<br /> 04/24/2008 <br /> Fedora<br /> 8<br /> 11/08/2007 <br /> Ubuntu<br /> 7.10<br /> 10/18/2007 <br /> SUSE<br /> 10.3<br /> 10/04/2007 <br /> Fedora<br /> 7<br /> 05/31/2007 <br /> 273<br /></p>
<hr />
<p>20 – Text Processing<br /> Ubuntu<br /> 7.04<br /> 04/19/2007 <br /> SUSE<br /> 10.2<br /> 12/07/2006 <br /> Ubuntu<br /> 6.10<br /> 10/26/2006 <br /> Fedora<br /> 6<br /> 10/24/2006 <br /> Ubuntu<br /> 6.06<br /> 06/01/2006 <br /> SUSE<br /> 10.1<br /> 05/11/2006 <br /> Fedora<br /> 5<br /> 03/20/2006 <br /> By specifying  -k 3.7  we instruct  sort  to use a sort key that begins at the seventh <br />character within the third field, which corresponds to the start of the year. Likewise, we <br />specify -k 3.1 and -k 3.4 to isolate the month and day portions of the date. We also <br />add the n and r options to achieve a reverse numeric sort. The b option is included to <br />suppress the leading spaces (whose numbers vary from line to line, thereby affecting the <br />outcome of the sort) in the date field.<br />Some files don’t use tabs and spaces as field delimiters; for example, the /etc/passwd <br />file:<br /> [me@linuxbox ~]$ <strong>head /etc/passwd </strong><br /> root:x:0:0:root:/root:/bin/bash <br />daemon:x:1:1:daemon:/usr/sbin:/bin/sh <br /> bin:x:2:2:bin:/bin:/bin/sh <br />sys:x:3:3:sys:/dev:/bin/sh <br /> sync:x:4:65534:sync:/bin:/bin/sync <br />games:x:5:60:games:/usr/games:/bin/sh <br /> man:x:6:12:man:/var/cache/man:/bin/sh <br />lp:x:7:7:lp:/var/spool/lpd:/bin/sh <br /> mail:x:8:8:mail:/var/mail:/bin/sh <br />news:x:9:9:news:/var/spool/news:/bin/sh<br /> The fields in this file are delimited with colons (:), so how would we sort this file using a <br />key field? sort provides the -t option to define the field separator character. To sort the <br />passwd file on the seventh field (the account’s default shell), we could do this:<br /> [me@linuxbox ~]$ <strong>sort -t ':' -k 7 /etc/passwd | head<br /></strong>me:x:1001:1001:Myself,,,:/home/me:/bin/bash<br /> root:x:0:0:root:/root:/bin/bash<br />dhcp:x:101:102::/nonexistent:/bin/false <br /> gdm:x:106:114:Gnome Display Manager:/var/lib/gdm:/bin/false<br />hplip:x:104:7:HPLIP system user,,,:/var/run/hplip:/bin/false<br /> klog:x:103:104::/home/klog:/bin/false<br />messagebus:x:108:119::/var/run/dbus:/bin/false<br /> polkituser:x:110:122:PolicyKit,,,:/var/run/PolicyKit:/bin/false<br /> 274<br /></p>
<hr />
<p>Revisiting Some Old Friends<br /> pulse:x:107:116:PulseAudio daemon,,,:/var/run/pulse:/bin/false<br /> By specifying the colon character as the field separator, we can sort on the seventh field.<br /> uniq<br />Compared to  sort, the  uniq  program is a lightweight.  uniq  performs a seemingly <br />trivial task. When given a sorted file (including standard input), it removes any duplicate <br />lines and sends the results to standard output. It is often used in conjunction with sort to <br />clean the output of duplicates.<br /> <strong>Tip:</strong> While uniq is a traditional Unix tool often used with sort, the GNU version <br />of sort supports a -u option, which removes duplicates from the sorted output.<br /> Let’s make a text file to try this out:<br /> [me@linuxbox ~]$ <strong>cat &gt; foo.txt <br />a </strong><br /> <strong>b <br />c </strong><br /> <strong>a <br />b </strong><br /> <strong>c</strong><br /> Remember to type Ctrl-d to terminate standard input. Now, if we run uniq on our text <br />file:<br /> [me@linuxbox ~]$ <strong>uniq foo.txt</strong> <br /> a <br />b <br /> c <br />a <br /> b <br />c <br /> the results are no different from our original file; the duplicates were not removed. For <br />uniq to actually do its job, the input must be sorted first:<br /> 275<br /></p>
<hr />
<p>20 – Text Processing<br /> [me@linuxbox ~]$ <strong>sort foo.txt | uniq</strong> <br />a <br /> b <br />c<br /> This is because uniq only removes duplicate lines which are adjacent to each other.<br /> uniq has several options. Here are the common ones:<br /> <em>Table 20-2: Common uniq Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> -c<br /> Output a list of duplicate lines preceded by the number of times the <br />line occurs.<br /> -d<br /> Only output repeated lines, rather than unique lines. <br /> -f <em>n</em><br /> Ignore <em>n</em> leading fields in each line. Fields are separated by <br />whitespace as they are in sort; however, unlike sort, uniq has <br />no option for setting an alternate field separator.<br /> -i<br /> Ignore case during the line comparisons.<br /> -s <em>n</em><br /> Skip (ignore) the leading <em>n</em> characters of each line.<br /> -u<br /> Only output unique lines. This is the default.<br /> Here we see uniq used to report the number of duplicates found in our text file, using <br />the -c option:<br /> [me@linuxbox ~]$ <strong>sort foo.txt | uniq -c</strong> <br />      2 a <br />       2 b <br />      2 c<br /> <strong>Slicing And Dicing<br /></strong>The next three programs we will discuss are used to peel columns of text out of files and <br />recombine them in useful ways.<br /> cut<br />The cut program is used to extract a section of text from a line and output the extracted <br /> 276<br /></p>
<hr />
<p>Slicing And Dicing<br /> section to standard output. It can accept multiple file arguments or input from standard in-<br />put.<br />Specifying the section of the line to be extracted is somewhat awkward and is specified <br />using the following options:<br /> <em>Table 20-3: cut Selection Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> -c <em>char_list</em><br /> Extract the portion of the line defined by <em>char_list</em>. The list <br />may consist of one or more comma-separated numerical <br />ranges.<br /> -f <em>field_list</em><br /> Extract one or more fields from the line as defined by <br /><em>field_list</em>. The list may contain one or more fields or field <br />ranges separated by commas.<br /> -d <em>delim_char</em><br /> When -f is specified, use <em>delim_char</em> as the field delimiting <br />character. By default, fields must be separated by a single tab <br />character.<br /> --complement<br /> Extract the entire line of text, except for those portions <br />specified by -c and/or -f.<br /> As we can see, the way cut extracts text is rather inflexible. cut is best used to extract <br />text from files that are produced by other programs, rather than text directly typed by hu-<br />mans. We’ll take a look at our distros.txt file to see if it is “clean” enough to be a <br />good specimen for our cut examples. If we use cat with the -A option, we can see if <br />the file meets our requirements of tab-separated fields:<br /> [me@linuxbox ~]$ <strong>cat -A distros.txt <br /></strong>SUSE^I10.2^I12/07/2006$ <br /> Fedora^I10^I11/25/2008$ <br />SUSE^I11.0^I06/19/2008$ <br /> Ubuntu^I8.04^I04/24/2008$ <br />Fedora^I8^I11/08/2007$ <br /> SUSE^I10.3^I10/04/2007$ <br />Ubuntu^I6.10^I10/26/2006$ <br /> Fedora^I7^I05/31/2007$ <br />Ubuntu^I7.10^I10/18/2007$ <br /> Ubuntu^I7.04^I04/19/2007$ <br />SUSE^I10.1^I05/11/2006$ <br /> Fedora^I6^I10/24/2006$ <br />Fedora^I9^I05/13/2008$ <br /> 277<br /></p>
<hr />
<p>20 – Text Processing<br /> Ubuntu^I6.06^I06/01/2006$ <br />Ubuntu^I8.10^I10/30/2008$ <br /> Fedora^I5^I03/20/2006$<br /> It looks good. No embedded spaces, just single tab characters between the fields. Since <br />the file uses tabs rather than spaces, we’ll use the -f option to extract a field:<br /> [me@linuxbox ~]$ <strong>cut -f 3 distros.txt</strong> <br /> 12/07/2006 <br />11/25/2008 <br /> 06/19/2008 <br />04/24/2008 <br /> 11/08/2007 <br />10/04/2007 <br /> 10/26/2006 <br />05/31/2007 <br /> 10/18/2007 <br />04/19/2007 <br /> 05/11/2006 <br />10/24/2006 <br /> 05/13/2008 <br />06/01/2006 <br /> 10/30/2008 <br />03/20/2006<br /> Because our distros file is tab-delimited, it is best to use cut to extract fields rather <br />than characters. This is because when a file is tab-delimited, it is unlikely that each line <br />will contain the same number of characters, which makes calculating character positions <br />within the line difficult or impossible. In our example above, however, we now have ex-<br />tracted a field that luckily contains data of identical length, so we can show how character <br />extraction works by extracting the year from each line:<br /> [me@linuxbox ~]$ <strong>cut -f 3 distros.txt | cut -c 7-10</strong> <br />2006 <br /> 2008 <br />2008 <br /> 2008 <br />2007 <br /> 2007 <br />2006 <br /> 2007 <br />2007 <br /> 2007 <br />2006 <br /> 278<br /></p>
<hr />
<p>Slicing And Dicing<br /> 2006 <br />2008 <br /> 2006 <br />2008 <br /> 2006<br /> By running  cut a second time on our list, we are able to extract character positions 7 <br />through 10, which corresponds to the year in our date field. The 7-10 notation is an ex-<br />ample of a range. The cut man page contains a complete description of how ranges can <br />be specified.<br /> <strong>Expanding Tabs<br /></strong>Our distros.txt file is ideally formatted for extracting fields using cut. But <br />what if we wanted a file that could be fully manipulated with cut by characters, <br />rather than fields? This would require us to replace the tab characters within the <br />file with the corresponding number of spaces. Fortunately, the GNU  Coreutils<br />package includes a tool for that. Named expand, this program accepts either one <br />or more file arguments or standard input, and outputs the modified text to stan-<br />dard output.<br />If we process our distros.txt file with expand, we can use the cut -c to <br />extract any range of characters from the file. For example, we could use the fol-<br />lowing command to extract the year of release from our list, by expanding the file <br />and using cut to extract every character from the twenty-third position to the end <br />of the line:<br /> [me@linuxbox ~]$ <strong>expand distros.txt | cut -c 23-<br /></strong>Coreutils also provides the unexpand program to substitute tabs for spaces.<br /> When working with fields, it is possible to specify a different field delimiter rather than <br />the tab character. Here we will extract the first field from the /etc/passwd file:<br /> [me@linuxbox ~]$ <strong>cut -d ':' -f 1 /etc/passwd | head</strong> <br />root <br /> daemon <br />bin <br /> sys <br />sync <br /> games <br />man <br /> lp <br /> 279<br /></p>
<hr />
<p>20 – Text Processing<br /> mail <br />news<br /> Using the -d option, we are able to specify the colon character as the field delimiter.<br /> paste<br />The paste command does the opposite of cut. Rather than extracting a column of text <br />from a file, it adds one or more columns of text to a file. It does this by reading multiple <br />files and combining the fields found in each file into a single stream on standard output. <br />Like cut, paste accepts multiple file arguments and/or standard input. To demonstrate <br />how paste operates, we will perform some surgery on our distros.txt file to pro-<br />duce a chronological list of releases.<br />From our earlier work with sort, we will first produce a list of distros sorted by date <br />and store the result in a file called distros-by-date.txt:<br /> [me@linuxbox ~]$ <strong>sort -k 3.7nbr -k 3.1nbr -k 3.4nbr distros.txt &gt; dis</strong><br /> <strong>tros-by-date.txt</strong><br /> Next, we will use cut to extract the first two fields from the file (the distro name and <br />version), and store that result in a file named distro-versions.txt:<br /> [me@linuxbox ~]$ <strong>cut -f 1,2 distros-by-date.txt &gt; distros-versions.t</strong><br /> <strong>xt<br /></strong>[me@linuxbox ~]$ <strong>head distros-versions.txt</strong><br /> Fedora<br /> 10 <br /> Ubuntu<br /> 8.10 <br /> SUSE<br /> 11.0 <br /> Fedora<br /> 9 <br /> Ubuntu<br /> 8.04 <br /> Fedora<br /> 8 <br /> Ubuntu<br /> 7.10 <br /> SUSE<br /> 10.3 <br /> Fedora<br /> 7 <br /> Ubuntu<br /> 7.04<br /> The final piece of preparation is to extract the release dates and store them a file named <br />distro-dates.txt:<br /> 280<br /></p>
<hr />
<p>Slicing And Dicing<br /> [me@linuxbox ~]$ <strong>cut -f 3 distros-by-date.txt &gt; distros-dates.txt<br /></strong>[me@linuxbox ~]$ <strong>head distros-dates.txt</strong><br /> 11/25/2008 <br />10/30/2008 <br /> 06/19/2008 <br />05/13/2008 <br /> 04/24/2008 <br />11/08/2007 <br /> 10/18/2007 <br />10/04/2007 <br /> 05/31/2007 <br />04/19/2007<br /> We now have the parts we need. To complete the process, use paste to put the column <br />of dates ahead of the distro names and versions, thus creating a chronological list. This is <br />done simply by using paste and ordering its arguments in the desired arrangement:<br /> [me@linuxbox ~]$ <strong>paste distros-dates.txt distros-versions.txt<br /></strong>11/25/2008 Fedora<br /> 10 <br /> 10/30/2008 Ubuntu<br /> 8.10 <br /> 06/19/2008 SUSE<br /> 11.0 <br /> 05/13/2008 Fedora<br /> 9 <br /> 04/24/2008 Ubuntu<br /> 8.04 <br /> 11/08/2007 Fedora<br /> 8 <br /> 10/18/2007 Ubuntu<br /> 7.10 <br /> 10/04/2007 SUSE<br /> 10.3 <br /> 05/31/2007 Fedora<br /> 7 <br /> 04/19/2007 Ubuntu<br /> 7.04 <br /> 12/07/2006 SUSE<br /> 10.2 <br /> 10/26/2006 Ubuntu<br /> 6.10 <br /> 10/24/2006 Fedora<br /> 6 <br /> 06/01/2006 Ubuntu<br /> 6.06 <br /> 05/11/2006 SUSE<br /> 10.1 <br /> 03/20/2006 Fedora<br /> 5<br /> join<br />In some ways, join is like paste in that it adds columns to a file, but it uses a unique <br />way to do it. A <em>join</em> is an operation usually associated with  <em>relational databases</em>  where <br />data from multiple <em>tables</em> with a shared key field is combined to form a desired result. <br />The join program performs the same operation. It joins data from multiple files based <br />on a shared key field.<br />To see how a join operation is used in a relational database, let’s imagine a very small <br />database consisting of two tables, each containing a single record. The first table, called <br /> 281<br /></p>
<hr />
<p>20 – Text Processing<br /> CUSTOMERS, has three fields: a customer number (CUSTNUM), the customer’s first <br />name (FNAME), and the customer’s last name (LNAME):<br />CUSTNUM<br /> FNAME<br /> LNAME<br /> ======== =====<br /> ======<br /> 4681934<br /> John<br /> Smith<br /> The second table is called ORDERS and contains four fields: an order number (ORDER-<br />NUM), the customer number (CUSTNUM), the quantity (QUAN), and the item ordered <br />(ITEM). <br />ORDERNUM<br /> CUSTNUM<br /> QUAN ITEM<br /> ========<br /> =======<br /> ==== ====<br /> 3014953305<br /> 4681934<br /> 1<br /> Blue Widget<br /> Note that both tables share the field CUSTNUM. This is important, as it allows a rela-<br />tionship between the tables.<br />Performing a join operation would allow us to combine the fields in the two tables to <br />achieve a useful result, such as preparing an invoice. Using the matching values in the <br />CUSTNUM fields of both tables, a join operation could produce the following:<br />FNAME<br /> LNAME<br /> QUAN ITEM<br /> =====<br /> =====<br /> ==== ====<br /> John<br /> Smith<br /> 1<br /> Blue Widget<br /> To demonstrate the join program, we’ll need to make a couple of files with a shared <br />key. To do this, we will use our distros-by-date.txt file. From this file, we will <br />construct two additional files, one containing the release dates (which will be our shared <br />key for this demonstration) and the release names:<br /> [me@linuxbox ~]$ <strong>cut -f 1,1 distros-by-date.txt &gt; distros-names.txt<br /></strong>[me@linuxbox ~]$ p<strong>aste distros-dates.txt distros-names.txt &gt; distros-</strong><br /> <strong>key-names.txt<br /></strong>[me@linuxbox ~]$ <strong>head distros-key-names.txt </strong><br /> 11/25/2008 Fedora <br />10/30/2008 Ubuntu <br /> 06/19/2008 SUSE <br />05/13/2008 Fedora <br /> 04/24/2008 Ubuntu <br />11/08/2007 Fedora <br /> 10/18/2007 Ubuntu <br />10/04/2007 SUSE <br /> 05/31/2007 Fedora <br />04/19/2007 Ubuntu<br /> and the second file, which contains the release dates and the version numbers:<br /> 282<br /></p>
<hr />
<p>Slicing And Dicing<br /> [me@linuxbox ~]$ <strong>cut -f 2,2 distros-by-date.txt &gt; distros-vernums.txt<br /></strong>[me@linuxbox ~]$ <strong>paste distros-dates.txt distros-vernums.txt &gt; distro</strong><br /> <strong>s-key-vernums.txt<br /></strong>[me@linuxbox ~]$ <strong>head distros-key-vernums.txt</strong> <br /> 11/25/2008 10 <br />10/30/2008 8.10 <br /> 06/19/2008 11.0 <br />05/13/2008 9 <br /> 04/24/2008 8.04 <br />11/08/2007 8 <br /> 10/18/2007 7.10 <br />10/04/2007 10.3 <br /> 05/31/2007 7 <br />04/19/2007 7.04<br /> We now have two files with a shared key (the “release date” field). It is important to point <br />out that the files must be sorted on the key field for join to work properly.<br /> [me@linuxbox ~]$ <strong>join distros-key-names.txt distros-key-vernums.txt | <br />head </strong><br /> 11/25/2008 Fedora 10 <br />10/30/2008 Ubuntu 8.10 <br /> 06/19/2008 SUSE 11.0 <br />05/13/2008 Fedora 9 <br /> 04/24/2008 Ubuntu 8.04 <br />11/08/2007 Fedora 8 <br /> 10/18/2007 Ubuntu 7.10 <br />10/04/2007 SUSE 10.3 <br /> 05/31/2007 Fedora 7 <br />04/19/2007 Ubuntu 7.04<br /> Note also that, by default, join uses whitespace as the input field delimiter and a single <br />space as the output field delimiter. This behavior can be modified by specifying options. <br />See the join man page for details.<br /> <strong>Comparing Text<br /></strong>It is often useful to compare versions of text files. For system administrators and software <br />developers, this is particularly important. A system administrator may, for example, need <br />to compare an existing configuration file to a previous version to diagnose a system prob-<br />lem. Likewise, a programmer frequently needs to see what changes have been made to <br />programs over time. <br /> 283<br /></p>
<hr />
<p>20 – Text Processing<br /> comm<br />The comm program compares two text files and displays the lines that are unique to each <br />one and the lines they have in common. To demonstrate, we will create two nearly identi-<br />cal text files using cat:<br /> [me@linuxbox ~]$ <strong>cat &gt; file1.txt </strong><br /> <strong>a <br />b </strong><br /> <strong>c <br />d</strong><br /> [me@linuxbox ~]$ <strong>cat &gt; file2.txt <br />b </strong><br /> <strong>c <br />d </strong><br /> <strong>e</strong><br /> Next, we will compare the two files using comm:<br /> [me@linuxbox ~]$ <strong>comm file1.txt file2.txt</strong> <br /> a <br /> b <br /> c <br />d <br /> e<br /> As we can see, comm produces three columns of output. The first column contains lines <br />unique to the first file argument; the second column, the lines unique to the second file ar-<br />gument; the third column contains the lines shared by both files. comm supports options <br />in the form -<em>n</em> where <em>n</em> is either 1, 2 or 3. When used, these options specify which col-<br />umn(s) to suppress. For example, if we only wanted to output the lines shared by both <br />files, we would suppress the output of columns one and two:<br /> [me@linuxbox ~]$ <strong>comm -12 file1.txt file2.txt</strong> <br /> b <br />c <br /> d<br /> diff<br />Like the comm program, diff is used to detect the differences between files. However, <br /> 284<br /></p>
<hr />
<p>Comparing Text<br /> diff is a much more complex tool, supporting many output formats and the ability to <br />process large collections of text files at once. diff is often used by software developers <br />to examine changes between different versions of program source code, and thus has the <br />ability to recursively examine directories of source code, often referred to as <em>source trees</em>. <br />One common use for diff is the creation of <em>diff files</em> or <em>patches</em> that are used by pro-<br />grams such as patch (which we’ll discuss shortly) to convert one version of a file (or <br />files) to another version.<br />If we use diff to look at our previous example files:<br /> [me@linuxbox ~]$ <strong>diff file1.txt file2.txt <br /></strong>1d0 <br /> &lt; a <br />4a4 <br /> &gt; e<br /> we see its default style of output: a terse description of the differences between the two <br />files. In the default format, each group of changes is preceded by a <em>change command</em> in <br />the form of <em>range</em> <em>operation</em> <em>range</em> to describe the positions and types of changes required <br />to convert the first file to the second file:<br /> <em>Table 20-4: diff Change Commands</em><br /> <strong>Change</strong><br /> <strong>Description</strong><br /> <em>r1</em>a<em>r2</em><br /> Append the lines at the position <em>r2</em> in the second file to the position <br /><em>r1</em> in the first file.<br /> <em>r1</em>c<em>r2</em><br /> Change (replace) the lines at position <em>r1</em> with the lines at the <br />position <em>r2</em> in the second file.<br /> <em>r1</em>d<em>r2</em><br /> Delete the lines in the first file at position <em>r1</em>, which would have <br />appeared at range <em>r2</em> in the second file<br /> In this format, a range is a comma-separated list of the starting line and the ending line. <br />While this format is the default (mostly for POSIX compliance and backward compatibil-<br />ity with traditional Unix versions of diff), it is not as widely used as other, optional for-<br />mats. Two of the more popular formats are the <em>context format</em> and the <em>unified format</em>.<br />When viewed using the context format (the -c option), we will see this:<br /> [me@linuxbox ~]$ <strong>diff -c file1.txt file2.txt </strong><br /> 285<br /></p>
<hr />
<p>20 – Text Processing<br /> *** file1.txt<br /> 2008-12-23 06:40:13.000000000 -0500 <br /> --- file2.txt<br /> 2008-12-23 06:40:34.000000000 -0500 <br /> *************** <br />*** 1,4 **** <br /> - a <br />  b <br />   c <br />  d <br /> --- 1,4 ---- <br />  b <br />   c <br />  d <br /> + e<br /> The output begins with the names of the two files and their timestamps. The first file is <br />marked with asterisks and the second file is marked with dashes. Throughout the remain-<br />der of the listing, these markers will signify their respective files. Next, we see groups of <br />changes, including the default number of surrounding context lines. In the first group, we <br />see:<br />*** 1,4 ***<br />which indicates lines 1 through 4 in the first file. Later we see:<br />--- 1,4 ---<br />which indicates lines 1 through 4 in the second file. Within a change group, lines begin <br />with one of four indicators:<br /> <em>Table 20-5: diff Context Format Change Indicators</em><br /> <strong>Indicator</strong><br /> <strong>Meaning</strong><br /> blank<br /> A line shown for context. It does not indicate a difference between <br />the two files.<br /> -<br /> A line deleted. This line will appear in the first file but not in the <br />second file.<br /> +<br /> A line added. This line will appear in the second file but not in the <br />first file.<br /> !<br /> A line changed. The two versions of the line will be displayed, each <br />in its respective section of the change group.<br /> The unified format is similar to the context format but is more concise. It is specified <br />with the -u option:<br /> 286<br /></p>
<hr />
<p>Comparing Text<br /> [me@linuxbox ~]$ <strong>diff -u file1.txt file2.txt</strong> <br />--- file1.txt<br /> 2008-12-23 06:40:13.000000000 -0500 <br /> +++ file2.txt<br /> 2008-12-23 06:40:34.000000000 -0500 <br /> @@ -1,4 +1,4 @@ <br /> -a <br /> b <br />  c <br /> d <br /> +e<br /> The most notable difference between the context and unified formats is the elimination of <br />the duplicated lines of context, making the results of the unified format shorter than those <br />of the context format. In our example above, we see file timestamps like those of the con-<br />text format, followed by the string @@ -1,4 +1,4 @@. This indicates the lines in the <br />first file and the lines in the second file described in the change group. Following this are <br />the lines themselves, with the default three lines of context. Each line starts with one of <br />three possible characters:<br /> <em>Table 20-6: diff Unified Format Change Indicators</em><br /> <strong>Character</strong><br /> <strong>Meaning</strong><br /> blank<br /> This line is shared by both files.<br /> -<br /> This line was removed from the first file.<br /> +<br /> This line was added to the first file.<br /> patch<br />The patch program is used to apply changes to text files. It accepts output from diff <br />and is generally used to convert older version of files into newer versions. Let’s consider <br />a famous example. The Linux kernel is developed by a large, loosely organized team of <br />contributors who submit a constant stream of small changes to the source code. The <br />Linux kernel consists of several million lines of code, while the changes that are made by <br />one contributor at one time are quite small. It makes no sense for a contributor to send <br />each developer an entire kernel source tree each time a small change is made. Instead, a <br />diff file is submitted. The diff file contains the change from the previous version of the <br />kernel to the new version with the contributor's changes. The receiver then uses the <br />patch program to apply the change to his own source tree. Using diff/patch offers <br />two significant advantages:<br /> 1. The diff file is very small, compared to the full size of the source tree.<br />2. The diff file concisely shows the change being made, allowing reviewers of the <br /> 287<br /></p>
<hr />
<p>20 – Text Processing<br /> patch to quickly evaluate it.<br /> Of course,  diff/patch  will work on any text file, not just source code. It would be <br />equally applicable to configuration files or any other text.<br />To prepare a diff file for use with patch, the GNU documentation (see Further Reading <br />below) suggests using diff as follows:<br />diff -Naur <em>old_file</em> <em>new_file</em> &gt; <em>diff_file<br /></em>Where <em>old_file</em> and <em>new_file</em> are either single files or directories containing files. The r <br />option supports recursion of a directory tree.<br />Once the diff file has been created, we can apply it to patch the old file into the new file:<br />patch &lt; <em>diff_file<br /></em>We’ll demonstrate with our test file:<br /> [me@linuxbox ~]$ <strong>diff -Naur file1.txt file2.txt &gt; patchfile.txt<br /></strong>[me@linuxbox ~]$ <strong>patch &lt; patchfile.txt</strong> <br /> patching file file1.txt<br />[me@linuxbox ~]$ <strong>cat file1.txt</strong> <br /> b <br />c <br /> d <br />e<br /> In  this  example,  we  created  a  diff file  named  patchfile.txt  and then used the <br />patch program to apply the patch. Note that we did not have to specify a target file to <br />patch, as the diff file (in unified format) already contains the filenames in the header. <br />Once the patch is applied, we can see that file1.txt now matches file2.txt.<br /> patch has a large number of options, and there are additional utility programs that can <br />be used to analyze and edit patches.<br /> <strong>Editing On The Fly<br /></strong>Our experience with text editors has been largely <em>interactive</em>, meaning that we manually <br />move a cursor around, then type our changes. However, there are <em>non-interactive</em> ways to <br />edit text as well. It’s possible, for example, to apply a set of changes to multiple files with <br />a single command. <br /> tr<br />The tr program is used to <em>transliterate</em> characters. We can think of this as a sort of char-<br /> 288<br /></p>
<hr />
<p>Editing On The Fly<br /> acter-based search-and-replace operation. Transliteration is the process of changing char-<br />acters from one alphabet to another. For example, converting characters from lowercase <br />to uppercase is transliteration. We can perform such a conversion with tr as follows:<br /> [me@linuxbox ~]$ <strong>echo &quot;lowercase letters&quot; | tr a-z A-Z</strong> <br />LOWERCASE LETTERS<br /> As we can see, tr operates on standard input, and outputs its results on standard output. <br />tr accepts two arguments: a set of characters to convert from and a corresponding set of <br />characters to convert to. Character sets may be expressed in one of three ways:<br /> 1. An enumerated list. For example, ABCDEFGHIJKLMNOPQRSTUVWXYZ<br />2. A character range. For example, A-Z. Note that this method is sometimes subject <br /> to the same issues as other commands, due to the locale collation order, and thus <br />should be used with caution.<br /> 3. POSIX character classes. For example, [:upper:].<br /> In most cases, both character sets should be of equal length; however, it is possible for <br />the first set to be larger than the second, particularly if we wish to convert multiple char-<br />acters to a single character:<br /> [me@linuxbox ~]$ <strong>echo &quot;lowercase letters&quot; | tr [:lower:] A</strong> <br />AAAAAAAAA AAAAAAA<br /> In addition to transliteration,  tr  allows characters to simply be deleted from the input <br />stream. Earlier in this chapter, we discussed the problem of converting MS-DOS text files <br />to Unix-style text. To perform this conversion, carriage return characters need to be re-<br />moved from the end of each line. This can be performed with tr as follows:<br />tr -d '\r' &lt; <em>dos_file</em> &gt; <em>unix_file<br /></em>where <em>dos_file</em> is the file to be converted and <em>unix_file</em> is the result. This form of the com-<br />mand uses the escape sequence  \r  to represent the carriage return character. To see a <br />complete list of the sequences and character classes tr supports, try:<br /> [me@linuxbox ~]$ <strong>tr --help</strong><br /> 289<br /></p>
<hr />
<p>20 – Text Processing<br /> <strong>ROT13: The Not-So-Secret Decoder Ring<br /></strong>One amusing use of tr is to perform <em>ROT13 encoding</em> of text. ROT13 is a trivial <br />type of encryption based on a simple substitution cipher. Calling ROT13 “encryp-<br />tion” is being generous; “text obfuscation” is more accurate. It is used sometimes <br />on text to obscure potentially offensive content. The method simply moves each <br />character 13 places up the alphabet. Since this is half way up the possible 26 char-<br />acters, performing the algorithm a second time on the text restores it to its original <br />form. To perform this encoding with tr:<br /><strong>echo &quot;secret text&quot; | tr a-zA-Z n-za-mN-ZA-M</strong> <br />frperg grkg<br />Performing the same procedure a second time results in the translation:<br /><strong>echo &quot;frperg grkg&quot; | tr a-zA-Z n-za-mN-ZA-M</strong> <br />secret text<br />A number of email programs and Usenet news readers support ROT13 encoding. <br />Wikipedia contains a good article on the subject:<br /><a href="http://en.wikipedia.org/wiki/ROT13">http://en.wikipedia.org/wiki/ROT13</a><br /> tr  can perform another trick, too. Using the  -s  option,  tr  can “squeeze” (delete) re-<br />peated instances of a character:<br /> [me@linuxbox ~]$ <strong>echo &quot;aaabbbccc&quot; | tr -s ab </strong><br /> abccc<br /> Here we have a string containing repeated characters. By specifying the set “ab” to tr, <br />we eliminate the repeated instances of the letters in the set, while leaving the character <br />that is missing from the set (“c”) unchanged. Note that the repeating characters must be <br />adjoining. If they are not:<br /> [me@linuxbox ~]$ <strong>echo &quot;abcabcabc&quot; | tr -s ab</strong> <br /> abcabcabc<br /> the squeezing will have no effect.<br /> sed<br />The name sed is short for <em>stream editor</em>. It performs text editing on a stream of text, ei-<br /> 290<br /></p>
<hr />
<p>Editing On The Fly<br /> ther a set of specified files or standard input. sed is a powerful and somewhat complex <br />program (there are entire books about it), so we will not cover it completely here.<br />In general, the way sed works is that it is given either a single editing command (on the <br />command line) or the name of a script file containing multiple commands, and it then <br />performs these commands upon each line in the stream of text. Here is a very simple ex-<br />ample of sed in action:<br /> [me@linuxbox ~]$ <strong>echo &quot;front&quot; | sed 's/front/back/'<br /></strong>back<br /> In this example, we produce a one-word stream of text using echo and pipe it into sed. <br />sed, in turn, carries out the instruction  s/front/back/ upon the text in the stream <br />and produces the output “back” as a result. We can also recognize this command as re-<br />sembling the “substitution” (search-and-replace) command in vi.<br />Commands in sed begin with a single letter. In the example above, the substitution com-<br />mand is represented by the letter s and is followed by the search-and-replace strings, sep-<br />arated by the slash character as a delimiter. The choice of the delimiter character is arbi-<br />trary. By convention, the slash character is often used, but sed will accept any character <br />that immediately follows the command as the delimiter. We could perform the same com-<br />mand this way:<br /> [me@linuxbox ~]$ <strong>echo &quot;front&quot; | sed 's_front_back_'</strong> <br />back<br /> By using the underscore character immediately after the command, it becomes the delim-<br />iter. The ability to set the delimiter can be used to make commands more readable, as we <br />shall see.<br />Most commands in sed may be preceded by an <em>address</em>, which specifies which line(s) of <br />the input stream will be edited. If the address is omitted, then the editing command is car-<br />ried out on every line in the input stream. The simplest form of address is a line number. <br />We can add one to our example:<br /> [me@linuxbox ~]$ <strong>echo &quot;front&quot; | sed '1s/front/back/' <br /></strong>back<br /> Adding the address 1 to our command causes our substitution to be performed on the first <br /> 291<br /></p>
<hr />
<p>20 – Text Processing<br /> line of our one-line input stream. If we specify another number:<br /> [me@linuxbox ~]$ <strong>echo &quot;front&quot; | sed '2s/front/back/'</strong> <br />front<br /> we see that the editing is not carried out, since our input stream does not have a line 2.<br />Addresses may be expressed in many ways. Here are the most common:<br /> <em>Table 20-7: sed Address Notation</em><br /> <strong>Address</strong><br /> <strong>Description</strong><br /> <em>n</em><br /> A line number where <em>n</em> is a positive integer.<br /> $<br /> The last line.<br /> /<em>regexp</em>/<br /> Lines matching a POSIX basic regular expression. Note that the <br />regular expression is delimited by slash characters. Optionally, <br />the regular expression may be delimited by an alternate <br />character, by specifying the expression with \<em>cregexpc</em>, <br />where <em>c</em> is the alternate character.<br /> <em>addr1</em>,<em>addr2</em><br /> A range of lines from <em>addr1</em> to <em>addr2</em>, inclusive. Addresses may <br />be any of the single address forms above.<br /> <em>first</em>~<em>step</em><br /> Match the line represented by the number <em>first</em>, then each <br />subsequent line at <em>step</em> intervals. For example 1~2 refers to <br />each odd numbered line, 5~5 refers to the fifth line and every <br />fifth line thereafter.<br /> <em>addr1</em>,+n<br /> Match <em>addr1</em> and the following <em>n</em> lines.<br /> <em>addr</em>!<br /> Match all lines except <em>addr</em>, which may be any of the forms <br />above.<br /> We’ll demonstrate different kinds of addresses using the distros.txt file from earlier <br />in this chapter. First, a range of line numbers:<br /> [me@linuxbox ~]$ <strong>sed -n '1,5p' distros.txt</strong> <br />SUSE<br /> 10.2<br /> 12/07/2006 <br /> Fedora<br /> 10<br /> 11/25/2008 <br /> SUSE<br /> 11.0<br /> 06/19/2008 <br /> Ubuntu<br /> 8.04<br /> 04/24/2008 <br /> 292<br /></p>
<hr />
<p>Editing On The Fly<br /> Fedora<br /> 8<br /> 11/08/2007<br /> In this example, we print a range of lines, starting with line 1 and continuing to line 5. To <br />do this, we use the p command, which simply causes a matched line to be printed. For <br />this to be effective however, we must include the option -n (the no auto-print option) to <br />cause sed not to print every line by default.<br />Next, we’ll try a regular expression:<br /> [me@linuxbox ~]$ <strong>sed -n '/SUSE/p' distros.txt</strong> <br /> SUSE<br /> 10.2<br /> 12/07/2006 <br /> SUSE<br /> 11.0<br /> 06/19/2008 <br /> SUSE<br /> 10.3<br /> 10/04/2007 <br /> SUSE<br /> 10.1<br /> 05/11/2006<br /> By including the slash-delimited regular expression /SUSE/, we are able to isolate the <br />lines containing it in much the same manner as grep.<br />Finally, we’ll try negation by adding an exclamation point (!) to the address:<br /> [me@linuxbox ~]$ <strong>sed -n '/SUSE/!p' distros.txt <br /></strong>Fedora<br /> 10<br /> 11/25/2008 <br /> Ubuntu<br /> 8.04<br /> 04/24/2008 <br /> Fedora<br /> 8<br /> 11/08/2007 <br /> Ubuntu<br /> 6.10<br /> 10/26/2006 <br /> Fedora<br /> 7<br /> 05/31/2007 <br /> Ubuntu<br /> 7.10<br /> 10/18/2007 <br /> Ubuntu<br /> 7.04<br /> 04/19/2007 <br /> Fedora<br /> 6<br /> 10/24/2006 <br /> Fedora<br /> 9<br /> 05/13/2008 <br /> Ubuntu<br /> 6.06<br /> 06/01/2006 <br /> Ubuntu<br /> 8.10<br /> 10/30/2008 <br /> Fedora<br /> 5<br /> 03/20/2006<br /> Here we see the expected result: all of the lines in the file except the ones matched by the <br />regular expression.<br />So far, we’ve looked at two of the sed editing commands, s and p. Here is a more com-<br />plete list of the basic editing commands:<br /> <em>Table 20-8: sed Basic Editing Commands</em><br /> <strong>Command</strong><br /> <strong>Description</strong><br /> 293<br /></p>
<hr />
<p>20 – Text Processing<br /> =<br /> Output current line number.<br /> a<br /> Append text after the current line.<br /> d<br /> Delete the current line.<br /> i<br /> Insert text in front of the current line.<br /> p<br /> Print the current line. By default, sed prints every <br />line and only edits lines that match a specified <br />address within the file. The default behavior can <br />be overridden by specifying the -n option.<br /> q<br /> Exit sed without processing any more lines. If the <br />-n option is not specified, output the current line.<br /> Q<br /> Exit sed without processing any more lines.<br /> s/<em>regexp</em>/<em>replacement</em>/<br /> Substitute the contents of <em>replacement</em> wherever <br /><em>regexp</em> is found. <em>replacement</em> may include the <br />special character &amp;, which is equivalent to the text <br />matched by <em>regexp</em>. In addition, <em>replacement</em> may <br />include the sequences \1 through \9, which are <br />the contents of the corresponding subexpressions <br />in <em>regexp</em>. For more about this, see the discussion <br />of <em>back references</em> below. After the trailing slash <br />following <em>replacement</em>, an optional flag may be <br />specified to modify the s command’s behavior.<br /> y/<em>set1</em>/<em>set2</em><br /> Perform transliteration by converting characters <br />from <em>set1</em> to the corresponding characters in <em>set2</em>. <br />Note that unlike tr, sed requires that both sets be <br />of the same length.<br />  <br />The s command is by far the most commonly used editing command. We will demon-<br />strate just some of its power by performing an edit on our distros.txt file. We dis-<br />cussed before how the date field in distros.txt was not in a “computer-friendly” for-<br />mat. While the date is formatted MM/DD/YYYY, it would be better (for ease of sorting) <br />if the format were YYYY-MM-DD. To perform this change on the file by hand would be <br />both time consuming and error prone, but with sed, this change can be performed in one <br />step:<br /> [me@linuxbox ~]$ <strong>sed 's/\([0-9]\{2\}\)\/\([0-9]\{2\}\)\/\([0-9]\{4\}\</strong><br /> 294<br /></p>
<hr />
<p>Editing On The Fly<br /> <strong>)$/\3-\1-\2/' distros.txt</strong> <br />SUSE<br /> 10.2<br /> 2006-12-07 <br /> Fedora<br /> 10<br /> 2008-11-25 <br /> SUSE<br /> 11.0<br /> 2008-06-19 <br /> Ubuntu<br /> 8.04<br /> 2008-04-24 <br /> Fedora<br /> 8<br /> 2007-11-08 <br /> SUSE<br /> 10.3<br /> 2007-10-04 <br /> Ubuntu<br /> 6.10<br /> 2006-10-26 <br /> Fedora<br /> 7<br /> 2007-05-31 <br /> Ubuntu<br /> 7.10<br /> 2007-10-18 <br /> Ubuntu<br /> 7.04<br /> 2007-04-19 <br /> SUSE<br /> 10.1<br /> 2006-05-11 <br /> Fedora<br /> 6<br /> 2006-10-24 <br /> Fedora<br /> 9<br /> 2008-05-13 <br /> Ubuntu<br /> 6.06<br /> 2006-06-01 <br /> Ubuntu<br /> 8.10<br /> 2008-10-30 <br /> Fedora<br /> 5<br /> 2006-03-20<br /> Wow! Now that is an ugly looking command. But it works. In just one step, we have <br />changed the date format in our file. It is also a perfect example of why regular expres-<br />sions are sometimes jokingly referred to as a “write-only” medium. We can write them, <br />but we sometimes cannot read them. Before we are tempted to run away in terror from <br />this command, let’s look at how it was constructed. First, we know that the command will <br />have this basic structure:<br /> <strong>sed 's/<em>regexp</em></strong><strong>/<em>replacement</em></strong><strong>/' distros.txt</strong><br /> Our next step is to figure out a regular expression that will isolate the date. Since it is in <br />MM/DD/YYYY format and appears at the end of the line, we can use an expression like <br />this:<br /> <strong>[0-9]{2}/[0-9]{2}/[0-9]{4}$</strong><br /> which matches two digits, a slash, two digits, a slash, four digits, and the end of line. So <br />that takes care of <em>regexp</em>, but what about <em>replacement</em>? To handle that, we must introduce <br />a new regular expression feature that appears in some applications which use BRE. This <br />feature is called  <em>back references</em>  and works like this: If the sequence \<em>n</em>  appears in  <em>re-<br />placement</em> where <em>n</em> is a number from 1 to 9, the sequence will refer to the corresponding <br />subexpression in the preceding regular expression. To create the subexpressions, we sim-<br />ply enclose them in parentheses like so:<br /> 295<br /></p>
<hr />
<p>20 – Text Processing<br /> <strong>([0-9]{2})/([0-9]{2})/([0-9]{4})$</strong><br /> We now have three subexpressions. The first contains the month, the second contains the <br />day of the month, and the third contains the year. Now we can construct <em>replacement</em> as <br />follows:<br /> <strong>\3-\1-\2</strong><br /> which gives us the year, a dash, the month, a dash, and the day.<br />Now, our command looks like this:<br /> <strong>sed 's/([0-9]{2})/([0-9]{2})/([0-9]{4})$/\3-\1-\2/' distros.txt</strong><br /> We have two remaining problems. The first is that the extra slashes in our regular expres-<br />sion will confuse sed when it tries to interpret the s command. The second is that since <br />sed, by default, accepts only basic regular expressions, several of the characters in our <br />regular expression will be taken as literals, rather than as metacharacters. We can solve <br />both these problems with a liberal application of backslashes to escape the offending <br />characters:<br /> <strong>sed 's/\([0-9]\{2\}\)\/\([0-9]\{2\}\)\/\([0-9]\{4\}\)$/\3-\1-\2/' dis</strong><br /> <strong>tros.txt</strong><br /> And there you have it!<br />Another feature of the  s command is the use of optional flags that may follow the re-<br />placement string. The most important of these is the g flag, which instructs sed to apply <br />the search-and-replace globally to a line, not just to the first instance, which is the default. <br />Here is an example:<br /> [me@linuxbox ~]$ <strong>echo &quot;aaabbbccc&quot; | sed 's/b/B/'</strong> <br /> aaaBbbccc<br /> We see that the replacement was performed, but only to the first instance of the letter “b,” <br />while the remaining instances were left unchanged. By adding the g flag, we are able to <br />change all the instances:<br /> 296<br /></p>
<hr />
<p>Editing On The Fly<br /> [me@linuxbox ~]$ <strong>echo &quot;aaabbbccc&quot; | sed 's/b/B/g'</strong> <br />aaaBBBccc<br /> So far, we have only given sed single commands via the command line. It is also possi-<br />ble to construct more complex commands in a script file using the -f option. To demon-<br />strate, we will use sed with our distros.txt file to build a report. Our report will <br />feature a title at the top, our modified dates, and all the distribution names converted to <br />uppercase. To do this, we will need to write a script, so we’ll fire up our text editor and <br />enter the following:<br /> <strong># sed script to produce Linux distributions report </strong><br /> <strong>1 i\ <br />\</strong><br /> <strong>Linux Distributions Report\ </strong><br /> <strong>s/\([0-9]\{2\}\)\/\([0-9]\{2\}\)\/\([0-9]\{4\}\)$/\3-\1-\2/ <br />y/abcdefghijklmnopqrstuvwxyz/ABCDEFGHIJKLMNOPQRSTUVWXYZ/</strong><br /> We will save our sed script as distros.sed and run it like this:<br /> [me@linuxbox ~]$ <strong>sed -f distros.sed distros.txt</strong><br /> Linux Distributions Report <br /> SUSE<br /> 10.2<br /> 2006-12-07 <br /> FEDORA<br /> 10<br /> 2008-11-25 <br /> SUSE<br /> 11.0<br /> 2008-06-19 <br /> UBUNTU<br /> 8.04<br /> 2008-04-24 <br /> FEDORA<br /> 8<br /> 2007-11-08 <br /> SUSE<br /> 10.3<br /> 2007-10-04 <br /> UBUNTU<br /> 6.10<br /> 2006-10-26 <br /> FEDORA<br /> 7<br /> 2007-05-31 <br /> UBUNTU<br /> 7.10<br /> 2007-10-18 <br /> UBUNTU<br /> 7.04<br /> 2007-04-19 <br /> SUSE<br /> 10.1<br /> 2006-05-11 <br /> FEDORA<br /> 6<br /> 2006-10-24 <br /> FEDORA<br /> 9<br /> 2008-05-13 <br /> UBUNTU<br /> 6.06<br /> 2006-06-01 <br /> UBUNTU<br /> 8.10<br /> 2008-10-30 <br /> FEDORA<br /> 5<br /> 2006-03-20<br /> As we can see, our script produces the desired results, but how does it do it? Let’s take <br /> 297<br /></p>
<hr />
<p>20 – Text Processing<br /> another look at our script. We’ll use cat to number the lines:<br /> [me@linuxbox ~]$ <strong>cat -n distros.sed</strong> <br />    1<br /> # sed script to produce Linux distributions report <br />     2<br />  <br />     3<br /> 1 i\ <br />     4<br /> \ <br />     5<br /> Linux Distributions Report\ <br />     6<br />  <br />     7<br /> s/\([0-9]\{2\}\)\/\([0-9]\{2\}\)\/\([0-9]\{4\}\)<br /> $/\3-\1-\2/ <br />    8<br /> y/abcdefghijklmnopqrstuvwxyz/ABCDEFGHIJKLMNOPQRSTUVWXYZ/<br /> Line one of our script is a <em>comment</em>. Like many configuration files and programming lan-<br />guages on Linux systems, comments begin with the # character and are followed by hu-<br />man-readable text. Comments can be placed anywhere in the script (though not within <br />commands themselves) and are helpful to any humans who might need to identify and/or <br />maintain the script.<br />Line 2 is a blank line. Like comments, blank lines may be added to improve readability.<br />Many sed commands support line addresses. These are used to specify which lines of <br />the input are to be acted upon. Line addresses may be expressed as single line numbers, <br />line number ranges, and the special line number “$” which indicates the last line of input. <br />Lines 3 through 6 contain text to be inserted at the address 1, the first line of the input. <br />The i command is followed by the sequence backslash-carriage return to produce an es-<br />caped carriage return, or what is called a  <em>line-continuation character</em>. This sequence, <br />which can be used in many circumstances including shell scripts, allows a carriage return <br />to be embedded in a stream of text without signaling the interpreter (in this case  sed) <br />that the end of the line has been reached. The i, and likewise, the a (which appends text, <br />rather than inserting it) and  c (which replaces text) commands, allow multiple lines of <br />text as long as each line, except the last, ends with a line-continuation character. The sixth <br />line of our script is actually the end of our inserted text and ends with a plain carriage re-<br />turn rather than a line-continuation character, signaling the end of the i command.<br /> <strong>Note:</strong> A line-continuation character is formed by a backslash followed <em>immediately <br /></em>by a carriage return. No intermediary spaces are permitted.<br /> Line 7 is our search-and-replace command. Since it is not preceded by an address, each <br />line in the input stream is subject to its action.<br />Line 8 performs transliteration of the lowercase letters into uppercase letters. Note that <br /> 298<br /></p>
<hr />
<p>Editing On The Fly<br /> unlike tr, the y command in sed does not support character ranges (for example, [a-<br />z]), nor does it support POSIX character classes. Again, since the y command is not pre-<br />ceded by an address, it applies to every line in the input stream.<br /> <strong>People Who Like sed Also Like...<br /></strong>sed  is a very capable program, able to perform fairly complex editing tasks to <br />streams of text. It is most often used for simple, one-line tasks rather than long <br />scripts. Many users prefer other tools for larger tasks. The most popular of these <br />are awk and perl. These go beyond mere tools like the programs covered here, <br />and extend into the realm of complete programming languages. perl, in particu-<br />lar, is often used in place of shell scripts for many system-management and ad-<br />ministration tasks, as well as being a very popular medium for web development. <br />awk  is a little more specialized. Its specific strength is its ability to manipulate <br />tabular data. It resembles sed in that awk programs normally process text files <br />line-by-line, using a scheme similar to the sed concept of an address followed by <br />an action. While both awk and perl are outside the scope of this book, they are <br />very good skills for the Linux command line user. <br /> aspell<br />The last tool we will look at is aspell, an interactive spelling checker. The aspell <br />program is the successor to an earlier program named ispell, and can be used, for the <br />most part, as a drop-in replacement. While the aspell program is mostly used by other <br />programs that require spell-checking capability, it can also be used very effectively as a <br />stand-alone tool from the command line. It has the ability to intelligently check various <br />type of text files, including  HTML  documents, C/C++ programs, email messages, and <br />other kinds of specialized texts.<br />To spell check a text file containing simple prose, it could be used like this:<br /> aspell check <em>textfile</em><br /> where <em>textfile</em> is the name of the file to check. As a practical example, let’s create a simple <br />text file named foo.txt containing some deliberate spelling errors:<br /> [me@linuxbox ~]$ <strong>cat &gt; foo.txt</strong><br /> 299<br /></p>
<hr />
<p>20 – Text Processing<br /> <strong>The quick brown fox jimped over the laxy dog.</strong><br /> Next we’ll check the file using aspell:<br /> [me@linuxbox ~]$ <strong>aspell check foo.txt</strong><br /> As aspell is interactive in the check mode, we will see a screen like this:<br /> The quick brown fox jimped over the laxy dog.                         <br /> 1) jumped                               6) wimped <br /> 2) gimped                               7) camped <br />3) comped                               8) humped <br /> 4) limped                               9) impede <br />5) pimped                               0) umped <br /> i) Ignore                               I) Ignore all <br />r) Replace                              R) Replace all <br /> a) Add                                  l) Add Lower <br />b) Abort                                x) Exit <br />             <br /> ?<br /> At the top of the display, we see our text with a suspiciously spelled word highlighted. In <br />the middle, we see ten spelling suggestions numbered zero through nine, followed by a <br />list of other possible actions. Finally, at the very bottom, we see a prompt ready to accept <br />our choice.<br />If we press the 1 key, aspell replaces the offending word with the word “jumped” and <br />moves on to the next misspelled word, which is “laxy.” If we select the replacement <br />“lazy,” aspell replaces it and terminates. Once aspell has finished, we can examine <br />our file and see that the misspellings have been corrected:<br /> [me@linuxbox ~]$ <strong>cat foo.txt</strong> <br />The quick brown fox jumped over the lazy dog.<br /> Unless told otherwise via the command line option --dont-backup, aspell creates <br />a backup file containing the original text by appending the extension .bak to the file-<br />name.<br /> 300<br /></p>
<hr />
<p>Editing On The Fly<br /> Showing off our sed editing prowess, we’ll put our spelling mistakes back in so we can <br />reuse our file:<br /> [me@linuxbox ~]$ <strong>sed -i 's/lazy/laxy/; s/jumped/jimped/' foo.txt</strong><br /> The sed option -i tells sed to edit the file “in-place,” meaning that rather than sending <br />the edited output to standard output, it will rewrite the file with the changes applied. We <br />also see the ability to place more than one editing command on the line by separating <br />them with a semicolon.<br />Next, we’ll look at how aspell can handle different kinds of text files. Using a text edi-<br />tor such as  vim  (the adventurous may want to try  sed), we will add some HTML <br />markup to our file:<br /> <strong>&lt;html&gt;</strong><br /> <strong>&lt;head&gt;</strong><br /> <strong>&lt;title&gt;Mispelled HTML file&lt;/title&gt;</strong><br /> <strong>&lt;/head&gt;<br />&lt;body&gt;&lt;p&gt;</strong>The quick brown fox jimped over the laxy dog.<strong>&lt;/p&gt;<br />&lt;/body&gt;</strong><br /> <strong>&lt;/html&gt;</strong><br /> Now, if we try to spell check our modified file, we run into a problem. If we do it this <br />way:<br /> [me@linuxbox ~]$ <strong>aspell check foo.txt</strong><br /> we’ll get this:<br /> &lt;html&gt; <br />        &lt;head&gt; <br />                 &lt;title&gt;Mispelled HTML file&lt;/title&gt; <br />        &lt;/head&gt; <br />         &lt;body&gt; <br />                &lt;p&gt;The quick brown fox jimped over the laxy dog.&lt;/p&gt; <br />         &lt;/body&gt; <br />&lt;/html&gt;                                                               <br /> 301<br /></p>
<hr />
<p>20 – Text Processing<br /> 1) HTML                                 4) Hamel <br />2) ht ml                                5) Hamil <br /> 3) ht-ml                                6) hotel<br /> i) Ignore                               I) Ignore all <br /> r) Replace                              R) Replace all <br />a) Add                                  l) Add Lower <br /> b) Abort                                x) Exit <br /> ?                                                                     <br /> aspell  will see the contents of the HTML tags as misspelled. This problem can be <br />overcome by including the -H (HTML) checking-mode option, like this:<br /> [me@linuxbox ~]$ <strong>aspell -H check foo.txt</strong><br /> which will result in this:<br /> &lt;html&gt; <br />        &lt;head&gt; <br />                 &lt;title&gt;Mispelled HTML file&lt;/title&gt; <br />        &lt;/head&gt; <br />         &lt;body&gt; <br />                &lt;p&gt;The quick brown fox jimped over the laxy dog.&lt;/p&gt; <br />         &lt;/body&gt; <br />&lt;/html&gt; <br /> 1) Mi spelled                           6) Misapplied <br />2) Mi-spelled                           7) Miscalled <br /> 3) Misspelled                           8) Respelled <br />4) Dispelled                            9) Misspell <br /> 5) Spelled                              0) Misled<br />i) Ignore                               I) Ignore all <br /> r) Replace                              R) Replace all <br />a) Add                                  l) Add Lower <br /> b) Abort                                x) Exit <br />             <br /> ?<br /> The HTML is ignored and only the non-markup portions of the file are checked. In this <br />mode, the contents of HTML tags are ignored and not checked for spelling. However, the <br />contents of ALT tags, which benefit from checking, are checked in this mode.<br /> 302<br /></p>
<hr />
<p>Editing On The Fly<br /> <strong>Note:</strong> By default, aspell will ignore URLs and email addresses in text. This be-<br />havior can be overridden with command line options. It is also possible to specify <br />which markup tags are checked and skipped. See the aspell man page for details.<br /> <strong>Summing Up<br /></strong>In this chapter, we have looked at a few of the many command line tools that operate on <br />text. In the next chapter, we will look at several more. Admittedly, it may not seem imme-<br />diately obvious how or why you might use some of these tools on a day-to-day basis, <br />though we have tried to show some semi-practical examples of their use. We will find in <br />later chapters that these tools form the basis of a tool set that is used to solve a host of <br />practical problems. This will be particularly true when we get into shell scripting, where <br />these tools will really show their worth.<br /> <strong>Further Reading<br /></strong>The GNU Project website contains many online guides to the tools discussed in this chap-<br />ter.<br /> ●<br /> From the Coreutils package:<br /><a href="http://www.gnu.org/software/coreutils/manual/coreutils.html#Output-of-entire-files">ht</a><br /> <a href="http://www.gnu.org/software/coreutils/manual/coreutils.html#Output-of-entire-files">  tp://www.gnu.org/software/coreutils/manual/coreutils.html#Output-of-entire - <br />files<br /></a><a href="http://www.gnu.org/software/coreutils/manual/coreutils.html#Operating-on-sorted-files">ht</a><br /> <a href="http://www.gnu.org/software/coreutils/manual/coreutils.html#Operating-on-sorted-files">  tp://www.gnu.org/software/coreutils/manual/coreutils.html#Operating-on - <br />sorted-files<br /></a><a href="http://www.gnu.org/software/coreutils/manual/coreutils.html#Operating-on-fields">http://www.gnu.org/software/coreutils/manual/coreutils.html#Operating-on-fields<br /></a><a href="http://www.gnu.org/software/coreutils/manual/coreutils.html#Operating-on-characters">http://www.gnu.org/software/coreutils/manual/coreutils.html#Operating-on-char-<br />acters</a><br /> ●<br /> From the Diffutils package:<br /><a href="http://www.gnu.org/software/diffutils/manual/html_mono/diff.html">http://www.gnu.org/software/diffutils/manual/html_mono/diff.html</a><br /> ●<br /> sed:<br /><a href="http://www.gnu.org/software/sed/manual/sed.html">http://www.gnu.org/software/sed/manual/sed.html</a><br /> ●<br /> aspell:<br /><a href="http://aspell.net/man-html/index.html">http://aspell.net/man-html/index.html</a><br /> ●<br /> There are many other online resources for sed, in particular:<br /><a href="http://www.grymoire.com/Unix/Sed.html">http://www.grymoire.com/Unix/Sed.html<br /></a><a href="http://sed.sourceforge.net/sed1line.txt">http://sed.sourceforge.net/sed1line.txt</a><br /> ●<br /> Also try googling “sed one liners”, “sed cheat sheets”<br /> 303<br /></p>
<hr />
<p>20 – Text Processing<br /> <strong>Extra Credit<br /></strong>There   are   a   few   more   interesting   text-manipulation   commands   worth   investigating. <br />Among these are: split (split files into pieces), csplit (split files into pieces based <br />on context), and sdiff (side-by-side merge of file differences.)<br /> 304<br /></p>
<hr />
<p>21 – Formatting Output<br /> <em><strong>21 – Formatting Output</strong></em><br /> In this chapter, we continue our look at text-related tools, focusing on programs that are <br />used to format text output, rather than changing the text itself. These tools are often used <br />to prepare text for eventual printing, a subject that we will cover in the next chapter. The <br />programs that we will cover in this chapter include:<br /> ●<br /> nl – Number lines<br /> ●<br /> fold – Wrap each line to a specified length<br /> ●<br /> fmt – A simple text formatter<br /> ●<br /> pr – Prepare text for printing<br /> ●<br /> printf – Format and print data<br /> ●<br /> groff – A document formatting system<br /> <strong>Simple Formatting Tools<br /></strong>We’ll look at some of the simple formatting tools first. These are mostly single-purpose <br />programs, and a bit unsophisticated in what they do, but they can be used for small tasks <br />and as parts of pipelines and scripts.<br /> nl – Number Lines<br />The nl program is a rather arcane tool used to perform a simple task. It numbers lines. In <br />its simplest use, it resembles cat -n:<br /> [me@linuxbox ~]$ <strong>nl distros.txt | head </strong><br />      1<br /> SUSE<br /> 10.2<br /> 12/07/2006 <br />      2<br /> Fedora<br /> 10<br /> 11/25/2008 <br />      3<br /> SUSE<br /> 11.0<br /> 06/19/2008 <br />      4<br /> Ubuntu<br /> 8.04<br /> 04/24/2008 <br />      5<br /> Fedora<br /> 8<br /> 11/08/2007 <br />      6<br /> SUSE<br /> 10.3<br /> 10/04/2007 <br />      7<br /> Ubuntu<br /> 6.10<br /> 10/26/2006 <br /> 305<br /></p>
<hr />
<p>21 – Formatting Output<br />      8<br /> Fedora<br /> 7<br /> 05/31/2007 <br />      9<br /> Ubuntu<br /> 7.10<br /> 10/18/2007 <br />     10<br /> Ubuntu<br /> 7.04<br /> 04/19/2007<br /> Like cat, nl can accept either multiple files as command line arguments, or standard in-<br />put. However, nl has a number of options and supports a primitive form of markup to al-<br />low more complex kinds of numbering.<br /> nl supports a concept called “logical pages” when numbering. This allows nl to reset <br />(start over) the numerical sequence when numbering. Using options, it is possible to set <br />the starting number to a specific value and, to a limited extent, its format. A logical page <br />is further broken down into a header, body, and footer. Within each of these sections, line <br />numbering may be reset and/or be assigned a different style. If nl is given multiple files, <br />it treats them as a single stream of text. Sections in the text stream are indicated by the <br />presence of some rather odd-looking markup added to the text:<br /> <em>Table 21-1: nl Markup</em><br /> <strong>Markup</strong><br /> <strong>Meaning</strong><br /> \:\:\:<br /> Start of logical page header<br /> \:\:<br /> Start of logical page body<br /> \:<br /> Start of logical page footer<br /> Each of the above markup elements must appear alone on its own line. After processing a <br />markup element, nl deletes it from the text stream.<br />Here are the common options for nl:<br /> <em>Table 21-2: Common nl Options</em><br /> <strong>Option</strong><br /> <strong>Meaning</strong><br /> -b <em>style</em><br /> Set body numbering to <em>style</em>, where <em>style</em> is one of the following:<br />a = number all lines<br />t = number only non-blank lines. This is the default.<br />n = none<br />p<em>regexp</em> = number only lines matching basic regular expression <br /><em>regexp</em>.<br /> -f <em>style</em><br /> Set footer numbering to <em>style</em>. Default is n (none).<br /> -h <em>style</em><br /> Set header numbering to <em>style</em>. Default is n (none).<br /> 306<br /></p>
<hr />
<p>Simple Formatting Tools<br /> -i <em>number</em><br /> Set page numbering increment to <em>number</em>. Default is one.<br /> -n <em>format</em><br /> Sets numbering format to <em>format</em>, where format is:<br />ln = left justified, without leading zeros.<br />rn = right justified, without leading zeros. This is the default.<br />rz = right justified, with leading zeros.<br /> -p<br /> Do not reset page numbering at the beginning of each logical page.<br /> -s <em>string</em><br /> Add <em>string</em> to the end of each line number to create a separator. <br />Default is a single tab character.<br /> -v <em>number</em><br /> Set first line number of each logical page to <em>number</em>. Default is one.<br /> -w <em>width</em><br /> Set width of the line number field to <em>width</em>. Default is 6.<br /> Admittedly, we probably won’t be numbering lines that often, but we can use nl to look <br />at how we can combine multiple tools to perform more complex tasks. We will build on <br />our work in the previous chapter to produce a Linux distributions report. Since we will be <br />using nl, it will be useful to include its header/body/footer markup. To do this, we will <br />add it to the sed script from the last chapter. Using our text editor, we will change the <br />script as follows and save it as distros-nl.sed:<br /> # sed script to produce Linux distributions report <br /> 1 i\ <br /><strong>\\:\\:\\:\ </strong><br /> \ <br />Linux Distributions Report\ <br /> <strong>\ <br />Name</strong><br /> <strong>Ver.</strong><br /> <strong>Released\ </strong><br /> <strong>----</strong><br /> <strong>----</strong><br /> <strong>--------\</strong><br /> <strong>\\:\\:</strong> <br /> s/\([0-9]\{2\}\)\/\([0-9]\{2\}\)\/\([0-9]\{4\}\)$/\3-\1-\2/ <br /><strong>$ a\ </strong><br /> <strong>\\:\ <br />\ </strong><br /> <strong>End Of Report</strong><br /> The script now inserts the nl logical page markup and adds a footer at the end of the re-<br />port. Note that we had to double up the backslashes in our markup, because they are nor-<br />mally interpreted as an escape character by sed.<br />Next, we’ll produce our enhanced report by combining sort, sed, and nl:<br /> 307<br /></p>
<hr />
<p>21 – Formatting Output<br /> [me@linuxbox ~]$ <strong>sort -k 1,1 -k 2n distros.txt | sed -f distros-nl.s<br />ed | nl</strong> <br />  <br />       <br />        Linux Distributions Report <br />       <br />        Name     Ver.    Released <br />       ----     ----    -------- <br />      1  Fedora  5       2006-03-20 <br />      2  Fedora  6       2006-10-24 <br />     3  Fedora  7       2007-05-31 <br />      4  Fedora  8       2007-11-08 <br />     5  Fedora  9       2008-05-13 <br />      6  Fedora  10      2008-11-25 <br />     7  SUSE    10.1    2006-05-11 <br />      8  SUSE    10.2    2006-12-07 <br />     9  SUSE    10.3    2007-10-04 <br />     10  SUSE    11.0    2008-06-19 <br />    11  Ubuntu  6.06    2006-06-01 <br />     12  Ubuntu  6.10    2006-10-26 <br />    13  Ubuntu  7.04    2007-04-19 <br />     14  Ubuntu  7.10    2007-10-18 <br />    15  Ubuntu  8.04    2008-04-24 <br />     16  Ubuntu  8.10    2008-10-30 <br />        <br />        End Of Report<br /> Our report is the result of our pipeline of commands. First, we sort the list by distribution <br />name and version (fields 1 and 2), then we process the results with sed, adding the re-<br />port header (including the logical page markup for nl) and footer. Finally, we process the <br />result with nl, which, by default, only numbers the lines of the text stream that belong to <br />the body section of the logical page.<br />We can repeat the command and experiment with different options for nl. Some interest-<br />ing ones are:<br /> <strong>nl -n rz</strong><br /> and <br />  <strong>nl -w 3 -s ' '</strong><br /> 308<br /></p>
<hr />
<p>Simple Formatting Tools<br /> fold – Wrap Each Line To A Specified Length<br /><em>Folding</em> is the process of breaking lines of text at a specified width. Like our other com-<br />mands, fold accepts either one or more text files or standard input. If we send fold a <br />simple stream of text, we can see how it works:<br /> [me@linuxbox ~]$ <strong>echo &quot;The quick brown fox jumped over the lazy dog.&quot; </strong><br /> <strong>| fold -w 12</strong> <br />The quick br <br /> own fox jump <br />ed over the <br /> lazy dog.<br /> Here we see  fold in action. The text sent by the echo command is broken into seg-<br />ments specified by the -w option. In this example, we specify a line width of 12 charac-<br />ters. If no width is specified, the default is 80 characters. Notice how the lines are broken <br />regardless of word boundaries. The addition of the -s option will cause fold to break <br />the line at the last available space before the line width is reached:<br /> [me@linuxbox ~]$ <strong>echo &quot;The quick brown fox jumped over the lazy dog.&quot; </strong><br /> <strong>| fold -w 12 -s</strong> <br />The quick <br /> brown fox <br />jumped over <br /> the lazy <br />dog. <br /> fmt – A Simple Text Formatter<br />The fmt program also folds text, plus a lot more. It accepts either files or standard input <br />and performs paragraph formatting on the text stream. Basically, it fills and joins lines in <br />text while preserving blank lines and indentation.<br />To demonstrate, we’ll need some text. Let’s lift some from the fmt info page:<br />    `fmt' reads from the specified FILE arguments (or standard input <br /> if none are given), and writes to standard output. <br />    By default, blank lines, spaces between words, and indentation are <br /> 309<br /></p>
<hr />
<p>21 – Formatting Output<br /> preserved in the output; successive input lines with different<br />indentation are not joined; tabs are expanded on input and introduced <br /> on output. <br />    `fmt' prefers breaking lines at the end of a sentence, and tries <br />to avoid line breaks after the first word of a sentence or before the <br /> last word of a sentence.  A &quot;sentence break&quot; is defined as either the <br />end of a paragraph or a word ending in any of `.?!', followed by two <br /> spaces or end of line, ignoring any intervening parentheses or <br />quotes.  Like TeX, `fmt' reads entire &quot;paragraphs&quot; before choosing <br /> line breaks; the algorithm is a variant of that given by Donald E. <br />Knuth and Michael F. Plass in &quot;Breaking Paragraphs Into Lines&quot;, <br /> `Software--Practice &amp; Experience' 11, 11 (November 1981), 1119-1184.<br /> We’ll copy this text into our text editor and save the file as fmt-info.txt. Now, let’s <br />say we wanted to reformat this text to fit a fifty character wide column. We could do this <br />by processing the file with fmt and the -w option:<br /> [me@linuxbox ~]$ <strong>fmt -w 50 fmt-info.txt | head </strong><br />    `fmt' reads from the specified FILE arguments <br />   (or standard input if <br /> none are given), and writes to standard output. <br />    By default, blank lines, spaces between words, <br />   and indentation are <br /> preserved in the output; successive input lines <br />with different indentation are not joined; tabs <br /> are expanded on input and introduced on output.<br /> Well, that’s an awkward result. Perhaps we should actually read this text, since it explains <br />what’s going on:<br /> <em>By default, blank lines, spaces between words, and indentation are preserved in the <br />output; successive input lines with different indentation are not joined; tabs are <br />expanded on input and introduced on output.</em><br /> So, fmt is preserving the indentation of the first line. Fortunately, fmt provides an op-<br />tion to correct this:<br /> [me@linuxbox ~]$ <strong>fmt -cw 50 fmt-info.txt</strong> <br />   `fmt' reads from the specified FILE arguments <br /> (or standard input if none are given), and writes <br />to standard output. <br /> 310<br /></p>
<hr />
<p>Simple Formatting Tools<br />    By default, blank lines, spaces between words, <br />and indentation are preserved in the output; <br /> successive input lines with different indentation <br />are not joined; tabs are expanded on input and <br /> introduced on output. <br />    `fmt' prefers breaking lines at the end of a <br />sentence, and tries to avoid line breaks after <br /> the first word of a sentence or before the <br />last word of a sentence.  A &quot;sentence break&quot; <br /> is defined as either the end of a paragraph <br />or a word ending in any of `.?!', followed <br /> by two spaces or end of line, ignoring any <br />intervening parentheses or quotes.  Like TeX, <br /> `fmt' reads entire &quot;paragraphs&quot; before choosing <br />line breaks; the algorithm is a variant of <br /> that given by Donald E. Knuth and Michael F. <br />Plass in &quot;Breaking Paragraphs Into Lines&quot;, <br /> `Software--Practice &amp; Experience' 11, 11 <br />(November 1981), 1119-1184.<br /> Much better. By adding the -c option, we now have the desired result.<br /> fmt has some interesting options:<br /> <em>Table 21-3: fmt Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> -c<br /> Operate in <em>crown margin</em> mode. This preserves the indentation of <br />the first two lines of a paragraph. Subsequent lines are aligned with <br />the indentation of the second line.<br /> -p <em>string</em><br /> Only format those lines beginning with the prefix <em>string</em>. After <br />formatting, the contents of <em>string</em> are prefixed to each reformatted <br />line. This option can be used to format text in source code <br />comments. For example, any programming language or <br />configuration file that uses a “#” character to delineate a comment <br />could be formatted by specifying -p '# ' so that only the <br />comments will be formatted. See the example below.<br /> -s<br /> Split-only mode. In this mode, lines will only be split to fit the <br />specified column width. Short lines will not be joined to fill lines. <br />This mode is useful when formatting text such as code where <br />joining is not desired.<br /> -u<br /> Perform uniform spacing. This will apply traditional “typewriter-<br /> 311<br /></p>
<hr />
<p>21 – Formatting Output<br /> style” formatting to the text. This means a single space between <br />words and two spaces between sentences. This mode is useful for <br />removing “justification,” that is, text that has been padded with <br />spaces to force alignment on both the left and right margins.<br /> -w <em>width</em><br /> Format text to fit within a column <em>width</em> characters wide. The <br />default is 75 characters. Note: fmt actually formats lines slightly <br />shorter than the specified width to allow for line balancing.<br /> The  -p  option is particularly interesting. With it, we can format selected portions of a <br />file, provided that the lines to be formatted all begin with the same sequence of charac-<br />ters. Many programming languages use the pound sign (#) to indicate the beginning of a <br />comment and thus can be formatted using this option. Let’s create a file that simulates a <br />program that uses comments:<br /> [me@linuxbox ~]$ <strong>cat &gt; fmt-code.txt<br /></strong># This file contains code with comments.<br /> # This line is a comment. <br /> # Followed by another comment line. <br /># And another. <br /> This, on the other hand, is a line of code. <br /> And another line of code. <br />And another.<br /> Our sample file contains comments which begin with the string “# “ (a # followed by a <br />space) and lines of “code” which do not. Now, using fmt, we can format the comments <br />and leave the code untouched:<br /> [me@linuxbox ~]$ <strong>fmt -w 50 -p '# ' fmt-code.txt</strong> <br /># This file contains code with comments. <br /> # This line is a comment. Followed by another <br /> # comment line. And another. <br /> This, on the other hand, is a line of code. <br />And another line of code. <br /> And another.<br /> Notice that the adjoining comment lines are joined, while the blank lines and the lines <br />that do not begin with the specified prefix are preserved.<br /> 312<br /></p>
<hr />
<p>Simple Formatting Tools<br /> pr – Format Text For Printing<br />The pr program is used to <em>paginate</em> text. When printing text, it is often desirable to sepa-<br />rate the pages of output with several lines of whitespace, to provide a top and bottom <br />margin for each page. Further, this whitespace can be used to insert a header and footer <br />on each page.<br />We’ll demonstrate pr by formatting our distros.txt file into a series of very short <br />pages (only the first two pages are shown):<br /> [me@linuxbox ~]$ <strong>pr -l 15 -w 65 distros.txt</strong><br /> 2008-12-11 18:27                distros.txt                Page 1 <br /> SUSE<br /> 10.2<br /> 12/07/2006 <br /> Fedora<br /> 10<br /> 11/25/2008 <br /> SUSE<br /> 11.0<br /> 06/19/2008 <br /> Ubuntu<br /> 8.04<br /> 04/24/2008 <br /> Fedora<br /> 8<br /> 11/08/2007 <br /> 2008-12-11 18:27                distros.txt                Page 2 <br /> SUSE<br /> 10.3<br /> 10/04/2007 <br /> Ubuntu<br /> 6.10<br /> 10/26/2006 <br /> Fedora<br /> 7<br /> 05/31/2007 <br /> Ubuntu<br /> 7.10<br /> 10/18/2007 <br /> Ubuntu<br /> 7.04<br /> 04/19/2007<br /> In this example, we employ the  -l  option (for page length) and the  -w  option (page <br />width) to define a “page” that is 65 columns wide and 15 lines long.  pr paginates the <br />contents of the distros.txt file, separates each page with several lines of whitespace <br />and creates a default header containing the file modification time, filename, and page <br />number. The pr program provides many options to control page layout. We’ll take a look <br />at more of them in the next chapter.<br /> 313<br /></p>
<hr />
<p>21 – Formatting Output<br /> printf – Format And Print Data<br />Unlike the other commands in this chapter, the printf command is not used for pipe-<br />lines (it does not accept standard input) nor does it find frequent application directly on <br />the command line (it’s mostly used in scripts). So why is it important? Because it is so <br />widely used.<br /> printf  (from the phrase “print formatted”) was originally developed for the C pro-<br />gramming language and has been implemented in many programming languages includ-<br />ing the shell. In fact, in bash, printf is a builtin.<br /> printf works like this:<br />printf “<em>format</em>” <em>arguments<br /></em>The command is given a string containing a format description which is then applied to a <br />list of arguments. The formatted result is sent to standard output. Here is a trivial exam-<br />ple:<br /> [me@linuxbox ~]$ <strong>printf &quot;I formatted the string: %s\n&quot; foo</strong> <br /> I formatted the string: foo<br /> The format string may contain literal text (like “I formatted the string:”), escape se-<br />quences (such as \n, a newline character), and sequences beginning with the % character, <br />which are called <em>conversion specifications</em>. In the example above, the conversion specifi-<br />cation %s is used to format the string “foo” and place it in the command’s output. Here it <br />is again:<br /> [me@linuxbox ~]$ <strong>printf &quot;I formatted '%s' as a string.\n&quot; foo</strong> <br /> I formatted 'foo' as a string.<br /> As we can see, the %s conversion specification is replaced by the string “foo” in the com-<br />mand’s output. The s conversion is used to format string data. There are other specifiers <br />for other kinds of data. This table lists the commonly used data types:<br /> <em>Table 21-4: Common printf Data Type Specifiers</em><br /> <strong>Specifier</strong><br /> <strong>Description</strong><br /> d<br /> Format a number as a signed decimal integer.<br /> f<br /> Format and output a floating point number.<br /> o<br /> Format an integer as an octal number.<br /> 314<br /></p>
<hr />
<p>Simple Formatting Tools<br /> s<br /> Format a string.<br /> x<br /> Format an integer as a hexadecimal number using lowercase a-f where <br />needed.<br /> X<br /> Same as x but use uppercase letters.<br /> %<br /> Print a literal % symbol (i.e., specify “%%”)<br /> We’ll demonstrate the effect each of the conversion specifiers on the string “380”:<br /> [me@linuxbox ~]$ <strong>printf &quot;%d, %f, %o, %s, %x, %X\n&quot; 380 380 380 380 <br />380 380</strong> <br /> 380, 380.000000, 574, 380, 17c, 17C<br /> Since we specified six conversion specifiers, we must also supply six arguments for <br />printf to process. The six results show the effect of each specifier.<br />Several optional components may be added to the conversion specifier to adjust its out-<br />put. A complete conversion specification may consist of the following:<br />%[<em>flags</em>][<em>width</em>][<em>.precision</em>]conversion_specification<br /> Multiple optional components, when used, must appear in the order specified above to be <br />properly interpreted. Here is a description of each:<br /> <em>Table 21-5: printf Conversion Specification Components</em><br /> <strong>Component</strong><br /> <strong>Description</strong><br /> <em>flags</em><br /> There are five different flags:<br /> # – Use the “alternate format” for output. This varies by data <br />type. For o (octal number) conversion, the output is prefixed with <br />0. For x and X (hexadecimal number) conversions, the output is <br />prefixed with 0x or 0X respectively.<br /> 0–(zero) Pad the output with zeros. This means that the field will <br />be filled with leading zeros, as in “000380”.<br /> - – (dash) Left-align the output. By default, printf right-aligns <br />output.<br /> ‘ ’ – (space) Produce a leading space for positive numbers.<br /> + – (plus sign) Sign positive numbers. By default, printf only <br /> 315<br /></p>
<hr />
<p>21 – Formatting Output<br /> signs negative numbers. <br /> <em>width</em><br /> A number specifying the minimum field width.<br /> <em>.precision</em><br /> For floating point numbers, specify the number of digits of <br />precision to be output after the decimal point. For string <br />conversion, <em>precision</em> specifies the number of characters to <br />output.<br /> Here are some examples of different formats in action:<br /> <em>Table 21-6: print Conversion Specification Examples</em><br /> <strong>Argument</strong><br /> <strong>Format</strong><br /> <strong>Result</strong><br /> <strong>Notes</strong><br /> 380<br /> &quot;%d&quot;<br /> 380<br /> Simple formatting of an <br />integer.<br /> 380<br /> &quot;%#x&quot;<br /> 0x17c<br /> Integer formatted as a <br />hexadecimal number using <br />the “alternate format” flag.<br /> 380<br /> &quot;%05d&quot;<br /> 00380<br /> Integer formatted with <br />leading zeros (padding) <br />and a minimum field width <br />of five characters.<br /> 380<br /> &quot;%05.5f&quot;<br /> 380.00000<br /> Number formatted as a <br />floating point number with <br />padding and five decimal <br />places of precision. Since <br />the specified minimum <br />field width (5) is less than <br />the actual width of the <br />formatted number, the <br />padding has no effect.<br /> 380<br /> &quot;%010.5f&quot;<br /> 0380.00000<br /> By increasing the <br />minimum field width to 10 <br />the padding is now visible.<br /> 380<br /> &quot;%+d&quot;<br /> +380<br /> The + flag signs a positive <br />number.<br /> 380<br /> &quot;%-d&quot;<br /> 380<br /> The - flag left aligns the <br />formatting.<br /> 316<br /></p>
<hr />
<p>Simple Formatting Tools<br /> abcdefghijk<br /> &quot;%5s&quot;<br /> abcedfghijk<br /> A string formatted with a <br />minimum field width.<br /> abcdefghijk<br /> &quot;%.5s&quot;<br /> abcde<br /> By applying precision to a <br />string, it is truncated.<br /> Again,  printf  is used mostly in scripts where it is employed to format  tabular data, <br />rather than on the command line directly. But we can still show how it can be used to <br />solve various formatting problems. First, let’s output some fields separated by tab charac-<br />ters:<br /> [me@linuxbox ~]$ <strong>printf &quot;%s\t%s\t%s\n&quot; str1 str2 str3 <br /></strong>str1 str2<br /> str3<br /> By inserting  \t  (the escape sequence for a tab), we achieve the desired effect. Next, <br />some numbers with neat formatting:<br /> [me@linuxbox ~]$ <strong>printf &quot;Line: %05d %15.3f Result: %+15d\n&quot; 1071 <br />3.14156295 32589</strong> <br /> Line: 01071           3.142 Result:          +32589<br /> This shows the effect of minimum field width on the spacing of the fields. Or how about <br />formatting a tiny web page:<br /> [me@linuxbox ~]$ <strong>printf &quot;&lt;html&gt;\n\t&lt;head&gt;\n\t\t&lt;title&gt;%s&lt;/title&gt;\n</strong><br /> <strong>\t&lt;/head&gt;\n\t&lt;body&gt;\n\t\t&lt;p&gt;%s&lt;/p&gt;\n\t&lt;/body&gt;\n&lt;/html&gt;\n&quot; &quot;Page Tit<br />le&quot; &quot;Page Content&quot;</strong> <br /> &lt;html&gt; <br /> &lt;head&gt; <br /> &lt;title&gt;Page Title&lt;/title&gt; <br /> &lt;/head&gt; <br /> &lt;body&gt; <br /> &lt;p&gt;Page Content&lt;/p&gt; <br /> &lt;/body&gt; <br /> &lt;/html&gt;<br /> <strong>Document Formatting Systems<br /></strong>So far, we have examined the simple text-formatting tools. These are good for small, sim-<br /> 317<br /></p>
<hr />
<p>21 – Formatting Output<br /> ple tasks, but what about larger jobs? One of the reasons that Unix became a popular op-<br />erating system among technical and scientific users (aside from providing a powerful <br />multitasking, multiuser environment for all kinds of software development) is that it of-<br />fered tools that could be used to produce many types of documents, particularly scientific <br />and   academic   publications.   In   fact,   as   the   GNU   documentation   describes,   document <br />preparation was instrumental to the development of Unix:<br /> <em>The first version of UNIX was developed on a PDP-7 which was sitting around Bell  <br />Labs. In 1971 the developers wanted to get a PDP-11 for further work on the  <br />operating system. In order to justify the cost for this system, they proposed that they  <br />would implement a document formatting system for the AT&amp;T patents division. This  <br />first formatting program was a reimplementation of McIllroy's `roff', written by J.  <br />F. Ossanna.</em><br /> Two main families of document formatters dominate the field: those descended from the <br />original  roff  program,   including  nroff  and  troff,   and   those   based   on   Donald <br />Knuth’s  TEX  (pronounced “tek”) typesetting system. And yes, the dropped “E” in the <br />middle is part of its name.<br />The name “roff” is derived from the term “run off” as in, “I’ll run off a copy for you.” <br />The  nroff  program   is   used   to   format   documents   for   output   to   devices   that   use <br />monospaced fonts, such as character terminals and typewriter-style printers. At the time <br />of its introduction, this included nearly all printing devices attached to computers. The <br />later troff program formats documents for output on <em>typesetters</em>, devices used to pro-<br />duce “camera-ready” type for commercial printing. Most computer printers today are able <br />to simulate the output of typesetters. The roff family also includes some other programs <br />that are used to prepare portions of documents. These include  eqn  (for mathematical <br />equations) and tbl (for tables).<br />The TEX system (in stable form) first appeared in 1989 and has, to some degree, dis-<br />placed  troff  as the tool of choice for typesetter output. We won’t be covering TEX <br />here, due both to its complexity (there are entire books about it) and to the fact that it is <br />not installed by default on most modern Linux systems.<br /> <strong>Tip:</strong>  For   those   interested   in   installing  TEX, check out the  texlive  package <br />which can be found in most distribution repositories, and the LyX graphical content <br />editor.<br /> groff<br />groff is a suite of programs containing the GNU implementation of troff. It also in-<br />cludes a script that is used to emulate nroff and the rest of the roff family as well.<br /> 318<br /></p>
<hr />
<p>Document Formatting Systems<br /> While roff and its descendants are used to make formatted documents, they do it in a <br />way that is rather foreign to modern users. Most documents today are produced using <br />word processors that are able to perform both the composition and layout of a document <br />in a single step. Prior to the advent of the graphical word processor, documents were of-<br />ten produced in a two-step process involving the use of a text editor to perform composi-<br />tion, and a processor, such as troff, to apply the formatting. Instructions for the format-<br />ting program were embedded into the composed text through the use of a  markup lan-<br />guage. The modern analog for such a process is the web page, which is composed using a <br />text editor of some kind and then rendered by a web browser using HTML as the markup <br />language to describe the final page layout.<br />We’re not going to cover groff in its entirety, as many elements of its markup language <br />deal with rather arcane details of typography. Instead we will concentrate on one of its <br /><em>macro packages</em> that remains in wide use. These macro packages condense many of its <br />low-level commands into a smaller set of high-level commands that make using groff <br />much easier.<br />For a moment, let’s consider the humble man page. It lives in the /usr/share/man <br />directory as a gzip compressed text file. If we were to examine its uncompressed con-<br />tents, we would see the following (the man page for ls in section 1 is shown):<br /> [me@linuxbox ~]$ <strong>zcat /usr/share/man/man1/ls.1.gz | head</strong> <br />.\&quot; DO NOT MODIFY THIS FILE!  It was generated by help2man 1.35. <br /> .TH LS &quot;1&quot; &quot;April 2008&quot; &quot;GNU coreutils 6.10&quot; &quot;User Commands&quot; <br />.SH NAME <br /> ls \- list directory contents <br />.SH SYNOPSIS <br /> .B ls <br />[\fIOPTION\fR]... [\fIFILE\fR]... <br /> .SH DESCRIPTION <br />.\&quot; Add any additional description here <br /> .PP<br /> Compared to the man page in its normal presentation, we can begin to see a correlation <br />between the markup language and its results:<br /> [me@linuxbox ~]$ <strong>man ls | head </strong><br /> LS(1)                     User Commands                      LS(1) <br /> NAME <br />        ls - list directory contents <br /> 319<br /></p>
<hr />
<p>21 – Formatting Output<br /> SYNOPSIS <br />       ls [OPTION]... [FILE]...<br /> The reason this is of interest is that man pages are rendered by groff, using the man-<br />doc macro package. In fact, we can simulate the man command with the following pipe-<br />line:<br /> [me@linuxbox ~]$ <strong>zcat /usr/share/man/man1/ls.1.gz | groff -mandoc -T <br />ascii | head</strong> <br /> LS(1)                     User Commands                      LS(1) <br /> NAME <br />       ls - list directory contents <br /> SYNOPSIS <br />        ls [OPTION]... [FILE]...<br /> Here we use the  groff  program with the options set to specify the  mandoc  macro <br />package and the output driver for ASCII. groff can produce output in several formats. <br />If no format is specified, PostScript is output by default:<br /> [me@linuxbox ~]$ <strong>zcat /usr/share/man/man1/ls.1.gz | groff -mandoc | </strong><br /> <strong>head <br /></strong>%!PS-Adobe-3.0 <br /> %%Creator: groff version 1.18.1 <br />%%CreationDate: Thu Feb  5 13:44:37 2009 <br /> %%DocumentNeededResources: font Times-Roman <br />%%+ font Times-Bold <br /> %%+ font Times-Italic <br />%%DocumentSuppliedResources: procset grops 1.18 1 <br /> %%Pages: 4 <br />%%PageOrder: Ascend <br /> %%Orientation: Portrait<br /> We briefly mentioned PostScript in the previous chapter, and will again in the next chap-<br />ter. PostScript is a  page description language  that is used to describe the contents of a <br />printed page to a typesetter-like device. If we take the output of our command and store it <br />to a file (assuming that we are using a graphical desktop with a Desktop directory):<br /> 320<br /></p>
<hr />
<p>Document Formatting Systems<br /> [me@linuxbox ~]$ <strong>zcat /usr/share/man/man1/ls.1.gz | groff -mandoc &gt; <br />~/Desktop/foo.ps</strong><br /> An icon for the output file should appear on the desktop. By double-clicking the icon, a <br />page viewer should start up and reveal the file in its rendered form:<br /> <em>Figure 4: Viewing PostScript Output With A Page Viewer In GNOME</em><br /> What we see is a nicely typeset man page for ls! In fact, it’s possible to convert the Post-<br />Script file into a PDF (<em>Portable Document Format</em>) file with this command:<br /> [me@linuxbox ~]$ <strong>ps2pdf ~/Desktop/foo.ps ~/Desktop/ls.pdf</strong><br /> The ps2pdf program is part of the ghostscript package, which is installed on most <br />Linux systems that support printing.<br /> <strong>Tip</strong>: Linux systems often include many command line programs for file format <br /> 321<br /></p>
<hr />
<p>21 – Formatting Output<br /> conversion. They are often named using the convention of <em>format</em>2<em>format</em>. Try us-<br />ing the command  ls /usr/bin/*[[:alpha:]]2[[:alpha:]]*  to iden-<br />tify them. Also try searching for programs named <em>format</em><strong>to</strong><em>format</em>.<br /> For our last exercise with  groff, we will revisit our old friend  distros.txt  once <br />more. This time, we will use the tbl program which is used to format tables to typeset <br />our list of Linux distributions. To do this, we are going to use our earlier sed script to <br />add markup to a text stream that we will feed to groff.<br />First, we need to modify our sed script to add the necessary requests that tbl requires. <br />Using a text editor, we will change distros.sed to the following:<br /> # sed script to produce Linux distributions report <br /> <strong>1 i\ <br />.TS\ </strong><br /> <strong>center box;\ <br />cb s s\ </strong><br /> <strong>cb cb cb\ <br />l n c.\ </strong><br /> <strong>Linux Distributions Report\ <br />=\ </strong><br /> <strong>Name Version</strong><br /> <strong>Released\ </strong><br /> <strong>_ </strong><br /> s/\([0-9]\{2\}\)\/\([0-9]\{2\}\)\/\([0-9]\{4\}\)$/\3-\1-\2/ <br /><strong>$ a\ </strong><br /> <strong>.TE</strong><br /> Note that for the script to work properly, care must been taken to see that the words <br />“Name Version Released” are separated by tabs, not spaces. We’ll save the resulting file <br />as distros-tbl.sed. tbl uses the .TS and .TE requests to start and end the table. <br />The rows following the .TS request define global properties of the table which, for our <br />example, are centered horizontally on the page and surrounded by a box. The remaining <br />lines of the definition describe the layout of each table row. Now, if we run our report-<br />generating pipeline again with the new sed script, we’ll get the following :<br /> [me@linuxbox ~]$ <strong>sort -k 1,1 -k 2n distros.txt | sed -f distros-tbl</strong><br /> <strong>.sed | groff -t -T ascii 2&gt;/dev/null<br /></strong>                 +------------------------------+ <br />                  | <strong>Linux Distributions Report</strong>   | <br />                 +------------------------------+ <br />                  | <strong>Name    Version    Released</strong>  | <br /> 322<br /></p>
<hr />
<p>Document Formatting Systems<br />                  +------------------------------+ <br />                 |Fedora     5       2006-03-20 | <br />                  |Fedora     6       2006-10-24 | <br />                 |Fedora     7       2007-05-31 | <br />                  |Fedora     8       2007-11-08 | <br />                 |Fedora     9       2008-05-13 | <br />                  |Fedora    10       2008-11-25 | <br />                 |SUSE      10.1     2006-05-11 | <br />                  |SUSE      10.2     2006-12-07 | <br />                 |SUSE      10.3     2007-10-04 | <br />                  |SUSE      11.0     2008-06-19 | <br />                 |Ubuntu     6.06    2006-06-01 | <br />                  |Ubuntu     6.10    2006-10-26 | <br />                 |Ubuntu     7.04    2007-04-19 | <br />                  |Ubuntu     7.10    2007-10-18 | <br />                 |Ubuntu     8.04    2008-04-24 | <br />                  |Ubuntu     8.10    2008-10-30 | <br />                 +------------------------------+<br /> Adding the  -t  option to  groff  instructs it to pre-process the text stream with  tbl. <br />Likewise, the -T option is used to output to ASCII rather than the default output medium, <br />PostScript.<br />The format of the output is the best we can expect if we are limited to the capabilities of a <br />terminal screen or typewriter-style printer. If we specify PostScript output and graphically <br />view the resulting output, we get a much more satisfying result:<br /> [me@linuxbox ~]$ <strong>sort -k 1,1 -k 2n distros.txt | sed -f distros-tbl<br />.sed | groff -t &gt; ~/Desktop/foo.ps</strong><br /> 323<br /></p>
<hr />
<p>21 – Formatting Output<br /> <em>Figure 5: Viewing The Finished Table</em><br /> <strong>Summing Up<br /></strong>Given that text is so central to the character of Unix-like operating systems, it makes <br />sense that there would be many tools that are used to manipulate and format text. As we <br />have seen, there are! The simple formatting tools like fmt and pr will find many uses in <br />scripts that produce short documents, while  groff  (and friends) can be used to write <br />books.  We may never write a technical paper using command line tools (though there are <br />many people who do!), but it’s good to know that we could.<br /> <strong>Further Reading</strong><br /> ●<br /> groff User’s Guide<br /><a href="http://www.gnu.org/software/groff/manual/">http://www.gnu.org/software/groff/manual/</a><br /> ●<br /> <em>Writing Papers With nroff Using -me</em>:<br /><a href="http://docs.freebsd.org/44doc/usd/19.memacros/paper.pdf">http://docs.freebsd.org/44doc/usd/19.memacros/paper.pdf</a><br /> ●<br /> <em>-me Reference Manual</em>:<br /> 324<br /></p>
<hr />
<p>Further Reading<br /> <a href="http://docs.freebsd.org/44doc/usd/20.meref/paper.pdf">http://docs.freebsd.org/44doc/usd/20.meref/paper.pdf</a><br /> ●<br /> <em>Tbl – A Program To Format Tables</em>:<br /><a href="http://plan9.bell-labs.com/10thEdMan/tbl.pdf">http://plan9.bell-labs.com/10thEdMan/tbl.pdf</a><br /> ●<br /> And, of course, try the following articles at Wikipedia:<br /><a href="http://en.wikipedia.org/wiki/TeX">http://en.wikipedia.org/wiki/TeX<br /></a><a href="http://en.wikipedia.org/wiki/Donald_Knuth">http://en.wikipedia.org/wiki/Donald_Knuth<br /></a><a href="http://en.wikipedia.org/wiki/Typesetting">http://en.wikipedia.org/wiki/Typesetting</a><br /> 325<br /></p>
<hr />
<p>22 – Printing<br /> <em><strong>22 – Printing</strong></em><br /> After spending the last couple of chapters manipulating text, it’s time to put that text on <br />paper. In this chapter, we’ll look at the command line tools that are used to print files and <br />control printer operation. We won’t be looking at how to configure printing, as that varies <br />from distribution to distribution and is usually set up automatically during installation. <br />Note that we will need a working printer configuration to perform the exercises in this <br />chapter.<br />We will discuss the following commands:<br /> ●<br /> pr – Convert text files for printing<br /> ●<br /> lpr – Print files<br /> ●<br /> a2ps – Format files for printing on a PostScript printer<br /> ●<br /> lpstat – Show printer status information<br /> ●<br /> lpq – Show printer queue status<br /> ●<br /> lprm – Cancel print jobs<br /> <strong>A Brief History Of Printing<br /></strong>To fully understand the printing features found in Unix-like operating systems, we must <br />first learn some history. Printing on Unix-like systems goes way back to the beginning of <br />the operating system itself. In those days, printers and how they were used was much dif-<br />ferent from today.<br /> Printing In The Dim Times<br />Like the computers themselves, printers in the pre-PC era tended to be large, expensive, <br />and centralized. The typical computer user of 1980 worked at a terminal connected to a <br />computer some distance away. The printer was located near the computer and was under <br />the watchful eyes of the computer’s operators.<br />When printers were expensive and centralized, as they often were in the early days of <br />Unix, it was common practice for many users to share a printer. To identify print jobs be-<br /> 326<br /></p>
<hr />
<p>A Brief History Of Printing<br /> longing to a particular user, a  <em>banner page</em>  displaying the name of the user was often <br />printed at the beginning of each print job. The computer support staff would then load up <br />a cart containing the day’s print jobs and deliver them to the individual users.<br /> Character-based Printers<br />The printer technology of the 80s was very different in two respects. First, printers of that <br />period were almost always <em>impact printers</em>. Impact printers use a mechanical mechanism <br />which strikes a ribbon against the paper to form character impressions on the page. Two <br />of the popular technologies of that time were <em>daisy-wheel</em> printing and <em>dot-matrix</em> print-<br />ing.<br />The second, and more important characteristic of early printers was that printers used a <br />fixed set of characters that were intrinsic to the device itself. For example, a daisy-wheel <br />printer could only print the characters actually molded into the petals of the daisy wheel. <br />This made the printers much like high-speed typewriters. As with most typewriters, they <br />printed using  monospaced (fixed width) fonts. This means that each character has the <br />same width. Printing was done at fixed positions on the page, and the printable area of a <br />page contained a fixed number of characters. Most printers printed ten characters per inch <br />(CPI) horizontally and six lines per inch (LPI) vertically. Using this scheme, a US-letter <br />sheet of paper is 85 characters wide and 66 lines high. Taking into account a small margin <br />on each side, 80 characters was considered the maximum width of a print line. This ex-<br />plains why  terminal displays (and our terminal emulators) are normally 80 characters <br />wide. It provides a <em>WYSIWYG</em> (<em>What You See Is What You Get</em>) view of printed output, <br />using a monospaced font.<br />Data is sent to a typewriter-like printer in a simple stream of bytes containing the charac-<br />ters to be printed. For example, to print an “a”, the ASCII character code 97 is sent. In ad-<br />dition, the low-numbered ASCII control codes provided a means of moving the printer’s <br />carriage and paper, using codes for carriage return, line feed, form feed, etc. Using the <br />control codes, it’s possible to achieve some limited font effects, such as boldface, by hav-<br />ing the printer print a character, backspace, and print the character again to get a darker <br />print impression on the page. We can actually witness this if we use nroff to render a <br />man page and examine the output using cat -A:<br /> [me@linuxbox ~]$ <strong>zcat /usr/share/man/man1/ls.1.gz | nroff -man | cat <br />-A | head </strong><br /> LS(1)                       User Commands                      LS(1)<br />$ <br /> $ <br />$ <br /> N^HNA^HAM^HME^HE$ <br />       ls - list directory contents$ <br /> 327<br /></p>
<hr />
<p>22 – Printing<br /> $ <br />S^HSY^HYN^HNO^HOP^HPS^HSI^HIS^HS$ <br />        l^Hls^Hs [_^HO_^HP_^HT_^HI_^HO_^HN]... [_^HF_^HI_^HL_^HE]...$<br /> The ^H (Control-h) characters are the backspaces used to create the boldface effect. Like-<br />wise, we can also see a backspace/underscore sequence used to produce underlining.<br /> Graphical Printers<br />The development of GUIs led to major changes in printer technology. As computers <br />moved to more picture-based displays, printing moved from character-based to graphical <br />techniques. This was facilitated by the advent of the low-cost laser printer which, instead <br />of printing fixed characters, could print tiny dots anywhere in the printable area of the <br />page. This made printing  proportional fonts  (like those used by  typesetters), and even <br />photographs and high-quality diagrams, possible.<br />However, moving from a character-based scheme to a graphical scheme presented a for-<br />midable technical challenge. Here’s why: The number of bytes needed to fill a page using <br />a character-based printer can be calculated this way (assuming 60 lines per page each <br />containing 80 characters):<br />60 X 80 = 4800 bytes<br />In comparison, a 300 dot per inch (DPI) laser printer (assuming an 8 by 10 inch print area <br />per page) requires:<br />(8 X 300) X (10 X 300) / 8 = 900000 bytes<br />Many of the slow PC networks simply could not handle the nearly one megabyte of data <br />required to print a full page on a laser printer, so it was clear that a clever invention was <br />needed.<br />That invention turned out to be the <em>page description language</em> (PDL). A page description <br />language is a programming language that describes the contents of a page. Basically it <br />says,   “go   to   this   position,   draw   the   character   ‘a’  in   10   point   Helvetica,   go   to   this <br />position...” until everything on the page is described. The first major PDL was <em>PostScript <br /></em>from Adobe Systems, which is still in wide use today. The PostScript language is a com-<br />plete programming language tailored for typography and other kinds of graphics and <br />imaging. It includes built-in support for 35 standard, high-quality fonts, plus the ability to <br />accept additional font definitions at run time. At first, support for PostScript was built <br />into the printers themselves. This solved the data transmission problem. While the typical <br />PostScript program was very verbose in comparison to the simple byte stream of charac-<br />ter-based printers, it was much smaller than the number of bytes required to represent the <br />entire printed page.<br />A <em>PostScript printer</em>  accepted a PostScript program as input. The printer contained its <br /> 328<br /></p>
<hr />
<p>A Brief History Of Printing<br /> own processor and memory (oftentimes making the printer a more powerful computer <br />than the computer to which it was attached) and executed a special program called a <br /><em>PostScript interpreter</em>, which read the incoming PostScript program and <em>rendered</em> the re-<br />sults into the printer’s internal memory, thus forming the pattern of bits (dots) that would <br />be transferred to the paper. The generic name for this process of rendering something into <br />a large bit pattern (called a <em>bitmap</em>) is <em>raster image processor</em> or RIP.<br />As the years went by, both computers and networks became much faster. This allowed the <br />RIP to move from the printer to the host computer, which, in turn, permitted high-quality <br />printers to be much less expensive.<br />Many printers today still accept character-based streams, but many low-cost printers do <br />not. They rely on the host computer’s RIP to provide a stream of bits to print as dots. <br />There are still some PostScript printers, too.<br /> <strong>Printing With Linux<br /></strong>Modern Linux systems employ two software suites to perform and manage printing. The <br />first,  CUPS (Common Unix Printing System) provides print drivers and print-job man-<br />agement , and the second, Ghostscript, a PostScript interpreter, acts as a RIP.<br />CUPS manages printers by creating and maintaining print queues. As we discussed in our <br />history  lesson  above,  Unix  printing  was  originally  designed  to  manage  a  centralized <br />printer shared by multiple users. Since printers are slow by nature, compared to the com-<br />puters that are feeding them, printing systems need a way to schedule multiple print jobs <br />and keep things organized. CUPS also has the ability to recognize different types of data <br />(within reason) and can convert files to a printable form.<br /> <strong>Preparing Files For Printing<br /></strong>As command line users, we are mostly interested in printing text, though it is certainly <br />possible to print other data formats as well.<br /> pr – Convert Text Files For Printing<br />We looked at pr a little in the previous chapter. Now we will examine some of its many <br />options used in conjunction with printing. In our history of printing, we saw how charac-<br />ter-based printers use monospaced fonts, resulting in fixed numbers of characters per line <br />and lines per page. pr is used to adjust text to fit on a specific page size, with optional <br />page headers and margins. Here is a summary of its most commonly used options:<br /> <em>Table 22-1: Common pr Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> 329<br /></p>
<hr />
<p>22 – Printing<br /> +<em>first</em>[:<em>last</em>]<br /> Output a range of pages starting with <em>first</em> and, optionally, <br />ending with <em>last</em>.<br /> -<em>columns</em><br /> Organize the content of the page into the number of columns <br />specified by <em>columns</em>.<br /> -a<br /> By default, multicolumn output is listed vertically. By adding <br />the -a (across) option, content is listed horizontally. <br /> -d<br /> Double-space output.<br /> -D “<em>format</em>”<br /> Format the date displayed in page headers using <em>format</em>. See <br />the man page for the date command for a description of the <br />format string.<br /> -f<br /> Use form feeds rather than carriage returns to separate pages.<br /> -h “<em>header</em>”<br /> In the center portion of the page header, use <em>header</em> rather <br />than the name of the file being processed.<br /> -l <em>length</em><br /> Set page length to <em>length</em>. Default is 66 (US letter at 6 lines <br />per inch)<br /> -n<br /> Number lines.<br /> -o <em>offset</em><br /> Create a left margin <em>offset</em> characters wide.<br /> -w <em>width</em><br /> Set page width to <em>width</em>. Default is 72.<br /> pr is often used in pipelines as a filter. In this example, we will produce a directory list-<br />ing of /usr/bin and format it into paginated, three-column output using pr:<br /> [me@linuxbox ~]$  <strong>ls /usr/bin | pr -3 -w 65 | head</strong> <br /> 2009-02-18 14:00                                           Page 1 <br /> [<br />       apturl<br />     bsd-write <br /> 411toppm<br />       ar<br />     bsh <br /> a2p<br />       arecord<br />     btcflash <br /> a2ps<br />       arecordmidi<br />     bug-buddy <br /> a2ps-lpr-wrapper       ark<br />     buildhash<br /> 330<br /></p>
<hr />
<p>Sending A Print Job To A Printer<br /> <strong>Sending A Print Job To A Printer<br /></strong>The CUPS printing suite supports two methods of printing historically used on Unix-like <br />systems. One method, called Berkeley or LPD (used in the Berkeley Software Distribu-<br />tion version of Unix), uses the lpr program, while the other method, called SysV (from <br />the System V version of Unix), uses the lp program. Both programs do roughly the same <br />thing. Choosing one over the other is a matter of personal taste.<br /> lpr – Print Files (Berkeley Style)<br />The lpr program can be used to send files to the printer. It may also used in pipelines, as <br />it accepts standard input. For example, to print the results of our multicolumn directory <br />listing above, we could do this:<br /> [me@linuxbox ~]$ <strong>ls /usr/bin | pr -3 | lpr</strong><br /> and the report would be sent to the system’s default printer. To send the file to a different <br />printer, the -P option can used like this:<br /> <strong>lpr -P <em>printer_name</em></strong><br /> where <em>printer_name</em> is the name of the desired printer. To see a list of printers known to <br />the system:<br /> [me@linuxbox ~]$ <strong>lpstat -a</strong><br /> <strong>Tip:</strong> Many Linux distributions allow you to define a “printer” that outputs files in <br />PDF (Portable Document Format), rather than printing on the physical printer. This <br />is very handy for experimenting with printing commands. Check your printer con-<br />figuration program to see if it supports this configuration. On some distributions, <br />you may need to install additional packages (such as cups-pdf) to enable this ca-<br />pability.<br /> Here are some of the common options for lpr:<br /> 331<br /></p>
<hr />
<p>22 – Printing<br /> <em>Table 22-2: Common lpr Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> -# <em>number</em><br /> Set number of copies to <em>number</em>.<br /> -p<br /> Print each page with a shaded header with the date, time, job <br />name, and page number. This so-called “pretty print” option <br />can be used when printing text files.<br /> -P <em>printer</em><br /> Specify the name of the printer used for output. If no printer is <br />specified, the system’s default printer is used.<br /> -r<br /> Delete files after printing. This would be useful for programs <br />that produce temporary printer-output files.<br /> lp – Print Files (System V Style)<br />Like lpr, lp accepts either files or standard input for printing. It differs from lpr in <br />that it supports a different (and slightly more sophisticated) option set. Here are the com-<br />mon options:<br /> <em>Table 22-3: Common lp Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> -d <em>printer</em><br /> Set the destination (printer) to <em>printer</em>. If no d <br />option is specified, the system default printer is <br />used.<br /> -n <em>number</em><br /> Set the number of copies to <em>number</em>.<br /> -o landscape<br /> Set output to landscape orientation.<br /> -o fitplot<br /> Scale the file to fit the page. This is useful when <br />printing images, such as JPEG files.<br /> -o scaling=<em>number</em><br /> Scale file to <em>number</em>. The value of 100 fills the <br />page. Values less than 100 are reduced, while <br />values greater than 100 cause the file to be printed <br />across multiple pages.<br /> -o cpi=<em>number</em><br /> Set the output characters per inch to <em>number</em>. <br />Default is 10.<br /> -o lpi=<em>number</em><br /> Set the output lines per inch to <em>number</em>. Default is <br />6.<br /> 332<br /></p>
<hr />
<p>Sending A Print Job To A Printer<br /> -o page-bottom=<em>points</em><br /> Set the page margins. Values are expressed in <br /> -o page-left=<em>points</em><br /> <em>points</em>, a unit of typographic measurement. There <br /> -o page-right=<em>points</em><br /> are 72 points to an inch.<br /> -o page-top=<em>points<br /></em>-P <em>pages</em><br /> Specify the list of pages. <em>pages</em> may be expressed <br />as a comma-separated list and/or a range. For <br />example “1,3,5,7-10”<br /> We’ll produce our directory listing again, this time printing 12 CPI and 8 LPI with a left <br />margin of one half inch. Note that we have to adjust the pr options to account for the <br />new page size:<br /> [me@linuxbox ~]$ <strong>ls /usr/bin | pr -4 -w 90 -l 88 | lp -o page-left=36 <br />-o cpi=12 -o lpi=8</strong><br /> This pipeline produces a four-column listing using smaller type than the default. The in-<br />creased number of characters per inch allows us to fit more columns on the page.<br /> Another Option: a2ps<br />The a2ps program is interesting. As we can surmise from its name, it’s a format conver-<br />sion program, but it also much more. Its name originally meant “ASCII  to  PostScript” <br />and it was used to prepare text files for printing on PostScript printers. Over the years, <br />however, the capabilities of the program have grown, and now its name means “Anything <br />to PostScript.”   While its name suggests a format-conversion program, it is actually a <br />printing program. It sends its default output to the system’s default printer rather than <br />standard output. The program’s default behavior is that of a “pretty printer,” meaning that <br />it improves the appearance of output. If we use the program to create a PostScript file on <br />our desktop:<br /> [me@linuxbox ~]$ <strong>ls /usr/bin | pr -3 -t | a2ps -o ~/Desktop/ls.ps -L </strong><br /> <strong>66 <br /></strong>[stdin (plain): 11 pages on 6 sheets] <br /> [Total: 11 pages on 6 sheets] saved into the file `/home/me/Desktop/<br />ls.ps'<br /> Here we filter the stream with pr, using the -t option (omit headers and footers) and <br />then with a2ps, specifying an output file (-o option) and 66 lines per page (-L option) <br /> 333<br /></p>
<hr />
<p>22 – Printing<br /> to match the output pagination of  pr. If we view the resulting file with a suitable file <br />viewer, we will see this:<br /> <em>Figure 6: Viewing a2ps Output</em><br /> As we can see, the default output layout is “two up” format. This causes the contents of 2 <br />pages to be printed on each sheet of paper. a2ps applies nice page headers and footers, <br />too.<br /> a2ps has a lot of options. Here is a summary:<br /> <em>Table 22-4: a2ps Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> --center-title <em>text</em><br /> Set center page title to <em>text</em>.<br /> --columns <em>number</em><br /> Arrange pages into <em>number</em> columns. Default <br />is 2.<br /> 334<br /></p>
<hr />
<p>Sending A Print Job To A Printer<br /> --footer <em>text</em><br /> Set page footer to <em>text</em>.<br /> --guess<br /> Report the types of files given as arguments. <br />Since a2ps tries to convert and format all <br />types of data, this option can be useful for <br />predicting what a2ps will do when given a <br />particular file.<br /> --left-footer <em>text</em><br /> Set left-page footer to <em>text</em>.<br /> --left-title <em>text</em><br /> Set left-page title to <em>text</em>.<br /> --line-numbers=<em>interval</em><br /> Number lines of output every <em>interval</em> lines.<br /> --list=defaults<br /> Display default settings.<br /> --list=<em>topic</em><br /> Display settings for <em>topic</em>, where <em>topic</em> is one <br />of the following: delegations (external <br />programs that will be used to convert data), <br />encodings, features, variables, media (paper <br />sizes and the like), ppd (PostScript printer <br />descriptions), printers, prologues (portions of <br />code that are prefixed to normal output), <br />stylesheets, and user options. <br /> --pages <em>range</em><br /> Print pages in range.<br /> --right-footer <em>text</em><br /> Set right-page footer to <em>text</em>.<br /> --right-title <em>text</em><br /> Set right-page title to <em>text</em>.<br /> --rows <em>number</em><br /> Arrange pages into <em>number</em> rows. Default is <br />one.<br /> -B<br /> No page headers.<br /> -b <em>text</em><br /> Set page header to <em>text</em>.<br /> -f <em>size</em><br /> Use <em>size</em> point font.<br /> -l <em>number</em><br /> Set characters per line to <em>number</em>. This and the <br />-L option (below) can be used to make files <br />paginated with other programs, such as pr, fit <br />correctly on the page. <br /> -L <em>number</em><br /> Set lines per page to <em>number</em>.<br /> -M <em>name</em><br /> Use media name. For example, “A4”.<br /> -n <em>number</em><br /> Output <em>number</em> copies of each page.<br /> 335<br /></p>
<hr />
<p>22 – Printing<br /> -o <em>file</em><br /> Send output to <em>file</em>. If <em>file</em> is specified as “-”, <br />use standard output.<br /> -P <em>printer</em><br /> Use <em>printer</em>. If a printer is not specified, the <br />system default printer is used.<br /> -R<br /> Portrait orientation.<br /> -r<br /> Landscape orientation.<br /> -T <em>number</em><br /> Set tab stops to every <em>number</em> characters.<br /> -u <em>text</em><br /> Underlay (watermark) pages with <em>text</em>.<br /> This is just a summary. a2ps has several more options.<br /> <strong>Note:</strong>  a2ps is still in active development. During my testing, I noticed different <br />behavior on various distributions. On  CentOS  4, output always went to standard <br />output by default. On CentOS 4 and Fedora 10, output defaulted to A4 media, de-<br />spite the program being configured to use letter-size media by default. I could over-<br />come these issues by explicitly specifying the desired option. On  Ubuntu  8.04, <br />a2ps performed as documented.<br /> Also note that there is another output formatter that is useful for converting text <br />into PostScript. Called enscript, it can perform many of the same kinds of for-<br />matting and printing tricks, but unlike a2ps, it only accepts text input.<br /> <strong>Monitoring And Controlling Print Jobs<br /></strong>As Unix printing systems are designed to handle multiple print jobs from multiple users, <br />CUPS is designed to do the same. Each printer is given a  <em>print queue</em>,  where jobs are <br />parked until they can be <em>spooled</em> to the printer. CUPS supplies several command line pro-<br />grams that are used to manage printer status and print queues. Like the lpr and lp pro-<br />grams, these management programs are modeled after the corresponding programs from <br />the Berkeley and System V printing systems.<br /> lpstat – Display Print System Status<br />The lpstat program is useful for determining the names and availability of printers on <br />the   system.   For   example,   if   we   had   a   system   with   both   a   physical   printer   (named <br />“printer”) and a PDF virtual printer (named “PDF”), we could check their status like this:<br /> 336<br /></p>
<hr />
<p>Monitoring And Controlling Print Jobs<br /> [me@linuxbox ~]$ <strong>lpstat -a</strong> <br />PDF accepting requests since Mon 08 Dec 2008 03:05:59 PM EST <br /> printer accepting requests since Tue 24 Feb 2009 08:43:22 AM EST<br /> Further, we could determine a more detailed description of the print system configuration <br />this way:<br /> [me@linuxbox ~]$ <strong>lpstat -s</strong> <br /> system default destination: printer <br />device for PDF: cups-pdf:/ <br /> device for printer: ipp://print-server:631/printers/printer<br /> In this example, we see that “printer” is the system’s default printer and that it is a net-<br />work printer using Internet Printing Protocol (ipp://) attached to a system named “print-<br />server”.<br />The commonly useful options include:<br /> <em>Table 22-5: Common lpstat Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> -a [<em>printer</em>...]<br /> Display the state of the printer queue for <em>printer</em>. Note that <br />this is the status of the printer queue’s ability to accept <br />jobs, not the status of the physical printers. If no printers <br />are specified, all print queues are shown.<br /> -d<br /> Display the name of the system’s default printer.<br /> -p [<em>printer</em>...]<br /> Display the status of the specified <em>printer</em>. If no printers <br />are specified, all printers are shown.<br /> -r<br /> Display the status of the print server.<br /> -s<br /> Display a status summary.<br /> -t<br /> Display a complete status report.<br /> lpq – Display Printer Queue Status<br />To see the status of a printer queue, the lpq program is used. This allows us to view the <br />status of the queue and the print jobs it contains. Here is an example of an empty queue <br />for a system default printer named “printer”:<br /> 337<br /></p>
<hr />
<p>22 – Printing<br /> [me@linuxbox ~]$ <strong>lpq</strong> <br />printer is ready <br /> no entries<br /> If we do not specify a printer (using the -P option), the system’s default printer is shown. <br />If we send a job to the printer and then look at the queue, we will see it listed:<br /> [me@linuxbox ~]$ <strong>ls *.txt | pr -3 | lp</strong> <br /> request id is printer-603 (1 file(s))<br />[me@linuxbox ~]$ <strong>lpq </strong><br /> printer is ready and printing <br />Rank    Owner   Job     File(s)                         Total Size <br /> active  me      603     (stdin)                         1024 bytes<br /> lprm / cancel – Cancel Print Jobs<br />CUPS supplies two programs used to terminate print jobs and remove them from the print <br />queue. One is Berkeley style (lprm) and the other is System V (cancel). They differ <br />slightly in the options they support, but do basically the same thing. Using our print job <br />above as an example, we could stop the job and remove it this way:<br /> [me@linuxbox ~]$ <strong>cancel 603<br /></strong>[me@linuxbox ~]$ <strong>lpq</strong> <br /> printer is ready <br />no entries<br /> Each command has options for removing all the jobs belonging to a particular user, par-<br />ticular printer, and multiple job numbers. Their respective man pages have all the details.<br /> <strong>Summing Up<br /></strong>In this chapter, we have seen how the printers of the past influenced the design of the <br />printing systems on Unix-like machines, and how much control is available on the com-<br />mand line to control not only the scheduling and execution of print jobs, but also the vari-<br />ous output options.<br /> <strong>Further Reading</strong><br /> ●<br /> A good article on the PostScript page description language:<br /><a href="http://en.wikipedia.org/wiki/PostScript">http://en.wikipedia.org/wiki/PostScript</a><br /> 338<br /></p>
<hr />
<p>Further Reading<br /> ●<br /> The Common Unix Printing System (CUPS):<br /><a href="http://en.wikipedia.org/wiki/Common_Unix_Printing_System">http://en.wikipedia.org/wiki/Common_Unix_Printing_System<br /></a><a href="http://www.cups.org/">http://www.cups.org/</a><br /> ●<br /> The Berkeley and System V Printing Systems:<br /><a href="http://en.wikipedia.org/wiki/Berkeley_printing_system">http://en.wikipedia.org/wiki/Berkeley_printing_system<br /></a><a href="http://en.wikipedia.org/wiki/System_V_printing_system">http://en.wikipedia.org/wiki/System_V_printing_system</a><br /> 339<br /></p>
<hr />
<p>23 – Compiling Programs<br /> <em><strong>23 – Compiling Programs</strong></em><br /> In this chapter, we will look at how to build programs by compiling  source code. The <br />availability of source code is the essential freedom that makes Linux possible. The entire <br />ecosystem of Linux development relies on free exchange between developers. For many <br />desktop users, compiling is a lost art. It used to be quite common, but today, distribution <br />providers maintain huge repositories of precompiled binaries, ready to download and use. <br />At the time of this writing, the Debian repository (one of the largest of any of the distri-<br />butions) contains almost 23,000 packages.<br />So why compile software? There are two reasons:<br /> 1. <strong>Availability</strong>. Despite the number of precompiled programs in distribution reposi-<br /> tories, some distributions may not include all the desired applications. In this case, <br />the only way to get the desired program is to compile it from source.<br /> 2. <strong>Timeliness</strong>. While some distributions specialize in cutting edge versions of pro-<br /> grams, many do not. This means that in order to have the very latest version of a <br />program, compiling is necessary.<br /> Compiling software from source code can become very complex and technical; well be-<br />yond the reach of many users. However, many compiling tasks are quite easy and involve <br />only a few steps. It all depends on the package. We will look at a very simple case in or-<br />der to provide an overview of the process and as a starting point for those who wish to <br />undertake further study.<br />We will introduce one new command:<br /> ●<br /> make – Utility to maintain programs<br /> <strong>What Is Compiling?<br /></strong>Simply put, compiling is the process of translating <em>source code</em> (the human-readable de-<br />scription of a program written by a programmer) into the native language of the com-<br />puter’s processor.<br />The computer’s processor (or <em>CPU</em>) works at a very elemental level, executing programs <br />in what is called <em>machine language</em>. This is a numeric code that describes very small op-<br />erations, such as “add this byte,” “point to this location in memory,” or “copy this byte.” <br /> 340<br /></p>
<hr />
<p>What Is Compiling?<br /> Each of these instructions is expressed in binary (ones and zeros). The earliest computer <br />programs were written using this numeric code, which may explain why programmers <br />who wrote it were said to smoke a lot, drink gallons of coffee, and wear thick glasses.<br />This problem was overcome by the advent of <em>assembly language</em>, which replaced the nu-<br />meric codes with (slightly) easier to use character <em>mnemonics</em> such as CPY (for copy) and <br />MOV (for move). Programs written in assembly language are processed into machine <br />language by a program called an  <em>assembler</em>. Assembly language is still used today for <br />certain specialized programming tasks, such as <em>device drivers</em> and <em>embedded systems</em>.<br />We next come to what are called <em>high-level programming languages</em>. They are called this <br />because they allow the programmer to be less concerned with the details of what the pro-<br />cessor is doing and more with solving the problem at hand. The early ones (developed <br />during the 1950s) included  <em>FORTRAN</em>  (designed for scientific and technical tasks) and <br /><em>COBOL</em> (designed for business applications). Both are still in limited use today.<br />While there are many popular programming languages, two predominate. Most programs <br />written for modern systems are written in either <em>C</em> or <em>C++</em>. In the examples to follow, we <br />will be compiling a C program. <br />Programs written in high-level programming languages are converted into machine lan-<br />guage by processing them with another program, called a  <em>compiler</em>. Some compilers <br />translate high-level instructions into assembly language and then use an assembler to per-<br />form the final stage of translation into machine language.<br />A process often used in conjunction with compiling is called  <em>linking</em>. There are many <br />common tasks performed by programs. Take, for instance, opening a file. Many programs <br />perform this task, but it would be wasteful to have each program implement its own rou-<br />tine to open files. It makes more sense to have a single piece of programming that knows <br />how to open files and to allow all programs that need it to share it. Providing support for <br />common tasks is accomplished by what are called <em>libraries</em>. They contain multiple <em>rou-<br />tines</em>, each performing some common task that multiple programs can share. If we look in <br />the /lib and /usr/lib directories, we can see where many of them live. A program <br />called a <em>linker</em> is used to form the connections between the output of the compiler and the <br />libraries that the compiled program requires. The final result of this process is the <em>exe-<br />cutable program file</em>, ready for use.<br /> Are Al  Programs Compiled?<br />No. As we have seen, there are programs such as shell scripts that do not require compil-<br />ing. They are executed directly. These are written in what are known as <em>scripting</em> or <em>inter-<br />preted</em> languages. These languages have grown in popularity in recent years and include <br />P<em>erl</em>, P<em>ython</em>, <em>PHP</em>, R<em>uby</em>, and many others.<br />Scripted languages are executed by a special program called an <em>interpreter</em>. An interpreter <br />inputs the program file and reads and executes each instruction contained within it. In <br /> 341<br /></p>
<hr />
<p>23 – Compiling Programs<br /> general, interpreted programs execute much more slowly than compiled programs. This is <br />because that each source code instruction in an interpreted program is translated every <br />time it is carried out, whereas with a compiled program, a source code instruction is only <br />translated once, and this translation is permanently recorded in the final executable file.<br />So why are interpreted languages so popular? For many programming chores, the results <br />are “fast enough,” but the real advantage is that it is generally faster and easier to develop <br />interpreted programs than compiled programs. Programs are usually developed in a re-<br />peating cycle of code, compile, test. As a program grows in size, the compilation phase of <br />the cycle can become quite long. Interpreted languages remove the compilation step and <br />thus speed up program development.<br /> <strong>Compiling A C Program<br /></strong>Let’s compile something. Before we do that however, we’re going to need some tools like <br />the compiler, the linker, and make. The C compiler used almost universally in the Linux <br />environment is called gcc (GNU C Compiler), originally written by Richard Stallman. <br />Most distributions do not install gcc by default. We can check to see if the compiler is <br />present like this:<br /> [me@linuxbox ~]$ <strong>which gcc<br /></strong>/usr/bin/gcc<br /> The results in this example indicate that the compiler is installed.<br /> <strong>Tip</strong>: Your distribution may have a meta-package (a collection of packages) for soft-<br />ware development. If so, consider installing it if you intend to compile programs on <br />your system. If your system does not provide a meta-package, try installing the <br />gcc and make packages. On many distributions, this is sufficient to carry out the <br />exercise below.<br /> Obtaining The Source Code<br />For our compiling exercise, we are going to compile a program from the  GNU Project <br />called diction. This is a handy little program that checks text files for writing quality <br />and style. As programs go, it is fairly small and easy to build.<br />Following convention, we’re first going to create a directory for our source code named <br />src and then download the source code into it using ftp:<br /> 342<br /></p>
<hr />
<p>Compiling A C Program<br /> [me@linuxbox ~]$ <strong>mkdir src<br /></strong>[me@linuxbox ~]$ <strong>cd src</strong><br /> [me@linuxbox src]$ <a href="ftp://ftp.gnu.org/"><strong>ftp ftp.gnu.org</strong> <br />Connected to ftp.gnu.org. </a><br /> 220 GNU FTP server ready. <br />Name (ftp.gnu.org:me): <strong>anonymous</strong> <br /> 230 Login successful. <br />Remote system type is UNIX. <br /> Using binary mode to transfer files. <br />ftp&gt; <strong>cd gnu/diction</strong> <br /> 250 Directory successfully changed. <br />ftp&gt; <strong>ls</strong> <br /> 200 PORT command successful. Consider using PASV. <br />150 Here comes the directory listing. <br /> -rw-r--r--    1 1003  65534   68940 Aug 28  1998 diction-0.7.tar.gz <br />-rw-r--r--    1 1003  65534   90957 Mar 04  2002 diction-1.02.tar.gz <br /> -rw-r--r--    1 1003  65534  141062 Sep 17  2007 diction-1.11.tar.gz <br />226 Directory send OK. <br /> ftp&gt; <strong>get diction-1.11.tar.gz <br /></strong>local: diction-1.11.tar.gz remote: diction-1.11.tar.gz <br /> 200 PORT command successful. Consider using PASV. <br />150 Opening BINARY mode data connection for diction-1.11.tar.gz <br /> (141062 bytes). <br />226 File send OK. <br /> 141062 bytes received in 0.16 secs (847.4 kB/s) <br />ftp&gt; <strong>bye</strong> <br /> 221 Goodbye. <br />[me@linuxbox src]$ <strong>ls</strong><br /> diction-1.11.tar.gz<br /> <strong>Note:</strong> Since we are the “maintainer” of this source code while we compile it, we <br />will keep it in ~/src. Source code installed by your distribution will be installed <br />in /usr/src, while source code intended for use by multiple users is usually in-<br />stalled in /usr/local/src.<br /> As we can see, source code is usually supplied in the form of a compressed tar file. <br />Sometimes called a <em>tarball</em>, this file contains the <em>source tree</em>, or hierarchy of directories <br />and files that comprise the source code. After arriving at the ftp site, we examine the list <br />of tar files available and select the newest version for download. Using the  get  com-<br />mand within ftp, we copy the file from the ftp server to the local machine.<br />Once the tar file is downloaded, it must be unpacked. This is done with the tar program:<br /> [me@linuxbox src]$ <strong>tar xzf diction-1.11.tar.gz</strong><br /> 343<br /></p>
<hr />
<p>23 – Compiling Programs<br /> [me@linuxbox src]$ <strong>ls<br /></strong>diction-1.11        diction-1.11.tar.gz<br /> <strong>Tip:</strong> The diction program, like all GNU Project software, follows certain stan-<br />dards for source code packaging. Most other source code available in the Linux <br />ecosystem also follows this standard. One element of the standard is that when the <br />source code tar file is unpacked, a directory will be created which contains the <br />source tree, and that this directory will be named <em>project-x.xx</em>, thus containing both <br />the project’s name and its version number. This scheme allows easy installation of <br />multiple versions of the same program. However, it is often a good idea to examine <br />the layout of the tree before unpacking it. Some projects will not create the direc-<br />tory, but instead will deliver the files directly into the current directory. This will <br />make a mess in your otherwise well-organized src directory. To avoid this, use the <br />following command to examine the contents of the tar file:<br /> tar tzvf <em>tarfile</em> | head <br /> Examining The Source Tree<br />Unpacking the tar file results in the creation of a new directory, named diction-1.11. <br />This directory contains the source tree. Let’s look inside:<br /> [me@linuxbox src]$ <strong>cd diction-1.11<br /></strong>[me@linuxbox diction-1.11]$ <strong>ls</strong><br /> config.guess  diction.c        getopt.c      nl <br />config.h.in   diction.pot      getopt.h      nl.po <br /> config.sub    diction.spec     getopt_int.h  README <br />configure     diction.spec.in  INSTALL       sentence.c <br /> configure.in  diction.texi.in  install-sh    sentence.h <br />COPYING       en               Makefile.in   style.1.in <br /> de            en_GB            misc.c        style.c <br />de.po         en_GB.po         misc.h        test <br /> diction.1.in  getopt1.c        NEWS<br /> In it, we see a number of files. Programs belonging to the GNU Project, as well as many <br />others, will supply the documentation files README, INSTALL, NEWS, and COPYING. <br />These files contain the description of the program, information on how to build and in-<br />stall it, and its licensing terms. It is always a good idea to carefully read the README and <br />INSTALL files before attempting to build the program.<br /> 344<br /></p>
<hr />
<p>Compiling A C Program<br /> The other interesting files in this directory are the ones ending with .c and .h:<br /> [me@linuxbox diction-1.11]$ <strong>ls *.c<br /></strong>diction.c  getopt1.c  getopt.c  misc.c  sentence.c  style.c<br /> [me@linuxbox diction-1.11]$ <strong>ls *.h<br /></strong>getopt.h  getopt_int.h  misc.h  sentence.h<br /> The  .c  files contain the two C programs supplied by the package (style  and  dic-<br />tion), divided into modules. It is common practice for large programs to be broken into <br />smaller, easier to manage pieces. The source code files are ordinary text and can be ex-<br />amined with less:<br /> [me@linuxbox diction-1.11]$ <strong>less diction.c</strong><br /> The .h files are known as <em>header files</em>. These, too, are ordinary text. Header files contain <br />descriptions of the routines included in a source code file or library. In order for the com-<br />piler to connect the modules, it must receive a description of all the modules needed to <br />complete the entire program. Near the beginning of the  diction.c  file, we see this <br />line:<br /> #include &quot;getopt.h&quot;<br /> This instructs the compiler to read the file  getopt.h  as it reads the source code in <br />diction.c  in order to “know” what’s in  getopt.c. The  getopt.c  file supplies <br />routines that are shared by both the style and diction programs.<br />Above the include statement for getopt.h, we see some other include statements <br />such as these:<br /> #include &lt;regex.h&gt; <br />#include &lt;stdio.h&gt; <br /> #include &lt;stdlib.h&gt; <br />#include &lt;string.h&gt; <br /> #include &lt;unistd.h&gt;<br /> These also refer to header files, but they refer to header files that live outside the current <br />source tree. They are supplied by the system to support the compilation of every program. <br />If we look in /usr/include, we can see them:<br /> 345<br /></p>
<hr />
<p>23 – Compiling Programs<br /> [me@linuxbox diction-1.11]$ <strong>ls /usr/include</strong><br /> The header files in this directory were installed when we installed the compiler.<br /> Building The Program<br />Most programs build with a simple, two-command sequence:<br /> ./configure<br /> make<br /> The configure program is a shell script which is supplied with the source tree. Its job <br />is to analyze the <em>build environment</em>. Most source code is designed to be <em>portable</em>. That is, <br />it is designed to build on more than one kind of Unix-like system. But in order to do that, <br />the source code may need to undergo slight adjustments during the build to accommodate <br />differences between systems.  configure  also checks to see that necessary external <br />tools and components are installed. Let’s run configure. Since configure is not lo-<br />cated where the shell normally expects programs to be located, we must explicitly tell the <br />shell its location by prefixing the command with ./ to indicate that the program is lo-<br />cated in the current working directory:<br /> [me@linuxbox diction-1.11]$ <strong>./configure</strong><br /> configure will output a lot of messages as it tests and configures the build. When it <br />finishes, it will look something like this:<br /> checking libintl.h presence... yes <br />checking for libintl.h... yes <br /> checking for library containing gettext... none required <br />configure: creating ./config.status <br /> config.status: creating Makefile <br />config.status: creating diction.1 <br /> config.status: creating diction.texi <br />config.status: creating diction.spec <br /> config.status: creating style.1 <br />config.status: creating test/rundiction <br /> config.status: creating config.h<br />[me@linuxbox diction-1.11]$ <br /> 346<br /></p>
<hr />
<p>Compiling A C Program<br /> What’s important here is that there are no error messages. If there were, the configuration <br />failed, and the program will not build until the errors are corrected.<br />We see configure created several new files in our source directory. The most impor-<br />tant one is Makefile. Makefile is a configuration file that instructs the make pro-<br />gram exactly how to build the program. Without it, make will refuse to run. Makefile <br />is an ordinary text file, so we can view it:<br /> [me@linuxbox diction-1.11]$ <strong>less Makefile</strong><br /> The make program takes as input a <em>makefile</em> (which is normally named Makefile), that <br />describes the relationships and dependencies among the components that comprise the <br />finished program.<br />The first part of the makefile defines variables that are substituted in later sections of the <br />makefile. For example we see the line:<br /> CC=             gcc<br /> which defines the C compiler to be  gcc. Later in the makefile, we see one instance <br />where it gets used:<br /> diction:        diction.o sentence.o misc.o getopt.o getopt1.o <br />                $(CC) -o $@ $(LDFLAGS) diction.o sentence.o misc.o \ <br />                 getopt.o getopt1.o $(LIBS)<br /> A substitution is performed here, and the value $(CC) is replaced by gcc at run time.<br />Most of the makefile consists of lines, which define a <em>target</em>, in this case the executable <br />file diction, and the files on which it is dependent. The remaining lines describe the <br />command(s) needed to create the target from its components. We see in this example that <br />the executable file diction (one of the final end products) depends on the existence of <br />diction.o, sentence.o, misc.o, getopt.o, and getopt1.o. Later on, in the <br />makefile, we see definitions of each of these as targets:<br /> diction.o:      diction.c config.h getopt.h misc.h sentence.h <br /> getopt.o:       getopt.c getopt.h getopt_int.h <br />getopt1.o:      getopt1.c getopt.h getopt_int.h <br /> misc.o:         misc.c config.h misc.h <br /> 347<br /></p>
<hr />
<p>23 – Compiling Programs<br /> sentence.o:     sentence.c config.h misc.h sentence.h <br />style.o:        style.c config.h getopt.h misc.h sentence.h<br /> However, we don’t see any command specified for them. This is handled by a general tar-<br />get, earlier in the file, that describes the command used to compile any .c file into a .o <br />file:<br /> .c.o: <br />                $(CC) -c $(CPPFLAGS) $(CFLAGS) $&lt;<br /> This all seems very complicated. Why not simply list all the steps to compile the parts <br />and be done with it? The answer to this will become clear in a moment. In the meantime, <br />let’s run make and build our programs:<br /> [me@linuxbox diction-1.11]$ <strong>make</strong><br /> The make program will run, using the contents of Makefile to guide its actions. It will <br />produce a lot of messages.<br />When it finishes, we will see that all the targets are now present in our directory:<br /> [me@linuxbox diction-1.11]$ <strong>ls</strong> <br /> config.guess   de.po            en            install-sh   sentence.c <br />config.h       diction          en_GB         Makefile     sentence.h <br /> config.h.in    diction.1        en_GB.mo      Makefile.in  sentence.o <br />config.log     diction.1.in     en_GB.po      misc.c       style <br /> config.status  diction.c        getopt1.c     misc.h       style.1 <br />config.sub     diction.o        getopt1.o     misc.o       style.1.in <br /> configure      diction.pot      getopt.c      NEWS         style.c <br />configure.in   diction.spec     getopt.h      nl           style.o <br /> COPYING        diction.spec.in  getopt_int.h  nl.mo        test <br />de             diction.texi     getopt.o      nl.po <br /> de.mo          diction.texi.in  INSTALL       README<br /> Among the files, we see diction and style, the programs that we set out to build. <br />Congratulations are in order! We just compiled our first programs from source code!<br />But just out of curiosity, let’s run make again:<br /> 348<br /></p>
<hr />
<p>Compiling A C Program<br /> [me@linuxbox diction-1.11]$ <strong>make<br /></strong>make: Nothing to be done for `all'.<br /> It only produces this strange message. What’s going on? Why didn’t it build the program <br />again? Ah, this is the magic of  make. Rather than simply building everything again, <br />make only builds what needs building. With all of the targets present, make determined <br />that there was nothing to do. We can demonstrate this by deleting one of the targets and <br />running make again to see what it does. Let’s get rid of one of the intermediate targets:<br /> [me@linuxbox diction-1.11]$ <strong>rm getopt.o<br /></strong>[me@linuxbox diction-1.11]$ <strong>make</strong><br /> We see that make rebuilds it and re-links the diction and style programs, since they <br />depend on the missing module. This behavior also points out another important feature of <br />make: it keeps targets up to date. make insists that targets be newer than their dependen-<br />cies. This makes perfect sense, as a programmer will often update a bit of source code <br />and then use make to build a new version of the finished product. make ensures that ev-<br />erything that needs building based on the updated code is built. If we use the touch pro-<br />gram to “update” one of the source code files, we can see this happen:<br /> [me@linuxbox diction-1.11]$ <strong>ls -l diction getopt.c</strong> <br />-rwxr-xr-x 1 me      me      37164 2009-03-05 06:14 diction <br /> -rw-r--r-- 1 me      me      33125 2007-03-30 17:45 getopt.c<br />[me@linuxbox diction-1.11]$ <strong>touch getopt.c</strong><br /> [me@linuxbox diction-1.11]$ <strong>ls -l diction getopt.c<br /></strong>-rwxr-xr-x 1 me      me      37164 2009-03-05 06:14 diction <br /> -rw-r--r-- 1 me      me      33125 2009-03-05 06:23 getopt.c<br />[me@linuxbox diction-1.11]$ <strong>make</strong><br /> After  make runs, we see that it has restored the target to being newer than the depen-<br />dency:<br /> [me@linuxbox diction-1.11]$ <strong>ls -l diction getopt.c <br /></strong>-rwxr-xr-x 1 me      me      37164 2009-03-05 06:24 diction <br /> -rw-r--r-- 1 me      me      33125 2009-03-05 06:23 getopt.c<br /> The ability of make to intelligently build only what needs building is a great benefit to <br />programmers. While the time savings may not be very apparent with our small project, it <br /> 349<br /></p>
<hr />
<p>23 – Compiling Programs<br /> is very significant with larger projects. Remember, the Linux kernel (a program that un-<br />dergoes   continuous   modification   and   improvement)   contains   several  <em>million</em>  lines   of <br />code.<br /> Installing The Program<br />Well-packaged source code will often include a special  make  target called  install. <br />This target will install the final product in a system directory for use. Usually, this direc-<br />tory is /usr/local/bin, the traditional location for locally built software. However, <br />this directory is not normally writable by ordinary users, so we must become the supe-<br />ruser to perform the installation:<br /> [me@linuxbox diction-1.11]$ <strong>sudo make install</strong><br /> After we perform the installation, we can check that the program is ready to go:<br /> [me@linuxbox diction-1.11]$ <strong>which diction</strong><br /> /usr/local/bin/diction<br />[me@linuxbox diction-1.11]$ <strong>man diction</strong><br /> And there we have it!<br /> <strong>Summing Up<br /></strong>In this chapter, we have seen how three simple commands:<br />./configure<br /> make<br /> make install<br /> can be used to build many source code packages. We have also seen the important role <br />that make plays in the maintenance of programs. The make program can be used for any <br />task that needs to maintain a target/dependency relationship, not just for compiling source <br />code.<br /> <strong>Further Reading</strong><br /> ●<br /> The Wikipedia has good articles on compilers and the make program:<br /><a href="http://en.wikipedia.org/wiki/Compiler">http://en.wikipedia.org/wiki/Compiler<br /></a><a href="http://en.wikipedia.org/wiki/Make_(software)">http://en.wikipedia.org/wiki/Make_(software)</a><br /> 350<br /></p>
<hr />
<p>Further Reading<br /> ●<br /> <em>The GNU Make Manual</em>:<br /><a href="http://www.gnu.org/software/make/manual/html_node/index.html">http://www.gnu.org/software/make/manual/html_node/index.html </a><br /> 351<br /></p>
<hr />
<hr />
<p>Part 4 – Writing Shell Scripts<br /> Part 4 – Writing Shel  Scripts<br /> 353<br /></p>
<hr />
<p>24 – Writing Your First Script<br /> <em><strong>24 – Writing Your First Script</strong></em><br /> In the preceding chapters, we have assembled an arsenal of command line tools. While <br />these tools can solve many kinds of computing problems, we are still limited to manually <br />using them one by one on the command line. Wouldn’t it be great if we could get the <br />shell to do more of the work? We can. By joining our tools together into programs of our <br />own design, the shell can carry out complex sequences of tasks all by itself. We can en-<br />able it to do this by writing <em>shell scripts</em>.<br /> <strong>What Are Shell Scripts?<br /></strong>In the simplest terms, a shell script is a file containing a series of commands. The shell <br />reads this file and carries out the commands as though they have been entered directly on <br />the command line.<br />The shell is somewhat unique, in that it is both a powerful command line interface to the <br />system and a scripting language interpreter. As we will see, most of the things that can be <br />done on the command line can be done in scripts, and most of the things that can be done <br />in scripts can be done on the command line.<br />We have covered many shell features, but we have focused on those features most often <br />used directly on the command line. The shell also provides a set of features usually (but <br />not always) used when writing programs.<br /> <strong>How To Write A Shell Script<br /></strong>To successfully create and run a shell script, we need to do three things:<br /> 1. <strong>Write a script.</strong> Shell scripts are ordinary text files. So we need a text  editor to <br /> write them. The best text editors will provide <em>syntax highlighting</em>, allowing us to <br />see a color-coded view of the elements of the script. Syntax highlighting will help <br />us spot certain kinds of common errors. vim, gedit, kate, and many other edi-<br />tors are good candidates for writing scripts.<br /> 2. <strong>Make the script executable.</strong> The system is rather fussy about not letting any old <br /> text file be treated as a program, and for good reason! We need to set the script <br />file’s permissions to allow execution.<br /> 354<br /></p>
<hr />
<p>How To Write A Shell Script<br /> 3. <strong>Put the script somewhere the shell can find it.</strong> The shell automatically searches <br /> certain directories for executable files when no explicit pathname is specified. For <br />maximum convenience, we will place our scripts in these directories.<br /> <strong>Script File Format<br /></strong>In keeping with programming tradition, we’ll create a “hello world” program to demon-<br />strate an extremely simple script. So let’s fire up our text editors and enter the following <br />script:<br /> <strong>#!/bin/bash</strong><br /> <strong># This is our first script.</strong><br /> <strong>echo 'Hello World!'</strong><br /> The last line of our script is pretty familiar, just an echo command with a string argu-<br />ment. The second line is also familiar. It looks like a comment that we have seen used in <br />many of the configuration files we have examined and edited. One thing about comments <br />in shell scripts is that they may also appear at the ends of lines, like so:<br /> echo 'Hello World!' # This is a comment too<br /> Everything from the # symbol onward on the line is ignored.<br />Like many things, this works on the command line, too:<br /> [me@linuxbox ~]$ <strong>echo 'Hello World!' # This is a comment too</strong> <br />Hello World!<br /> Though comments are of little use on the command line, they will work.<br />The first line of our script is a little mysterious. It looks as if it should be a comment, <br />since it starts with  #, but it looks too purposeful to be just that. The  #!  character se-<br />quence is, in fact, a special construct called a  <em>shebang</em>. The shebang is used to tell the <br />system the name of the interpreter that should be used to execute the script that follows. <br />Every shell script should include this as its first line.<br />Let’s save our script file as hello_world.<br /> 355<br /></p>
<hr />
<p>24 – Writing Your First Script<br /> <strong>Executable Permissions<br /></strong>The next thing we have to do is make our script executable. This is easily done using <br />chmod:<br /> [me@linuxbox ~]$ <strong>ls -l hello_world<br /></strong>-rw-r--r-- 1 me      me      63 2009-03-07 10:10 hello_world<br /> [me@linuxbox ~]$ <strong>chmod 755 hello_world<br /></strong>[me@linuxbox ~]$ <strong>ls -l hello_world </strong><br /> -rwxr-xr-x 1 me      me      63 2009-03-07 10:10 hello_world<br /> There are two common permission settings for scripts; 755 for scripts that everyone can <br />execute, and 700 for scripts that only the owner can execute. Note that scripts must be <br />readable in order to be executed.<br /> <strong>Script File Location<br /></strong>With the permissions set, we can now execute our script:<br /> [me@linuxbox ~]$ <strong>./hello_world</strong><br /> Hello World!<br /> In order for the script to run, we must precede the script name with an explicit path. If we <br />don’t, we get this:<br /> [me@linuxbox ~]$ <strong>hello_world</strong><br /> bash: hello_world: command not found<br /> Why is this? What makes our script different from other programs? As it turns out, noth-<br />ing. Our script is fine. Its location is the problem. Back in Chapter 11, we discussed the <br />PATH environment variable and its effect on how the system searches for executable pro-<br />grams. To recap, the system searches a list of directories each time it needs to find an exe-<br />cutable program, if no explicit path is specified. This is how the system knows to execute <br />/bin/ls when we type ls at the command line. The /bin directory is one of the di-<br />rectories that the system automatically searches. The list of directories is held within an <br />environment variable named PATH. The PATH variable contains a colon-separated list of <br />directories to be searched. We can view the contents of PATH:<br /> 356<br /></p>
<hr />
<p>Script File Location<br /> [me@linuxbox ~]$ <strong>echo $PATH</strong> <br />/home/me/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:<br /> /bin:/usr/games<br /> Here we see our list of directories. If our script were located in any of the directories in <br />the   list,   our   problem   would   be   solved.   Notice   the   first   directory   in   the   list, <br />/home/me/bin. Most Linux distributions configure the  PATH  variable to contain a <br />bin directory in the user’s home directory, to allow users to execute their own programs. <br />So if we create the bin directory and place our script within it, it should start to work <br />like other programs:<br /> [me@linuxbox ~]$ <strong>mkdir bin</strong><br /> [me@linuxbox ~]$ <strong>mv hello_world bin<br /></strong>[me@linuxbox ~]$ <strong>hello_world</strong><br /> Hello World!<br /> And so it does.<br />If the PATH variable does not contain the directory, we can easily add it by including this <br />line in our .bashrc file:<br /> <strong>export PATH=~/bin:&quot;$PATH&quot;</strong><br /> After this change is made, it will take effect in each new terminal session. To apply the <br />change to the current terminal session, we must have the shell re-read the .bashrc file. <br />This can be done by “sourcing” it:<br /> [me@linuxbox ~]$ <strong>. .bashrc</strong><br /> The dot (.) command is a synonym for the  source  command, a shell builtin which <br />reads a specified file of shell commands and treats it like input from the keyboard.<br /> <strong>Note:</strong> Ubuntu automatically adds the ~/bin directory to the PATH variable if the <br />~/bin directory exists when the user’s .bashrc file is executed. So, on Ubuntu <br />systems, if we create the ~/bin directory and then log out and log in again, every-<br />thing works. <br /> 357<br /></p>
<hr />
<p>24 – Writing Your First Script<br /> Good Locations For Scripts<br />The ~/bin directory is a good place to put scripts intended for personal use. If we write <br />a   script   that   everyone   on   a   system   is   allowed   to   use,   the   traditional   location   is <br />/usr/local/bin. Scripts intended for use by the system administrator are often lo-<br />cated in /usr/local/sbin. In most cases, locally supplied software, whether scripts <br />or compiled programs, should be placed in the /usr/local hierarchy and not in /bin <br />or /usr/bin. These directories are specified by the Linux Filesystem Hierarchy Stan-<br />dard to contain only files supplied and maintained by the Linux distributor.<br /> <strong>More Formatting Tricks<br /></strong>One of the key goals of serious script writing is ease of  <em>maintenance</em>;  that is, the ease <br />with which a script may be modified by its author or others to adapt it to changing needs. <br />Making a script easy to read and understand is one way to facilitate easy maintenance.<br /> Long Option Names<br />Many of the commands we have studied feature both short and long option names. For <br />instance, the ls command has many options that can be expressed in either short or long <br />form. For example:<br /> [me@linuxbox ~]$ <strong>ls -ad</strong><br /> and:<br /> [me@linuxbox ~]$ <strong>ls --all --directory</strong> <br /> are equivalent commands. In the interests of reduced typing, short options are preferred <br />when entering options on the command line, but when writing scripts, long options can <br />provide improved readability.<br /> Indentation And line-continuation<br />When employing long commands, readability can be enhanced by spreading the com-<br />mand over several lines. In Chapter 17, we looked at a particularly long example of the <br />find command:<br /> 358<br /></p>
<hr />
<p>More Formatting Tricks<br /> [me@linuxbox ~]$ <strong>find playground \( -type f -not -perm 0600 -exec<br />chmod 0600 ‘{}’ ‘;’ \) -or \( -type d -not -perm 0700 -exec chmod </strong><br /> <strong>0700 ‘{}’ ‘;’ \) </strong><br /> Obviously, this command is a little hard to figure out at first glance. In a script, this com-<br />mand might be easier to understand if written this way:<br /> find playground \<br /> \( \<br /> -type f \<br /> -not -perm 0600 \<br />-exec chmod 0600 ‘{}’ ‘;’ \<br /> \) \<br />-or \<br /> \( \<br /> -type d \<br /> -not -perm 0700 \<br />-exec chmod 0700 ‘{}’ ‘;’ \<br /> \) <br /> By using line-continuations (backslash-linefeed sequences) and indentation, the logic of <br />this complex command is more clearly described to the reader. This technique works on <br />the command line, too, though it is seldom used, as it is very awkward to type and edit. <br />One difference between a script and a command line is that the script may employ tab <br />characters to achieve indentation, whereas the command line cannot, since tabs are used <br />to activate completion.<br /> <strong>Configuring vim For Script Writing<br /></strong>The  vim  text editor has many, many configuration settings. There are several <br />common options that can facilitate script writing:<br /><strong>:syntax on<br /></strong>turns on syntax highlighting. With this setting, different elements of shell syntax <br />will be displayed in different colors when viewing a script. This is helpful for <br />identifying certain kinds of programming errors. It looks cool, too. Note that for <br />this feature to work, you must have a complete version of vim installed, and the <br />file you are editing must have a shebang indicating the file is a shell script. If you <br />have difficulty with the command above, try <strong>:set syntax=sh</strong> instead. <br /><strong>:set hlsearch</strong><br /> 359<br /></p>
<hr />
<p>24 – Writing Your First Script<br /> turns on the option to highlight search results. Say we search for the word “echo.” <br />With this option on, each instance of the word will be highlighted.<br /><strong>:set tabstop=4<br /></strong>sets the number of columns occupied by a tab character. The default is 8 columns. <br />Setting the value to 4 (which is a common practice) allows long lines to fit more <br />easily on the screen.<br /><strong>:set autoindent<br /></strong>turns on the “auto indent” feature. This causes vim to indent a new line the same <br />amount as the line just typed. This speeds up typing on many kinds of program-<br />ming constructs. To stop indentation, type Ctrl-d.<br />These changes can be made permanent by adding these commands (without the <br />leading colon characters) to your ~/.vimrc file.<br /> <strong>Summing Up<br /></strong>In this first chapter of scripting, we have looked at how scripts are written and made to <br />easily execute on our system. We also saw how we may use various formatting tech-<br />niques to improve the readability (and thus, the maintainability) of our scripts. In future <br />chapters, ease of maintenance will come up again and again as a central principle in good <br />script writing.<br /> <strong>Further Reading</strong><br /> ●<br /> For “Hello World” programs and examples in various programming languages, <br />see: <br /><a href="http://en.wikipedia.org/wiki/Hello_world">http://en.wikipedia.org/wiki/Hello_world</a><br /> ●<br /> This Wikipedia article talks more about the shebang mechanism:<br /><a href="http://en.wikipedia.org/wiki/Shebang_(Unix)">http://en.wikipedia.org/wiki/Shebang_(Unix)</a><br /> 360<br /></p>
<hr />
<p>25 – Starting A Project<br /> <em><strong>25 – Starting A Project</strong></em><br /> Starting with this chapter, we will begin to build a program. The purpose of this project is <br />to see how various shell features are used to create programs and, more importantly, cre-<br />ate <em>good</em> programs. <br />The program we will write is a <em>report generator</em>. It will present various statistics about <br />our system and its status, and will produce this report in HTML format, so we can view it <br />with a web browser such as Firefox or Chrome.<br />Programs are usually built up in a series of stages, with each stage adding features and <br />capabilities. The first stage of our program will produce a very minimal HTML page that <br />contains no system information. That will come later.<br /> <strong>First Stage: Minimal Document<br /></strong>The first thing we need to know is the format of a well-formed HTML document. It looks <br />like this:<br /> &lt;HTML&gt;<br /> &lt;HEAD&gt;&lt;TITLE&gt;Page Title&lt;/TITLE&gt;<br />&lt;/HEAD&gt;<br /> &lt;BODY&gt;<br /> Page body.<br /> &lt;/BODY&gt;<br /> &lt;/HTML&gt;<br /> If we enter this into our text editor and save the file as foo.html, we can use the fol-<br />lowing URL in Firefox to view the file:<br />file:///home/<em>username</em>/foo.html<br />The first stage of our program will be able to output this HTML file to standard output. <br />We can write a program to do this pretty easily. Let’s start our text editor and create a new <br />file named ~/bin/sys_info_page:<br /> 361<br /></p>
<hr />
<p>25 – Starting A Project<br /> [me@linuxbox ~]$ <strong>vim ~/bin/sys_info_page</strong><br /> and enter the following program:<br /> <strong>#!/bin/bash </strong><br /> <strong># Program to output a system information page </strong><br /> <strong>echo &quot;&lt;HTML&gt;&quot; </strong><br /> <strong>echo &quot;</strong><br /> <strong>&lt;HEAD&gt;&quot; </strong><br /> <strong>echo &quot;</strong><br /> <strong>&lt;TITLE&gt;Page Title&lt;/TITLE&gt;&quot; </strong><br /> <strong>echo &quot;</strong><br /> <strong>&lt;/HEAD&gt;&quot; </strong><br /> <strong>echo &quot;</strong><br /> <strong>&lt;BODY&gt;&quot; </strong><br /> <strong>echo &quot;</strong><br /> <strong>Page body.&quot; </strong><br /> <strong>echo &quot;</strong><br /> <strong>&lt;/BODY&gt;&quot; </strong><br /> <strong>echo &quot;&lt;/HTML&gt;&quot;</strong><br /> Our first attempt at this problem contains a shebang, a comment (always a good idea) and <br />a sequence of echo commands, one for each line of output. After saving the file, we’ll <br />make it executable and attempt to run it:<br /> [me@linuxbox ~]$ <strong>chmod 755 ~/bin/sys_info_page</strong><br /> [me@linuxbox ~]$ <strong>sys_info_page</strong><br /> When the program runs, we should see the text of the HTML document displayed on the <br />screen, since the echo commands in the script send their output to standard output. We’ll <br />run   the   program   again   and   redirect   the   output   of   the   program   to   the   file <br />sys_info_page.html, so that we can view the result with a web browser:<br /> [me@linuxbox ~]$ <strong>sys_info_page &gt; sys_info_page.html</strong><br /> [me@linuxbox ~]$<strong> firefox sys_info_page.html</strong><br /> So far, so good.<br />When writing programs, it’s always a good idea to strive for simplicity and clarity. Main-<br />tenance is easier when a program is easy to read and understand, not to mention that it <br />can make the program easier to write by reducing the amount of typing. Our current ver-<br />sion of the program works fine, but it could be simpler. We could actually combine all the <br />echo commands into one, which will certainly make it easier to add more lines to the pro-<br />gram’s output. So, let’s change our program to this:<br /> 362<br /></p>
<hr />
<p>First Stage: Minimal Document<br /> #!/bin/bash <br /> # Program to output a system information page <br /> <strong>echo &quot;&lt;HTML&gt; </strong><br /> <strong>&lt;HEAD&gt; </strong><br /> <strong>&lt;TITLE&gt;Page Title&lt;/TITLE&gt; </strong><br /> <strong>&lt;/HEAD&gt; </strong><br /> <strong>&lt;BODY&gt; </strong><br /> <strong>Page body. </strong><br /> <strong>&lt;/BODY&gt; </strong><br /> <strong>&lt;/HTML&gt;&quot;</strong><br /> A quoted string may include newlines, and therefore contain multiple lines of text. The <br />shell will keep reading the text until it encounters the closing quotation mark. It works <br />this way on the command line, too: <br /> [me@linuxbox ~]$ <strong>echo &quot;&lt;HTML&gt; <br /></strong>&gt;         <strong>&lt;HEAD&gt;</strong> <br /> &gt;                 <strong>&lt;TITLE&gt;Page Title&lt;/TITLE&gt;</strong> <br />&gt;         <strong>&lt;/HEAD&gt; </strong><br /> &gt;         <strong>&lt;BODY&gt; <br /></strong>&gt;                 <strong>Page body.</strong> <br /> &gt;         <strong>&lt;/BODY&gt; <br /></strong>&gt; <strong>&lt;/HTML&gt;&quot;</strong><br /> The leading “&gt;” character is the shell prompt contained in the PS2 shell variable. It ap-<br />pears whenever we type a multi-line statement into the shell. This feature is a little ob-<br />scure right now, but later, when we cover multi-line programming statements, it will turn <br />out to be quite handy.<br /> <strong>Second Stage: Adding A Little Data<br /></strong>Now that our program can generate a minimal document, let’s put some data in the re-<br />port.  To do this, we will make the following changes:<br /> #!/bin/bash <br /> # Program to output a system information page <br /> echo &quot;&lt;HTML&gt; <br />        &lt;HEAD&gt; <br />                 &lt;TITLE&gt;<strong>System Information Report</strong>&lt;/TITLE&gt; <br /> 363<br /></p>
<hr />
<p>25 – Starting A Project<br />         &lt;/HEAD&gt; <br />        &lt;BODY&gt; <br />                 &lt;H1&gt;<strong>System Information Report</strong>&lt;/H1&gt; <br />        &lt;/BODY&gt; <br /> &lt;/HTML&gt;&quot;<br /> We added a page title and a heading to the body of the report.<br /> <strong>Variables And Constants<br /></strong>There is an issue with our script, however. Notice how the string “System Information <br />Report” is repeated? With our tiny script it’s not a problem, but let’s imagine that our <br />script was really long and we had multiple instances of this string. If we wanted to <br />change the title to something else, we would have to change it in multiple places, which <br />could be a lot of work. What if we could arrange the script so that the string only ap -<br />peared once and not multiple times? That would make future maintenance of the script <br />much easier. Here’s how we could do that:<br /> #!/bin/bash <br /> # Program to output a system information page <br /> <strong>title=&quot;System Information Report&quot; </strong><br /> echo &quot;&lt;HTML&gt; <br />         &lt;HEAD&gt; <br />                &lt;TITLE&gt;<strong>$title</strong>&lt;/TITLE&gt; <br />         &lt;/HEAD&gt; <br />        &lt;BODY&gt; <br />                 &lt;H1&gt;<strong>$title</strong>&lt;/H1&gt; <br />        &lt;/BODY&gt; <br /> &lt;/HTML&gt;&quot;<br /> By creating a <em>variable</em> named title and assigning it the value “System Information Re-<br />port”, we can take advantage of parameter expansion and place the string in multiple lo-<br />cations.<br />So, how do we create a variable? Simple, we just use it. When the shell encounters a vari-<br />able, it automatically creates it. This differs from many programming languages in which <br />variables must be explicitly <em>declared</em> or defined before use. The shell is very lax about <br />this, which can lead to some problems. For example, consider this scenario played out on <br />the command line:<br /> 364<br /></p>
<hr />
<p>Variables And Constants<br /> [me@linuxbox ~]$ <strong>foo=&quot;yes&quot;<br /></strong>[me@linuxbox ~]$ <strong>echo $foo</strong><br /> yes<br />[me@linuxbox ~]$ <strong>echo $fool</strong><br /> [me@linuxbox ~]$ <br /> We first assign the value “yes” to the variable foo, and then display its value with echo. <br />Next we display the value of the variable name misspelled as “fool” and get a blank re-<br />sult. This is because the shell happily created the variable fool when it encountered it, <br />and gave it the default value of nothing, or empty. From this, we learn that we must pay <br />close attention to our spelling! It’s also important to understand what really happened in <br />this example. From our previous look at how the shell performs  expansions, we know <br />that the command:<br /> [me@linuxbox ~]$ echo $foo<br /> undergoes parameter expansion and results in:<br /> [me@linuxbox ~]$ echo yes<br /> Whereas the command:<br /> [me@linuxbox ~]$ echo $fool<br /> expands into:<br /> [me@linuxbox ~]$ echo<br /> The empty variable expands into nothing! This can play havoc with commands that re-<br />quire arguments. Here’s an example:<br /> [me@linuxbox ~]$ <strong>foo=foo.txt<br /></strong>[me@linuxbox ~]$ <strong>foo1=foo1.txt</strong><br /> [me@linuxbox ~]$ <strong>cp $foo $fool<br /></strong>cp: missing destination file operand after `foo.txt' <br /> 365<br /></p>
<hr />
<p>25 – Starting A Project<br /> Try `cp --help' for more information.<br /> We assign values to two variables, foo and foo1. We then perform a cp, but misspell <br />the name of the second argument. After expansion, the cp command is only sent one ar-<br />gument, though it requires two.<br />There are some rules about variable names:<br /> 1. Variable names may consist of alphanumeric characters (letters and numbers) and <br /> underscore characters.<br /> 2. The first character of a variable name must be either a letter or an underscore.<br />3. Spaces and punctuation symbols are not allowed.<br /> The word “variable” implies a value that changes, and in many applications, variables are <br />used this way. However, the variable in our application, title, is used as a <em>constant</em>. A <br />constant is just like a variable in that it has a name and contains a value. The difference is <br />that the value of a constant does not change. In an application that performs geometric <br />calculations, we might define PI as a constant, and assign it the value of 3.1415, in-<br />stead of using the number literally throughout our program. The shell makes no distinc-<br />tion between variables and constants; they are mostly for the programmer’s convenience. <br />A common convention is to use uppercase letters to designate constants and lower case <br />letters for true variables. We will modify our script to comply with this convention: <br /> #!/bin/bash <br /> # Program to output a system information page <br /> <strong>TITLE</strong>=&quot;System Information Report <strong>For $HOSTNAME</strong>&quot; <br /> echo &quot;&lt;HTML&gt; <br />         &lt;HEAD&gt; <br />                &lt;TITLE&gt;$<strong>TITLE</strong>&lt;/TITLE&gt; <br />         &lt;/HEAD&gt; <br />        &lt;BODY&gt; <br />                 &lt;H1&gt;$<strong>TITLE</strong>&lt;/H1&gt; <br />        &lt;/BODY&gt; <br /> &lt;/HTML&gt;&quot;<br /> We also took the opportunity to jazz up our title by adding the value of the shell variable <br />HOSTNAME. This is the network name of the machine.<br /> 366<br /></p>
<hr />
<p>Variables And Constants<br /> <strong>Note</strong>: The shell actually does provide a way to enforce the immutability of con-<br />stants, through the use of the declare builtin command with the -r (read-only) <br />option. Had we assigned TITLE this way:<br /> declare -r TITLE=&quot;Page Title&quot;<br /> the shell would prevent any subsequent assignment to TITLE. This feature is rarely <br />used, but it exists for very formal scripts.<br /> Assigning Values To Variables And Constants<br />Here is where our knowledge of expansion really starts to pay off. As we have seen, vari-<br />ables are assigned values this way:<br /><em>variable</em>=<em>value<br /></em>where <em>variable</em> is the name of the variable and <em>value</em> is a string. Unlike some other pro-<br />gramming languages, the shell does not care about the type of data assigned to a variable; <br />it treats them all as strings. You can force the shell to restrict the assignment to integers <br />by using the declare command with the -i option, but, like setting variables as read-<br />only, this is rarely done.<br />Note that in an assignment, there must be no spaces between the variable name, the <br />equals sign, and the value. So what can the value consist of? Anything that we can ex-<br />pand into a string:<br /> a=z<br /> # Assign the string &quot;z&quot; to variable a. <br /> b=&quot;a string&quot;<br /> # Embedded spaces must be within quotes. <br /> c=&quot;a string and $b&quot;<br /> # Other expansions such as variables can be  <br /># expanded into the assignment. <br /> d=$(ls -l foo.txt)<br /> # Results of a command. <br /> e=$((5 * 7))<br /> # Arithmetic expansion.<br /> f=&quot;\t\ta string\n&quot;<br /> # Escape sequences such as tabs and newlines.<br /> Multiple variable assignments may be done on a single line:<br /> a=5 b=&quot;a string&quot;<br /> During expansion, variable names may be surrounded by optional curly braces “{}”. This <br />is useful in cases where a variable name becomes ambiguous due to its surrounding con-<br /> 367<br /></p>
<hr />
<p>25 – Starting A Project<br /> text. Here, we try to change the name of a file from myfile to myfile1, using a vari-<br />able:<br /> [me@linuxbox ~]$ <strong>filename=&quot;myfile&quot;<br /></strong>[me@linuxbox ~]$ <strong>touch $filename</strong><br /> [me@linuxbox ~]$ <strong>mv $filename $filename1<br /></strong>mv: missing destination file operand after `myfile' <br /> Try `mv --help' for more information.<br /> This attempt fails because the shell interprets the second argument of the mv command as <br />a new (and empty) variable. The problem can be overcome this way:<br /> [me@linuxbox ~]$ <strong>mv $filename ${filename}1</strong><br /> By adding the surrounding braces, the shell no longer interprets the trailing 1 as part of <br />the variable name.<br />We’ll take this opportunity to add some data to our report, namely the date and time the <br />report was created and the username of the creator:<br /> #!/bin/bash <br /> # Program to output a system information page <br /> TITLE=&quot;System Information Report For $HOSTNAME&quot; <br /><strong>CURRENT_TIME=$(date +&quot;%x %r %Z&quot;)</strong> <br /> <strong>TIMESTAMP=&quot;Generated $CURRENT_TIME, by $USER&quot;</strong> <br /> echo &quot;&lt;HTML&gt; <br />        &lt;HEAD&gt; <br />                 &lt;TITLE&gt;$TITLE&lt;/TITLE&gt; <br />        &lt;/HEAD&gt; <br />         &lt;BODY&gt; <br />                &lt;H1&gt;$TITLE&lt;/H1&gt; <br />                 <strong>&lt;P&gt;$TIMESTAMP&lt;/P&gt; <br /></strong>        &lt;/BODY&gt; <br /> &lt;/HTML&gt;&quot; <br /> <strong>Here Documents<br /></strong>We’ve looked at two different methods of outputting our text, both using the echo com-<br /> 368<br /></p>
<hr />
<p>Here Documents<br /> mand. There is a third way called a <em>here document</em> or <em>here script</em>. A here document is an <br />additional form of I/O redirection in which we embed a body of text into our script and <br />feed it into the standard input of a command. It works like this:<br /><em>command</em> &lt;&lt; <em>token<br /></em>text<br /><em>token<br /></em>where <em>command</em> is the name of command that accepts standard input and <em>token</em> is a string <br />used to indicate the end of the embedded text. We’ll modify our script to use a here docu-<br />ment:<br /> #!/bin/bash <br /> # Program to output a system information page <br /> TITLE=&quot;System Information Report For $HOSTNAME&quot; <br />CURRENT_TIME=$(date +&quot;%x %r %Z&quot;) <br /> TIMESTAMP=&quot;Generated $CURRENT_TIME, by $USER&quot;<br /> <strong>cat &lt;&lt; _EOF_ <br /></strong>&lt;HTML&gt; <br />         &lt;HEAD&gt; <br />                &lt;TITLE&gt;$TITLE&lt;/TITLE&gt; <br />         &lt;/HEAD&gt; <br />        &lt;BODY&gt; <br />                 &lt;H1&gt;$TITLE&lt;/H1&gt; <br />                &lt;P&gt;$TIMESTAMP&lt;/P&gt;<br />         &lt;/BODY&gt; <br />&lt;/HTML&gt; <br /> <strong>_EOF_</strong><br /> Instead of using echo, our script now uses cat and a here document. The string _EOF_ <br />(meaning “End Of File,” a common convention) was selected as the token, and marks the <br />end of the embedded text. Note that the token must appear alone and that there must not <br />be trailing spaces on the line.<br />So what’s the advantage of using a here document? It’s mostly the same as echo, except <br />that, by default, single and double quotes within here documents lose their special mean-<br />ing to the shell. Here is a command line example:<br /> [me@linuxbox ~]$ <strong>foo=&quot;some text&quot;</strong><br /> [me@linuxbox ~]$ <strong>cat &lt;&lt; _EOF_</strong> <br />&gt; <strong>$foo</strong> <br /> 369<br /></p>
<hr />
<p>25 – Starting A Project<br /> &gt; <strong>&quot;$foo&quot;</strong> <br />&gt; <strong>'$foo'</strong> <br /> &gt; <strong>\$foo</strong> <br />&gt; <strong>_EOF_ </strong><br /> some text <br />&quot;some text&quot; <br /> 'some text' <br />$foo<br /> As we can see, the shell pays no attention to the quotation marks. It treats them as ordi-<br />nary characters. This allows us to embed quotes freely within a here document. This <br />could turn out to be handy for our report program.<br />Here documents can be used with any command that accepts standard input. In this ex-<br />ample, we use a here document to pass a series of commands to the ftp program in or-<br />der to retrieve a file from a remote FTP server:<br /> #!/bin/bash <br /> # Script to retrieve a file via FTP <br /> FTP_SERVER=ftp.nl.debian.org <br />FTP_PATH=/debian/dists/lenny/main/installer-i386/current/images/cdrom <br /> REMOTE_FILE=debian-cd_info.tar.gz <br /> ftp -n &lt;&lt; _EOF_ <br />open $FTP_SERVER <br /> user anonymous me@linuxbox <br />cd $FTP_PATH <br /> hash <br />get $REMOTE_FILE <br /> bye <br />_EOF_<br /> ls -l $REMOTE_FILE<br /> If we change the redirection operator from “&lt;&lt;” to “&lt;&lt;-”, the shell will ignore leading <br />tab characters in the here document. This allows a here document to be indented, which <br />can improve readability:<br /> #!/bin/bash <br /> # Script to retrieve a file via FTP <br /> FTP_SERVER=ftp.nl.debian.org <br /> 370<br /></p>
<hr />
<p>Here Documents<br /> FTP_PATH=/debian/dists/lenny/main/installer-i386/current/images/cdrom <br />REMOTE_FILE=debian-cd_info.tar.gz <br /> ftp -n &lt;&lt;- _EOF_ <br /> open $FTP_SERVER <br />user anonymous me@linuxbox <br /> cd $FTP_PATH <br />hash <br /> get $REMOTE_FILE <br />bye <br /> _EOF_ <br /> ls -l $REMOTE_FILE<br /> <strong>Summing Up<br /></strong>In this chapter, we started a project that will carry us through the process of building a <br />successful script. We introduced the concept of variables and constants and how they can <br />be employed. They are the first of many applications we will find for parameter expan-<br />sion. We also looked at how to produce output from our script, and various methods for <br />embedding blocks of text.<br /> <strong>Further Reading</strong><br /> ●<br /> For more information about HTML, see the following articles and tutorials:<br /><a href="http://en.wikipedia.org/wiki/Html">http://en.wikipedia.org/wiki/Html<br /></a><a href="http://en.wikibooks.org/wiki/HTML_Programming">http://en.wikibooks.org/wiki/HTML_Programming<br /></a><a href="http://html.net/tutorials/html/">http://html.net/tutorials/html/</a><br /> ●<br /> The bash man page includes a section entitled “HERE DOCUMENTS,” which <br />has a full description of this feature. <br /> 371<br /></p>
<hr />
<p>26 – Top-Down Design<br /> <em><strong>26 – Top-Down Design</strong></em><br /> As programs get larger and more complex, they become more difficult to design, code <br />and maintain. As with any large project, it is often a good idea to break large, complex <br />tasks into a series of small, simple tasks. Let’s imagine that we are trying to describe a <br />common, everyday task, going to the market to buy food, to a person from Mars. We <br />might describe the overall process as the following series of steps:<br /> 1. Get in car.<br />2. Drive to market.<br />3. Park car.<br />4. Enter market.<br />5. Purchase food.<br />6. Return to car.<br />7. Drive home.<br />8. Park car.<br />9. Enter house.<br /> However, a person from Mars is likely to need more detail. We could further break down <br />the subtask “Park car” into this series of steps:<br /> 1. Find parking space.<br />2. Drive car into space.<br />3. Turn off motor.<br />4. Set parking brake.<br />5. Exit car.<br />6. Lock car.<br /> The “Turn off motor” subtask could further be broken down into steps including “Turn <br />off ignition,” “Remove ignition key,” and so on, until every step of the entire process of <br />going to the market has been fully defined.<br />This process of identifying the top-level steps and developing increasingly detailed views <br />of those steps is called <em>top-down design</em>. This technique allows us to break large complex <br />tasks into many small, simple tasks. Top-down design is a common method of designing <br /> 372<br /></p>
<hr />
<p>26 – Top-Down Design<br /> programs and one that is well suited to shell programming in particular.<br />In this chapter, we will use top-down design to further develop our report-generator <br />script.<br /> <strong>Shell Functions<br /></strong>Our script currently performs the following steps to generate the HTML document:<br /> 1. Open page.<br />2. Open page header.<br />3. Set page title.<br />4. Close page header.<br />5. Open page body.<br />6. Output page heading.<br />7. Output timestamp.<br />8. Close page body.<br />9. Close page.<br /> For our next stage of development, we will add some tasks between steps 7 and 8. These <br />will include:<br /> ●<br /> System uptime and load. This is the amount of time since the last shutdown or re-<br />boot and the average number of tasks currently running on the processor over sev-<br />eral time intervals.<br /> ●<br /> Disk space. The overall use of space on the system’s storage devices.<br /> ●<br /> Home space. The amount of storage space being used by each user.<br /> If we had a command for each of these tasks, we could add them to our script simply <br />through command substitution:<br /> #!/bin/bash <br /> # Program to output a system information page <br /> TITLE=&quot;System Information Report For $HOSTNAME&quot; <br /> CURRENT_TIME=$(date +&quot;%x %r %Z&quot;) <br />TIMESTAMP=&quot;Generated $CURRENT_TIME, by $USER&quot; <br /> cat &lt;&lt; _EOF_ <br /> &lt;HTML&gt; <br />        &lt;HEAD&gt; <br /> 373<br /></p>
<hr />
<p>26 – Top-Down Design<br />                 &lt;TITLE&gt;$TITLE&lt;/TITLE&gt; <br />        &lt;/HEAD&gt; <br />         &lt;BODY&gt; <br />                &lt;H1&gt;$TITLE&lt;/H1&gt; <br />                 &lt;P&gt;$TIMESTAMP&lt;/P&gt; <br />                <strong>$(report_uptime) </strong><br /> <strong>                $(report_disk_space) <br />                $(report_home_space) </strong><br />         &lt;/BODY&gt; <br />&lt;/HTML&gt; <br /> _EOF_<br /> We could create these additional commands two ways. We could write three separate <br />scripts and place them in a directory listed in our PATH, or we could embed the scripts <br />within our program as <em>shell functions</em>. As we have mentioned before, shell functions are <br />“mini-scripts” that are located inside other scripts and can act as autonomous programs. <br />Shell functions have two syntactic forms:<br />function <em>name</em> {<br /> <em>commands<br /></em>return<br /> }<br />and<br /><em>name</em> () {<br /> <em>commands<br /></em>return<br /> }<br />where <em>name</em> is the name of the function and <em>commands</em> is a series of commands contained <br />within the function. Both forms are equivalent and may be used interchangeably. Below <br />we see a script that demonstrates the use of a shell function:<br />  1<br /> #!/bin/bash <br />  2<br />  <br />  3<br /> # Shell function demo <br />  4<br />  <br />  5<br /> function funct { <br />  6<br /> echo &quot;Step 2&quot; <br />  7<br /> return <br />  8<br /> } <br />  9<br />  <br /> 10<br /> # Main program starts here <br /> 11<br />  <br /> 12<br /> echo &quot;Step 1&quot; <br /> 374<br /></p>
<hr />
<p>Shell Functions<br /> 13<br /> funct <br /> 14<br /> echo &quot;Step 3&quot;<br /> As the shell reads the script, it passes over lines 1 through 11, as those lines consist of <br />comments and the function definition. Execution begins at line 12, with an echo com-<br />mand. Line 13 <em>calls</em> the shell function funct and the shell executes the function just as <br />it would any other command. Program control then moves to line 6, and the second echo <br />command is executed. Line 7 is executed next. Its  return  command  terminates the <br />function and returns control to the program at the line following the function call (line <br />14), and the final echo command is executed. Note that in order for function calls to be <br />recognized as shell functions and not interpreted as the names of external programs, shell <br />function definitions must appear in the script before they are called.<br />We’ll add minimal shell function definitions to our script:<br /> #!/bin/bash <br /> # Program to output a system information page <br /> TITLE=&quot;System Information Report For $HOSTNAME&quot; <br />CURRENT_TIME=$(date +&quot;%x %r %Z&quot;) <br /> TIMESTAMP=&quot;Generated $CURRENT_TIME, by $USER&quot; <br /> <strong>report_uptime () { </strong><br /> <strong>return </strong><br /> <strong>}<br /> </strong><br /> <strong>report_disk_space () { </strong><br /> <strong>return </strong><br /> <strong>} </strong><br /> <strong>report_home_space () { </strong><br /> <strong>return </strong><br /> <strong>} </strong><br /> cat &lt;&lt; _EOF_ <br />&lt;HTML&gt; <br /> &lt;HEAD&gt; <br /> &lt;TITLE&gt;$TITLE&lt;/TITLE&gt; <br /> &lt;/HEAD&gt; <br />&lt;BODY&gt; <br /> &lt;H1&gt;$TITLE&lt;/H1&gt; <br />&lt;P&gt;$TIMESTAMP&lt;/P&gt; <br /> $(report_uptime) <br />$(report_disk_space) <br /> $(report_home_space) <br /> 375<br /></p>
<hr />
<p>26 – Top-Down Design<br /> &lt;/BODY&gt; <br /> &lt;/HTML&gt; <br /> _EOF_ <br /> Shell function names follow the same rules as variables. A function must contain at least <br />one command. The return command (which is optional) satisfies the requirement.<br /> <strong>Local Variables<br /></strong>In the scripts we have written so far, all the variables (including constants) have been <br /><em>global variables</em>. Global variables maintain their existence throughout the program. This <br />is fine for many things, but it can sometimes complicate the use of shell functions. Inside <br />shell functions, it is often desirable to have <em>local variables</em>. Local variables are only ac-<br />cessible within the shell function in which they are defined and cease to exist once the <br />shell function terminates.<br />Having local variables allows the programmer to use variables with names that may al-<br />ready exist, either in the script globally or in other shell functions, without having to <br />worry about potential name conflicts.<br />Here is an example script that demonstrates how local variables are defined and used:<br /> #!/bin/bash <br /> # local-vars: script to demonstrate local variables <br /> foo=0<br /> # global variable foo <br /> funct_1 () { <br /> local foo<br /> # variable foo local to funct_1 <br /> foo=1<br /> echo &quot;funct_1: foo = $foo&quot;<br /> } <br /> funct_2 () { <br /> local foo<br /> # variable foo local to funct_2 <br /> foo=2<br /> echo &quot;funct_2: foo = $foo&quot; <br /> } <br /> echo &quot;global:  foo = $foo&quot; <br /> funct_1 <br /> 376<br /></p>
<hr />
<p>Local Variables<br /> echo &quot;global:  foo = $foo&quot; <br />funct_2 <br /> echo &quot;global:  foo = $foo&quot;<br /> As we can see, local variables are defined by preceding the variable name with the word <br />local. This creates a variable that is local to the shell function in which it is defined. <br />Once outside the shell function, the variable no longer exists. When we run this script, we <br />see the results:<br /> [me@linuxbox ~]$ <strong>local-vars </strong><br /> global:  foo = 0 <br />funct_1: foo = 1 <br /> global:  foo = 0 <br />funct_2: foo = 2 <br /> global:  foo = 0<br /> We see that the assignment of values to the local variable foo within both shell functions <br />has no effect on the value of foo defined outside the functions.<br />This feature allows shell functions to be written so that they remain independent of each <br />other and of the script in which they appear. This is very valuable, as it helps prevent one <br />part of a program from interfering with another. It also allows shell functions to be writ-<br />ten so that they can be portable. That is, they may be cut and pasted from script to script, <br />as needed.<br /> <strong>Keep Scripts Running<br /></strong>While developing our program, it is useful to keep the program in a runnable state. By <br />doing this, and testing frequently, we can detect errors early in the development process. <br />This will make  debugging  problems much easier. For example, if we run the program, <br />make a small change, then run the program again and find a problem, it’s very likely that <br />the most recent change is the source of the problem. By adding the empty functions, <br />called  <em>stubs</em> in programmer-speak, we can verify the logical flow of our program at an <br />early stage. When constructing a stub, it’s a good idea to include something that provides <br />feedback to the programmer, which shows the logical flow is being carried out. If we <br />look at the output of our script now:<br /> [me@linuxbox ~]$ <strong>sys_info_page </strong><br /> &lt;HTML&gt; <br /> &lt;HEAD&gt; <br /> &lt;TITLE&gt;System Information Report For twin2&lt;/TITLE&gt; <br /> 377<br /></p>
<hr />
<p>26 – Top-Down Design<br /> &lt;/HEAD&gt; <br />&lt;BODY&gt; <br /> &lt;H1&gt;System Information Report For linuxbox&lt;/H1&gt; <br />&lt;P&gt;Generated 03/19/2009 04:02:10 PM EDT, by me&lt;/P&gt;<br />  <br /> &lt;/BODY&gt; <br /> &lt;/HTML&gt;<br /> we see that there are some blank lines in our output after the timestamp, but we can’t be <br />sure of the cause. If we change the functions to include some feedback:<br /> report_uptime () { <br />         <strong>echo &quot;Function report_uptime executed.&quot; <br /></strong>        return <br /> } <br /> report_disk_space () { <br />        <strong>echo &quot;Function report_disk_space executed.&quot;</strong> <br />         return <br />} <br /> report_home_space () { <br />         <strong>echo &quot;Function report_home_space executed.&quot;</strong> <br />        return <br /> } <br /> and run the script again:<br /> [me@linuxbox ~]$ <strong>sys_info_page</strong> <br /> &lt;HTML&gt; <br /> &lt;HEAD&gt; <br /> &lt;TITLE&gt;System Information Report For linuxbox&lt;/TITLE&gt;<br />  <br /> &lt;/HEAD&gt; <br /> &lt;BODY&gt; <br /> &lt;H1&gt;System Information Report For linuxbox&lt;/H1&gt; <br /> &lt;P&gt;Generated 03/20/2009 05:17:26 AM EDT, by me&lt;/P&gt; <br />Function report_uptime executed. <br /> Function report_disk_space executed. <br />Function report_home_space executed. <br /> &lt;/BODY&gt; <br /> &lt;/HTML&gt;<br /> 378<br /></p>
<hr />
<p>Keep Scripts Running<br /> we now see that, in fact, our three functions are being executed.<br />With our function framework in place and working, it’s time to flesh out some of the <br />function code. First, the report_uptime function:<br /> report_uptime () { <br /> <strong>cat &lt;&lt;- _EOF_ </strong><br /> <strong>        </strong><br /> <strong>&lt;H2&gt;System Uptime&lt;/H2&gt; </strong><br /> <strong>        </strong><br /> <strong>&lt;PRE&gt;$(uptime)&lt;/PRE&gt; </strong><br /> <strong>        </strong><br /> <strong>_EOF_</strong> <br /> return <br /> }<br /> It’s pretty straightforward. We use a here document to output a section header and the <br />output of the uptime command, surrounded by &lt;PRE&gt; tags to preserve the formatting <br />of the command. The report_disk_space function is similar:<br /> report_disk_space () { <br /> <strong>cat &lt;&lt;- _EOF_ </strong><br /> <strong>&lt;H2&gt;Disk Space Utilization&lt;/H2&gt; </strong><br /> <strong>&lt;PRE&gt;$(df -h)&lt;/PRE&gt; <br />_EOF_ </strong><br /> return <br /> }<br /> This function uses the df -h command to determine the amount of disk space. Lastly, <br />we’ll build the report_home_space function:<br /> report_home_space () { <br /> <strong>cat &lt;&lt;- _EOF_ </strong><br /> <strong>&lt;H2&gt;Home Space Utilization&lt;/H2&gt; <br />&lt;PRE&gt;$(du -sh /home/*)&lt;/PRE&gt; </strong><br /> <strong>_EOF_ </strong><br /> return <br /> }<br /> We use the du command with the -sh options to perform this task. This, however, is not <br />a complete solution to the problem. While it will work on some systems (Ubuntu, for ex-<br />ample), it will not work on others. The reason is that many systems set the permissions of <br />home directories to prevent them from being world-readable, which is a reasonable secu-<br />rity measure. On these systems, the  report_home_space  function, as written, will <br /> 379<br /></p>
<hr />
<p>26 – Top-Down Design<br /> only work if our script is run with superuser privileges. A better solution would be to <br />have the script adjust its behavior according to the privileges of the user. We will take this <br />up in the next chapter.<br /> <strong>Shell Functions In Your .bashrc File<br /></strong>Shell functions make excellent replacements for aliases, and are actually the pre-<br />ferred method of creating small commands for personal use. Aliases are very lim-<br />ited in the kind of commands and shell features they support, whereas shell func-<br />tions   allow   anything   that   can   be   scripted.   For   example,   if   we   liked   the <br />report_disk_space  shell   function   that   we   developed   for   our   script,   we <br />could create a similar function named ds for our .bashrc file:<br /> ds () {<br /> echo “Disk Space Utilization For $HOSTNAME”<br /> df -h<br /> }<br /> <strong>Summing Up<br /></strong>In this chapter, we have introduced a common method of program design called top-<br />down design, and we have seen how shell functions are used to build the stepwise refine-<br />ment that it requires. We have also seen how local variables can be used to make shell <br />functions independent from one another and from the program in which they are placed. <br />This makes it possible for shell functions to be written in a portable manner and to be <em>re-<br />usable</em> by allowing them to be placed in multiple programs; a great time saver.<br /> <strong>Further Reading</strong><br /> ●<br /> The Wikipedia has many articles on software design philosophy. Here are a cou-<br />ple of good ones:<br /><a href="http://en.wikipedia.org/wiki/Top-down_design">http://en.wikipedia.org/wiki/Top-down_design<br /></a><a href="http://en.wikipedia.org/wiki/Subroutines">http://en.wikipedia.org/wiki/Subroutines</a><br /> 380<br /></p>
<hr />
<p>27 – Flow Control: Branching With if<br /> <em><strong>27 – Flow Control: Branching With if</strong></em><br /> In the last chapter, we were presented with a problem. How can we make our report-gen-<br />erator script adapt to the privileges of the user running the script? The solution to this <br />problem will require us to find a way to “change directions” within our script, based on <br />the results of a test. In programming terms, we need the program to <em>branch</em>.<br />Let’s consider a simple example of logic expressed in <em>pseudocode</em>, a simulation of a com-<br />puter language intended for human consumption:<br />X = 5<br />If X = 5, then:<br /> Say “X equals 5.”<br /> Otherwise:<br /> Say “X is not equal to 5.”<br /> This is an example of a branch. Based on the condition, “Does X = 5?” do one thing, <br />“Say X equals 5,” otherwise do another thing, “Say X is not equal to 5.” <br /> <strong>if<br /></strong>Using the shell, we can code the logic above as follows:<br /> x=5 <br /> if [ $x -eq 5 ]; then <br /> echo &quot;x equals 5.&quot; <br /> else echo &quot;x does not equal 5.&quot; <br />fi<br /> or we can enter it directly at the command line (slightly shortened):<br /> 381<br /></p>
<hr />
<p>27 – Flow Control: Branching With if<br /> [me@linuxbox ~]$ <strong>x=5<br /></strong>[me@linuxbox ~]$ <strong>if [ $x -eq 5 ]; then echo &quot;equals 5&quot;; else echo </strong><br /> <strong>&quot;does not equal 5&quot;; fi<br /></strong>equals 5<br /> [me@linuxbox ~]$ <strong>x=0<br /></strong>[me@linuxbox ~]$ <strong>if [ $x -eq 5 ]; then echo &quot;equals 5&quot;; else echo </strong><br /> <strong>&quot;does not equal 5&quot;; fi<br /></strong>does not equal 5<br /> In this example, we execute the command twice. Once, with the value of  x  set to 5, <br />which results in the string “equals 5” being output, and the second time with the value of <br />x set to 0, which results in the string “does not equal 5” being output.<br />The if statement has the following syntax:<br />if <em>commands</em>; then<br /> <em>commands</em><br /> [elif <em>commands</em>; then<br /> <em>commands</em>...]<br /> [else<br /> <em>commands</em>]<br /> fi<br />where <em>commands</em> is a list of commands. This is a little confusing at first glance. But be-<br />fore we can clear this up, we have to look at how the shell evaluates the success or failure <br />of a command.<br /> <strong>Exit Status<br /></strong>Commands (including the scripts and shell functions we write) issue a value to the system <br />when they terminate, called an <em>exit status</em>. This value, which is an integer in the range of <br />0 to 255, indicates the success or failure of the command’s execution. By convention, a <br />value of zero indicates success and any other value indicates failure. The shell provides a <br />parameter that we can use to examine the exit status. Here we see it in action:<br /> [me@linuxbox ~]$ <strong>ls -d /usr/bin<br /></strong>/usr/bin<br /> [me@linuxbox ~]$ <strong>echo $?<br /></strong>0<br /> [me@linuxbox ~]$ <strong>ls -d /bin/usr<br /></strong>ls: cannot access /bin/usr: No such file or directory<br /> [me@linuxbox ~]$ <strong>echo $?<br /></strong>2<br /> 382<br /></p>
<hr />
<p>Exit Status<br /> In this example, we execute the  ls command twice. The first time, the command exe-<br />cutes successfully. If we display the value of the parameter $?, we see that it is zero. We <br />execute the ls command a second time, producing an error, and examine the parameter <br />$?  again. This time it contains a 2, indicating that the command encountered an error. <br />Some commands use different exit status values to provide diagnostics for errors, while <br />many commands simply exit with a value of one when they fail. Man pages often include <br />a section entitled “Exit Status,” describing what codes are used. However, a zero always <br />indicates success.<br />The shell provides two extremely simple builtin commands that do nothing except termi-<br />nate with either a zero or one exit status. The true command always executes success-<br />fully and the false command always executes unsuccessfully:<br /> [me@linuxbox ~]$ <strong>true<br /></strong>[me@linuxbox ~]$ <strong>echo $?</strong><br /> 0<br />[me@linuxbox ~]$ <strong>false</strong><br /> [me@linuxbox ~]$ <strong>echo $?<br /></strong>1 <br /> We can use these commands to see how the if statement works. What the if statement <br />really does is evaluate the success or failure of commands:<br /> [me@linuxbox ~]$ <strong>if true; then echo &quot;It's true.&quot;; fi<br /></strong>It's true.<br /> [me@linuxbox ~]$ <strong>if false; then echo &quot;It's true.&quot;; fi<br /></strong>[me@linuxbox ~]$ <br /> The command echo &quot;It's true.&quot; is executed when the command following if exe-<br />cutes successfully, and is not executed when the command following if does not execute <br />successfully. If a list of commands follows if, the last command in the list is evaluated:<br /> [me@linuxbox ~]$ if false; true; then echo &quot;It's true.&quot;; fi<br />It's true.<br /> [me@linuxbox ~]$ if true; false; then echo &quot;It's true.&quot;; fi<br />[me@linuxbox ~]$ <br /> 383<br /></p>
<hr />
<p>27 – Flow Control: Branching With if<br /> <strong>test<br /></strong>By far, the command used most frequently with if is test. The test command per-<br />forms a variety of checks and comparisons. It has two equivalent forms:<br />test <em>expression<br /></em>and the more popular:<br />[ <em>expression</em> ]<br />where <em>expression</em> is an expression that is evaluated as either true or false. The test com-<br />mand returns an exit status of zero when the expression is true and a status of one when <br />the expression is false.<br /> File Expressions<br />The following expressions are used to evaluate the status of files:<br /> <em>Table 27-1: test File Expressions</em><br /> <strong>Expression</strong><br /> <strong>Is True If:</strong><br /> <em>file1</em> -ef <em>file2</em><br /> <em>file1</em> and <em>file2</em> have the same inode numbers (the two <br />filenames refer to the same file by hard linking).<br /> <em>file1</em> -nt <em>file2</em><br /> <em>file1</em> is newer than <em>file2</em>.<br /> <em>file1</em> -ot <em>file2</em><br /> <em>file1</em> is older than <em>file2</em>.<br /> -b <em>file</em><br /> <em>file</em> exists and is a block-special (device) file.<br /> -c <em>file</em><br /> <em>file</em> exists and is a character-special (device) file.<br /> -d <em>file</em><br /> <em>file</em> exists and is a directory.<br /> -e <em>file</em><br /> <em>file</em> exists.<br /> -f <em>file</em><br /> <em>file</em> exists and is a regular file.<br /> -g <em>file</em><br /> <em>file</em> exists and is set-group-ID.<br /> -G <em>file</em><br /> <em>file</em> exists and is owned by the effective group ID.<br /> -k <em>file</em><br /> <em>file</em> exists and has its “sticky bit” set.<br /> -L <em>file</em><br /> <em>file</em> exists and is a symbolic link.<br /> -O <em>file</em><br /> <em>file</em> exists and is owned by the effective user ID.<br /> -p <em>file</em><br /> <em>file</em> exists and is a named pipe.<br /> -r <em>file</em><br /> <em>file</em> exists and is readable (has readable permission for <br /> 384<br /></p>
<hr />
<p>test<br /> the effective user).<br /> -s <em>file</em><br /> <em>file</em> exists and has a length greater than zero.<br /> -S <em>file</em><br /> <em>file</em> exists and is a network socket.<br /> -t <em>fd</em><br /> <em>fd</em> is a file descriptor directed to/from the terminal. This <br />can be used to determine whether standard <br />input/output/error is being redirected.<br /> -u <em>file</em><br /> <em>file</em> exists and is setuid.<br /> -w <em>file</em><br /> <em>file</em> exists and is writable (has write permission for the <br />effective user).<br /> -x <em>file</em><br /> <em>file</em> exists and is executable (has execute/search <br />permission for the effective user).<br /> Here we have a script that demonstrates some of the file expressions:<br /> #!/bin/bash <br /> # test-file: Evaluate the status of a file <br /> FILE=~/.bashrc <br /> if [ -e &quot;$FILE&quot; ]; then <br /> if [ -f &quot;$FILE&quot; ]; then <br /> echo &quot;$FILE is a regular file.&quot; <br /> fi <br /> if [ -d &quot;$FILE&quot; ]; then <br /> echo &quot;$FILE is a directory.&quot; <br /> fi <br />if [ -r &quot;$FILE&quot; ]; then <br /> echo &quot;$FILE is readable.&quot; <br /> fi <br /> if [ -w &quot;$FILE&quot; ]; then <br /> echo &quot;$FILE is writable.&quot; <br /> fi <br />if [ -x &quot;$FILE&quot; ]; then <br /> echo &quot;$FILE is executable/searchable.&quot; <br /> fi <br /> else <br /> echo &quot;$FILE does not exist&quot; <br /> exit 1 <br /> fi <br /> exit<br /> 385<br /></p>
<hr />
<p>27 – Flow Control: Branching With if<br /> The script evaluates the file assigned to the constant FILE and displays its results as the <br />evaluation is performed. There are two interesting things to note about this script. First, <br />notice how the parameter $FILE is quoted within the expressions. This is not required, <br />but is a defense against the parameter being empty. If the parameter expansion of $FILE <br />were to result in an empty value, it would cause an error (the operators would be inter-<br />preted as non-null strings rather than operators). Using the quotes around the parameter <br />ensures that the operator is always followed by a string, even if the string is empty. Sec-<br />ond, notice the presence of the  exit  command  near the end of the script. The  exit <br />command accepts a single, optional argument, which becomes the script’s exit status. <br />When no argument is passed, the exit status defaults to the exit status of the last com-<br />mand executed. Using exit in this way allows the script to indicate failure if $FILE ex-<br />pands to the name of a nonexistent file. The exit command appearing on the last line of <br />the script is there as a formality. When a script “runs off the end” (reaches end of file), it <br />terminates with an exit status of the last command executed by default, anyway.<br />Similarly, shell functions can return an exit status by including an integer argument to the <br />return command. If we were to convert the script above to a shell function to include it <br />in a larger program, we could replace the exit commands with return statements and <br />get the desired behavior:<br /> test_file () {<br /> # test-file: Evaluate the status of a file <br /> FILE=~/.bashrc <br /> if [ -e &quot;$FILE&quot; ]; then <br /> if [ -f &quot;$FILE&quot; ]; then <br /> echo &quot;$FILE is a regular file.&quot; <br /> fi <br /> if [ -d &quot;$FILE&quot; ]; then <br /> echo &quot;$FILE is a directory.&quot; <br /> fi <br />if [ -r &quot;$FILE&quot; ]; then <br /> echo &quot;$FILE is readable.&quot; <br /> fi <br /> if [ -w &quot;$FILE&quot; ]; then <br /> echo &quot;$FILE is writable.&quot; <br /> fi <br />if [ -x &quot;$FILE&quot; ]; then <br /> echo &quot;$FILE is executable/searchable.&quot; <br /> fi <br /> else <br /> echo &quot;$FILE does not exist&quot; <br /> return 1 <br /> 386<br /></p>
<hr />
<p>test<br /> fi <br /> }<br /> String Expressions<br />The following expressions are used to evaluate strings:<br /> <em>Table 27-2: test String Expressions</em><br /> <strong>Expression</strong><br /> <strong>Is True If...</strong><br /> <em>string</em><br /> <em>string</em> is not null.<br /> -n <em>string</em><br /> The length of <em>string</em> is greater than zero.<br /> -z <em>string</em><br /> The length of <em>string</em> is zero.<br /> <em>string1</em> = <em>string2</em><br /> <em>string1</em> and <em>string2</em> are equal. Single or double <br /> <em>string1 == string2</em><br /> equal signs may be used, but the use of double <br />equal signs is greatly preferred.<br /> <em>string1</em> != <em>string2</em><br /> <em>string1</em> and <em>string2</em> are not equal.<br /> <em>string1</em> &gt; <em>string2</em><br /> <em>string1</em> sorts after <em>string2</em>.<br /> <em>string1</em> &lt; <em>string2</em><br /> <em>string1</em> sorts before <em>string2</em>.<br /> <strong>Warning</strong>: the  &gt;  and  &lt;  expression operators must be quoted (or escaped with a <br />backslash) when used with test. If they are not, they will be interpreted by the <br />shell as redirection operators, with potentially destructive results. Also note that <br />while the bash documentation states that the sorting order conforms to the colla-<br />tion order of the current locale, it does not. ASCII (POSIX) order is used in ver-<br />sions of bash up to and including 4.0.<br /> Here is a script that incorporates string expressions:<br /> #!/bin/bash <br /> # test-string: evaluate the value of a string <br /> ANSWER=maybe <br /> if [ -z &quot;$ANSWER&quot; ]; then <br /> 387<br /></p>
<hr />
<p>27 – Flow Control: Branching With if<br /> echo &quot;There is no answer.&quot; &gt;&amp;2<br />exit 1 <br /> fi <br /> if [ &quot;$ANSWER&quot; = &quot;yes&quot; ]; then <br /> echo &quot;The answer is YES.&quot; <br /> elif [ &quot;$ANSWER&quot; = &quot;no&quot; ]; then <br /> echo &quot;The answer is NO.&quot; <br /> elif [ &quot;$ANSWER&quot; = &quot;maybe&quot; ]; then <br /> echo &quot;The answer is MAYBE.&quot; <br /> else <br /> echo &quot;The answer is UNKNOWN.&quot; <br /> fi<br /> In this script, we evaluate the constant ANSWER. We first determine if the string is empty. <br />If it is, we terminate the script and set the exit status to one. Notice the redirection that is <br />applied to the echo command. This redirects the error message “There is no answer.” to <br />standard error, which is the “proper” thing to do with error messages. If the string is not <br />empty, we evaluate the value of the string to see if it is equal to either “yes,” “no,” or <br />“maybe.” We do this by using elif, which is short for “else if.” By using elif, we are <br />able to construct a more complex logical test.<br /> Integer Expressions<br />The following expressions are used with integers:<br /> <em>Table 27-3: test Integer Expressions</em><br /> <strong>Expression</strong><br /> <strong>Is True If...</strong><br /> <em>integer1</em> -eq <em>integer2</em><br /> <em>integer1</em> is equal to <em>integer2</em>.<br /> <em>integer1</em> -ne <em>integer2</em><br /> <em>integer1</em> is not equal to <em>integer2</em>.<br /> <em>integer1</em> -le <em>integer2</em><br /> <em>integer1</em> is less than or equal to <em>integer2</em>.<br /> <em>integer1</em> -lt <em>integer2</em><br /> <em>integer1</em> is less than <em>integer2</em>.<br /> <em>integer1</em> -ge <em>integer2</em><br /> <em>integer1</em> is greater than or equal to <em>integer2</em>.<br /> <em>integer1</em> -gt <em>integer2</em><br /> <em>integer1</em> is greater than <em>integer2</em>.<br /> Here is a script that demonstrates them:<br /> #!/bin/bash <br /> 388<br /></p>
<hr />
<p>test<br /> # test-integer: evaluate the value of an integer. <br /> INT=-5 <br /> if [ -z &quot;$INT&quot; ]; then <br /> echo &quot;INT is empty.&quot; &gt;&amp;2 <br />exit 1 <br /> fi <br /> if [ $INT -eq 0 ]; then <br /> echo &quot;INT is zero.&quot; <br /> else <br /> if [ $INT -lt 0 ]; then <br /> echo &quot;INT is negative.&quot; <br /> else  echo &quot;INT is positive.&quot; <br />fi <br /> if [ $((INT % 2)) -eq 0 ]; then <br /> echo &quot;INT is even.&quot; <br /> else <br /> echo &quot;INT is odd.&quot; <br /> fi <br /> fi<br /> The interesting part of the script is how it determines whether an integer is even or odd. <br />By performing a modulo 2 operation on the number, which divides the number by two <br />and returns the remainder, it can tell if the number is odd or even.<br /> <strong>A More Modern Version Of test<br /></strong>Recent versions of bash include a compound command that acts as an enhanced replace-<br />ment for test. It uses the following syntax:<br />[[ <em>expression</em> ]]<br />where, like test, <em>expression</em> is an expression that evaluates to either a true or false re-<br />sult. The [[ ]] command is very similar to test (it supports all of its expressions), but <br />adds an important new string expression:<br /><em>string1</em> =~ <em>regex<br /></em>which returns true if <em>string1</em> is matched by the extended regular expression <em>regex</em>. This <br />opens up a lot of possibilities for performing such tasks as data validation. In our earlier <br />example of the integer expressions, the script would fail if the constant  INT contained <br />anything except an integer. The script needs a way to verify that the constant contains an <br />integer. Using  [[ ]]  with the  =~  string expression operator, we could improve the <br /> 389<br /></p>
<hr />
<p>27 – Flow Control: Branching With if<br /> script this way:<br /> #!/bin/bash <br /> # test-integer2: evaluate the value of an integer. <br /> INT=-5 <br /> <strong>if [[ &quot;$INT&quot; =~ ^-?[0-9]+$ ]]; then</strong> <br /> if [ $INT -eq 0 ]; then <br /> echo &quot;INT is zero.&quot; <br /> else  if [ $INT -lt 0 ]; then <br /> echo &quot;INT is negative.&quot; <br /> else <br /> echo &quot;INT is positive.&quot; <br /> fi <br />if [ $((INT % 2)) -eq 0 ]; then <br /> echo &quot;INT is even.&quot; <br /> else  echo &quot;INT is odd.&quot; <br />fi <br /> fi <br /> <strong>else echo &quot;INT is not an integer.&quot; &gt;&amp;2 </strong><br /> <strong>exit 1 </strong><br /> <strong>fi</strong><br /> By applying the regular expression, we are able to limit the value of INT to only strings <br />that begin with an optional minus sign, followed by one or more numerals. This expres-<br />sion also eliminates the possibility of empty values.<br />Another added feature of [[ ]] is that the == operator supports pattern matching the <br />same way pathname expansion does. For example:<br /> [me@linuxbox ~]$ <strong>FILE=foo.bar</strong> <br /> [me@linuxbox ~]$ <strong>if [[ $FILE == foo.* ]]; then</strong> <br />&gt; <strong>echo &quot;$FILE matches pattern 'foo.*'&quot; </strong><br /> &gt; <strong>fi <br /></strong>foo.bar matches pattern 'foo.*'<br /> This makes [[ ]] useful for evaluating file and pathnames.<br /> 390<br /></p>
<hr />
<p>(( )) - Designed For Integers<br /> <strong>(( )) - Designed For Integers<br /></strong>In addition to the  [[ ]]  compound command,  bash  also provides the  (( ))  com-<br />pound command, which is useful for operating on integers. It supports a full set of arith-<br />metic evaluations, a subject we will cover fully in Chapter 34.<br /> (( )) is used to perform <em>arithmetic truth tests</em>. An arithmetic truth test results in true if <br />the result of the arithmetic evaluation is non-zero.<br /> [me@linuxbox ~]$ <strong>if ((1)); then echo &quot;It is true.&quot;; fi </strong><br /> It is true.<br />[me@linuxbox ~]$ <strong>if ((0)); then echo &quot;It is true.&quot;; fi</strong><br /> [me@linuxbox ~]$ <br /> Using (( )), we can slightly simplify the test-integer2 script like this:<br /> #!/bin/bash <br /> # test-integer2a: evaluate the value of an integer. <br /> INT=-5 <br /> if [[ &quot;$INT&quot; =~ ^-?[0-9]+$ ]]; then <br /> if <strong>((INT == 0))</strong>; then <br /> echo &quot;INT is zero.&quot; <br /> else <br /> if <strong>((INT &lt; 0))</strong>; then <br /> echo &quot;INT is negative.&quot; <br /> else  echo &quot;INT is positive.&quot; <br />fi <br /> if <strong>(( ((INT % 2)) == 0))</strong>; then <br /> echo &quot;INT is even.&quot; <br /> else <br /> echo &quot;INT is odd.&quot; <br /> fi <br /> fi <br /> else <br /> echo &quot;INT is not an integer.&quot; &gt;&amp;2 <br /> exit 1 <br /> fi<br /> Notice that we use less-than and greater-than signs and that == is used to test for equiva-<br />lence. This is a more natural-looking syntax for working with integers. Notice too, that <br />because the compound command (( )) is part of the shell syntax rather than an ordi-<br /> 391<br /></p>
<hr />
<p>27 – Flow Control: Branching With if<br /> nary command, and it deals only with integers, it is able to recognize variables by name <br />and does not require expansion to be performed. We’ll discuss  (( )) and the related <br />arithmetic expansion further in Chapter 34.<br /> <strong>Combining Expressions<br /></strong>It’s also possible to combine expressions to create more complex evaluations. Expres-<br />sions are combined by using logical operators. We saw these in Chapter 17, when we <br />learned about the  find  command. There are three  logical operations  for  test  and <br />[[ ]]. They are AND, OR and NOT. test and [[ ]] use different operators to repre-<br />sent these operations :<br /> <em>Table 27-4: Logical Operators</em><br /> <strong>Operation</strong><br /> <strong>test</strong><br /> <strong>[[ ]] and (( ))</strong><br /> AND<br /> -a<br /> &amp;&amp;<br /> OR<br /> -o<br /> ||<br /> NOT<br /> !<br /> !<br /> Here’s an example of an AND operation. The following script determines if an integer is <br />within a range of values:<br /> #!/bin/bash <br /> # test-integer3: determine if an integer is within a <br /> # specified range of values. <br /> MIN_VAL=1<br />MAX_VAL=100 <br /> INT=50 <br /> if [[ &quot;$INT&quot; =~ ^-?[0-9]+$ ]]; then <br /> if [[ INT -ge MIN_VAL &amp;&amp; INT -le MAX_VAL ]]; then <br /> echo &quot;$INT is within $MIN_VAL to $MAX_VAL.&quot; <br /> else <br /> echo &quot;$INT is out of range.&quot; <br /> fi <br /> else <br />         echo &quot;INT is not an integer.&quot; &gt;&amp;2 <br />        exit 1 <br /> fi<br /> 392<br /></p>
<hr />
<p>Combining Expressions<br /> In   this   script,   we   determine   if   the   value   of   integer  INT  lies between  the  values  of <br />MIN_VAL and MAX_VAL. This is performed by a single use of [[ ]], which includes <br />two expressions separated by the  &amp;&amp;  operator. We could have also coded this using <br />test:<br />  <br /> if <strong>[</strong> $INT -ge $MIN_VAL <strong>-a</strong> $INT -le $MAX_VAL <strong>]</strong>; then <br /> echo &quot;$INT is within $MIN_VAL to $MAX_VAL.&quot; <br /> else <br /> echo &quot;$INT is out of range.&quot; <br /> fi<br /> The ! negation operator reverses the outcome of an expression. It returns true if an ex-<br />pression is false, and it returns false if an expression is true. In the following script, we <br />modify the logic of our evaluation to find values of  INT that are outside the specified <br />range:<br /> #!/bin/bash <br /> # test-integer4: determine if an integer is outside a <br /> # specified range of values. <br /> MIN_VAL=1 <br />MAX_VAL=100 <br /> INT=50 <br /> if [[ &quot;$INT&quot; =~ ^-?[0-9]+$ ]]; then <br /> if [[ ! (INT -ge MIN_VAL &amp;&amp; INT -le MAX_VAL) ]]; then <br /> echo &quot;$INT is outside $MIN_VAL to $MAX_VAL.&quot; <br /> else <br /> echo &quot;$INT is in range.&quot; <br /> fi <br /> else <br />         echo &quot;INT is not an integer.&quot; &gt;&amp;2 <br />        exit 1 <br /> fi<br /> We also include parentheses around the expression, for grouping. If these were not in-<br />cluded, the negation would only apply to the first expression and not the combination of <br />the two. Coding this with test would be done this way:<br /> if [ ! \( $INT -ge $MIN_VAL -a $INT -le $MAX_VAL \) ]; then <br /> 393<br /></p>
<hr />
<p>27 – Flow Control: Branching With if<br /> echo &quot;$INT is outside $MIN_VAL to $MAX_VAL.&quot; <br /> else  echo &quot;$INT is in range.&quot; <br />fi<br /> Since all expressions and operators used by test are treated as command arguments by <br />the shell (unlike [[ ]] and (( )) ), characters which have special meaning to bash, <br />such as &lt;, &gt;, (, and ), must be quoted or escaped.<br />Seeing that test and [[ ]] do roughly the same thing, which is preferable? test is <br />traditional (and part of POSIX), whereas [[ ]] is specific to bash. It’s important to <br />know how to use test, since it is very widely used, but [[ ]] is clearly more useful <br />and is easier to code.<br /> <strong>Portability Is The Hobgoblin Of Little Minds<br /></strong>If you talk to “real” Unix people, you quickly discover that many of them don’t <br />like Linux very much. They regard it as impure and unclean. One tenet of Unix <br />followers is that everything should be “portable.” This means that any script you <br />write should be able to run, unchanged, on any Unix-like system.<br />Unix people have good reason to believe this. Having seen what proprietary ex-<br />tensions to commands and shells did to the Unix world before POSIX, they are <br />naturally wary of the effect of Linux on their beloved OS.<br />But portability has a serious downside. It prevents progress. It requires that things <br />are always done using “lowest common denominator” techniques. In the case of <br />shell programming, it means making everything compatible with sh, the original <br />Bourne shell.<br />This downside is the excuse that proprietary vendors use to justify their propri-<br />etary extensions, only they call them “innovations.” But they are really just lock-<br />-in devices for their customers.<br />The GNU tools, such as bash, have no such restrictions. They encourage porta-<br />bility by supporting standards and by being universally available. You can install <br />bash  and the other GNU tools on almost any kind of system, even Windows, <br />without cost. So feel free to use all the features of bash. It’s <em>really</em> portable.<br /> <strong>Control Operators: Another Way To Branch<br /></strong>bash provides two control operators that can perform branching. The &amp;&amp; (AND) and || <br />(OR) operators work like the logical operators in the [[ ]] compound command. This <br />is the syntax:<br /> 394<br /></p>
<hr />
<p>Control Operators: Another Way To Branch<br /> <em>command1</em> &amp;&amp; <em>command2<br /></em>and <br /><em>command1</em> || <em>command2<br /></em>It is important to understand the behavior of these. With the &amp;&amp; operator, <em>command1</em> is <br />executed and <em>command2</em> is executed if, <em>and only if</em>, <em>command1</em> is successful. With the || <br />operator, <em>command1</em> is executed and <em>command2</em> is executed if, <em>and only if</em>, <em>command1</em> is <br />unsuccessful.<br />In practical terms, it means that we can do something like this:<br /> [me@linuxbox ~]$ <strong>mkdir temp &amp;&amp; cd temp</strong><br /> This will create a directory named temp, and if it succeeds, the current working directory <br />will be changed to  temp. The second command is attempted only if the  mkdir com-<br />mand is successful. Likewise, a command like this:<br /> [me@linuxbox ~]$ <strong>[ -d temp ] || mkdir temp</strong><br /> will test for the existence of the directory temp, and only if the test fails, will the direc-<br />tory be created. This type of construct is very handy for handling errors in scripts, a sub-<br />ject we will discuss more in later chapters. For example, we could do this in a script:<br /> [ -d temp ] || exit 1<br /> If the script requires the directory temp, and it does not exist, then the script will termi-<br />nate with an exit status of one.<br /> <strong>Summing Up<br /></strong>We started this chapter with a question. How could we make our  sys_info_page <br />script detect if the user had permission to read all the home directories? With our knowl-<br />edge   of  if,   we   can   solve   the   problem   by   adding   this   code   to   the <br />report_home_space function:<br /> report_home_space () { <br /> <strong>if [[ $(id -u) -eq 0 ]]; then </strong><br /> 395<br /></p>
<hr />
<p>27 – Flow Control: Branching With if<br /> <strong>cat &lt;&lt;- _EOF_ </strong><br /> <strong>&lt;H2&gt;Home Space Utilization (All Users)&lt;/H2&gt; </strong><br /> <strong>&lt;PRE&gt;$(du -sh /home/*)&lt;/PRE&gt; <br />_EOF_ </strong><br /> <strong>else </strong><br /> <strong>cat &lt;&lt;- _EOF_ </strong><br /> <strong>&lt;H2&gt;Home Space Utilization ($USER)&lt;/H2&gt; <br />&lt;PRE&gt;$(du -sh $HOME)&lt;/PRE&gt; </strong><br /> <strong>_EOF_ </strong><br /> <strong>fi </strong><br /> <strong>return</strong> <br /> }<br /> We evaluate the output of the id command. With the -u option, id outputs the numeric <br />user ID number of the effective user. The superuser is always zero and every other user is <br />a number greater than zero. Knowing this, we can construct two different here docu-<br />ments, one taking advantage of superuser privileges, and the other, restricted to the user’s <br />own home directory.<br />We are going to take a break from the sys_info_page program, but don’t worry. It <br />will be back. In the meantime, we’ll cover some topics that we’ll need when we resume <br />our work.<br /> <strong>Further Reading<br /></strong>There are several sections of the bash man page that provide further detail on the topics <br />covered in this chapter:<br /> ●<br /> Lists (covers the control operators || and &amp;&amp;)<br /> ●<br /> Compound Commands (covers [[ ]], (( )) and if)<br /> ●<br /> CONDITIONAL EXPRESSIONS<br /> ●<br /> SHELL BUILTIN COMMANDS (covers test)<br /> Further, the Wikipedia has a good article on the concept of pseudocode:<br /><a href="http://en.wikipedia.org/wiki/Pseudocode">http://en.wikipedia.org/wiki/Pseudocode</a><br /> 396<br /></p>
<hr />
<p>28 – Reading Keyboard Input<br /> <em><strong>28 – Reading Keyboard Input</strong></em><br /> The scripts we have written so far lack a feature common in most computer programs—<br />    <br /> <em>interactivity</em>. That is, the ability of the program to interact with the user. While many pro-<br />grams don’t need to be interactive, some programs benefit from being able to accept input <br />directly from the user. Take, for example, this script from the previous chapter:<br /> #!/bin/bash <br /> # test-integer2: evaluate the value of an integer. <br /> INT=-5 <br /> if [[ &quot;$INT&quot; =~ ^-?[0-9]+$ ]]; then <br /> if [ $INT -eq 0 ]; then <br /> echo &quot;INT is zero.&quot; <br /> else  if [ $INT -lt 0 ]; then <br /> echo &quot;INT is negative.&quot; <br /> else <br /> echo &quot;INT is positive.&quot; <br /> fi <br />if [ $((INT % 2)) -eq 0 ]; then <br /> echo &quot;INT is even.&quot; <br /> else  echo &quot;INT is odd.&quot; <br />fi <br /> fi <br /> else echo &quot;INT is not an integer.&quot; &gt;&amp;2 <br /> exit 1 <br /> fi<br /> Each time we want to change the value of INT, we have to edit the script. It would be <br />much more useful if the script could ask the user for a value. In this chapter, we will be-<br />gin to look at how we can add interactivity to our programs.<br /> 397<br /></p>
<hr />
<p>28 – Reading Keyboard Input<br /> <strong>read – Read Values From Standard Input<br /></strong>The read builtin command is used to read a single line of standard input. This command <br />can be used to read keyboard input or, when redirection is employed, a line of data from a <br />file. The command has the following syntax:<br />read [-<em>options</em>] [<em>variable</em>...]<br />where  <em>options</em>  is one or more of the available options listed below and  <em>variable</em>  is the <br />name of one or more variables used to hold the input value. If no variable name is sup-<br />plied, the shell variable REPLY contains the line of data.<br />Basically, read assigns fields from standard input to the specified variables. If we mod-<br />ify our integer evaluation script to use read, it might look like this:<br /> #!/bin/bash <br /> # read-integer: evaluate the value of an integer. <br /> <strong>echo -n &quot;Please enter an integer -&gt; &quot; </strong><br /> <strong>read int</strong> <br /> if [[ &quot;$int&quot; =~ ^-?[0-9]+$ ]]; then <br /> if [ $int -eq 0 ]; then <br /> echo &quot;$int is zero.&quot; <br /> else  if [ $int -lt 0 ]; then <br /> echo &quot;$int is negative.&quot; <br /> else <br /> echo &quot;$int is positive.&quot; <br /> fi <br />if [ $((int % 2)) -eq 0 ]; then <br /> echo &quot;$int is even.&quot; <br /> else  echo &quot;$int is odd.&quot; <br />fi <br /> fi <br /> else echo &quot;Input value is not an integer.&quot; &gt;&amp;2 <br /> exit 1 <br /> fi<br /> We use  echo  with the  -n  option  (which suppresses the trailing newline on output) to <br />display a prompt, and then use read to input a value for the variable int. Running this <br />script results in this:<br /> 398<br /></p>
<hr />
<p>read – Read Values From Standard Input<br /> [me@linuxbox ~]$ <strong>read-integer <br /></strong>Please enter an integer -&gt; <strong>5</strong> <br /> 5 is positive. <br />5 is odd.<br /> read can assign input to multiple variables, as shown in this script:<br /> #!/bin/bash <br /> # read-multiple: read multiple values from keyboard <br /> echo -n &quot;Enter one or more values &gt; &quot; <br />read var1 var2 var3 var4 var5 <br /> echo &quot;var1 = '$var1'&quot; <br /> echo &quot;var2 = '$var2'&quot; <br />echo &quot;var3 = '$var3'&quot; <br /> echo &quot;var4 = '$var4'&quot; <br />echo &quot;var5 = '$var5'&quot;<br /> In this script, we assign and display up to five values. Notice how read behaves when <br />given different numbers of values:<br /> [me@linuxbox ~]$ <strong>read-multiple</strong> <br />Enter one or more values &gt; <strong>a b c d e</strong> <br /> var1 = 'a' <br />var2 = 'b' <br /> var3 = 'c' <br />var4 = 'd' <br /> var5 = 'e' <br />[me@linuxbox ~]$ <strong>read-multiple</strong> <br /> Enter one or more values &gt; <strong>a</strong> <br />var1 = 'a' <br /> var2 = '' <br />var3 = '' <br /> var4 = '' <br />var5 = '' <br /> [me@linuxbox ~]$ <strong>read-multiple</strong> <br />Enter one or more values &gt; <strong>a b c d e f g</strong> <br /> var1 = 'a' <br />var2 = 'b' <br /> var3 = 'c' <br />var4 = 'd' <br /> var5 = 'e f g'<br /> 399<br /></p>
<hr />
<p>28 – Reading Keyboard Input<br /> If read receives fewer than the expected number, the extra variables are empty, while an <br />excessive amount of input results in the final variable containing all of the extra input.<br />If no variables are listed after the read command, a shell variable, REPLY, will be as-<br />signed all the input:<br /> #!/bin/bash <br /> # read-single: read multiple values into default variable<br /> echo -n &quot;Enter one or more values &gt; &quot; <br />read <br /> echo &quot;REPLY = '$REPLY'&quot;<br /> Running this script results in this:<br /> [me@linuxbox ~]$ <strong>read-single <br /></strong>Enter one or more values &gt; <strong>a b c d </strong><br /> REPLY = 'a b c d'<br /> Options<br />read supports the following options:<br /> <em>Table 28-1: read Options</em><br /> <strong>Option</strong><br /> <strong>Description</strong><br /> -a <em>array</em><br /> Assign the input to <em>array</em>, starting with index zero. We <br />will cover arrays in Chapter 35.<br /> -d <em>delimiter</em><br /> The first character in the string <em>delimiter</em> is used to <br />indicate end of input, rather than a newline character.<br /> -e<br /> Use Readline to handle input. This permits input editing <br />in the same manner as the command line.<br /> -i <em>string</em><br /> Use <em>string</em> as a default reply if the user simply presses <br />Enter. Requires the -e option.<br /> -n <em>num</em><br /> Read <em>num</em> characters of input, rather than an entire line.<br /> -p <em>prompt</em><br /> Display a prompt for input using the string <em>prompt</em>.<br /> 400<br /></p>
<hr />
<p>read – Read Values From Standard Input<br /> -r<br /> Raw mode. Do not interpret backslash characters as <br />escapes.<br /> -s<br /> Silent mode. Do not echo characters to the display as <br />they are typed. This is useful when inputting passwords <br />and other confidential information.<br /> -t <em>seconds</em><br /> Timeout. Terminate input after <em>seconds</em>. read returns a <br />non-zero exit status if an input times out.<br /> -u <em>fd</em><br /> Use input from file descriptor <em>fd</em>, rather than standard <br />input.<br /> Using the various options, we can do interesting things with read. For example, with the <br />-p option, we can provide a prompt string:<br /> #!/bin/bash <br /> # read-single: read multiple values into default variable<br /> read -p &quot;Enter one or more values &gt; &quot; <br /> echo &quot;REPLY = '$REPLY'&quot;<br /> With the -t and -s options we can write a script that reads “secret” input and times out <br />if the input is not completed in a specified time:<br /> #!/bin/bash <br /> # read-secret: input a secret passphrase <br /> if read -t 10 -sp &quot;Enter secret passphrase &gt; &quot; secret_pass; then <br /> echo -e &quot;\nSecret passphrase = '$secret_pass'&quot; <br /> else echo -e &quot;\nInput timed out&quot; &gt;&amp;2 <br /> exit 1 <br /> fi<br /> The script prompts the user for a secret passphrase and waits 10 seconds for input. If the <br />entry is not completed within the specified time, the script exits with an error. Since the <br />-s option is included, the characters of the passphrase are not echoed to the display as <br />they are typed.<br /> 401<br /></p>
<hr />
<p>28 – Reading Keyboard Input<br /> It's possible to supply the user with a default response using the -e and -i options to-<br />gether:<br /> #!/bin/bash<br /> # read-default: supply a default value if user presses Enter key.<br /> read -e -p &quot;What is your user name? &quot; -i $USER<br />echo &quot;You answered: '$REPLY'&quot;<br /> In this script, we prompt the user to enter his/her user name and use the environment vari-<br />able USER to provide a default value. When the script is run it displays the default string <br />and if the user simply presses the Enter key, read will assign the default string to the <br />REPLY variable.<br /> [me@linuxbox ~]$ <strong>read-default<br /></strong>What is your user name? me<br /> You answered: 'me'<br /> IFS<br />Normally, the shell performs word splitting on the input provided to read. As we have <br />seen, this means that multiple words separated by one or more spaces become separate <br />items on the input line, and are assigned to separate variables by read. This behavior is <br />configured by a shell variable named  IFS  (for  Internal Field Separator). The default <br />value of IFS contains a space, a tab, and a newline character, each of which will separate <br />items from one another.<br />We can adjust the value of IFS to control the separation of fields input to read. For ex-<br />ample, the  /etc/passwd file contains lines of data that use the colon character as a <br />field separator. By changing the value of IFS to a single colon, we can use read to input <br />the contents of /etc/passwd and successfully separate fields into different variables. <br />Here we have a script that does just that:<br /> #!/bin/bash <br /> # read-ifs: read fields from a file <br /> FILE=/etc/passwd <br /> 402<br /></p>
<hr />
<p>read – Read Values From Standard Input<br /> read -p &quot;Enter a username &gt; &quot; user_name <br /> file_info=$(grep &quot;^$user_name:&quot; $FILE) <br /> if [ -n &quot;$file_info&quot; ]; then <br /> IFS=&quot;:&quot; read user pw uid gid name home shell &lt;&lt;&lt; &quot;$file_info&quot; <br />echo &quot;User =      '$user'&quot; <br /> echo &quot;UID =       '$uid'&quot; <br />echo &quot;GID =       '$gid'&quot; <br /> echo &quot;Full Name = '$name'&quot; <br />echo &quot;Home Dir. = '$home'&quot; <br /> echo &quot;Shell =     '$shell'&quot; <br /> else echo &quot;No such user '$user_name'&quot; &gt;&amp;2 <br /> exit 1 <br /> fi<br /> This script prompts the user to enter the username of an account on the system, then dis-<br />plays the different fields found in the user’s record in the /etc/passwd file. The script <br />contains two interesting lines. The first is:<br />file_info=$(grep &quot;^$user_name:&quot; $FILE) <br /> This line assigns the results of a grep command to the variable file_info. The regu-<br />lar expression used by grep assures that the username will only match a single line in <br />the /etc/passwd file.<br />The second interesting line is this one:<br />IFS=&quot;:&quot; read user pw uid gid name home shell &lt;&lt;&lt; &quot;$file_info&quot;<br /> The line consists of three parts: a variable assignment, a read command with a list of <br />variable names as arguments, and a strange new redirection operator. We’ll look at the <br />variable assignment first.<br />The shell allows one or more variable assignments to take place immediately before a <br />command. These assignments alter the environment for the command that follows. The <br />effect of the assignment is temporary; only changing the environment for the duration of <br />the command. In our case, the value of IFS is changed to a colon character. Alternately, <br />we could have coded it this way:<br />OLD_IFS=&quot;$IFS&quot;<br />IFS=&quot;:&quot;<br /> read user pw uid gid name home shell &lt;&lt;&lt; &quot;$file_info&quot;<br />IFS=&quot;$OLD_IFS&quot;<br /> where we store the value of IFS, assign a new value, perform the read command, and <br />then restore IFS to its original value. Clearly, placing the variable assignment in front of <br /> 403<br /></p>
<hr />
<p>28 – Reading Keyboard Input<br /> the command is a more concise way of doing the same thing.<br />The  &lt;&lt;&lt;  operator indicates a  <em>here string</em>. A here string is like a here document, only <br />shorter,   consisting   of   a   single   string.   In   our   example,   the   line   of   data   from   the <br />/etc/passwd file is fed to the standard input of the read command. We might won-<br />der why this rather oblique method was chosen rather than:<br />echo &quot;$file_info&quot; | IFS=&quot;:&quot; read user pw uid gid name home shell<br /> Well, there’s a reason...<br /> <strong>You Can’t Pipe read<br /></strong>While the read command normally takes input from standard input, you cannot <br />do this:<br />echo &quot;foo&quot; | read<br />We would expect this to work, but it does not. The command will appear to suc-<br />ceed but the REPLY variable will always be empty. Why is this?<br />The explanation has to do with the way the shell handles pipelines. In bash (and <br />other shells such as sh), pipelines create <em>subshells</em>. These are copies of the shell <br />and its environment which are used to execute the command in the pipeline. In <br />our example above, read is executed in a subshell.<br />Subshells in Unix-like systems create copies of the environment for the processes <br />to use while they execute. When the processes finishes the copy of the environ-<br />ment is destroyed. This means that <em>a subshell can never alter the environment of  <br />its parent process</em>. read assigns variables, which then become part of the envi-<br />ronment. In the example above, read assigns the value “foo” to the variable RE-<br />PLY in its subshell’s environment, but when the command exits, the subshell and <br />its environment are destroyed, and the effect of the assignment is lost.<br />Using here strings is one way to work around this behavior. Another method is <br />discussed in Chapter 36.<br /> <strong>Validating Input<br /></strong>With our new ability to have keyboard input comes an additional programming challenge, <br />validating input. Very often the difference between a well-written program and a poorly <br />written one lies in the program’s ability to deal with the unexpected. Frequently, the un-<br />expected appears in the form of bad input. We’ve done a little of this with our evaluation <br />programs in the previous chapter, where we checked the values of integers and screened <br />out empty values and non-numeric characters. It is important to perform these kinds of <br />programming checks every time a program receives input, to guard against invalid data. <br />This is especially important for programs that are shared by multiple users. Omitting <br /> 404<br /></p>
<hr />
<p>Validating Input<br /> these safeguards in the interests of economy might be excused if a program is to be used <br />once and only by the author to perform some special task. Even then, if the program per-<br />forms dangerous tasks such as deleting files, it would be wise to include data validation, <br />just in case.<br />Here we have an example program that validates various kinds of input:<br /> #!/bin/bash <br /> # read-validate: validate input <br /> invalid_input () { <br /> echo &quot;Invalid input '$REPLY'&quot; &gt;&amp;2 <br /> exit 1 <br /> } <br /> read -p &quot;Enter a single item &gt; &quot; <br /> # input is empty (invalid) <br /> [[ -z $REPLY ]] &amp;&amp; invalid_input <br /> # input is multiple items (invalid) <br />(( $(echo $REPLY | wc -w) &gt; 1 )) &amp;&amp; invalid_input <br /> # is input a valid filename? <br /> if [[ $REPLY =~ ^[-[:alnum:]\._]+$ ]]; then <br /> echo &quot;'$REPLY' is a valid filename.&quot; <br /> if [[ -e $REPLY ]]; then <br /> echo &quot;And file '$REPLY' exists.&quot; <br /> else <br /> echo &quot;However, file '$REPLY' does not exist.&quot; <br /> fi <br /> # is input a floating point number? <br />if [[ $REPLY =~ ^-?[[:digit:]]*\.[[:digit:]]+$ ]]; then <br /> echo &quot;'$REPLY' is a floating point number.&quot; <br /> else  echo &quot;'$REPLY' is not a floating point number.&quot; <br />fi <br /> # is input an integer? <br /> if [[ $REPLY =~ ^-?[[:digit:]]+$ ]]; then <br /> echo &quot;'$REPLY' is an integer.&quot; <br /> else <br /> echo &quot;'$REPLY' is not an integer.&quot; <br /> fi <br /> else echo &quot;The string '$REPLY' is not a valid filename.&quot; <br />fi<br /> 405<br /></p>
<hr />
<p>28 – Reading Keyboard Input<br /> This script prompts the user to enter an item. The item is subsequently analyzed to deter-<br />mine its contents. As we can see, the script makes use of many of the concepts that we <br />have covered thus far, including shell functions,  [[ ]],  (( )), the control operator <br />&amp;&amp;, and if, as well as a healthy dose of regular expressions.<br /> <strong>Menus<br /></strong>A common type of interactivity is called <em>menu-driven</em>. In menu-driven programs, the user <br />is presented with a list of choices and is asked to choose one. For example, we could <br />imagine a program that presented the following:<br /> Please Select:<br /> 1. Display System Information<br />2. Display Disk Space<br /> 3. Display Home Space Utilization<br />0. Quit<br /> Enter selection [0-3] &gt;<br /> Using what we learned from writing our sys_info_page program, we can construct a <br />menu-driven program to perform the tasks on the above menu:<br /> #!/bin/bash <br /> # read-menu: a menu driven system information program <br /> clear <br />echo &quot; <br /> Please Select: <br /> 1. Display System Information <br />2. Display Disk Space <br /> 3. Display Home Space Utilization <br />0. Quit <br /> &quot; <br />read -p &quot;Enter selection [0-3] &gt; &quot; <br /> if [[ $REPLY =~ ^[0-3]$ ]]; then <br /> if [[ $REPLY == 0 ]]; then <br /> echo &quot;Program terminated.&quot; <br /> exit <br /> fi <br /> if [[ $REPLY == 1 ]]; then <br /> 406<br /></p>
<hr />
<p>Menus<br /> echo &quot;Hostname: $HOSTNAME&quot; <br />uptime <br /> exit <br /> fi <br /> if [[ $REPLY == 2 ]]; then <br /> df -h <br /> exit <br /> fi <br /> if [[ $REPLY == 3 ]]; then <br /> if [[ $(id -u) -eq 0 ]]; then <br /> echo &quot;Home Space Utilization (All Users)&quot; <br />du -sh /home/* <br /> else <br /> echo &quot;Home Space Utilization ($USER)&quot; <br /> du -sh $HOME <br /> fi <br /> exit <br /> fi <br /> else <br /> echo &quot;Invalid entry.&quot; &gt;&amp;2 <br /> exit 1 <br /> fi<br /> This script is logically divided into two parts. The first part displays the menu and inputs <br />the response from the user. The second part identifies the response and carries out the se-<br />lected action. Notice the use of the exit command in this script. It is used here to pre-<br />vent the script from executing unnecessary code after an action has been carried out. The <br />presence of multiple exit points in a program is generally a bad idea (it makes program <br />logic harder to understand), but it works in this script. <br /> <strong>Summing Up<br /></strong>In this chapter, we took our first steps toward interactivity; allowing users to input data <br />into our programs via the keyboard. Using the techniques presented thus far, it is possible <br />to write many useful programs, such as specialized calculation programs and easy-to-use <br />front-ends for arcane command line tools. In the next chapter, we will build on the menu-<br />driven program concept to make it even better.<br /> Extra Credit<br />It is important to study the programs in this chapter carefully and have a complete under-<br />standing of the way they are logically structured, as the programs to come will be increas-<br />ingly complex. As an exercise, rewrite the programs in this chapter using the test com-<br />mand rather than the [[ ]] compound command. Hint: Use grep to evaluate the regu-<br />lar expressions and evaluate the exit status. This will be good practice. <br /> 407<br /></p>
<hr />
<p>28 – Reading Keyboard Input<br /> <strong>Further Reading</strong><br /> ●<br /> The <em>Bash Reference Manual</em> contains a chapter on builtins, which includes the <br />read command:<br /><a href="http://www.gnu.org/software/bash/manual/bashref.html#Bash-Builtins">http://www.gnu.org/software/bash/manual/bashref.html#Bash-Builtins</a><br /> 408<br /></p>
<hr />
<p>29 – Flow Control: Looping With while / until<br /> <em><strong>29 – Flow Control: Looping With while / until</strong></em><br /> In the previous chapter, we developed a menu-driven program to produce various kinds <br />of system information. The program works, but it still has a significant usability problem. <br />It only executes a single choice and then terminates. Even worse, if an invalid selection is <br />made, the program terminates with an error, without giving the user an opportunity to try <br />again. It would be better if we could somehow construct the program so that it could re-<br />peat the menu display and selection over and over, until the user chooses to exit the pro-<br />gram.<br />In this chapter, we will look at a programming concept called <em>looping</em>, which can be used <br />to make portions of programs repeat. The shell provides three compound commands for <br />looping. We will look at two of them in this chapter, and the third in a later one.<br /> <strong>Looping<br /></strong>Daily life is full of repeated activities. Going to work each day, walking the dog, slicing a <br />carrot are all tasks that involve repeating a series of steps. Let’s consider slicing a carrot. <br />If we express this activity in pseudocode, it might look something like this:<br /> 1. get cutting board<br />2. get knife<br />3. place carrot on cutting board<br />4. lift knife<br />5. advance carrot<br />6. slice carrot<br />7. if entire carrot sliced, then quit, else go to step 4<br /> Steps 4 through 7 form a <em>loop</em>. The actions within the loop are repeated until the condi-<br />tion, “entire carrot sliced,” is reached.<br /> while<br />bash can express a similar idea. Let’s say we wanted to display five numbers in sequen-<br /> 409<br /></p>
<hr />
<p>29 – Flow Control: Looping With while / until<br /> tial order from one to five. a bash script could be constructed as follows:<br /> #!/bin/bash <br /> # while-count: display a series of numbers <br /> count=1 <br /> while [[ $count -le 5 ]]; do <br /> echo $count <br /> count=$((count + 1)) <br /> done<br /> echo &quot;Finished.&quot;<br /> When executed, this script displays the following:<br /> [me@linuxbox ~]$ <strong>while-count</strong><br /> 1<br />2<br /> 3<br />4<br /> 5<br />Finished.<br /> The syntax of the while command is:<br />while <em>commands</em>; do <em>commands</em>; done<br />Like if, while evaluates the exit status of a list of commands. As long as the exit status <br />is  zero,   it  performs  the  commands  inside   the  loop.   In  the  script   above,  the   variable <br />count is created and assigned an initial value of 1. The while command evaluates the <br />exit status of the test command. As long as the test command returns an exit status of <br />zero, the commands within the loop are executed. At the end of each cycle, the  test <br />command is repeated. After six iterations of the loop, the value of count has increased <br />to 6, the test command no longer returns an exit status of zero and the loop terminates. <br />The program continues with the next statement following the loop.<br />We can use a <em>while loop</em> to improve the read-menu program from the previous chapter:<br /> #!/bin/bash <br /> # while-menu: a menu driven system information program <br /> 410<br /></p>
<hr />
<p>Looping<br /> <strong>DELAY=3</strong> # Number of seconds to display results <br /> <strong>while [[ $REPLY != 0 ]]; do</strong> <br /> clear <br /> cat &lt;&lt;- _EOF_ <br /> Please Select: <br />  <br /> 1. Display System Information <br /> 2. Display Disk Space <br />3. Display Home Space Utilization <br /> 0. Quit <br /> _EOF_ <br />read -p &quot;Enter selection [0-3] &gt; &quot; <br /> if [[ $REPLY =~ ^[0-3]$ ]]; then <br /> if [[ $REPLY == 1 ]]; then <br /> echo &quot;Hostname: $HOSTNAME&quot; <br /> uptime <br /><strong>sleep $DELAY</strong> <br /> fi <br />if [[ $REPLY == 2 ]]; then <br /> df -h <br /><strong>sleep $DELAY</strong> <br /> fi <br />if [[ $REPLY == 3 ]]; then <br /> if [[ $(id -u) -eq 0 ]]; then <br /> echo &quot;Home Space Utilization (All Users)&quot; <br /> du -sh /home/* <br /> else  echo &quot;Home Space Utilization ($USER)&quot; <br /> du -sh $HOME <br /> fi <br /><strong>sleep $DELAY </strong><br /> fi <br /> else  echo &quot;Invalid entry.&quot; <br /> <strong>sleep $DELAY </strong><br /> fi <br /> <strong>done</strong> <br /> echo &quot;Program terminated.&quot;<br /> By enclosing the menu in a while loop, we are able to have the program repeat the menu <br />display after each selection. The loop continues as long as REPLY is not equal to “0” and <br />the menu is displayed again, giving the user the opportunity to make another selection. At <br />the end of each action, a sleep command is executed so the program will pause for a <br />few seconds to allow the results of the selection to be seen before the screen is cleared <br />and the menu is redisplayed. Once REPLY is equal to “0,” indicating the “quit” selection, <br /> 411<br /></p>
<hr />
<p>29 – Flow Control: Looping With while / until<br /> the loop terminates and execution continues with the line following done.<br /> <strong>Breaking Out Of A Loop<br /></strong>bash  provides two builtin commands that can be used to control program flow inside <br />loops. The  break  command  immediately  terminates a loop, and program control re-<br />sumes with the next statement following the loop. The continue command causes the <br />remainder of the loop to be skipped, and program control resumes with the next iteration <br />of the loop. Here we see a version of the  while-menu  program incorporating both <br />break and continue: <br /> #!/bin/bash <br /> # while-menu2: a menu driven system information program <br /> DELAY=3 # Number of seconds to display results <br /> <strong>while true; do</strong> <br /> clear <br /> cat &lt;&lt;- _EOF_ <br /> Please Select: <br /> 1. Display System Information <br /> 2. Display Disk Space <br />3. Display Home Space Utilization <br /> 0. Quit <br /> _EOF_ <br />read -p &quot;Enter selection [0-3] &gt; &quot; <br /> if [[ $REPLY =~ ^[0-3]$ ]]; then <br /> if [[ $REPLY == 1 ]]; then <br /> echo &quot;Hostname: $HOSTNAME&quot; <br /> uptime <br />sleep $DELAY <br /> <strong>continue</strong> <br /> fi <br /> if [[ $REPLY == 2 ]]; then <br /> df -h <br /> sleep $DELAY <br /><strong>continue</strong> <br /> fi <br />if [[ $REPLY == 3 ]]; then <br /> if [[ $(id -u) -eq 0 ]]; then <br /> echo &quot;Home Space Utilization (All Users)&quot; <br /> du -sh /home/* <br /> else <br /> 412<br /></p>
<hr />
<p>Breaking Out Of A Loop<br /> echo &quot;Home Space Utilization ($USER)&quot;<br />du -sh $HOME <br /> fi <br />sleep $DELAY<br /> <strong>continue</strong> <br /> fi <br /> <strong>if [[ $REPLY == 0 ]]; then </strong><br /> <strong>break </strong><br /> <strong>fi </strong><br /> else  echo &quot;Invalid entry.&quot; <br /> sleep $DELAY <br /> fi <br /> done <br /> echo &quot;Program terminated.&quot;<br /> In this version of the script, we set up an <em>endless loop</em> (one that never terminates on its <br />own) by using the true command to supply an exit status to while. Since true will <br />always exit with a exit status of zero, the loop will never end. This is a surprisingly com-<br />mon scripting technique. Since the loop will never end on its own, it’s up to the program-<br />mer to provide some way to break out of the loop when the time is right. In this script, the <br />break command is used to exit the loop when the “0” selection is chosen. The con-<br />tinue  command has been included at the end of the other script choices to allow for <br />more efficient execution. By using continue, the script will skip over code that is not <br />needed when a selection is identified. For example, if the “1” selection is chosen and <br />identified, there is no reason to test for the other selections.<br /> until<br />The until command is much like while, except instead of exiting a loop when a non-<br />zero exit status is encountered, it does the opposite. An <em>until loop</em> continues until it re-<br />ceives a zero exit status. In our while-count script, we continued the loop as long as <br />the value of the count variable was less than or equal to 5. We could get the same result <br />by coding the script with until:<br /> #!/bin/bash <br /> # until-count: display a series of numbers <br /> count=1 <br /> <strong>until [[ $count -gt 5 ]]</strong>; do <br /> echo $count <br /> 413<br /></p>
<hr />
<p>29 – Flow Control: Looping With while / until<br /> count=$((count + 1)) <br /> done<br /> echo &quot;Finished.&quot;<br /> By changing the test expression to $count -gt 5, until will terminate the loop at <br />the correct time. The decision of whether to use the while or until loop is usually a <br />matter of choosing the one that allows the clearest test to be written.<br /> <strong>Reading Files With Loops<br /></strong>while  and  until  can process standard input. This allows files to be processed with <br />while and until loops. In the following example, we will display the contents of the dis-<br />tros.txt file used in earlier chapters:<br /> #!/bin/bash <br /> # while-read: read lines from a file <br /> while read distro version release; do <br /> printf &quot;Distro: %s\tVersion: %s\tReleased: %s\n&quot; \ <br /> $distro \ <br /> $version \ <br />$release <br /> done <strong>&lt; distros.txt</strong><br /> To redirect a file to the loop, we place the redirection operator after the done statement. <br />The loop will use read to input the fields from the redirected file. The read command <br />will exit after each line is read, with a zero exit status until the end-of-file is reached. At <br />that point, it will exit with a non-zero exit status, thereby terminating the loop. It is also <br />possible to pipe standard input into a loop:<br /> #!/bin/bash <br /> # while-read2: read lines from a file <br /> <strong>sort -k 1,1 -k 2n distros.txt |</strong> while read distro version release; do <br /> printf &quot;Distro: %s\tVersion: %s\tReleased: %s\n&quot; \ <br /> $distro \ <br />$version \ <br /> $release <br /> done<br /> 414<br /></p>
<hr />
<p>Reading Files With Loops<br /> Here we take the output of the sort command and display the stream of text. However, <br />it is important to remember that since a pipe will execute the loop in a subshell, any vari-<br />ables created or assigned within the loop will be lost when the loop terminates.<br /> <strong>Summing Up<br /></strong>With the introduction of loops, and our previous encounters with branching, subroutines <br />and sequences, we have covered the major types of flow control used in programs. bash <br />has some more tricks up its sleeve, but they are refinements on these basic concepts. <br /> <strong>Further Reading</strong><br /> ●<br /> The <em>Bash Guide for Beginners</em> from the Linux Documentation Project has some <br />more examples of while loops:<br /><a href="http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_09_02.html">http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_09_02.html</a><br /> ●<br /> The Wikipedia has an article on loops, which is part of a larger article on flow <br />control:<br /><a href="http://en.wikipedia.org/wiki/Control_flow#Loops">http://en.wikipedia.org/wiki/Control_flow#Loops</a><br />  <br /> 415<br /></p>
<hr />
<p>30 – Troubleshooting<br /> <em><strong>30 – Troubleshooting</strong></em><br /> As our scripts become more complex, it’s time to take a look at what happens when <br />things go wrong and they don’t do what we want. In this chapter, we’ll look at some of <br />the common kinds of errors that occur in scripts, and describe a few useful techniques <br />that can be used to track down and eradicate problems.<br /> <strong>Syntactic Errors<br /></strong>One general class of errors is <em>syntactic</em>. Syntactic errors involve mistyping some element <br />of shell syntax. In most cases, these kinds of errors will lead to the shell refusing to exe-<br />cute the script.<br />In the following discussions, we will use this script to demonstrate common types of er-<br />rors:<br /> #!/bin/bash <br /> # trouble: script to demonstrate common errors <br /> number=1 <br /> if [ $number = 1 ]; then <br /> echo &quot;Number is equal to 1.&quot; <br /> else <br /> echo &quot;Number is not equal to 1.&quot; <br /> fi<br /> As written, this script runs successfully:<br /> [me@linuxbox ~]$ <strong>trouble</strong> <br /> Number is equal to 1.<br /> 416<br /></p>
<hr />
<p>Syntactic Errors<br /> Missing Quotes<br />If we edit our script and remove the trailing quote from the argument following the first <br />echo command:<br /> #!/bin/bash <br /> # trouble: script to demonstrate common errors <br /> number=1 <br /> if [ $number = 1 ]; then <br /> <strong>echo &quot;Number is equal to 1.</strong> <br /> else <br /> echo &quot;Number is not equal to 1.&quot; <br /> fi<br /> watch what happens:<br /> [me@linuxbox ~]$ <strong>trouble</strong> <br /> /home/me/bin/trouble: line 10: unexpected EOF while looking for <br />matching `&quot;' <br /> /home/me/bin/trouble: line 13: syntax error: unexpected end of file<br /> It generates two errors. Interestingly, the line numbers reported are not where the missing <br />quote was removed, but rather much later in the program. We can see why, if we follow <br />the program after the missing quote.  bash will continue looking for the closing quote <br />until it finds one, which it does immediately after the second echo command. bash be-<br />comes very confused after that, and the syntax of the if command is broken because the <br />fi statement is now inside a quoted (but open) string.<br />In long scripts, this kind of error can be quite hard to find. Using an editor with syntax <br />highlighting will help. If a complete version of vim is installed, syntax highlighting can <br />be enabled by entering the command:<br /> <strong>:syntax on</strong><br /> Missing Or Unexpected Tokens<br />Another common mistake is forgetting to complete a compound command, such as if or <br /> 417<br /></p>
<hr />
<p>30 – Troubleshooting<br /> while. Let’s look at what happens if we remove the semicolon after the test in the if <br />command:<br /> #!/bin/bash <br /> # trouble: script to demonstrate common errors <br /> number=1 <br /> <strong>if [ $number = 1 ] then</strong> <br /> echo &quot;Number is equal to 1.&quot; <br /> else <br /> echo &quot;Number is not equal to 1.&quot; <br /> fi<br /> The result is this:<br /> [me@linuxbox ~]$ <strong>trouble</strong> <br /> /home/me/bin/trouble: line 9: syntax error near unexpected token <br />`else' <br /> /home/me/bin/trouble: line 9: `else'<br /> Again, the error message points to a error that occurs later than the actual problem. What <br />happens is really pretty interesting. As we recall, if accepts a list of commands and eval-<br />uates the exit code of the last command in the list. In our program, we intend this list to <br />consist of a single command, [, a synonym for test. The [ command takes what follows <br />it as a list of arguments; in our case, four arguments: $number, 1, =, and ]. With the <br />semicolon removed, the word then is added to the list of arguments, which is syntacti-<br />cally legal. The following echo command is legal, too. It’s interpreted as another com-<br />mand in the list of commands that  if will evaluate for an exit code. The else is en-<br />countered next, but it’s out of place, since the shell recognizes it as a <em>reserved word</em> (a <br />word that has special meaning to the shell) and not the name of a command, hence the er-<br />ror message.<br /> Unanticipated Expansions<br />It’s possible to have errors that only occur intermittently in a script. Sometimes the script <br />will run fine and other times it will fail because of the results of an expansion. If we re-<br />turn our missing semicolon and change the value of number to an empty variable, we <br />can demonstrate:<br /> 418<br /></p>
<hr />
<p>Syntactic Errors<br /> #!/bin/bash <br /> # trouble: script to demonstrate common errors <br /> <strong>number= </strong><br /> if [ $number = 1 ]; then <br /> echo &quot;Number is equal to 1.&quot; <br /> else <br /> echo &quot;Number is not equal to 1.&quot; <br /> fi<br /> Running the script with this change results in the output:<br /> [me@linuxbox ~]$ <strong>trouble</strong> <br /> /home/me/bin/trouble: line 7: [: =: unary operator expected<br /> Number is not equal to 1.<br /> We get this rather cryptic error message, followed by the output of the second  echo <br />command. The problem is the expansion of the number variable within the test com-<br />mand. When the command:<br /> [ $number = 1 ]<br /> undergoes expansion with number being empty, the result is this:<br /> [  = 1 ]<br /> which is invalid and the error is generated. The = operator is a binary operator (it requires <br />a value on each side), but the first value is missing, so the  test  command  expects a <br />unary operator (such as -z) instead. Further, since the test failed (because of the error), <br />the  if  command receives a non-zero exit code and acts accordingly, and the second <br />echo command is executed.<br />This problem can be corrected by adding quotes around the first argument in the test <br />command:<br /> [ &quot;$number&quot; = 1 ]<br /> 419<br /></p>
<hr />
<p>30 – Troubleshooting<br /> Then when expansion occurs, the result will be this:<br /> [ &quot;&quot; = 1 ]<br /> which yields the correct number of arguments. In addition to empty strings, quotes should <br />be used in cases where a value could expand into multi-word strings, as with filenames <br />containing embedded spaces.<br /> <strong>Logical Errors <br /></strong>Unlike syntactic errors,  <em>logical errors</em>  do not prevent a script from running. The script <br />will run, but it will not produce the desired result, due to a problem with its logic. There <br />are countless numbers of possible logical errors, but here are a few of the most common <br />kinds found in scripts:<br /> 1. <strong>Incorrect  conditional  expressions.</strong>  It’s easy to incorrectly code an if/then/else <br /> and have the wrong logic carried out. Sometimes the logic will be reversed, or it <br />will be incomplete.<br /> 2. <strong>“Off by one” errors.</strong> When coding loops that employ counters, it is possible to <br /> overlook that the loop may require that the counting start with zero, rather than <br />one, for the count to conclude at the correct point. These kinds of errors result in <br />either a loop “going off the end” by counting too far, or else missing the last itera-<br />tion of the loop by terminating one iteration too soon.<br /> 3. <strong>Unanticipated situations.</strong> Most logic errors result from a program encountering <br /> data or situations that were unforeseen by the programmer. This can also include <br />unanticipated expansions, such as a filename that contains embedded spaces that <br />expands into multiple command arguments rather than a single filename.<br /> Defensive Programming<br />It is important to verify assumptions when programming. This means a careful evaluation <br />of the exit status of programs and commands that are used by a script. Here is an exam-<br />ple, based on a true story. An unfortunate system administrator wrote a script to perform a <br />maintenance task on an important server. The script contained the following two lines of <br />code:<br /> cd $dir_name<br /> rm *<br /> 420<br /></p>
<hr />
<p>Logical Errors <br /> There is nothing intrinsically wrong with these two lines, as long as the directory named <br />in the variable, dir_name, exists. But what happens if it does not? In that case, the cd <br />command fails and the script continues to the next line and deletes the files in the current <br />working directory. Not the desired outcome at all! The hapless administrator destroyed an <br />important part of the server because of this design decision.<br />Let’s look at some ways this design could be improved. First, it might be wise to make <br />the execution of rm contingent on the success of cd:<br /> cd $dir_name &amp;&amp; rm *<br /> This way, if the cd command fails, the rm command is not carried out. This is better, but <br />still leaves open the possibility that the variable,  dir_name, is unset or empty, which <br />would result in the files in the user’s home directory being deleted. This could also be <br />avoided by checking to see that dir_name actually contains the name of an existing di-<br />rectory:<br /> [[ -d $dir_name ]] &amp;&amp; cd $dir_name &amp;&amp; rm *<br /> Often, it is best to terminate the script with an error when an situation such as the one <br />above occurs:<br /> # Delete files in directory $dir_name<br />if [[ ! -d &quot;$dir_name&quot; ]]; then<br /> echo &quot;No such directory: '$dir_name'&quot; &gt;&amp;2<br />exit 1<br /> fi<br />if ! cd $dir_name; then<br /> echo &quot;Cannot cd to '$dir_name'&quot; &gt;&amp;2<br />exit 1<br /> fi<br />if ! rm *; then<br /> echo &quot;File deletion failed. Check results&quot; &gt;&amp;2<br />exit 1<br /> fi<br /> Here, we check both the name, to see that it is that of an existing directory, and the suc-<br />cess of the cd command. If either fails, a descriptive error message is sent to standard er-<br />ror and the script terminates with an exit status of one to indicate a failure.<br /> 421<br /></p>
<hr />
<p>30 – Troubleshooting<br /> Verifying Input<br />A general rule of good programming is that if a program accepts input, it must be able to <br />deal with anything it receives. This usually means that input must be carefully screened, <br />to ensure that only valid input is accepted for further processing. We saw an example of <br />this in the previous chapter when we studied the read command. One script contained <br />the following test to verify a menu selection:<br /> [[ $REPLY =~ ^[0-3]$ ]]<br /> This test is very specific. It will only return a zero exit status if the string returned by the <br />user is a numeral in the range of zero to three. Nothing else will be accepted. Sometimes <br />these sorts of tests can be very challenging to write, but the effort is necessary to produce <br />a high quality script. <br /> <strong>Design Is A Function Of Time<br /></strong>When I was a college student studying industrial design, a wise professor stated <br />that the degree of design on a project was determined by the amount of time given <br />to the designer. If you were given five minutes to design a device “that kills flies,” <br />you designed a flyswatter. If you were given five months, you might come up <br />with a laser-guided “anti-fly system” instead.<br />The   same   principle   applies   to   programming.   Sometimes   a   “quick-and-dirty” <br />script will do if it’s only going to be used once and only used by the programmer. <br />That kind of script is common and should be developed quickly to make the effort <br />economical. Such scripts don’t need a lot of comments and defensive checks. On <br />the other hand, if a script is intended for <em>production use,</em> that is, a script that will <br />be used over and over for an important task or by multiple users, it needs much <br />more careful development.<br /> <strong>Testing<br /></strong>Testing is an important step in every kind of software development, including scripts. <br />There is a saying in the open-source world, “release early, release often,” which reflects <br />this fact. By releasing early and often, software gets more exposure to use and testing. <br />Experience has shown that bugs are much easier to find, and much less expensive to fix, <br />if they are found early in the development cycle.<br />In a previous discussion, we saw how stubs can be used to verify program flow. From the <br />earliest stages of script development, they are a valuable technique to check the progress <br /> 422<br /></p>
<hr />
<p>Testing<br /> of our work.<br />Let’s look at the file-deletion problem above and see how this could be coded for easy <br />testing. Testing the original fragment of code would be dangerous, since its purpose is to <br />delete files, but we could modify the code to make the test safe:<br /> if [[ -d $dir_name ]]; then<br /> if cd $dir_name; then<br /> <strong>echo</strong> rm * <strong># TESTING</strong><br /> else<br /> echo &quot;cannot cd to '$dir_name'&quot; &gt;&amp;2<br />exit 1<br /> fi<br /> else echo &quot;no such directory: '$dir_name'&quot; &gt;&amp;2<br /> exit 1<br /> fi<br /><strong>exit # TESTING</strong><br /> Since the error conditions already output useful messages, we don't have to add any. The <br />most important change is placing an echo command just before the rm command to al-<br />low the command and its expanded argument list to be displayed, rather than the com-<br />mand actually being executed. This change allows safe execution of the code. At the end <br />of the code fragment, we place an exit command to conclude the test and prevent any <br />other part of the script from being carried out. The need for this will vary according to the <br />design of the script.<br />We also include some comments that act as “markers” for our test-related changes. These <br />can be used to help find and remove the changes when testing is complete.<br /> Test Cases<br />To perform useful testing, it's important to develop and apply good  <em>test cases</em>. This is <br />done by carefully choosing input data or operating conditions that reflect <em>edge</em> and <em>cor-<br />ner</em> cases. In our code fragment (which is very simple), we want to know how the code <br />performs under three specific conditions:<br /> 1. dir_name contains the name of an existing directory<br />2. dir_name contains the name of a non-existent directory<br />3. dir_name is empty<br /> By performing the test with each of these conditions, good <em>test coverage</em> is achieved.<br />Just as with design, testing is a function of time, as well. Not every script feature needs to <br /> 423<br /></p>
<hr />
<p>30 – Troubleshooting<br /> be extensively tested. It's really a matter of determining what is most important. Since it <br />could be so potentially destructive if it malfunctioned, our code fragment deserves careful <br />consideration during both its design and testing.<br /> <strong>Debugging<br /></strong>If testing reveals a problem with a script, the next step is debugging. “A problem” usually <br />means that the script is, in some way, not performing to the programmer's expectations. If <br />this is the case, we need to carefully determine exactly what the script is actually doing <br />and why. Finding bugs can sometimes involve a lot of detective work. <br />A well designed script will try to help. It should be programmed defensively, to detect ab-<br />normal conditions and provide useful feedback to the user. Sometimes, however, prob-<br />lems are quite strange and unexpected, and more involved techniques are required.<br /> Finding The Problem Area<br />In some scripts, particularly long ones, it is sometimes useful to isolate the area of the <br />script that is related to the problem. This won’t always be the actual error, but isolation <br />will often provide insights into the actual cause. One technique that can be used to isolate <br />code is “commenting out” sections of a script. For example, our file deletion fragment <br />could be modified to determine if the removed section was related to an error:<br /> if [[ -d $dir_name ]]; then<br /> if cd $dir_name; then<br /> rm *<br /> else<br /> echo &quot;cannot cd to '$dir_name'&quot; &gt;&amp;2<br />exit 1<br /> fi<br /> <strong># else</strong><br /> <strong>#</strong><br /> <strong>echo &quot;no such directory: '$dir_name'&quot; &gt;&amp;2</strong><br /> <strong>#</strong><br /> <strong>exit 1</strong><br /> fi<br /> By placing comment symbols at the beginning of each line in a logical section of a script, <br />we prevent that section from being executed. Testing can then be performed again, to see <br />if the removal of the code has any impact on the behavior of the bug. <br /> Tracing<br />Bugs are often cases of unexpected logical flow within a script. That is, portions of the <br />script are either never being executed, or are being executed in the wrong order or at the <br /> 424<br /></p>
<hr />
<p>Debugging<br /> wrong time. To view the actual flow of the program, we use a technique called <em>tracing</em>.<br />One tracing method involves placing informative messages in a script that display the lo-<br />cation of execution. We can add messages to our code fragment:<br /> <strong>echo &quot;preparing to delete files&quot; &gt;&amp;2<br /></strong>if [[ -d $dir_name ]]; then<br /> if cd $dir_name; then<br /> <strong>echo &quot;deleting files&quot; &gt;&amp;2</strong><br /> rm *<br /> else<br /> echo &quot;cannot cd to '$dir_name'&quot; &gt;&amp;2<br />exit 1<br /> fi<br /> else echo &quot;no such directory: '$dir_name'&quot; &gt;&amp;2<br /> exit 1<br /> fi<br /><strong>echo &quot;file deletion complete&quot; &gt;&amp;2</strong><br /> We send the messages to standard error to separate them from normal output. We also do <br />not indent the lines containing the messages, so it is easier to find when it’s time to re-<br />move them.<br />Now when the script is executed, it’s possible to see that the file deletion has been per-<br />formed:<br /> [me@linuxbox ~]$ deletion-script<br />preparing to delete files<br /> deleting files<br />file deletion complete<br /> [me@linuxbox ~]$ <br /> bash  also provides a method of tracing, implemented by the  -x  option and the  set <br />command with the -x option. Using our earlier trouble script, we can activate tracing <br />for the entire script by adding the -x option to the first line:<br /> <strong>#!/bin/bash -x</strong><br /> # trouble: script to demonstrate common errors <br /> number=1 <br /> 425<br /></p>
<hr />
<p>30 – Troubleshooting<br /> if [ $number = 1 ]; then <br /> echo &quot;Number is equal to 1.&quot; <br /> else <br /> echo &quot;Number is not equal to 1.&quot; <br /> fi<br /> When executed, the results look like this:<br /> [me@linuxbox ~]$ <strong>trouble</strong> <br /> + number=1 <br />+ '[' 1 = 1 ']' <br /> + echo 'Number is equal to 1.' <br />Number is equal to 1.<br /> With tracing enabled, we see the commands performed with expansions applied. The <br />leading plus signs indicate the display of the trace to distinguish them from lines of regu-<br />lar output. The plus sign is the default character for trace output. It is contained in the <br />PS4  (prompt string 4) shell variable. The contents of this variable can be adjusted to <br />make the prompt more useful. Here, we modify the contents of the variable to include the <br />current line number in the script where the trace is performed. Note that single quotes are <br />required to prevent expansion until the prompt is actually used:  <br /> [me@linuxbox ~]$ <strong>export PS4='$LINENO + '<br /></strong>[me@linuxbox ~]$ <strong>trouble</strong> <br /> 5 + number=1 <br />7 + '[' 1 = 1 ']' <br /> 8 + echo 'Number is equal to 1.' <br />Number is equal to 1.<br /> To perform a trace on a selected portion of a script, rather than the entire script, we can <br />use the set command with the -x option:<br /> #!/bin/bash<br /> # trouble: script to demonstrate common errors <br /> number=1<br /> <strong>set -x # Turn on tracing<br /></strong>if [ $number = 1 ]; then <br /> echo &quot;Number is equal to 1.&quot; <br /> 426<br /></p>
<hr />
<p>Debugging<br /> else <br /> echo &quot;Number is not equal to 1.&quot; <br /> fi<br /><strong>set +x # Turn off tracing</strong><br /> We use the set command with the -x option to activate tracing and the +x option to de-<br />activate tracing. This technique can be used to examine multiple portions of a trouble-<br />some script.<br /> Examining Values During Execution<br />It is often useful, along with tracing, to display the content of variables to see the internal <br />workings of a script while it is being executed. Applying additional echo statements will <br />usually do the trick:<br /> #!/bin/bash<br /> # trouble: script to demonstrate common errors <br /> number=1<br /> <strong>echo &quot;number=$number&quot; # DEBUG<br /></strong>set -x # Turn on tracing<br /> if [ $number = 1 ]; then <br /> echo &quot;Number is equal to 1.&quot; <br /> else <br /> echo &quot;Number is not equal to 1.&quot; <br /> fi<br />set +x # Turn off tracing<br /> In this trivial example, we simply display the value of the variable number and mark the <br />added line with a comment to facilitate its later identification and removal. This tech-<br />nique is particularly useful when watching the behavior of loops and arithmetic within <br />scripts.<br /> <strong>Summing Up<br /></strong>In this chapter, we looked at just a few of the problems that can crop up during script de-<br />velopment. Of course, there are many more. The techniques described here will enable <br />finding most common bugs. Debugging is a fine art that can be developed through expe-<br />rience, both in knowing how to avoid bugs (testing constantly throughout development) <br />and in finding bugs (effective use of tracing).<br /> 427<br /></p>
<hr />
<p>30 – Troubleshooting<br /> <strong>Further Reading</strong><br /> ●<br /> The Wikipedia has a couple of short articles on syntactic and logical errors:<br /><a href="http://en.wikipedia.org/wiki/Syntax_error">http://en.wikipedia.org/wiki/Syntax_error<br /></a><a href="http://en.wikipedia.org/wiki/Logic_error">http://en.wikipedia.org/wiki/Logic_error</a><br /> ●<br /> There are many online resources for the technical aspects of bash programming:<br /><a href="http://mywiki.wooledge.org/BashPitfalls">http://mywiki.wooledge.org/BashPitfalls<br /></a><a href="http://tldp.org/LDP/abs/html/gotchas.html">http://tldp.org/LDP/abs/html/gotchas.html<br /></a><a href="http://www.gnu.org/software/bash/manual/html_node/Reserved-Word-Index.html">http://www.gnu.org/software/bash/manual/html_node/Reserved-Word-Index.html</a><br /> ●<br /> Eric Raymond’s <em>The Art of Unix Programming</em> is a great resource for learning the <br />basic concepts found in well-written Unix programs. Many of these ideas apply to <br />shell scripts:<br /><a href="http://www.faqs.org/docs/artu/">http://www.faqs.org/docs/artu/<br /></a><a href="http://www.faqs.org/docs/artu/ch01s06.html">http://www.faqs.org/docs/artu/ch01s06.html</a><br /> ●<br /> For really heavy-duty debugging, there is the Bash Debugger:<br /><a href="http://bashdb.sourceforge.net/">http://bashdb.sourceforge.net/</a><br /> 428<br /></p>
<hr />
<p>31 – Flow Control: Branching With case<br /> <em><strong>31 – Flow Control: Branching With case</strong></em><br /> In this chapter, we will continue to look at flow control. In Chapter 28, we constructed <br />some simple menus and built the logic used to act on a user’s selection. To do this, we <br />used a series of  if  commands to identify which of the possible choices has been se-<br />lected. This type of construct appears frequently in programs, so much so that many pro-<br />gramming languages (including the shell) provide a flow control mechanism for multiple-<br />choice decisions.<br /> <strong>case<br /></strong>The bash multiple-choice compound command is called case. It has the following syn-<br />tax:<br />case <em>word</em> in<br /> [<em>pattern</em> [| <em>pattern</em>]...) <em>commands</em> ;;]...<br /> esac<br /> If we look at the read-menu program from Chapter 28, we see the logic used to act on <br />a user’s selection:<br /> #!/bin/bash <br /> # read-menu: a menu driven system information program <br /> clear <br />echo &quot; <br /> Please Select: <br /> 1. Display System Information <br />2. Display Disk Space <br /> 3. Display Home Space Utilization <br />0. Quit <br /> &quot; <br />read -p &quot;Enter selection [0-3] &gt; &quot; <br /> <strong>if [[ $REPLY =~ ^[0-3]$ ]]; then </strong><br /> <strong>if [[ $REPLY == 0 ]]; then </strong><br /> 429<br /></p>
<hr />
<p>31 – Flow Control: Branching With case<br /> <strong>echo &quot;Program terminated.&quot; <br />exit </strong><br /> <strong>fi <br />if [[ $REPLY == 1 ]]; then </strong><br /> <strong>echo &quot;Hostname: $HOSTNAME&quot; <br />uptime </strong><br /> <strong>exit </strong><br /> <strong>fi </strong><br /> <strong>if [[ $REPLY == 2 ]]; then </strong><br /> <strong>df -h </strong><br /> <strong>exit </strong><br /> <strong>fi </strong><br /> <strong>if [[ $REPLY == 3 ]]; then </strong><br /> <strong>if [[ $(id -u) -eq 0 ]]; then </strong><br /> <strong>echo &quot;Home Space Utilization (All Users)&quot; <br />du -sh /home/* </strong><br /> <strong>else </strong><br /> <strong>echo &quot;Home Space Utilization ($USER)&quot; </strong><br /> <strong>du -sh $HOME </strong><br /> <strong>fi </strong><br /> <strong>exit </strong><br /> <strong>fi </strong><br /> <strong>else </strong><br /> <strong>echo &quot;Invalid entry.&quot; &gt;&amp;2 </strong><br /> <strong>exit 1 </strong><br /> <strong>fi</strong><br /> Using case, we can replace this logic with something simpler:<br /> #!/bin/bash <br /> # case-menu: a menu driven system information program <br /> clear <br />echo &quot; <br /> Please Select: <br /> 1. Display System Information <br />2. Display Disk Space <br /> 3. Display Home Space Utilization <br />0. Quit <br /> &quot; <br />read -p &quot;Enter selection [0-3] &gt; &quot; <br /> <strong>case $REPLY in </strong><br /> <strong>0)</strong><br /> <strong>echo &quot;Program terminated.&quot; <br />exit </strong><br /> <strong>;; </strong><br /> 430<br /></p>
<hr />
<p>case<br /> <strong>1)</strong><br /> <strong>echo &quot;Hostname: $HOSTNAME&quot; <br />uptime </strong><br /> <strong>;; </strong><br /> <strong>2)</strong><br /> <strong>df -h </strong><br /> <strong>;; </strong><br /> <strong>3)</strong><br /> <strong>if [[ $(id -u) -eq 0 ]]; then </strong><br /> <strong>echo &quot;Home Space Utilization (All Users)&quot; <br />du -sh /home/* </strong><br /> <strong>else </strong><br /> <strong>echo &quot;Home Space Utilization ($USER)&quot; </strong><br /> <strong>du -sh $HOME </strong><br /> <strong>fi </strong><br /> <strong>;; </strong><br /> <strong>*)</strong><br /> <strong>echo &quot;Invalid entry&quot; &gt;&amp;2 </strong><br /> <strong>exit 1 <br />;; </strong><br /> <strong>esac</strong><br /> The case command looks at the value of <em>word</em>, in our example, the value of the REPLY <br />variable, and then attempts to match it against one of the specified  <em>patterns</em>. When a <br />match is found, the <em>commands</em> associated with the specified pattern are executed. After a <br />match is found, no further matches are attempted.<br /> Patterns<br />The patterns used by case are the same as those used by pathname expansion. Patterns <br />are terminated with a “)” character. Here are some valid patterns:<br /> <em>Table32- 1: case Pattern Examples</em><br /> <strong>Pattern</strong><br /> <strong>Description</strong><br /> a)<br /> Matches if <em>word</em> equals “a”.<br /> [[:alpha:]])<br /> Matches if <em>word</em> is a single alphabetic character.<br /> ???)<br /> Matches if <em>word</em> is exactly three characters long.<br /> *.txt)<br /> Matches if <em>word</em> ends with the characters “.txt”.<br /> *)<br /> Matches any value of <em>word</em>. It is good practice to include this <br />as the last pattern in a case command, to catch any values of <br /><em>word</em> that did not match a previous pattern; that is, to catch any <br />possible invalid values. <br /> Here is an example of patterns at work:<br /> 431<br /></p>
<hr />
<p>31 – Flow Control: Branching With case<br /> #!/bin/bash <br /> read -p &quot;enter word &gt; &quot; <br /> case $REPLY in <br /> [[:alpha:]])<br /> echo &quot;is a single alphabetic character.&quot; ;; <br /> [ABC][0-9])<br /> echo &quot;is A, B, or C followed by a digit.&quot; ;; <br /> ???)<br /> echo &quot;is three characters long.&quot; ;; <br /> *.txt)<br /> echo &quot;is a word ending in '.txt'&quot; ;; <br /> *)<br /> echo &quot;is something else.&quot; ;; <br /> esac<br /> It is also possible to combine multiple patterns using the vertical bar character as a sepa-<br />rator. This creates an “or” conditional pattern. This is useful for such things as handling <br />both upper- and lowercase characters. For example:<br /> #!/bin/bash <br /> # case-menu: a menu driven system information program <br /> clear <br /> echo &quot; <br />Please Select: <br /> <strong>A.</strong> Display System Information <br /> <strong>B.</strong> Display Disk Space <br /><strong>C.</strong> Display Home Space Utilization <br /> <strong>Q.</strong> Quit <br />&quot; <br /> read -p &quot;Enter selection <strong>[A, B, C or Q]</strong> &gt; &quot; <br /> case $REPLY in <br /> <strong>q|Q)</strong><br /> echo &quot;Program terminated.&quot; <br /> exit <br />;; <br /> <strong>a|A)</strong><br /> echo &quot;Hostname: $HOSTNAME&quot; <br />uptime <br /> ;; <br /> <strong>b|B)</strong><br /> df -h <br /> ;; <br /> <strong>c|C)</strong><br /> if [[ $(id -u) -eq 0 ]]; then <br /> echo &quot;Home Space Utilization (All Users)&quot; <br />du -sh /home/* <br /> else <br /> echo &quot;Home Space Utilization ($USER)&quot; <br /> du -sh $HOME <br /> fi <br /> 432<br /></p>
<hr />
<p>case<br /> ;; <br /> *)<br /> echo &quot;Invalid entry&quot; &gt;&amp;2 <br /> exit 1 <br />;; <br /> esac<br /> Here, we modify the case-menu program to use letters instead of digits for menu selec-<br />tion. Notice how the new patterns allow for entry of both upper- and lowercase letters.<br /> Performing Multiple Actions<br />In versions of  bash prior to 4.0, case allowed only one action to be performed on a <br />successful match.  After a successful match, the command would terminate.  Here we see <br />a script that tests a character:<br /> #!/bin/bash<br /> # case4-1: test a character<br /> read -n 1 -p &quot;Type a character &gt; &quot;<br /> echo<br />case $REPLY in<br />     [[:upper:]])    echo &quot;'$REPLY' is upper case.&quot; ;;<br />    [[:lower:]])    echo &quot;'$REPLY' is lower case.&quot; ;;<br />     [[:alpha:]])    echo &quot;'$REPLY' is alphabetic.&quot; ;;<br />    [[:digit:]])    echo &quot;'$REPLY' is a digit.&quot; ;;<br />     [[:graph:]])    echo &quot;'$REPLY' is a visible character.&quot; ;;<br />    [[:punct:]])    echo &quot;'$REPLY' is a punctuation symbol.&quot; ;;<br />     [[:space:]])    echo &quot;'$REPLY' is a whitespace character.&quot; ;;<br />    [[:xdigit:]])   echo &quot;'$REPLY' is a hexadecimal digit.&quot; ;; <br /> esac<br /> Running this script produces this:<br /> [me@linuxbox ~]$ <strong>case4-1</strong><br /> Type a character &gt; <strong>a<br /></strong>'a' is lower case.<br /> The script works for the most part, but fails if a character matches more than one of the <br />POSIX characters classes.  For example, the character &quot;a&quot; is both lower case and alpha-<br />betic, as well as a hexadecimal digit.  In bash prior to version 4.0 there was no way for <br />case to match more than one test.  Modern versions of bash, add the “;;&amp;” notation to <br /> 433<br /></p>
<hr />
<p>31 – Flow Control: Branching With case<br /> terminate each action, so now we can do this:<br /> #!/bin/bash<br /> # case4-2: test a character<br /> read -n 1 -p &quot;Type a character &gt; &quot;<br />echo<br /> case $REPLY in<br />    [[:upper:]])    echo &quot;'$REPLY' is upper case.&quot; ;;&amp;<br />     [[:lower:]])    echo &quot;'$REPLY' is lower case.&quot; ;;&amp;<br />    [[:alpha:]])    echo &quot;'$REPLY' is alphabetic.&quot; ;;&amp;<br />     [[:digit:]])    echo &quot;'$REPLY' is a digit.&quot; ;;&amp;<br />    [[:graph:]])    echo &quot;'$REPLY' is a visible character.&quot; ;;&amp;<br />     [[:punct:]])    echo &quot;'$REPLY' is a punctuation symbol.&quot; ;;&amp;<br />    [[:space:]])    echo &quot;'$REPLY' is a whitespace character.&quot; ;;&amp;<br />     [[:xdigit:]])   echo &quot;'$REPLY' is a hexadecimal digit.&quot; ;;&amp; <br />esac<br /> When we run this script, we get this:<br /> [me@linuxbox ~]$ <strong>case4-2<br /></strong>Type a character &gt; <strong>a</strong><br /> 'a' is lower case.<br />'a' is alphabetic.<br /> 'a' is a visible character.<br />'a' is a hexadecimal digit.<br /> The addition of the &quot;;;&amp;&quot; syntax allows case to continue on to the next test rather than <br />simply terminating.<br /> <strong>Summing Up<br /></strong>The case command is a handy addition to our bag of programming tricks. As we will <br />see in the next chapter, it’s the perfect tool for handling certain types of problems.<br /> <strong>Further Reading</strong><br /> ●<br /> The <em>Bash Reference Manual</em> section on Conditional Constructs describes the <br />case command in detail:<br /><a href="http://tiswww.case.edu/php/chet/bash/bashref.html#SEC21">http://tiswww.case.edu/php/chet/bash/bashref.html#SEC21</a><br /> ●<br /> The <em>Advanced Bash-Scripting Guide</em> provides further examples of case applica-<br /> 434<br /></p>
<hr />
<p>Further Reading<br /> tions:<br /><a href="http://tldp.org/LDP/abs/html/testbranch.html">http://tldp.org/LDP/abs/html/testbranch.html</a><br /> 435<br /></p>
<hr />
<p>32 – Positional Parameters<br /> <em><strong>32 – Positional Parameters</strong></em><br /> One feature that has been missing from our programs is the ability to accept and process <br />command line options and arguments. In this chapter, we will examine the shell features <br />that allow our programs to get access to the contents of the command line.<br /> <strong>Accessing The Command Line<br /></strong>The shell provides a set of variables called <em>positional parameters</em> that contain the individ-<br />ual words on the command line. The variables are named  0  through  9. They can be <br />demonstrated this way:<br /> #!/bin/bash <br /> # posit-param: script to view command line parameters <br /> echo &quot; <br />\$0 = $0 <br /> \$1 = $1 <br />\$2 = $2 <br /> \$3 = $3 <br />\$4 = $4 <br /> \$5 = $5 <br />\$6 = $6 <br /> \$7 = $7 <br />\$8 = $8 <br /> \$9 = $9 <br />&quot;<br /> A very simple script that displays the values of the variables  $0-$9. When executed <br />with no command line arguments:<br /> [me@linuxbox ~]$ <strong>posit-param </strong><br /> $0 = /home/me/bin/posit-param <br /> 436<br /></p>
<hr />
<p>Accessing The Command Line<br /> $1 = <br />$2 = <br /> $3 = <br />$4 = <br /> $5 = <br />$6 = <br /> $7 = <br />$8 = <br /> $9 = <br /> Even when no arguments are provided, $0 will always contain the first item appearing on <br />the command line, which is the pathname of the program being executed. When argu-<br />ments are provided, we see the results:<br /> [me@linuxbox ~]$ <strong>posit-param a b c d </strong><br /> $0 = /home/me/bin/posit-param <br /> $1 = a <br />$2 = b <br /> $3 = c <br />$4 = d <br /> $5 = <br />$6 = <br /> $7 = <br />$8 = <br /> $9 =<br /> <strong>Note:</strong> You can actually access more than nine parameters using parameter expan-<br />sion. To specify a number greater than nine, surround the number in braces. For ex-<br />ample ${10}, ${55}, ${211}, and so on.<br /> Determining The Number of Arguments<br />The shell also provides a variable, $#, that yields the number of arguments on the com-<br />mand line:<br /> #!/bin/bash <br /> # posit-param: script to view command line parameters <br /> echo &quot; <br /> 437<br /></p>
<hr />
<p>32 – Positional Parameters<br /> <strong>Number of arguments: $# <br /></strong>\$0 = $0 <br /> \$1 = $1 <br />\$2 = $2 <br /> \$3 = $3 <br />\$4 = $4 <br /> \$5 = $5 <br />\$6 = $6 <br /> \$7 = $7 <br />\$8 = $8 <br /> \$9 = $9 <br />&quot;<br /> The result:<br /> [me@linuxbox ~]$ <strong>posit-param a b c d </strong><br /> Number of arguments: 4 <br />$0 = /home/me/bin/posit-param <br /> $1 = a <br />$2 = b <br /> $3 = c <br />$4 = d <br /> $5 = <br />$6 = <br /> $7 = <br />$8 = <br /> $9 = <br /> shift – Getting Access To Many Arguments<br />But what happens when we give the program a large number of arguments such as this:<br /> [me@linuxbox ~]$ <strong>posit-param * </strong><br /> Number of arguments: 82 <br />$0 = /home/me/bin/posit-param <br /> $1 = addresses.ldif <br />$2 = bin <br /> $3 = bookmarks.html <br />$4 = debian-500-i386-netinst.iso <br /> $5 = debian-500-i386-netinst.jigdo <br />$6 = debian-500-i386-netinst.template <br /> $7 = debian-cd_info.tar.gz <br /> 438<br /></p>
<hr />
<p>Accessing The Command Line<br /> $8 = Desktop <br />$9 = dirlist-bin.txt<br /> On this example system, the wildcard * expands into 82 arguments. How can we process <br />that many? The shell provides a method, albeit a clumsy one, to do this. The  shift <br />command causes all the parameters to “move down one” each time it is executed. In fact, <br />by using  shift, it is possible to get by with only one parameter (in addition to  $0, <br />which never changes): <br /> #!/bin/bash <br /> # posit-param2: script to display all arguments <br /> count=1 <br /> while [[ $# -gt 0 ]]; do <br /> echo &quot;Argument $count = $1&quot; <br /> count=$((count + 1)) <br />shift <br /> done<br /> Each time shift is executed, the value of $2 is moved to $1, the value of $3 is moved <br />to $2 and so on. The value of $# is also reduced by one.<br />In the  posit-param2  program, we create a loop that evaluates the number of argu-<br />ments remaining and continues as long as there is at least one. We display the current ar-<br />gument, increment the variable count with each iteration of the loop to provide a run-<br />ning count of the number of arguments processed and, finally, execute a shift to load <br />$1 with the next argument. Here is the program at work:<br /> [me@linuxbox ~]$ <strong>posit-param2 a b c d</strong> <br /> Argument 1 = a <br />Argument 2 = b <br /> Argument 3 = c <br />Argument 4 = d<br /> Simple Applications<br />Even without shift, it’s possible to write useful applications using positional parame-<br />ters. By way of example, here is a simple file information program:<br /> 439<br /></p>
<hr />
<p>32 – Positional Parameters<br /> #!/bin/bash <br /> # file_info: simple file information program <br /> PROGNAME=$(basename $0) <br /> if [[ -e $1 ]]; then <br /> echo -e &quot;\nFile Type:&quot; <br /> file $1 <br />echo -e &quot;\nFile Status:&quot; <br /> stat $1 <br /> else echo &quot;$PROGNAME: usage: $PROGNAME file&quot; &gt;&amp;2 <br /> exit 1 <br /> fi<br /> This program displays the file type (determined by the file command) and the file sta-<br />tus (from the stat command) of a specified file. One interesting feature of this program <br />is the  PROGNAME  variable. It is given the value that results from the  basename $0 <br />command. The basename command removes the leading portion of a pathname, leav-<br />ing only the base name of a file. In our example, basename removes the leading portion <br />of the pathname contained in the  $0 parameter, the full pathname of our example pro-<br />gram. This value is useful when constructing messages such as the usage message at the <br />end of the program. By coding it this way, the script can be renamed and the message au-<br />tomatically adjusts to contain the name of the program.<br /> Using Positional Parameters With Shell Functions<br />Just as positional parameters are used to pass arguments to shell scripts, they can also be <br />used   to   pass   arguments   to  shell   functions.   To   demonstrate,   we   will   convert   the <br />file_info script into a shell function:<br /> file_info () { <br /> # file_info: function to display file information <br /> if [[ -e $1 ]]; then <br /> echo -e &quot;\nFile Type:&quot; <br />file $1 <br /> echo -e &quot;\nFile Status:&quot; <br />stat $1 <br /> else <br /> echo &quot;$FUNCNAME: usage: $FUNCNAME file&quot; &gt;&amp;2 <br /> return 1 <br /> 440<br /></p>
<hr />
<p>Accessing The Command Line<br /> fi <br /> }<br /> Now, if a script that incorporates the file_info shell function calls the function with a <br />filename argument, the argument will be passed to the function.<br />With this capability, we can write many useful shell functions that can not only be used in <br />scripts, but also within the .bashrc file.<br />Notice that the PROGNAME variable was changed to the shell variable FUNCNAME. The <br />shell automatically updates this variable to keep track of the currently executed shell <br />function. Note that  $0 always contains the full pathname of the first item on the com-<br />mand line (i.e., the name of the program) and does not contain the name of the shell func-<br />tion as we might expect.<br /> <strong>Handling Positional Parameters <em>En Masse<br /></em></strong>It is sometimes useful to manage all the positional parameters as a group. For example, <br />we might want to write a “wrapper” around another program. This means that we create a <br />script or shell function that simplifies the execution of another program. The wrapper <br />supplies a list of arcane command line options and then passes a list of arguments to the <br />lower-level program.<br />The shell provides two  special parameters  for this purpose. They both expand into the <br />complete list of positional parameters, but differ in rather subtle ways. They are:<br /> <em>Table 32-1: The * And @ Special Parameters</em><br /> <strong>Parameter</strong><br /> <strong>Description</strong><br /> $*<br /> Expands into the list of positional parameters, starting with 1. <br />When surrounded by double quotes, it expands into a double <br />quoted string containing all of the positional parameters, each <br />separated by the first character of the IFS shell variable (by default <br />a space character).<br /> $@<br /> Expands into the list of positional parameters, starting with 1. <br />When surrounded by double quotes, it expands each positional <br />parameter into a separate word surrounded by double quotes.<br /> Here is a script that shows these special paramaters in action:<br /> 441<br /></p>
<hr />
<p>32 – Positional Parameters<br /> #!/bin/bash <br /> # posit-params3 : script to demonstrate $* and $@ <br /> print_params () { <br /> echo &quot;\$1 = $1&quot; <br /> echo &quot;\$2 = $2&quot; <br />echo &quot;\$3 = $3&quot; <br /> echo &quot;\$4 = $4&quot; <br /> } <br /> pass_params () { <br /> echo -e &quot;\n&quot; '$* :';   print_params $* <br />echo -e &quot;\n&quot; '&quot;$*&quot; :'; print_params &quot;$*&quot; <br /> echo -e &quot;\n&quot; '$@ :';   print_params $@ <br />echo -e &quot;\n&quot; '&quot;$@&quot; :'; print_params &quot;$@&quot; <br /> } <br /> pass_params &quot;word&quot; &quot;words with spaces&quot;<br /> In this rather convoluted program, we create two arguments: “word” and “words with <br />spaces”, and pass them to the  pass_params  function. That function, in turn, passes <br />them on to the print_params function, using each of the four methods available with <br />the special parameters $! and $@. When executed, the script reveals the differences:<br /> [me@linuxbox ~]$ <strong>posit-param3 </strong><br />  $* : <br /> $1 = word <br />$2 = words <br /> $3 = with <br />$4 = spaces <br />  &quot;$*&quot; : <br /> $1 = word words with spaces <br />$2 = <br /> $3 = <br />$4 = <br />  $@ : <br /> $1 = word <br />$2 = words <br /> $3 = with <br />$4 = spaces <br />  &quot;$@&quot; : <br /> $1 = word <br /> 442<br /></p>
<hr />
<p>Handling Positional Parameters En Masse<br /> $2 = words with spaces <br />$3 = <br /> $4 = <br /> With our arguments, both $! and $@ produce a four word result:<br />word words with spaces<br /> &quot;$*&quot; produces a one word result:<br /> &quot;word words with spaces&quot;<br /> &quot;$@&quot; produces a two word result:<br /> &quot;word&quot; &quot;words with spaces&quot;<br /> which matches our actual intent. The lesson to take from this is that even though the shell <br />provides four different ways of getting the list of positional parameters, &quot;$@&quot; is by far <br />the most useful for most situations, because it preserves the integrity of each positional <br />parameter.<br /> <strong>A More Complete Application<br /></strong>After a long hiatus, we are going to resume work on our  sys_info_page  program. <br />Our next addition will add several command line options to the program as follows:<br /> ●<br /> <strong>Output file.</strong> We will add an option to specify a name for a file to contain the pro-<br />gram’s output. It will be specified as either -f <em>file</em> or --file <em>file</em>.<br /> ●<br /> <strong>Interactive mode.</strong> This option will prompt the user for an output filename and <br />will determine if the specified file already exists. If it does, the user will be <br />prompted before the existing file is overwritten. This option will be specified by <br />either -i or --interactive.<br /> ●<br /> <strong>Help.</strong> Either -h or --help may be specified to cause the program to output an <br />informative usage message.<br /> Here is the code needed to implement the command line processing:<br /> usage () { <br /> echo &quot;$PROGNAME: usage: $PROGNAME [-f file | -i]&quot; <br /> return <br /> } <br /> # process command line options <br /> interactive= <br /> 443<br /></p>
<hr />
<p>32 – Positional Parameters<br /> filename= <br /> while [[ -n $1 ]]; do <br /> case $1 in <br /> -f | --file)<br /> shift <br />filename=$1 <br /> ;; <br /> -i | --interactive)<br /> interactive=1 <br /> ;; <br /> -h | --help)<br /> usage <br /> exit <br />;; <br /> *)<br /> usage &gt;&amp;2 <br />exit 1 <br /> ;; <br /> esac <br /> shift <br /> done<br /> First, we add a shell function called usage to display a message when the help option is <br />invoked or an unknown option is attempted.<br />Next, we begin the processing loop. This loop continues while the positional parameter <br />$1 is not empty. At the bottom of the loop, we have a shift command to advance the <br />positional parameters to ensure that the loop will eventually terminate.<br />Within the loop, we have a case statement that examines the current positional parame-<br />ter to see if it matches any of the supported choices. If a supported parameter is found, it <br />is acted upon. If not, the usage message is displayed and the script terminates with an er-<br />ror.<br />The -f parameter is handled in an interesting way. When detected, it causes an additional <br />shift to occur, which advances the positional parameter $1 to the filename argument <br />supplied to the -f option. <br />We next add the code to implement the interactive mode:<br /> # interactive mode <br /> if [[ -n $interactive ]]; then <br /> while true; do <br /> read -p &quot;Enter name of output file: &quot; filename <br />if [[ -e $filename ]]; then <br /> read -p &quot;'$filename' exists. Overwrite? [y/n/q] &gt; &quot; <br />case $REPLY in <br /> Y|y)<br /> break <br /> 444<br /></p>
<hr />
<p>A More Complete Application<br /> ;; <br /> Q|q)<br /> echo &quot;Program terminated.&quot; <br /> exit <br />;; <br /> *)<br /> continue <br />;; <br /> esac<br /> elif [[ -z $filename ]]; then<br /> continue<br /> else<br /> break <br /> fi<br /> done <br /> fi<br /> If the interactive variable is not empty, an endless loop is started, which contains <br />the filename prompt and subsequent existing file-handling code. If the desired output file <br />already exists, the user is prompted to overwrite, choose another filename, or quit the <br />program. If the user chooses to overwrite an existing file, a break is executed to termi-<br />nate the loop. Notice how the case statement only detects if the user chooses to over-<br />write or quit. Any other choice causes the loop to continue and prompts the user again.<br />In order to implement the output filename feature, we must first convert the existing <br />page-writing code into a shell function, for reasons that will become clear in a moment:<br /> write_html_page () { <br /> cat &lt;&lt;- _EOF_ <br /> &lt;HTML&gt; <br /> &lt;HEAD&gt; <br /> &lt;TITLE&gt;$TITLE&lt;/TITLE&gt; <br /> &lt;/HEAD&gt; <br /> &lt;BODY&gt; <br /> &lt;H1&gt;$TITLE&lt;/H1&gt; <br /> &lt;P&gt;$TIMESTAMP&lt;/P&gt; <br />$(report_uptime) <br /> $(report_disk_space) <br />$(report_home_space) <br /> &lt;/BODY&gt; <br /> &lt;/HTML&gt; <br /> _EOF_ <br />return <br /> }<br /> # output html page <br /> if [[ -n $filename ]]; then <br /> 445<br /></p>
<hr />
<p>32 – Positional Parameters<br /> if touch $filename &amp;&amp; [[ -f $filename ]]; then <br /> write_html_page &gt; $filename <br /> else <br /> echo &quot;$PROGNAME: Cannot write file '$filename'&quot; &gt;&amp;2 <br /> exit 1 <br /> fi <br /> else <br /> write_html_page <br /> fi<br /> The code that handles the logic of the -f option appears at the end of the listing shown <br />above. In it, we test for the existence of a filename and, if one is found, a test is per-<br />formed to see if the file is indeed writable.  To do this, a touch is performed, followed <br />by a test to determine if the resulting file is a regular file. These two tests take care of sit-<br />uations where an invalid pathname is input (touch will fail), and, if the file already ex-<br />ists, that it’s a regular file.<br />As we can see, the write_html_page function is called to perform the actual gener-<br />ation of the page. Its output is either directed to standard output (if the variable file-<br />name is empty) or redirected to the specified file.<br /> <strong>Summing Up<br /></strong>With the addition of positional parameters, we can now write fairly functional scripts. <br />For simple, repetitive tasks, positional parameters make it possible to write very useful <br />shell functions that can be placed in a user’s .bashrc file.<br />Our sys_info_page program has grown in complexity and sophistication. Here is a <br />complete listing, with the most recent changes highlighted:<br /> #!/bin/bash <br /> # sys_info_page: program to output a system information page <br /> <strong>PROGNAME=$(basename $0) </strong><br /> TITLE=&quot;System Information Report For $HOSTNAME&quot; <br />CURRENT_TIME=$(date +&quot;%x %r %Z&quot;) <br /> TIMESTAMP=&quot;Generated $CURRENT_TIME, by $USER&quot; <br /> report_uptime () { <br /> cat &lt;&lt;- _EOF_ <br /> &lt;H2&gt;System Uptime&lt;/H2&gt; <br />&lt;PRE&gt;$(uptime)&lt;/PRE&gt; <br /> _EOF_ <br /> return <br /> 446<br /></p>
<hr />
<p>Summing Up<br /> } <br /> report_disk_space () { <br /> cat &lt;&lt;- _EOF_ <br /> &lt;H2&gt;Disk Space Utilization&lt;/H2&gt; <br />&lt;PRE&gt;$(df -h)&lt;/PRE&gt; <br /> _EOF_ <br /> return <br /> } <br /> report_home_space () { <br /> if [[ $(id -u) -eq 0 ]]; then <br /> cat &lt;&lt;- _EOF_ <br /> &lt;H2&gt;Home Space Utilization (All Users)&lt;/H2&gt; <br /> &lt;PRE&gt;$(du -sh /home/*)&lt;/PRE&gt; <br />_EOF_ <br /> else <br /> cat &lt;&lt;- _EOF_ <br /> &lt;H2&gt;Home Space Utilization ($USER)&lt;/H2&gt; <br />&lt;PRE&gt;$(du -sh $HOME)&lt;/PRE&gt; <br /> _EOF_ <br /> fi <br /> return <br /> } <br /> <strong>usage () { </strong><br /> <strong>echo &quot;$PROGNAME: usage: $PROGNAME [-f file | -i]&quot; <br />return </strong><br /> <strong>} </strong><br /> <strong>write_html_page () { </strong><br /> <strong>cat &lt;&lt;- _EOF_ </strong><br /> <strong>&lt;HTML&gt; </strong><br /> <strong>&lt;HEAD&gt; </strong><br /> <strong>&lt;TITLE&gt;$TITLE&lt;/TITLE&gt; </strong><br /> <strong>&lt;/HEAD&gt; </strong><br /> <strong>&lt;BODY&gt; </strong><br /> <strong>&lt;H1&gt;$TITLE&lt;/H1&gt; </strong><br /> <strong>&lt;P&gt;$TIMESTAMP&lt;/P&gt; <br />$(report_uptime) </strong><br /> <strong>$(report_disk_space) <br />$(report_home_space) </strong><br /> <strong>&lt;/BODY&gt; </strong><br /> <strong>&lt;/HTML&gt; </strong><br /> <strong>_EOF_ <br />return </strong><br /> <strong>} </strong><br /> # process command line options <br /> 447<br /></p>
<hr />
<p>32 – Positional Parameters<br /> <strong>interactive= <br />filename= </strong><br /> <strong>while [[ -n $1 ]]; do </strong><br /> <strong>case $1 in </strong><br /> <strong>-f | --file)</strong><br /> <strong>shift </strong><br /> <strong>filename=$1 <br />;; </strong><br /> <strong>-i | --interactive)</strong><br /> <strong>interactive=1 <br />;; </strong><br /> <strong>-h | --help)</strong><br /> <strong>usage <br />exit </strong><br /> <strong>;; </strong><br /> <strong>*)</strong><br /> <strong>usage &gt;&amp;2 </strong><br /> <strong>exit 1 <br />;; </strong><br /> <strong>esac <br />shift </strong><br /> <strong>done </strong><br /> # interactive mode <br /> <strong>if [[ -n $interactive ]]; then </strong><br /> <strong>while true; do </strong><br /> <strong>read -p &quot;Enter name of output file: &quot; filename <br />if [[ -e $filename ]]; then </strong><br /> <strong>read -p &quot;'$filename' exists. Overwrite? [y/n/q] &gt; &quot; <br />case $REPLY in </strong><br /> <strong>Y|y)</strong><br /> <strong>break <br />;; </strong><br /> <strong>Q|q)</strong><br /> <strong>echo &quot;Program terminated.&quot; <br />exit </strong><br /> <strong>;; </strong><br /> <strong>*)</strong><br /> <strong>continue </strong><br /> <strong>;; </strong><br /> <strong>esac </strong><br /> <strong>fi </strong><br /> <strong>done </strong><br /> <strong>fi </strong><br /> # output html page <br /> <strong>if [[ -n $filename ]]; then </strong><br /> <strong>if touch $filename &amp;&amp; [[ -f $filename ]]; then </strong><br /> <strong>write_html_page &gt; $filename </strong><br /> <strong>else  echo &quot;$PROGNAME: Cannot write file '$filename'&quot; &gt;&amp;2 </strong><br /> <strong>exit 1 </strong><br /> <strong>fi </strong><br /> <strong>else </strong><br /> 448<br /></p>
<hr />
<p>Summing Up<br /> <strong>write_html_page </strong><br /> <strong>fi </strong><br /> We’re not done yet. There are still more things we can do and improvements we can <br />make.<br /> <strong>Further Reading</strong><br /> ●<br /> The <em>Bash Hackers Wiki</em> has a good article on positional parameters:<br /><a href="http://wiki.bash-hackers.org/scripting/posparams">http://wiki.bash-hackers.org/scripting/posparams</a><br /> ●<br /> The <em>Bash Reference Manual</em> has an article on the special parameters, including <br />$* and $@:<br /><a href="http://www.gnu.org/software/bash/manual/bashref.html#Special-Parameters">http://www.gnu.org/software/bash/manual/bashref.html#Special-Parameters</a><br /> ●<br /> In addition to the techniques discussed in this chapter, bash includes a builtin <br />command called getopts, which can also be used for process command line ar-<br />guments. It is described in the SHELL BUILTIN COMMANDS section of the <br />bash man page and at the <em>Bash Hackers Wiki</em>:<br /><a href="http://wiki.bash-hackers.org/howto/getopts_tutorial">http://wiki.bash-hackers.org/howto/getopts_tutorial</a><br /> 449<br /></p>
<hr />
<p>33 – Flow Control: Looping With for<br /> <em><strong>33 – Flow Control: Looping With for</strong></em><br /> In this final chapter on flow control, we will look at another of the shell’s looping con-<br />structs. The <em>for loop</em> differs from the while and until loops in that it provides a means of <br />processing sequences during a loop. This turns out to be very useful when programming. <br />Accordingly, the for loop is a very popular construct in bash scripting.<br />A for loop is implemented, naturally enough, with the for command. In modern versions <br />of bash, for is available in two forms.<br /> <strong>for: Traditional Shell Form<br /></strong>The original for command’s syntax is:<br />for <em>variable</em> [in <em>words</em>]; do<br /> <em>commands</em><br /> done<br /> Where <em>variable</em> is the name of a variable that will increment during the execution of the <br />loop, <em>words</em> is an optional list of items that will be sequentially assigned to <em>variable</em>, and <br /><em>commands</em> are the commands that are to be executed on each iteration of the loop.<br />The for command is useful on the command line. We can easily demonstrate how it <br />works:<br /> [me@linuxbox ~]$ <strong>for i in A B C D; do echo $i; done <br /></strong>A <br /> B <br />C <br /> D<br /> In this example, for is given a list of four words: “A”, “B”, “C”, and “D”. With a list of <br />four words, the loop is executed four times. Each time the loop is executed, a word is as-<br />signed to the variable i. Inside the loop, we have an echo command that displays the <br />value of i to show the assignment. As with the while and until loops, the done key-<br />word closes the loop.<br /> 450<br /></p>
<hr />
<p>for: Traditional Shell Form<br /> The really powerful feature of for is the number of interesting ways we can create the <br />list of words. For example, through brace expansion:<br /> [me@linuxbox ~]$ <strong>for i in {A..D}; do echo $i; done<br /></strong>A<br /> B<br />C<br /> D<br /> or pathname expansion:<br /> [me@linuxbox ~]$ <strong>for i in distros*.txt; do echo $i; done</strong><br /> distros-by-date.txt <br />distros-dates.txt <br /> distros-key-names.txt <br />distros-key-vernums.txt <br /> distros-names.txt  <br />distros.txt <br /> distros-vernums.txt <br />distros-versions.txt<br /> or command substitution:<br /> #!/bin/bash <br /> # longest-word : find longest string in a file <br /> while [[ -n $1 ]]; do <br /> if [[ -r $1 ]]; then <br /> max_word= <br />max_len=0<br /> for i in $(strings $1); do <br /> len=$(echo $i | wc -c) <br /> if (( len &gt; max_len )); then <br /> max_len=$len <br /> max_word=$i <br /> fi <br /> done <br />echo &quot;$1: '$max_word' ($max_len characters)&quot; <br /> fi <br />shift <br /> done<br /> 451<br /></p>
<hr />
<p>33 – Flow Control: Looping With for<br /> In this example, we look for the longest string found within a file. When given one or <br />more filenames on the command line, this program uses the strings program (which is <br />included in the GNU binutils package) to generate a list of readable text “words” in each <br />file. The for loop processes each word in turn and determines if the current word is the <br />longest found so far. When the loop concludes, the longest word is displayed.<br />If the optional in <em>words</em> portion of the for command is omitted, for defaults to pro-<br />cessing the positional parameters. We will modify our longest-word script to use this <br />method:<br /> #!/bin/bash <br /> # longest-word2 : find longest string in a file <br /> for i; do <br /> if [[ -r $i ]]; then <br /> max_word= <br />max_len=0 <br /> for j in $(strings $i); do <br /> len=$(echo $j | wc -c) <br /> if (( len &gt; max_len )); then <br /> max_len=$len <br /> max_word=$j <br /> fi <br /> done <br />echo &quot;$i: '$max_word' ($max_len characters)&quot; <br /> fi <br /> done<br /> As we can see, we have changed the outermost loop to use for in place of while. By <br />omitting the list of words in the  for command, the positional parameters are used in-<br />stead. Inside the loop, previous instances of the variable i have been changed to the vari-<br />able j. The use of shift has also been eliminated.<br /> <strong>Why i?<br /></strong>You may have noticed that the variable i was chosen for each of the for loop <br />examples above. Why? No specific reason actually, besides tradition. The variable <br />used with for can be any valid variable, but i is the most common, followed by <br />j and k.<br /> 452<br /></p>
<hr />
<p>for: Traditional Shell Form<br /> The basis of this tradition comes from the Fortran programming language. In For-<br />tran, undeclared variables starting with the letters I, J, K, L, and M are automati-<br />cally typed as integers, while variables beginning with any other letter are typed <br />as real (numbers with decimal fractions). This behavior led programmers to use <br />the variables I, J, and K for loop variables, since it was less work to use them <br />when a temporary variable (as loop variables often are) was needed.<br />It also led to the following Fortran-based witticism:<br />“GOD is real, unless declared integer.” <br /> <strong>for: C Language Form<br /></strong>Recent versions of bash have added a second form of for command syntax, one that <br />resembles the form found in the C programming language. Many other languages support <br />this form, as well:<br />for (( <em>expression1</em>; <em>expression2</em>; <em>expression3</em> )); do<br /> <em>commands</em><br /> done<br /> where  <em>expression1</em>,  <em>expression2</em>, and  <em>expression3</em>  are  arithmetic  expressions  and  <em>com-<br />mands</em> are the commands to be performed during each iteration of the loop.<br />In terms of behavior, this form is equivalent to the following construct:<br />(( <em>expression1</em> ))<br /> while (( <em>expression2</em> )); do<br /> <em>commands</em><br /> (( <em>expression3</em> ))<br /> done<br /> <em>expression1</em> is used to initialize conditions for the loop, <em>expression2</em> is used to determine <br />when the loop is finished, and <em>expression3</em> is carried out at the end of each iteration of the <br />loop.<br />Here is a typical application:<br /> #!/bin/bash <br /> # simple_counter : demo of C style for command <br /> for (( i=0; i&lt;5; i=i+1 )); do <br /> echo $i <br /> done<br /> 453<br /></p>
<hr />
<p>33 – Flow Control: Looping With for<br /> When executed, it produces the following output:<br /> [me@linuxbox ~]$ <strong>simple_counter</strong> <br />0 <br /> 1 <br />2 <br /> 3 <br />4<br /> In this example, <em>expression1</em> initializes the variable i with the value of zero, <em>expression2 <br /></em>allows the loop to continue as long as the value of i remains less than 5, and <em>expression3 <br /></em>increments the value of i by one each time the loop repeats.<br />The C language form of for is useful anytime a numeric sequence is needed. We will see <br />several applications for this in the next two chapters.<br /> <strong>Summing Up<br /></strong>With our knowledge of the for command, we will now apply the final improvements to <br />our  sys_info_page  script.   Currently,   the  report_home_space  function   looks <br />like this:<br /> report_home_space () { <br /> if [[ $(id -u) -eq 0 ]]; then <br /> cat &lt;&lt;- _EOF_ <br /> &lt;H2&gt;Home Space Utilization (All Users)&lt;/H2&gt; <br /> &lt;PRE&gt;$(du -sh /home/*)&lt;/PRE&gt; <br />_EOF_ <br /> else <br /> cat &lt;&lt;- _EOF_ <br /> &lt;H2&gt;Home Space Utilization ($USER)&lt;/H2&gt; <br />&lt;PRE&gt;$(du -sh $HOME)&lt;/PRE&gt; <br /> _EOF_ <br /> fi <br /> return <br /> }<br /> Next, we will rewrite it to provide more detail for each user’s home directory, and include <br />the total number of files and subdirectories in each:<br /> report_home_space () { <br /> 454<br /></p>
<hr />
<p>Summing Up<br /> local format=&quot;%8s%10s%10s\n&quot; <br />local i dir_list total_files total_dirs total_size user_name<br /> if [[ $(id -u) -eq 0 ]]; then <br /> dir_list=/home/*<br />user_name=&quot;All Users&quot; <br /> else <br /> dir_list=$HOME <br /> user_name=$USER <br /> fi <br /> echo &quot;&lt;H2&gt;Home Space Utilization ($user_name)&lt;/H2&gt;&quot; <br /> for i in $dir_list; do<br />  <br /> total_files=$(find $i -type f | wc -l) <br /> total_dirs=$(find $i -type d | wc -l) <br />total_size=$(du -sh $i | cut -f 1) <br /> echo &quot;&lt;H3&gt;$i&lt;/H3&gt;&quot; <br /> echo &quot;&lt;PRE&gt;&quot; <br />printf &quot;$format&quot; &quot;Dirs&quot; &quot;Files&quot; &quot;Size&quot; <br /> printf &quot;$format&quot; &quot;----&quot; &quot;-----&quot; &quot;----&quot; <br />printf &quot;$format&quot; $total_dirs $total_files $total_size <br /> echo &quot;&lt;/PRE&gt;&quot; <br /> done <br /> return <br /> }<br /> This rewrite applies much of what we have learned so far. We still test for the superuser, <br />but instead of performing the complete set of actions as part of the if, we set some vari-<br />ables used later in a for loop. We have added several local variables to the function and <br />made use of printf to format some of the output.<br /> <strong>Further Reading</strong><br /> ●<br /> The <em>Advanced Bash-Scripting Guide</em> has a chapter on loops, with a variety of ex-<br />amples using for:<br /><a href="http://tldp.org/LDP/abs/html/loops1.html">http://tldp.org/LDP/abs/html/loops1.html</a><br /> ●<br /> The <em>Bash Reference Manual</em> describes the looping compound commands, includ-<br />ing for:<br /><a href="http://www.gnu.org/software/bash/manual/bashref.html#Looping-Constructs">http://www.gnu.org/software/bash/manual/bashref.html#Looping-Constructs</a><br /> 455<br /></p>
<hr />
<p>34 – Strings And Numbers<br /> <em><strong>34 – Strings And Numbers</strong></em><br /> Computer programs are all about working with data. In past chapters, we have focused on <br />processing  data  at   the  file  level.   However,   many  programming  problems  need  to   be <br />solved using smaller units of data such as strings and numbers.<br />In this chapter, we will look at several shell features that are used to manipulate strings <br />and numbers. The shell provides a variety of parameter expansions that perform string <br />operations. In addition to  arithmetic  expansion (which we touched upon in Chapter 7), <br />there is a common command line program called bc, which performs higher level math.<br /> <strong>Parameter Expansion<br /></strong>Though parameter expansion came up in Chapter 7, we did not cover it in detail because <br />most parameter expansions are used in scripts rather than on the command line. We have <br />already worked with some forms of parameter expansion; for example, shell variables. <br />The shell provides many more.<br /> Basic Parameters<br />The simplest form of parameter expansion is reflected in the ordinary use of  variables. <br />For example:<br />$a<br /> when expanded, becomes whatever the variable a contains. Simple parameters may also <br />be surrounded by braces:<br />${a}<br /> This has no effect on the expansion, but is required if the variable is adjacent to other <br />text, which may confuse the shell. In this example, we attempt to create a filename by ap-<br />pending the string “_file” to the contents of the variable a.<br /> [me@linuxbox ~]$ <strong>a=&quot;foo&quot;<br /></strong>[me@linuxbox ~]$ <strong>echo &quot;$a_file&quot;</strong><br /> 456<br /></p>
<hr />
<p>Parameter Expansion<br /> If we perform this sequence, the result will be nothing, because the shell will try to ex-<br />pand a variable named  a_file  rather than  a. This problem can be solved by adding <br />braces:<br /> [me@linuxbox ~]$ <strong>echo &quot;${a}_file&quot;<br /></strong>foo_file<br /> We have also seen that positional parameters greater than 9 can be accessed by surround-<br />ing the number in braces. For example, to access the eleventh positional parameter, we <br />can do this:<br />${11}<br /> Expansions To Manage Empty Variables<br />Several parameter expansions deal with nonexistent and  empty variables. These expan-<br />sions are handy for handling missing positional parameters and assigning default values <br />to parameters.<br />${<em>parameter</em>:-<em>word</em>}<br />If <em>parameter</em> is unset (i.e., does not exist) or is empty, this expansion results in the value <br />of <em>word</em>. If <em>parameter</em> is not empty, the expansion results in the value of <em>parameter</em>.<br /> [me@linuxbox ~]$ <strong>foo=</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo:-&quot;substitute value if unset&quot;}<br /></strong>substitute value if unset<br /> [me@linuxbox ~]$ <strong>echo $foo</strong><br /> [me@linuxbox ~]$ <strong>foo=bar<br /></strong>[me@linuxbox ~]$ <strong>echo ${foo:-&quot;substitute value if unset&quot;}</strong><br /> bar<br />[me@linuxbox ~]$ <strong>echo $foo</strong><br /> bar<br /> ${<em>parameter</em>:=<em>word</em>}<br />If <em>parameter</em> is unset or empty, this expansion results in the value of <em>word</em>. In addition, <br />the value of <em>word</em> is assigned to <em>parameter</em>. If <em>parameter</em> is not empty, the expansion re-<br />sults in the value of <em>parameter</em>.<br /> [me@linuxbox ~]$ <strong>foo=</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo:=&quot;default value if unset&quot;}</strong><br /> 457<br /></p>
<hr />
<p>34 – Strings And Numbers<br /> default value if unset<br />[me@linuxbox ~]$ <strong>echo $foo</strong><br /> default value if unset<br />[me@linuxbox ~]$ <strong>foo=bar</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo:=&quot;default value if unset&quot;}<br /></strong>bar<br /> [me@linuxbox ~]$ <strong>echo $foo<br /></strong>bar<br /> <strong>Note</strong>: Positional and other special parameters cannot be assigned this way.<br /> ${<em>parameter</em>:?<em>word</em>}<br />If <em>parameter</em> is unset or empty, this expansion causes the script to exit with an error, and <br />the contents of <em>word</em> are sent to standard error. If <em>parameter</em> is not empty, the expansion <br />results in the value of <em>parameter</em>.<br /> [me@linuxbox ~]$ <strong>foo=<br /></strong>[me@linuxbox ~]$ <strong>echo ${foo:?&quot;parameter is empty&quot;}</strong><br /> bash: foo: parameter is empty<br />[me@linuxbox ~]$ <strong>echo $?</strong><br /> 1<br />[me@linuxbox ~]$ <strong>foo=bar</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo:?&quot;parameter is empty&quot;}<br /></strong>bar<br /> [me@linuxbox ~]$ <strong>echo $?<br /></strong>0<br /> ${<em>parameter</em>:+<em>word</em>}<br />If  <em>parameter</em>  is unset or empty, the expansion results in nothing. If  <em>parameter</em>  is not <br />empty, the value of <em>word</em> is substituted for <em>parameter</em>; however, the value of <em>parameter</em> is <br />not changed.<br /> [me@linuxbox ~]$ <strong>foo=<br /></strong>[me@linuxbox ~]$ <strong>echo ${foo:+&quot;substitute value if set&quot;}</strong><br /> [me@linuxbox ~]$ <strong>foo=bar</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo:+&quot;substitute value if set&quot;}<br /></strong>substitute value if set<br /> 458<br /></p>
<hr />
<p>Parameter Expansion<br /> Expansions That Return Variable Names<br />The shell has the ability to return the names of variables. This is used in some rather ex-<br />otic situations.<br />${!<em>prefix</em>*}<br />${!<em>prefix</em>@}<br />This expansion returns the names of existing variables with names beginning with <em>prefix</em>. <br />According to the bash documentation, both forms of the expansion perform identically. <br />Here, we list all the variables in the environment with names that begin with BASH:<br /> [me@linuxbox ~]$ <strong>echo ${!BASH*}<br /></strong>BASH BASH_ARGC BASH_ARGV BASH_COMMAND BASH_COMPLETION <br /> BASH_COMPLETION_DIR BASH_LINENO BASH_SOURCE BASH_SUBSHELL <br />BASH_VERSINFO BASH_VERSION<br /> String Operations<br />There is a large set of expansions that can be used to operate on strings. Many of these <br />expansions are particularly well suited for operations on pathnames.<br />${#<em>parameter</em>}<br />expands into the length of the string contained by <em>parameter</em>. Normally, <em>parameter</em> is a <br />string; however, if <em>parameter</em> is either @ or *, then the expansion results in the number of <br />positional parameters.<br /> [me@linuxbox ~]$ <strong>foo=&quot;This string is long.&quot;<br /></strong>[me@linuxbox ~]$ <strong>echo &quot;'$foo' is ${#foo} characters long.&quot;</strong><br /> 'This string is long.' is 20 characters long.<br /> ${<em>parameter</em>:<em>offset</em>}<br />${<em>parameter</em>:<em>offset</em>:<em>length</em>}<br />These expansions are used to extract a portion of the string contained in <em>parameter</em>. The <br />extraction begins at <em>offset</em> characters from the beginning of the string and continues until <br />the end of the string, unless the <em>length</em> is specified.<br /> [me@linuxbox ~]$ <strong>foo=&quot;This string is long.&quot;</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo:5}<br /></strong>string is long.<br /> 459<br /></p>
<hr />
<p>34 – Strings And Numbers<br /> [me@linuxbox ~]$ <strong>echo ${foo:5:6}<br /></strong>string<br /> If the value of <em>offset</em> is negative, it is taken to mean it starts from the end of the string <br />rather than the beginning. Note that negative values must be preceded by a space to pre-<br />vent confusion with the ${<em>parameter</em>:-<em>word</em>} expansion. <em>length</em>, if present, must not <br />be less than zero.<br />If <em>parameter</em> is @, the result of the expansion is <em>length</em> positional parameters, starting at <br /><em>offset</em>. <br /> [me@linuxbox ~]$ <strong>foo=&quot;This string is long.&quot;<br /></strong>[me@linuxbox ~]$ <strong>echo ${foo: -5}</strong><br /> long.<br />[me@linuxbox ~]$ <strong>echo ${foo: -5:2}</strong><br /> lo<br /> ${<em>parameter</em>#<em>pattern</em>}<br />${<em>parameter</em>##<em>pattern</em>}<br />These expansions remove a leading portion of the string contained in <em>parameter</em> defined <br />by <em>pattern</em>. <em>pattern</em> is a wildcard pattern like those used in pathname expansion. The dif-<br />ference in the two forms is that the # form removes the shortest match, while the ## form <br />removes the longest match.<br /> [me@linuxbox ~]$ <strong>foo=file.txt.zip</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo#*.}<br /></strong>txt.zip<br /> [me@linuxbox ~]$ <strong>echo ${foo##*.}<br /></strong>zip<br /> ${<em>parameter</em>%<em>pattern</em>}<br />${<em>parameter</em>%%<em>pattern</em>}<br />These expansions are the same as the # and ## expansions above, except they remove <br />text from the end of the string contained in <em>parameter</em> rather than from the beginning.<br /> [me@linuxbox ~]$ <strong>foo=file.txt.zip<br /></strong>[me@linuxbox ~]$ <strong>echo ${foo%.*}</strong><br /> file.txt<br />[me@linuxbox ~]$ <strong>echo ${foo%%.*}</strong><br /> 460<br /></p>
<hr />
<p>Parameter Expansion<br /> file<br /> ${<em>parameter</em>/<em>pattern</em>/<em>string</em>}<br />${<em>parameter</em>//<em>pattern</em>/<em>string</em>}<br />${<em>parameter</em>/#<em>pattern</em>/<em>string</em>}<br />${<em>parameter</em>/%<em>pattern</em>/<em>string</em>}<br />This expansion performs a search-and-replace upon the contents of <em>parameter</em>. If text is <br />found matching wildcard <em>pattern</em>, it is replaced with the contents of <em>string</em>. In the normal <br />form, only the first occurrence of <em>pattern</em> is replaced. In the // form, all occurrences are <br />replaced. The /# form requires that the match occur at the beginning of the string, and <br />the /% form requires the match to occur at the end of the string. /<em>string</em> may be omitted, <br />which causes the text matched by <em>pattern</em> to be deleted.<br /> [me@linuxbox ~]$ <strong>foo=JPG.JPG</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo/JPG/jpg}<br /></strong>jpg.JPG<br /> [me@linuxbox ~]$ <strong>echo ${foo//JPG/jpg}<br /></strong>jpg.jpg<br /> [me@linuxbox ~]$ <strong>echo ${foo/#JPG/jpg}<br /></strong>jpg.JPG<br /> [me@linuxbox ~]$ <strong>echo ${foo/%JPG/jpg}<br /></strong>JPG.jpg<br /> Parameter expansion is a good thing to know. The string manipulation expansions can be <br />used as substitutes for other common commands such as sed and cut. Expansions im-<br />prove the efficiency of scripts by eliminating the use of external programs. As an exam-<br />ple, we will modify the longest-word program discussed in the previous chapter to <br />use the parameter expansion ${#j} in place of the command substitution $(echo $j <br />| wc -c) and its resulting subshell, like so:<br /> #!/bin/bash <br /> # longest-word3 : find longest string in a file <br /> for i; do <br /> if [[ -r $i ]]; then <br /> max_word= <br />max_len= <br /> for j in $(strings $i); do <br /> <strong>len=${#j} </strong><br /> if (( len &gt; max_len )); then <br /> 461<br /></p>
<hr />
<p>34 – Strings And Numbers<br /> max_len=$len <br />max_word=$j <br /> fi <br /> done <br /> echo &quot;$i: '$max_word' ($max_len characters)&quot; <br /> fi <br /> shift <br /> done<br /> Next, we will compare the efficiency of the two versions by using the time command:<br /> [me@linuxbox ~]$ <strong>time longest-word2 dirlist-usr-bin.txt<br /></strong>dirlist-usr-bin.txt: 'scrollkeeper-get-extended-content-list' (38 <br /> characters)<br /> real 0m3.618s <br />user 0m1.544s <br /> sys 0m1.768s<br />[me@linuxbox ~]$ <strong>time longest-word3 dirlist-usr-bin.txt </strong><br /> dirlist-usr-bin.txt: 'scrollkeeper-get-extended-content-list' (38 <br />characters) <br /> real 0m0.060s <br /> user 0m0.056s <br />sys 0m0.008s<br /> The original version of the script takes 3.618 seconds to scan the text file, while the new <br />version, using parameter expansion, takes only 0.06 seconds—<br />   a  very significant im-<br /> provement.<br /> Case Conversion<br />Recent versions of bash have support for upper/lowercase conversion of strings.  bash <br />has four parameter expansions and two options to the declare command to support it.<br />So what is case conversion good for?  Aside from the obvious aesthetic value, it has an <br />important role in programming.  Let's consider the case of a database look-up.  Imagine <br />that a user has entered a string into a data input field that we want to look up in a data-<br />base.  It's possible the user will enter the value in all uppercase letters or lowercase letters <br />or a combination of both.  We certainly don't want to populate our database with every <br />possible permutation of upper and lower case spellings.  What to do?<br />A common approach to this problem is to <em>normalize</em> the user's input.  That is, convert it <br />into a standardized form before we attempt the database look-up.  We can do this by con-<br /> 462<br /></p>
<hr />
<p>Parameter Expansion<br /> verting all of the characters in the user's input to either lower or uppercase and ensure that <br />the database entries are normalized the same way.<br />The declare command can be used to normalize strings to either upper or lowercase. <br />Using declare, we can force a variable to always contain the desired format no matter <br />what is assigned to it:<br /> #!/bin/bash<br /> # ul-declare: demonstrate case conversion via declare<br /> declare -u upper<br />declare -l lower<br /> if [[ $1 ]]; then<br />         upper=&quot;$1&quot;<br />        lower=&quot;$1&quot;<br />         echo $upper<br />        echo $lower<br /> fi<br /> In the above script, we use declare to create two variables, upper and lower.  We <br />assign the value of the first command line argument (positional parameter 1) to each of <br />the variables and then display them on the screen:<br /> [me@linuxbox ~]$<strong> ul-declare aBc</strong><br /> ABC<br />abc<br /> As we can see, the command line argument (&quot;aBc&quot;) has been normalized.<br />There are four parameter expansions that perform upper/lowercase conversion:<br /> <em>Table 34-1: Case Conversion Parameter Expansions</em><br /> <strong>Format</strong><br /> <strong>Result</strong><br /> ${<em>parameter</em>,,}<br /> Expand the value of <em>parameter</em> into all lowercase.<br /> ${<em>parameter</em>,}<br /> Expand the value of <em>parameter</em> changing only the first <br />character to lowercase.<br /> ${<em>parameter</em>^^}<br /> Expand the value of <em>parameter</em> into all uppercase letters.<br /> ${<em>parameter</em>^}<br /> Expand the value of <em>parameter</em> changing only the first<em> </em><br /> 463<br /></p>
<hr />
<p>34 – Strings And Numbers<br /> character to uppercase (capitalization).<br /> Here is a script that demonstrates these expansions:<br /> #!/bin/bash<br /> # ul-param - demonstrate case conversion via parameter expansion<br /> if [[ $1 ]]; then<br />        echo ${1,,}<br />         echo ${1,}<br />        echo ${1^^}<br />         echo ${1^}<br />fi<br /> Here is the script in action:<br /> [me@linuxbox ~]$ <strong>ul-param aBc<br /></strong>abc<br /> aBc<br />ABC<br /> ABc<br /> Again, we process the first command line argument and output the four variations sup-<br />ported by the parameter expansions.  While this script uses the first positional parameter, <br /><em>parameter</em> my be any string, variable, or string expression.<br /> <strong>Arithmetic Evaluation And Expansion<br /></strong>We looked at arithmetic expansion in Chapter 7. It is used to perform various arithmetic <br />operations on integers. Its basic form is:<br />$((<em>expression</em>))<br />where <em>expression</em> is a valid arithmetic expression.<br />This is related to the compound command (( )) used for arithmetic evaluation (truth <br />tests) we encountered in Chapter 27.<br />In previous chapters, we saw some of the common types of expressions and operators. <br />Here, we will look at a more complete list.<br /> 464<br /></p>
<hr />
<p>Arithmetic Evaluation And Expansion<br /> Number Bases<br />Back in Chapter 9, we got a look at octal (base 8) and hexadecimal (base 16) numbers. In <br />arithmetic expressions, the shell supports integer constants in any base.<br /> <em>Table 34-2: Specifying Different Number Bases</em><br /> <strong>Notation</strong><br /> <strong>Description</strong><br /> <em>number</em><br /> By default, numbers without any notation are treated as decimal <br />(base 10) integers.<br /> 0<em>number</em><br /> In arithmetic expressions, numbers with a leading zero are <br />considered octal.<br /> 0x<em>number</em><br /> Hexadecimal notation<br /> <em>base</em>#<em>number</em><br /> <em>number</em> is in <em>base</em><br /> Some examples:<br /> [me@linuxbox ~]$ <strong>echo $((0xff))<br /></strong>255<br /> [me@linuxbox ~]$ <strong>echo $((2#11111111))<br /></strong>255<br /> In the examples above, we print the value of the hexadecimal number  ff  (the largest <br />two-digit number) and the largest eight-digit binary (base 2) number.<br /> Unary Operators<br />There are two unary operators, the + and -, which are used to indicate if a number is pos-<br />itive or negative, respectively. For example, -5.<br /> Simple Arithmetic<br />The ordinary arithmetic operators are listed in the table below:<br /> <em>Table 34-3: Arithmetic Operators</em><br /> <strong>Operator</strong><br /> <strong>Description</strong><br /> +<br /> Addition<br /> -<br /> Subtraction<br /> 465<br /></p>
<hr />
<p>34 – Strings And Numbers<br /> *<br /> Multiplication<br /> /<br /> Integer division<br /> **<br /> Exponentiation<br /> %<br /> Modulo (remainder)<br /> Most of these are self-explanatory, but integer division and modulo require further dis-<br />cussion.<br />Since the shell’s arithmetic only operates on integers, the results of division are always <br />whole numbers:<br /> [me@linuxbox ~]$ <strong>echo $(( 5 / 2 ))<br /></strong>2<br /> This makes the determination of a remainder in a division operation more important:<br /> [me@linuxbox ~]$ <strong>echo $(( 5 % 2 ))<br /></strong>1<br /> By using the division and modulo operators, we can determine that 5 divided by 2 results <br />in 2, with a remainder of 1.<br />Calculating the remainder is useful in  loops. It allows an operation to be performed at <br />specified intervals during the loop's execution. In the example below, we display a line of <br />numbers, highlighting each multiple of 5: <br /> #!/bin/bash <br /> # modulo : demonstrate the modulo operator <br /> for ((i = 0; i &lt;= 20; i = i + 1)); do <br /> remainder=$((i % 5)) <br /> if (( remainder == 0 )); then <br /> printf &quot;&lt;%d&gt; &quot; $i<br /> else <br /> printf &quot;%d &quot; $i<br /> fi <br /> done <br /> printf &quot;\n&quot;<br /> 466<br /></p>
<hr />
<p>Arithmetic Evaluation And Expansion<br /> When executed, the results look like this:<br /> [me@linuxbox ~]$ <strong>modulo<br /></strong>&lt;0&gt; 1 2 3 4 &lt;5&gt; 6 7 8 9 &lt;10&gt; 11 12 13 14 &lt;15&gt; 16 17 18 19 &lt;20&gt;<br /> Assignment<br />Although its uses may not be immediately apparent, arithmetic expressions may perform <br />assignment. We have performed assignment many times, though in a different context. <br />Each time we give a variable a value, we are performing assignment. We can also do it <br />within arithmetic expressions: <br /> [me@linuxbox ~]$ <strong>foo=<br /></strong>[me@linuxbox ~]$ <strong>echo $foo</strong><br /> [me@linuxbox ~]$ <strong>if (( foo = 5 ));then echo &quot;It is true.&quot;; fi</strong><br /> It is true.<br />[me@linuxbox ~]$ <strong>echo $foo</strong><br /> 5<br /> In the example above, we first assign an empty value to the variable foo and verify that <br />it is indeed empty. Next, we perform an if with the compound command (( foo = 5 <br />)). This process does two interesting things: 1) it assigns the value of 5 to the variable <br />foo, and 2) it evaluates to true because foo was assigned a nonzero value.<br /> <strong>Note:</strong>  It is important to remember the exact meaning of the  =  in the expression <br />above. A single  = performs assignment. foo = 5 says “make foo equal to 5,” <br />while == evaluates equivalence. foo == 5 says “does foo equal 5?”  This can <br />be very confusing because the test command accepts a single = for string equiva-<br />lence. This is yet another reason to use the more modern [[ ]] and (( )) com-<br />pound commands in place of test.<br /> In addition to the =, the shell also provides notations that perform some very useful as-<br />signments:<br /> <em>Table 34-4: Assignment Operators</em><br /> <strong>Notation</strong><br /> <strong>Description</strong><br /> 467<br /></p>
<hr />
<p>34 – Strings And Numbers<br /> <em>parameter</em> = <em>value</em><br /> Simple assignment. Assigns <em>value</em> to <em>parameter</em>. <br /> <em>parameter</em> += <em>value</em><br /> Addition. Equivalent to <em>parameter</em> = <em>parameter</em> + <br /><em>value.</em><br /> <em>parameter</em> -= <em>value</em><br /> Subtraction. Equivalent to <em>parameter</em> = <em>parameter</em> – <br /><em>value.</em><br /> <em>parameter</em> *= <em>value</em><br /> Multiplication. Equivalent to <em>parameter</em> = <em>parameter</em> <br />* <em>value.</em><br /> <em>parameter</em> /= <em>value</em><br /> Integer division. Equivalent to <em>parameter</em> = <br /><em>parameter</em> / <em>value.</em><br /> <em>parameter</em> %= <em>value</em><br /> Modulo. Equivalent to <em>parameter</em> = <em>parameter</em> % <br /><em>value.</em><br /> <em>parameter</em>++<br /> Variable post-increment. Equivalent to <em>parameter</em> = <br /><em>parameter</em> + 1 (however, see discussion below).<br /> <em>parameter−−</em><br /> Variable post-decrement. Equivalent to <em>parameter</em> = <br /><em>parameter</em> − 1.<br /> ++<em>parameter</em><br /> Variable pre-increment. Equivalent to <em>parameter</em> = <br /><em>parameter</em> + 1.<br /> --<em>parameter</em><br /> Variable pre-decrement. Equivalent to <em>parameter</em> = <br /><em>parameter</em> − 1.<br /> These assignment operators provide a convenient shorthand for many common arithmetic <br />tasks. Of special interest are the increment (++) and decrement (−−) operators, which in-<br />crease or decrease the value of their parameters by one. This style of notation is taken <br />from the C programming language and has been incorporated by several other program-<br />ming languages, including bash.<br />The operators may appear either at the front of a parameter or at the end. While they both <br />either increment or decrement the parameter by one, the two placements have a subtle <br />difference. If placed at the front of the parameter, the parameter is incremented (or decre-<br />mented) before the parameter is returned. If placed after, the operation is performed <em>after <br /></em>the parameter is returned. This is rather strange, but it is the intended behavior. Here is a <br />demonstration:<br /> [me@linuxbox ~]$ <strong>foo=1<br /></strong>[me@linuxbox ~]$ <strong>echo $((foo++))</strong><br /> 1<br />[me@linuxbox ~]$ <strong>echo $foo</strong><br /> 468<br /></p>
<hr />
<p>Arithmetic Evaluation And Expansion<br /> 2<br /> If we assign the value of one to the variable foo and then increment it with the ++ opera-<br />tor placed after the parameter name, foo is returned with the value of one. However, if <br />we look at the value of the variable a second time, we see the incremented value. If we <br />place the ++ operator in front of the parameter, we get the more expected behavior:<br /> [me@linuxbox ~]$ <strong>foo=1</strong><br /> [me@linuxbox ~]$ <strong>echo $((++foo))<br /></strong>2<br /> [me@linuxbox ~]$ <strong>echo $foo<br /></strong>2<br /> For most shell applications, prefixing the operator will be the most useful.<br />The ++ and -- operators are often used in conjunction with loops. We will make some im-<br />provements to our modulo script to tighten it up a bit:<br /> #!/bin/bash <br /> # modulo2 : demonstrate the modulo operator <br /> for ((i = 0; i &lt;= 20; <strong>++i</strong> )); do <br /> if ((<strong>(i % 5)</strong> == 0 )); then <br /> printf &quot;&lt;%d&gt; &quot; $i<br /> else  printf &quot;%d &quot; $i<br />fi <br /> done <br />printf &quot;\n&quot;<br /> Bit Operations<br />One class of operators manipulates numbers in an unusual way. These operators work at <br />the bit level. They are used for certain kinds of low level tasks, often involving setting or <br />reading bit-flags.<br /> <em>Table 34-5: Bit Operators</em><br /> <strong>Operator</strong><br /> <strong>Description</strong><br /> ~<br /> Bitwise negation. Negate all the bits in a number.<br /> 469<br /></p>
<hr />
<p>34 – Strings And Numbers<br /> &lt;&lt;<br /> Left bitwise shift. Shift all the bits in a number to the left.<br /> &gt;&gt;<br /> Right bitwise shift. Shift all the bits in a number to the right.<br /> &amp;<br /> Bitwise AND. Perform an AND operation on all the bits in two <br />numbers.<br /> |<br /> Bitwise OR. Perform an OR operation on all the bits in two <br />numbers.<br /> ^<br /> Bitwise XOR. Perform an exclusive OR operation on all the <br />bits in two numbers.<br /> Note that there are also corresponding assignment operators ( for example, &lt;&lt;=) for all <br />but bitwise negation.<br />Here we will demonstrate producing a list of powers of 2, using the left bitwise shift op-<br />erator:<br /> [me@linuxbox ~]$ <strong>for ((i=0;i&lt;8;++i)); do echo $((1&lt;&lt;i)); done<br /></strong>1<br /> 2<br />4<br /> 8<br />16<br /> 32<br />64<br /> 128<br /> Logic<br />As we discovered in Chapter 27, the (( )) compound command supports a variety of <br />comparison operators. There are a few more that can be used to evaluate logic. Here is <br />the complete list:<br /> <em>Table 34-6: Comparison Operators</em><br /> <strong>Operator</strong><br /> <strong>Description</strong><br /> &lt;=<br /> Less than or equal to<br /> &gt;=<br /> Greater than or equal to<br /> &lt;<br /> Less than<br /> &gt;<br /> Greater than<br /> 470<br /></p>
<hr />
<p>Arithmetic Evaluation And Expansion<br /> ==<br /> Equal to<br /> !=<br /> Not equal to<br /> &amp;&amp;<br /> Logical AND<br /> ||<br /> Logical OR<br /> <em>expr1</em>?<em>expr2</em>:<em>expr3</em><br /> Comparison (ternary) operator. If expression <em>expr1</em> <br />evaluates to be non-zero (arithmetic true) then <em>expr2</em>, <br />else <em>expr3</em>.<br /> When used for logical operations, expressions follow the rules of arithmetic logic; that is, <br />expressions that evaluate as zero are considered false, while non-zero expressions are <br />considered true. The (( )) compound command maps the results into the shell’s normal <br />exit codes:<br /> [me@linuxbox ~]$ <strong>if ((1)); then echo &quot;true&quot;; else echo &quot;false&quot;; fi<br /></strong>true<br /> [me@linuxbox ~]$ <strong>if ((0)); then echo &quot;true&quot;; else echo &quot;false&quot;; fi<br /></strong>false<br /> The strangest of the logical operators is the  <em>ternary  operator</em>. This operator (which is <br />modeled after the one in the C programming language) performs a standalone logical test. <br />It can be used as a kind of if/then/else statement. It acts on three arithmetic expressions <br />(strings won’t work), and if the first expression is true (or non-zero) the second expres-<br />sion is performed. Otherwise, the third expression is performed. We can try this on the <br />command line:<br /> [me@linuxbox ~]$ <strong>a=0<br /></strong>[me@linuxbox ~]$ <strong>((a&lt;1?++a:--a))</strong><br /> [me@linuxbox ~]$ <strong>echo $a<br /></strong>1<br /> [me@linuxbox ~]$ <strong>((a&lt;1?++a:--a))<br /></strong>[me@linuxbox ~]$ <strong>echo $a</strong><br /> 0<br /> Here we see a ternary operator in action. This example implements a toggle. Each time <br />the operator is performed, the value of the variable a switches from zero to one or vice <br />versa.<br />Please note that performing assignment within the expressions is not straightforward. <br /> 471<br /></p>
<hr />
<p>34 – Strings And Numbers<br /> When attempted, bash will declare an error: <br /> [me@linuxbox ~]$ <strong>a=0<br /></strong>[me@linuxbox ~]$ <strong>((a&lt;1?a+=1:a-=1))</strong> <br /> bash: ((: a&lt;1?a+=1:a-=1: attempted assignment to non-variable (error <br />token is &quot;-=1&quot;)<br /> This problem can be mitigated by surrounding the assignment expression with parenthe-<br />ses:<br /> [me@linuxbox ~]$ <strong>((a&lt;1?(a+=1):(a-=1)))</strong><br /> Next, we see a more complete example of using arithmetic operators in a script that pro-<br />duces a simple table of numbers:<br /> #!/bin/bash <br /> # arith-loop: script to demonstrate arithmetic operators <br /> finished=0 <br /> a=0 <br />printf &quot;a\ta**2\ta**3\n&quot; <br /> printf &quot;=\t====\t====\n&quot; <br /> until ((finished)); do <br /> b=$((a**2)) <br /> c=$((a**3)) <br />printf &quot;%d\t%d\t%d\n&quot; $a $b $c <br /> ((a&lt;10?++a:(finished=1)))<br />  <br /> done<br /> In this script, we implement an until loop based on the value of the finished variable. <br />Initially, the variable is set to zero (arithmetic false) and we continue the loop until it be-<br />comes non-zero. Within the loop, we calculate the square and cube of the counter variable <br />a. At the end of the loop, the value of the counter variable is evaluated. If it is less than <br />10 (the maximum number of iterations), it is incremented by one, else the variable fin-<br />ished is given the value of one, making finished arithmetically true, thereby termi-<br />nating the loop. Running the script gives this result:<br /> 472<br /></p>
<hr />
<p>Arithmetic Evaluation And Expansion<br /> [me@linuxbox ~]$ <strong>arith-loop<br /></strong>a<br /> a**2<br /> a**3 <br /> =<br /> ====<br /> ==== <br /> 0<br /> 0<br /> 0 <br /> 1<br /> 1<br /> 1 <br /> 2<br /> 4<br /> 8 <br /> 3<br /> 9<br /> 27 <br /> 4<br /> 16<br /> 64 <br /> 5<br /> 25<br /> 125 <br /> 6<br /> 36<br /> 216 <br /> 7<br /> 49<br /> 343 <br /> 8<br /> 64<br /> 512 <br /> 9<br /> 81<br /> 729 <br /> 10<br /> 100<br /> 1000<br /> <strong>bc – An Arbitrary Precision Calculator Language<br /></strong>We have seen how the shell can handle all types of  integer arithmetic, but what if we <br />need to perform higher math or even just use floating point numbers? The answer is, we <br />can’t. At least not directly with the shell. To do this, we need to use an external program. <br />There are several approaches we can take. Embedding Perl or AWK programs is one pos-<br />sible solution, but unfortunately, outside the scope of this book.<br />Another approach is to use a specialized calculator program. One such program found on <br />most Linux systems is called bc.<br />The  bc  program reads a file written in its own C-like language and executes it. A bc <br />script may be a separate file or it may be read from standard input. The bc language sup-<br />ports quite a few features including variables, loops, and programmer-defined functions. <br />We won’t cover bc entirely here, just enough to get a taste. bc is well documented by its <br />man page.<br />Let’s start with a simple example. We’ll write a bc script to add 2 plus 2:<br /> /* A very simple bc script */ <br /> 2 + 2<br /> The first line of the script is a comment. bc uses the same syntax for comments as the C <br />programming language. Comments, which may span multiple lines, begin with  /* and <br />end with */.<br /> 473<br /></p>
<hr />
<p>34 – Strings And Numbers<br /> Using bc<br />If we save the bc script above as foo.bc, we can run it this way:<br /> [me@linuxbox ~]$ <strong>bc foo.bc</strong><br /> bc 1.06.94 <br />Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006 Free Software <br /> Foundation, Inc. <br />This is free software with ABSOLUTELY NO WARRANTY. <br /> For details type `warranty'. <br />4<br /> If we look carefully, we can see the result at the very bottom, after the copyright message. <br />This message can be suppressed with the -q (quiet) option.<br /> bc can also be used interactively:<br /> [me@linuxbox ~]$ <strong>bc -q<br />2 + 2</strong><br /> 4<br /><strong>quit</strong><br /> When using  bc interactively, we simply type the calculations we wish to perform, and <br />the results are immediately displayed. The bc command quit ends the interactive ses-<br />sion.<br />It is also possible to pass a script to bc via standard input:<br /> [me@linuxbox ~]$ <strong>bc &lt; foo.bc<br /></strong>4<br /> The ability to take standard input means that we can use here documents, here strings, <br />and pipes to pass scripts. This is a here string example:<br /> [me@linuxbox ~]$ <strong>bc &lt;&lt;&lt; &quot;2+2&quot;<br /></strong>4<br /> 474<br /></p>
<hr />
<p>bc – An Arbitrary Precision Calculator Language<br /> An Example Script<br />As a real-world example, we will construct a script that performs a common calculation, <br />monthly loan payments. In the script below, we use a here document to pass a script to <br />bc:<br /> #!/bin/bash <br /> # loan-calc : script to calculate monthly loan payments <br /> PROGNAME=$(basename $0) <br /> usage () { <br /> cat &lt;&lt;- EOF <br /> Usage: $PROGNAME PRINCIPAL INTEREST MONTHS <br /> Where: <br /> PRINCIPAL is the amount of the loan.<br />INTEREST is the APR as a number (7% = 0.07).<br /> MONTHS is the length of the loan's term. <br /> EOF <br /> } <br /> if (($# != 3)); then <br /> usage <br />exit 1 <br /> fi <br /> principal=$1 <br />interest=$2 <br /> months=$3 <br /> bc &lt;&lt;- EOF <br /> scale = 10 <br /> i = $interest / 12 <br />p = $principal <br /> n = $months <br />a = p * ((i * ((1 + i) ^ n)) / (((1 + i) ^ n) - 1)) <br /> print a, &quot;\n&quot; <br /> EOF<br /> When executed, the results look like this:<br /> [me@linuxbox ~]$ <strong>loan-calc 135000 0.0775 180</strong> <br /> 475<br /></p>
<hr />
<p>34 – Strings And Numbers<br /> 1270.7222490000<br /> This example calculates the monthly payment for a $135,000 loan at 7.75% APR for 180 <br />months (15 years). Notice the precision of the answer. This is determined by the value <br />given to the special scale variable in the bc script. A full description of the bc script-<br />ing language is provided by the bc man page. While its mathematical notation is slightly <br />different from that of the shell (bc more closely resembles C), most of it will be quite fa-<br />miliar, based on what we have learned so far.<br /> <strong>Summing Up<br /></strong>In this chapter, we have learned about many of the little things that can be used to get the <br />“real work” done in scripts. As our experience with scripting grows, the ability to effec-<br />tively manipulate strings and numbers will prove extremely valuable. Our loan-calc <br />script demonstrates that even simple scripts can be created to do some really useful <br />things.<br /> <strong>Extra Credit<br /></strong>While the basic functionality of the loan-calc script is in place, the script is far from <br />complete. For extra credit, try improving the loan-calc script with the following fea-<br />tures:<br /> ●<br /> Full verification of the command line arguments<br /> ●<br /> A command line option to implement an “interactive” mode that will prompt the <br />user to input the principal, interest rate, and term of the loan.<br /> ●<br /> A better format for the output. <br /> <strong>Further Reading</strong><br /> ●<br /> The <em>Bash Hackers Wiki</em> has a good discussion of parameter expansion:<br /><a href="http://wiki.bash-hackers.org/syntax/pe">http://wiki.bash-hackers.org/syntax/pe</a><br /> ●<br /> The <em>Bash Reference Manual</em> covers this, too:<br /><a href="http://www.gnu.org/software/bash/manual/bashref.html#Shell-Parameter-Expansion">http://www.gnu.org/software/bash/manual/bashref.html#Shell-Parameter-Expan-<br />sion</a><br /> ●<br /> The <em>Wikipedia</em> has a good article describing bit operations:<br /><a href="http://en.wikipedia.org/wiki/Bit_operation">http://en.wikipedia.org/wiki/Bit_operation</a><br /> ●<br /> and an article on ternary operations:<br /><a href="http://en.wikipedia.org/wiki/Ternary_operation">http://en.wikipedia.org/wiki/Ternary_operation</a><br /> 476<br /></p>
<hr />
<p>Further Reading<br /> ●<br /> as well as a description of the formula for calculating loan payments used in our <br />loan-calc script:<br /><a href="http://en.wikipedia.org/wiki/Amortization_calculator">http://en.wikipedia.org/wiki/Amortization_calculator</a><br /> 477<br /></p>
<hr />
<p>35 – Arrays<br /> <em><strong>35 – Arrays</strong></em><br /> In the last chapter, we looked at how the shell can manipulate strings and numbers. The <br />data types we have looked at so far are known in computer science circles as <em>scalar vari-<br />ables</em>; that is, variables that contain a single value.<br />In this chapter, we will look at another kind of data structure called an <em>array</em>, which holds <br />multiple values. Arrays are a feature of virtually every programming language. The shell <br />supports them, too, though in a rather limited fashion. Even so, they can be very useful <br />for solving programming problems.<br /> <strong>What Are Arrays?<br /></strong>Arrays are variables that hold more than one value at a time. Arrays are organized like a <br />table. Let’s consider a spreadsheet as an example. A spreadsheet acts like a <em>two-dimen-<br />sional array</em>. It has both rows and columns, and an individual cell in the spreadsheet can <br />be located according to its row and column address. An array behaves the same way. An <br />array has cells, which are called <em>elements</em>, and each element contains data. An individual <br />array element is accessed using an address called an <em>index</em> or <em>subscript</em>.<br />Most programming languages support <em>multidimensional arrays</em>. A spreadsheet is an ex-<br />ample of a multidimensional array with two dimensions, width and height. Many lan-<br />guages support arrays with an arbitrary number of dimensions, though two- and three-di-<br />mensional arrays are probably the most commonly used.<br />Arrays in bash are limited to a single dimension. We can think of them as a spreadsheet <br />with a single column. Even with this limitation, there are many applications for them. Ar-<br />ray support first appeared in bash version 2. The original Unix shell program, sh, did <br />not support arrays at all.<br /> <strong>Creating An Array<br /></strong>Array variables are named just like other bash variables, and are created automatically <br />when they are accessed. Here is an example:<br /> 478<br /></p>
<hr />
<p>Creating An Array<br /> [me@linuxbox ~]$ <strong>a[1]=foo<br /></strong>[me@linuxbox ~]$ <strong>echo ${a[1]}</strong><br /> foo<br /> Here we see an example of both the assignment and access of an array element. With the <br />first command, element 1 of array a is assigned the value “foo”. The second command <br />displays the stored value of element 1. The use of braces in the second command is re-<br />quired to prevent the shell from attempting pathname expansion on the name of the array <br />element.<br />An array can also be created with the declare command:<br /> [me@linuxbox ~]$ <strong>declare -a a</strong><br /> Using the -a option, this example of declare creates the array a. <br /> <strong>Assigning Values To An Array<br /></strong>Values may be assigned in one of two ways. Single values may be assigned using the fol-<br />lowing syntax:<br /><em>name</em>[<em>subscript</em>]=<em>value</em><br /> where <em>name</em> is the name of the array and <em>subscript</em> is an integer (or arithmetic expression) <br />greater than or equal to zero. Note that the first element of an array is subscript zero, not <br />one. <em>value</em> is a string or integer assigned to the array element.<br />Multiple values may be assigned using the following syntax:<br /><em>name</em>=(<em>value1</em> <em>value2</em> ...)<br /> where <em>name</em> is the name of the array and <em>value...</em> are values assigned sequentially to ele-<br />ments of the array, starting with element zero. For example, if we wanted to assign abbre-<br />viated days of the week to the array days, we could do this:<br /> [me@linuxbox ~]$ <strong>days=(Sun Mon Tue Wed Thu Fri Sat)</strong> <br /> It is also possible to assign values to a specific element by specifying a subscript for each <br />value:<br /> [me@linuxbox ~]$ <strong>days=([0]=Sun [1]=Mon [2]=Tue [3]=Wed [4]=Thu </strong><br /> 479<br /></p>
<hr />
<p>35 – Arrays<br /> <strong>[5]=Fri [6]=Sat)</strong><br /> <strong>Accessing Array Elements<br /></strong>So what are arrays good for? Just as many data-management tasks can be performed with <br />a spreadsheet program, many programming tasks can be performed with arrays.<br />Let’s consider a simple data-gathering and presentation example. We will construct a <br />script that examines the modification times of the files in a specified directory. From this <br />data, our script will output a table showing at what hour of the day the files were last <br />modified. Such a script could be used to determine when a system is most active. This <br />script, called hours, produces this result:<br /> [me@linuxbox ~]$ <strong>hours .</strong><br /> Hour Files Hour<br /> Files <br /> ---- ----- ----<br /> ----- <br /> 00<br /> 0<br /> 12<br /> 11 <br /> 01<br /> 1<br /> 13<br /> 7 <br /> 02<br /> 0<br /> 14<br /> 1 <br /> 03<br /> 0<br /> 15<br /> 7 <br /> 04<br /> 1<br /> 16<br /> 6 <br /> 05<br /> 1<br /> 17<br /> 5 <br /> 06<br /> 6<br /> 18<br /> 4 <br /> 07<br /> 3<br /> 19<br /> 4 <br /> 08<br /> 1<br /> 20<br /> 1 <br /> 09<br /> 14<br /> 21<br /> 0 <br /> 10<br /> 2<br /> 22<br /> 0 <br /> 11<br /> 5<br /> 23<br /> 0 <br /> Total files = 80<br /> We execute the  hours  program, specifying the current directory as the target. It pro-<br />duces a table showing, for each hour of the day (0-23), how many files were last modi-<br />fied. The code to produce this is as follows: <br /> #!/bin/bash <br /> # hours : script to count files by modification time <br /> usage () { <br /> echo &quot;usage: $(basename $0) directory&quot; &gt;&amp;2 <br /> } <br /> 480<br /></p>
<hr />
<p>Accessing Array Elements<br /> # Check that argument is a directory <br />if [[ ! -d $1 ]]; then <br /> usage <br />exit 1 <br /> fi <br /> # Initialize array <br />for i in {0..23}; do hours[i]=0; done <br /> # Collect data <br /> for i in $(stat -c %y &quot;$1&quot;/* | cut -c 12-13); do <br /> j=${i/#0} <br /> ((++hours[j])) <br />((++count)) <br /> done <br /> # Display data <br />echo -e &quot;Hour\tFiles\tHour\tFiles&quot; <br /> echo -e &quot;----\t-----\t----\t-----&quot; <br />for i in {0..11}; do <br /> j=$((i + 12)) <br />printf &quot;%02d\t%d\t%02d\t%d\n&quot; $i ${hours[i]} $j ${hours[j]} <br /> done <br />printf &quot;\nTotal files = %d\n&quot; $count<br /> The script consists of one function (usage) and a main body with four sections. In the <br />first section, we check that there is a command line argument and that it is a directory. If <br />it is not, we display the usage message and exit.<br />The second section initializes the array hours. It does this by assigning each element a <br />value of zero. There is no special requirement to prepare arrays prior to use, but our script <br />needs to ensure that no element is empty. Note the interesting way the loop is con-<br />structed. By employing brace expansion ({0..23}), we are able to easily generate a se-<br />quence of words for the for command.<br />The next section gathers the data by running the stat program on each file in the direc-<br />tory. We use cut to extract the two-digit hour from the result. Inside the loop, we need to <br />remove leading zeros from the hour field, since the shell will try (and ultimately fail) to <br />interpret values “00” through “09” as octal numbers (see Table 34-1). Next, we increment <br />the value of the array element corresponding with the hour of the day. Finally, we incre-<br />ment a counter (count) to track the total number of files in the directory.<br />The last section of the script displays the contents of the array. We first output a couple of <br />header lines and then enter a loop that produces two columns of output. Lastly, we output <br />the final tally of files.<br /> 481<br /></p>
<hr />
<p>35 – Arrays<br /> <strong>Array Operations<br /></strong>There are many common array operations. Such things as deleting arrays, determining <br />their size, sorting, etc. have many applications in scripting.<br /> Outputting The Entire Contents Of An Array<br />The subscripts * and @ can be used to access every element in an array. As with posi-<br />tional parameters, the @ notation is the more useful of the two. Here is a demonstration:<br /> [me@linuxbox ~]$ <strong>animals=(&quot;a dog&quot; &quot;a cat&quot; &quot;a fish&quot;)<br /></strong>[me@linuxbox ~]$ <strong>for i in ${animals[*]}; do echo $i; done</strong><br /> a <br />dog <br /> a <br />cat <br /> a <br />fish<br /> [me@linuxbox ~]$ <strong>for i in ${animals[@]}; do echo $i; done<br /></strong>a <br /> dog <br />a <br /> cat <br />a <br /> fish<br />[me@linuxbox ~]$ <strong>for i in &quot;${animals[*]}&quot;; do echo $i; done</strong><br /> a dog a cat a fish<br />[me@linuxbox ~]$ <strong>for i in &quot;${animals[@]}&quot;; do echo $i; done</strong><br /> a dog <br />a cat <br /> a fish<br /> We create the array animals and assign it three two-word strings. We then execute four <br />loops to see the affect of word-splitting on the array contents. The behavior of notations $<br />{animals[*]} and ${animals[@]} is identical until they are quoted. The * nota-<br />tion results in a single word containing the array’s contents, while the @ notation results <br />in three words, which matches the arrays “real” contents.<br /> Determining The Number Of Array Elements<br />Using parameter expansion, we can  determine the number of elements in an array in <br />much the same way as finding the length of a string. Here is an example:<br /> 482<br /></p>
<hr />
<p>Array Operations<br /> [me@linuxbox ~]$ <strong>a[100]=foo<br /></strong>[me@linuxbox ~]$ <strong>echo ${#a[@]}  # number of array elements</strong><br /> 1<br />[me@linuxbox ~]$ <strong>echo ${#a[100]}  # length of element 100</strong><br /> 3<br /> We create array a and assign the string “foo” to element 100. Next, we use parameter ex-<br />pansion to examine the length of the array, using the @ notation. Finally, we look at the <br />length of element 100 which contains the string “foo”. It is interesting to note that while <br />we assigned our string to element 100, bash only reports one element in the array. This <br />differs from the behavior of some other languages in which the unused elements of the ar-<br />ray (elements 0-99) would be initialized with empty values and counted.<br /> Finding The Subscripts Used By An Array<br />As bash allows arrays to contain “gaps” in the assignment of subscripts, it is sometimes <br />useful to determine which elements actually exist. This can be done with a parameter ex-<br />pansion using the following forms:<br />${!<em>array</em>[*]}<br />${!<em>array</em>[@]}<br />where <em>array</em> is the name of an array variable. Like the other expansions that use * and @, <br />the @ form enclosed in quotes is the most useful, as it expands into separate words:<br /> [me@linuxbox ~]$ <strong>foo=([2]=a [4]=b [6]=c)</strong><br /> [me@linuxbox ~]$ <strong>for i in &quot;${foo[@]}&quot;; do echo $i; done<br /></strong>a<br /> b<br />c<br /> [me@linuxbox ~]$ <strong>for i in &quot;${!foo[@]}&quot;; do echo $i; done<br /></strong>2<br /> 4<br />6<br /> Adding Elements To The End Of An Array<br />Knowing the number of elements in an array is no help if we need to append values to the <br />end of an array, since the values returned by the * and @ notations do not tell us the maxi-<br />mum array index in use. Fortunately, the shell provides us with a solution. By using the <br />+= assignment operator, we can automatically append values to the end of an array. Here, <br />we assign three values to the array foo, and then append three more.<br /> 483<br /></p>
<hr />
<p>35 – Arrays<br /> [me@linuxbox ~]$ <strong>foo=(a b c)<br /></strong>[me@linuxbox ~]$ <strong>echo ${foo[@]}</strong><br /> a b c<br />[me@linuxbox ~]$ <strong>foo+=(d e f)</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo[@]}<br /></strong>a b c d e f<br /> Sorting An Array<br />Just as with spreadsheets, it is often necessary to sort the values in a column of data. The <br />shell has no direct way of doing this, but it's not hard to do with a little coding:<br /> #!/bin/bash <br /> # array-sort : Sort an array <br /> a=(f e d c b a) <br /> echo &quot;Original array: ${a[@]}&quot; <br />a_sorted=($(for i in &quot;${a[@]}&quot;; do echo $i; done | sort)) <br /> echo &quot;Sorted array:   ${a_sorted[@]}&quot;<br /> When executed, the script produces this:<br /> [me@linuxbox ~]$ <strong>array-sort</strong><br /> Original array: f e d c b a <br />Sorted array:   a b c d e f<br /> The script operates by copying the contents of the original array (a) into a second array <br />(a_sorted) with a tricky piece of command substitution. This basic technique can be <br />used to perform many kinds of operations on the array by changing the design of the <br />pipeline.<br /> Deleting An Array<br />To delete an array, use the unset command:<br /> [me@linuxbox ~]$ <strong>foo=(a b c d e f)<br /></strong>[me@linuxbox ~]$ <strong>echo ${foo[@]}</strong><br /> a b c d e f<br /> 484<br /></p>
<hr />
<p>Array Operations<br /> [me@linuxbox ~]$ <strong>unset foo<br /></strong>[me@linuxbox ~]$ <strong>echo ${foo[@]}</strong><br /> [me@linuxbox ~]$ <br /> unset may also be used to delete single array elements:<br /> [me@linuxbox ~]$ <strong>foo=(a b c d e f)<br /></strong>[me@linuxbox ~]$ <strong>echo ${foo[@]}</strong><br /> a b c d e f<br />[me@linuxbox ~]$ <strong>unset 'foo[2]'</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo[@]} <br /></strong>a b d e f<br /> In this example, we delete the third element of the array, subscript 2. Remember, arrays <br />start with subscript zero, not one! Notice also that the array element must be quoted to <br />prevent the shell from performing pathname expansion.<br />Interestingly, the assignment of an empty value to an array does not empty its contents:<br /> [me@linuxbox ~]$ <strong>foo=(a b c d e f)<br /></strong>[me@linuxbox ~]$ <strong>foo=</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo[@]}<br /></strong>b c d e f<br /> Any reference to an array variable without a subscript refers to element zero of the array:<br /> [me@linuxbox ~]$ <strong>foo=(a b c d e f)<br /></strong>[me@linuxbox ~]$ <strong>echo ${foo[@]}</strong><br /> a b c d e f<br />[me@linuxbox ~]$ <strong>foo=A</strong><br /> [me@linuxbox ~]$ <strong>echo ${foo[@]}<br /></strong>A b c d e f<br /> <strong>Associative Arrays<br /></strong>Recent versions of bash now support <em>associative arrays</em>.  Associative arrays use strings <br />rather than integers as array indexes.  This capability allow interesting new approaches to <br />managing data.  For example, we can create an array called “colors” and use color names <br />as indexes:<br /> 485<br /></p>
<hr />
<p>35 – Arrays<br /> declare -A colors<br />colors[&quot;red&quot;]=&quot;#ff0000&quot;<br /> colors[&quot;green&quot;]=&quot;#00ff00&quot;<br />colors[&quot;blue&quot;]=&quot;#0000ff&quot;<br /> Unlike integer indexed arrays, which are created by merely referencing them, associative <br />arrays must be created with the declare command using the new -A option. Associa-<br />tive array elements are accessed in much the same way as integer indexed arrays:<br /> echo ${colors[&quot;blue&quot;]}<br /> In the next chapter, we will look at a script that makes good use of associative arrays to <br />produce an interesting report.<br /> <strong>Summing Up<br /></strong>If we search the bash man page for the word “array,” we find many instances of where <br />bash makes use of array variables. Most of these are rather obscure, but they may pro-<br />vide occasional utility in some special circumstances. In fact, the entire topic of arrays is <br />rather under-utilized in shell programming owing largely to the fact that the traditional <br />Unix shell programs (such as sh) lacked any support for arrays. This lack of popularity is <br />unfortunate because arrays are widely used in other programming languages and provide <br />a powerful tool for solving many kinds of programming problems.<br />Arrays and loops have a natural affinity and are often used together. The<br />for ((<em>expr</em>; <em>expr</em>; <em>expr</em>))<br />form of loop is particularly well-suited to calculating array subscripts.<br /> <strong>Further Reading</strong><br /> ●<br /> A couple of Wikipedia articles about the data structures found in this chapter:<br /><a href="http://en.wikipedia.org/wiki/Scalar_(computing)">http://en.wikipedia.org/wiki/Scalar_(computing)</a><br /> <a href="http://en.wikipedia.org/wiki/Associative_array">http://en.wikipedia.org/wiki/Associative_array</a><br /> 486<br /></p>
<hr />
<p>36 – Exotica<br /> <em><strong>36 – Exotica</strong></em><br /> In this, the final chapter of our journey, we will look at some odds and ends. While we <br />have certainly covered a lot of ground in the previous chapters, there are many bash fea-<br />tures that we have not covered. Most are fairly obscure, and useful mainly to those inte-<br />grating bash into a Linux distribution. However, there are a few that, while not in com-<br />mon use, are helpful for certain programming problems. We will cover them here. <br /> <strong>Group Commands And Subshells<br /></strong>bash allows commands to be grouped together. This can be done in one of two ways; ei-<br />ther with a <em>group</em> <em>command</em> or with a <em>subshell</em>. Here are examples of the syntax of each:<br />Group command:<br />{ command1; command2; [command3; ...] }<br />Subshell:<br />(command1; command2; [command3;...])<br />The two forms differ in that a group command surrounds its commands with braces and a <br />subshell uses parentheses. It is important to note that, due to the way bash implements <br />group commands, the braces must be separated from the commands by a space and the <br />last command must be terminated with either a semicolon or a newline prior to the clos-<br />ing brace.<br />So what are group commands and subshells good for? While they have an important dif-<br />ference (which we will get to in a moment), they are both used to  manage redirection. <br />Let’s consider a script segment that performs redirections on multiple commands:<br /> ls -l &gt; output.txt<br />echo &quot;Listing of foo.txt&quot; &gt;&gt; output.txt<br /> cat foo.txt &gt;&gt; output.txt<br /> This is pretty straightforward. Three commands with their output redirected to a file <br />named output.txt. Using a group command, we could code this as follows:<br /> 487<br /></p>
<hr />
<p>36 – Exotica<br /> { ls -l; echo &quot;Listing of foo.txt&quot;; cat foo.txt; } &gt; output.txt<br /> Using a subshell is similar:<br /> (ls -l; echo &quot;Listing of foo.txt&quot;; cat foo.txt) &gt; output.txt<br /> Using this technique we have saved ourselves some typing, but where a group command <br />or subshell really shines is with pipelines. When constructing a pipeline of commands, it <br />is often useful to combine the results of several commands into a single stream. Group <br />commands and subshells make this easy:<br /> { ls -l; echo &quot;Listing of foo.txt&quot;; cat foo.txt; } | lpr<br /> Here we have combined the output of our three commands and piped them into the input <br />of lpr to produce a printed report.<br />In the script that follows, we will use groups commands and look at several programming <br />techniques that can be employed in conjunction with  associative arrays.   This script, <br />called array-2, when given the name of a directory, prints a listing of the files in the <br />directory along with the names of the the file's owner and group owner.  At the end of <br />listing, the script prints a tally of the number of files belonging to each owner and group. <br />Here we see the results (condensed for brevity) when the script is given the directory <br />/usr/bin:<br /> [me@linuxbox ~]$ <strong>array-2 /usr/bin</strong><br /> /usr/bin/2to3-2.6                        root       root      <br />/usr/bin/2to3                            root       root      <br /> /usr/bin/a2p                             root       root      <br />/usr/bin/abrowser                        root       root      <br /> /usr/bin/aconnect                        root       root      <br />/usr/bin/acpi_fakekey                    root       root      <br /> /usr/bin/acpi_listen                     root       root      <br />/usr/bin/add-apt-repository              root       root<br /> .<br />.<br /> .<br />/usr/bin/zipgrep                         root       root      <br /> /usr/bin/zipinfo                         root       root      <br />/usr/bin/zipnote                         root       root      <br /> /usr/bin/zip                             root       root      <br /> 488<br /></p>
<hr />
<p>Group Commands And Subshells<br /> /usr/bin/zipsplit                        root       root      <br />/usr/bin/zjsdecode                       root       root      <br /> /usr/bin/zsoelim                         root       root      <br /> File owners:<br />daemon    :     1 file(s)<br /> root      :  1394 file(s)<br /> File group owners:<br />crontab   :     1 file(s)<br /> daemon    :     1 file(s)<br />lpadmin   :     1 file(s)<br /> mail      :     4 file(s)<br />mlocate   :     1 file(s)<br /> root      :  1380 file(s)<br />shadow    :     2 file(s)<br /> ssh       :     1 file(s)<br />tty       :     2 file(s)<br /> utmp      :     2 file(s)<br /> Here is a listing (with line numbers) of the script:<br />      1    #!/bin/bash<br />      2    <br />     3    # array-2: Use arrays to tally file owners<br />      4    <br />     5    declare -A files file_group file_owner groups owners<br />      6    <br />     7    if [[ ! -d &quot;$1&quot; ]]; then<br />      8        echo &quot;Usage: array-2 dir&quot; &gt;&amp;2<br />     9        exit 1<br />     10    fi<br />    11    <br />     12    for i in &quot;$1&quot;/*; do<br />    13        owner=$(stat -c %U &quot;$i&quot;)<br />     14        group=$(stat -c %G &quot;$i&quot;)<br />    15        files[&quot;$i&quot;]=&quot;$i&quot;<br />     16        file_owner[&quot;$i&quot;]=$owner<br />    17        file_group[&quot;$i&quot;]=$group<br />     18        ((++owners[$owner]))<br />    19        ((++groups[$group]))<br />     20    done<br />    21    <br />     22    # List the collected files<br />    23    { for i in &quot;${files[@]}&quot;; do<br />     24        printf &quot;%-40s %-10s %-10s\n&quot; \<br />    25            &quot;$i&quot; ${file_owner[&quot;$i&quot;]} ${file_group[&quot;$i&quot;]}<br />     26    done } | sort<br /> 489<br /></p>
<hr />
<p>36 – Exotica<br />     27    echo<br />    28    <br />     29    # List owners<br />    30    echo &quot;File owners:&quot;<br />     31    { for i in &quot;${!owners[@]}&quot;; do<br />    32        printf &quot;%-10s: %5d file(s)\n&quot; &quot;$i&quot; ${owners[&quot;$i&quot;]}<br />     33    done } | sort<br />    34    echo<br />     35    <br />    36    # List groups<br />     37    echo &quot;File group owners:&quot;<br />    38    { for i in &quot;${!groups[@]}&quot;; do<br />     39        printf &quot;%-10s: %5d file(s)\n&quot; &quot;$i&quot; ${groups[&quot;$i&quot;]}<br />    40    done } | sort<br /> Let's take a look at the mechanics of this script:<br /><strong>Line 5:</strong> Associative arrays must be created with the  declare command using the -A <br />option.  In this script we create five arrays as follows:<br /> files contains the names of the files in the directory, indexed by filename<br /> file_group contains the group owner of each file, indexed by filename<br /> file_owner contains the owner of each file, indexed by file name<br /> groups contains the number of files belonging to the indexed group<br /> owners contains the number of files belonging to the indexed owner<br /><strong>Lines 7-10:</strong> Checks to see that a valid directory name was passed as a positional parame-<br />ter.  If not, a usage message is displayed and the script exits with an exit status of 1.<br /><strong>Lines 12-20:</strong>   Loop through the files in the directory.  Using the stat command, lines <br />13 and 14 extract the names of the file owner and group owner and assign the values to <br />their respective arrays (lines 16, 17) using the name of the file as the array index.  Like-<br />wise the file name itself is assigned to the files array (line 15).<br /><strong>Lines 18-19:</strong>  The total number of files belonging to the file owner and group owner are <br />incremented by one.<br /><strong>Lines 22-27:</strong>  The list of files is output.  This is done using the &quot;${array[@]}&quot; parameter <br />expansion which expands into the entire list of array element with each element treated as <br />a separate word.  This allows for the possibility that a file name may contain embedded <br />spaces.  Also note that the entire loop is enclosed in braces thus forming a group com-<br />mand.  This permits the entire output of the loop to be piped into the sort command. <br />This is necessary because the expansion of the array elements is not sorted.<br /><strong>Lines 29-40:</strong>  These two loops are similar to the file list loop except that they use the &quot;${!<br /> 490<br /></p>
<hr />
<p>Group Commands And Subshells<br /> array[@]}&quot; expansion which expands into the list of array indexes rather than the list of <br />array elements.<br /> Process Substitution<br />While they look similar and can both be used to combine streams for redirection, there is <br />an important difference between group commands and subshells. Whereas a group com-<br />mand executes all of its commands in the current shell, a subshell (as the name suggests) <br />executes its commands in a child copy of the current shell. This means that the environ-<br />ment is copied and given to a new instance of the shell. When the subshell exits, the copy <br />of the environment is lost, so any changes made to the subshell’s environment (including <br />variable assignment) is lost as well. Therefore, in most cases, unless a script requires a <br />subshell, group commands are preferable to subshells. Group commands are both faster <br />and require less memory.<br />We saw an example of the subshell environment problem in Chapter 28, when we discov-<br />ered that a read command in a pipeline does not work as we might intuitively expect. To <br />recap, if we construct a pipeline like this:<br /> echo &quot;foo&quot; | read<br />echo $REPLY<br /> The content of the REPLY variable is always empty because the read command is exe-<br />cuted in a subshell, and its copy of REPLY is destroyed when the subshell terminates.<br />Because commands in pipelines are always executed in subshells, any command that as-<br />signs variables will encounter this issue. Fortunately, the shell provides an exotic form of <br />expansion called <em>process substitution</em> that can be used to work around this problem.<br />Process substitution is expressed in two ways:<br />For processes that produce standard output:<br />&lt;(<em>list</em>)<br />or, for processes that intake standard input:<br />&gt;(<em>list</em>)<br />where <em>list</em> is a list of commands.<br />To solve our problem with read, we can employ process substitution like this:<br /> read &lt; &lt;(echo &quot;foo&quot;)<br />echo $REPLY<br /> 491<br /></p>
<hr />
<p>36 – Exotica<br /> Process substitution allows us to treat the output of a subshell as an ordinary file for pur-<br />poses of redirection. In fact, since it is a form of expansion, we can examine its real <br />value:<br /> [me@linuxbox ~]$ echo &lt;(echo &quot;foo&quot;)<br />/dev/fd/63<br /> By using echo to view the result of the expansion, we see that the output of the subshell <br />is being provided by a file named /dev/fd/63.<br />Process substitution is often used with loops containing read. Here is an example of a <br />read loop that processes the contents of a directory listing created by a subshell:<br /> #!/bin/bash <br /> # pro-sub : demo of process substitution <br /> while read attr links owner group size date time filename; do <br /> cat &lt;&lt;- EOF <br /> Filename:   $filename <br />Size:       $size <br /> Owner:      $owner <br />Group:      $group <br /> Modified:   $date $time <br />Links:      $links <br /> Attributes: $attr <br /> EOF <br /> done &lt; &lt;(ls -l | tail -n +2)<br /> The loop executes read for each line of a directory listing. The listing itself is produced <br />on the final line of the script. This line redirects the output of the process substitution into <br />the standard input of the loop. The tail command is included in the process substitution <br />pipeline to eliminate the first line of the listing, which is not needed.<br />When executed, the script produces output like this:<br /> [me@linuxbox ~]$ <strong>pro_sub | head -n 20<br /></strong>Filename:   addresses.ldif <br /> Size:       14540 <br />Owner:      me<br /> Group:      me <br />Modified:   2009-04-02 11:12 <br /> 492<br /></p>
<hr />
<p>Group Commands And Subshells<br /> Links:      1 <br />Attributes: -rw-r--r-- <br /> Filename:   bin <br /> Size:       4096 <br />Owner:      me <br /> Group:      me <br />Modified:   2009-07-10 07:31 <br /> Links:      2 <br />Attributes: drwxr-xr-x <br /> Filename:   bookmarks.html <br /> Size:       394213 <br />Owner:      me <br /> Group:      me<br /> <strong>Traps<br /></strong>In Chapter 10, we saw how programs can respond to signals. We can add this capability <br />to our scripts, too. While the scripts we have written so far have not needed this capabil-<br />ity (because they have very short execution times, and do not create temporary files), <br />larger and more complicated scripts may benefit from having a signal handling routine.<br />When we design a large, complicated script, it is important to consider what happens if <br />the user logs off or shuts down the computer while the script is running. When such an <br />event occurs, a signal will be sent to all affected processes. In turn, the programs repre-<br />senting those processes can perform actions to ensure a proper and orderly termination of <br />the program. Let’s say, for example, that we wrote a script that created a temporary file <br />during its execution. In the course of good design, we would have the script delete the file <br />when the script finishes its work. It would also be smart to have the script delete the file <br />if a signal is received indicating that the program was going to be terminated prematurely.<br /> bash  provides a mechanism for this purpose known as a  <em>trap</em>. Traps are implemented <br />with the appropriately named builtin command, trap. trap uses the following syntax:<br />trap <em>argument</em> <em>signal</em> [<em>signal</em>...]<br />where <em>argument</em> is a string which will be read and treated as a command and <em>signal</em> is the <br />specification of a signal that will trigger the execution of the interpreted command.<br />Here is a simple example:<br /> #!/bin/bash <br /> # trap-demo : simple signal handling demo <br /> 493<br /></p>
<hr />
<p>36 – Exotica<br /> trap &quot;echo 'I am ignoring you.'&quot; SIGINT SIGTERM <br /> for i in {1..5}; do <br /> echo &quot;Iteration $i of 5&quot; <br />sleep 5 <br /> done<br /> This script defines a trap that will execute an echo command each time either the SIG-<br />INT  or  SIGTERM  signal is received while the script is running. Execution of the pro-<br />gram looks like this when the user attempts to stop the script by pressing Ctrl-c:<br /> [me@linuxbox ~]$ <strong>trap-demo</strong> <br /> Iteration 1 of 5 <br />Iteration 2 of 5 <br /> I am ignoring you. <br />Iteration 3 of 5 <br /> I am ignoring you. <br />Iteration 4 of 5 <br /> Iteration 5 of 5<br /> As we can see, each time the user attempts to interrupt the program, the message is <br />printed instead.<br />Constructing a string to form a useful sequence of commands can be awkward, so it is <br />common practice to specify a shell function as the command. In this example, a separate <br />shell function is specified for each signal to be handled:<br /> #!/bin/bash <br /> # trap-demo2 : simple signal handling demo <br /> exit_on_signal_SIGINT () { <br /> echo &quot;Script interrupted.&quot; 2&gt;&amp;1 <br />exit 0 <br /> } <br /> exit_on_signal_SIGTERM () { <br /> echo &quot;Script terminated.&quot; 2&gt;&amp;1 <br /> exit 0 <br /> } <br /> trap exit_on_signal_SIGINT SIGINT <br /> trap exit_on_signal_SIGTERM SIGTERM <br /> 494<br /></p>
<hr />
<p>Traps<br /> for i in {1..5}; do <br /> echo &quot;Iteration $i of 5&quot; <br />sleep 5 <br /> done<br /> This script features two trap commands, one for each signal. Each trap, in turn, speci-<br />fies a shell function to be executed when the particular signal is received. Note the inclu-<br />sion of an exit command in each of the signal-handling functions. Without an exit, <br />the script would continue after completing the function.<br />When the user presses Ctrl-c during the execution of this script, the results look like <br />this:<br /> [me@linuxbox ~]$ <strong>trap-demo2 </strong><br /> Iteration 1 of 5 <br />Iteration 2 of 5 <br /> Script interrupted.<br /> <strong>Temporary Files<br /></strong>One reason signal handlers are included in scripts is to remove temporary files <br />that the script may create to hold intermediate results during execution. There is <br />something of an art to naming temporary files. Traditionally, programs on Unix-<br />like systems create their temporary files in the /tmp directory, a shared directory <br />intended for such files. However, since the directory is shared, this poses certain <br />security concerns, particularly for programs running with superuser privileges. <br />Aside from the obvious step of setting proper permissions for files exposed to all <br />users of the system, it is important to give temporary files non-predictable file-<br />names. This avoids an exploit known as a <em>temp race attack</em>. One way to create a <br />non-predictable (but still descriptive) name is to do something like this:<br /> tempfile=/tmp/$(basename $0).$$.$RANDOM<br />This will create a filename consisting of the program’s name, followed by its <br />process ID (PID), followed by a random integer. Note, however, that the $RAN-<br />DOM shell variable only returns a value in the range of 1-32767, which is not a <br />very large range in computer terms, so a single instance of the variable is not suf-<br />ficient to overcome a determined attacker.<br /> 495<br /></p>
<hr />
<p>36 – Exotica<br /> A better way is to use the mktemp program (not to be confused with the mktemp <br />standard library function) to both name and create the temporary file. The  mk-<br />temp program accepts a template as an argument that is used to build the file-<br />name. The template should include a series of “X” characters, which are replaced <br />by a corresponding number of random letters and numbers. The longer the series <br />of “X” characters, the longer the series of random characters. Here is an example:<br />tempfile=$(mktemp /tmp/foobar.$$.XXXXXXXXXX)<br />This creates a temporary file and assigns its name to the variable  tempfile. <br />The “X” characters in the template are replaced with random letters and numbers <br />so that the final filename (which, in this example, also includes the expanded <br />value of the special parameter $$ to obtain the PID) might be something like:<br /> /tmp/foobar.6593.UOZuvM6654<br />For scripts that are executed by regular users, it may be wise to avoid the use of <br />the  /tmp  directory and create a directory for temporary files within the user’s <br />home directory, with a line of code such as this:<br />[[ -d $HOME/tmp ]] || mkdir $HOME/tmp<br /> <strong>Asynchronous Execution<br /></strong>It is sometimes desirable to perform more than one task at the same time. We have seen <br />how all modern operating systems are at least multitasking if not multiuser as well. <br />Scripts can be constructed to behave in a multitasking fashion.<br />Usually this involves launching a script that, in turn, launches one or more child scripts <br />that perform an additional task while the parent script continues to run. However, when a <br />series of scripts runs this way, there can be problems keeping the parent and child coordi-<br />nated. That is, what if the parent or child is dependent on the other, and one script must <br />wait for the other to finish its task before finishing its own?<br /> bash has a builtin command to help manage <em>asynchronous execution</em> such as this. The <br />wait command causes a parent script to pause until a specified process (i.e., the child <br />script) finishes.<br /> wait<br />We will demonstrate the wait command first. To do this, we will need two scripts, a par-<br />ent script:<br /> 496<br /></p>
<hr />
<p>Asynchronous Execution<br /> #!/bin/bash <br /> # async-parent : Asynchronous execution demo (parent) <br /> echo &quot;Parent: starting...&quot; <br /> echo &quot;Parent: launching child script...&quot; <br />async-child &amp; <br /> pid=$! <br />echo &quot;Parent: child (PID= $pid) launched.&quot; <br /> echo &quot;Parent: continuing...&quot; <br /> sleep 2 <br /> echo &quot;Parent: pausing to wait for child to finish...&quot; <br />wait $pid <br /> echo &quot;Parent: child is finished. Continuing...&quot; <br /> echo &quot;Parent: parent is done. Exiting.&quot;<br /> and a child script:<br /> #!/bin/bash <br /> # async-child : Asynchronous execution demo (child) <br /> echo &quot;Child: child is running...&quot; <br /> sleep 5 <br />echo &quot;Child: child is done. Exiting.&quot;<br /> In this example, we see that the child script is very simple. The real action is being per-<br />formed by the parent. In the parent script, the child script is launched and put into the <br />background. The process ID of the child script is recorded by assigning the pid variable <br />with the value of the $! shell parameter, which will always contain the process ID of the <br />last job put into the background.<br />The parent script continues and then executes a wait command with the PID of the child <br />process. This causes the parent script to pause until the child script exits, at which point <br />the parent script concludes.<br />When executed, the parent and child scripts produce the following output:<br /> [me@linuxbox ~]$ <strong>async-parent <br /></strong>Parent: starting... <br /> 497<br /></p>
<hr />
<p>36 – Exotica<br /> Parent: launching child script... <br />Parent: child (PID= 6741) launched. <br /> Parent: continuing... <br />Child: child is running... <br /> Parent: pausing to wait for child to finish... <br />Child: child is done. Exiting. <br /> Parent: child is finished. Continuing... <br />Parent: parent is done. Exiting.<br /> <strong>Named Pipes<br /></strong>In most Unix-like systems, it is possible to create a special type of file called a <em>named <br />pipe</em>. Named pipes are used to create a connection between two processes and can be <br />used just like other types of files. They are not that popular, but they’re good to know <br />about.<br />There is a common programming architecture called <em>client-server</em>, which can make use of <br />a communication method such as named pipes, as well as other kinds of  <em>interprocess <br />communication</em> such as network connections.<br />The most widely used type of client-server system is, of course, a web browser communi-<br />cating with a web server. The web browser acts as the client, making requests to the <br />server and the server responds to the browser with web pages.<br />Named pipes behave like files, but actually form first-in first-out (FIFO) buffers. As with <br />ordinary (unnamed) pipes, data goes in one end and emerges out the other. With named <br />pipes, it is possible to set up something like this:<br /><em>process1</em> &gt; <em>named_pipe<br /></em>and <br /><em>process2</em> &lt; <em>named_pipe<br /></em>and it will behave as if:<br /><em>process1</em> | <em>process2</em><br /> Setting Up A Named Pipe<br />First, we must create a named pipe. This is done using the mkfifo command:<br /> [me@linuxbox ~]$ <strong>mkfifo pipe1<br /></strong>[me@linuxbox ~]$ <strong>ls -l pipe1</strong><br /> prw-r--r-- 1 me   me    0 2009-07-17 06:41 pipe1<br /> 498<br /></p>
<hr />
<p>Named Pipes<br /> Here we use mkfifo to create a named pipe called pipe1. Using ls, we examine the <br />file and see that the first letter in the attributes field is “p”, indicating that it is a named <br />pipe.<br /> Using Named Pipes<br />To demonstrate how the named pipe works, we will need two terminal windows (or alter-<br />nately, two virtual consoles). In the first terminal, we enter a simple command and redi-<br />rect its output to the named pipe:<br /> [me@linuxbox ~]$ <strong>ls -l &gt; pipe1</strong><br /> After we press the Enter key, the command will appear to hang. This is because there is <br />nothing receiving data from the other end of the pipe yet. When this occurs, it is said that <br />the pipe is <em>blocked</em>. This condition will clear once we attach a process to the other end <br />and it begins to read input from the pipe. Using the second terminal window, we enter <br />this command:<br /> [me@linuxbox ~]$ <strong>cat &lt; pipe1</strong><br /> and the directory listing produced from the first terminal window appears in the second <br />terminal as the output from the  cat  command. The  ls  command in the first terminal <br />successfully completes once it is no longer blocked.<br /> <strong>Summing Up<br /></strong>Well, we have completed our journey. The only thing left to do now is practice, practice, <br />practice. Even though we covered a lot of ground in our trek, we barely scratched the sur-<br />face as far as the command line goes. There are still thousands of command line pro-<br />grams left to be discovered and enjoyed. Start digging around in /usr/bin and you’ll <br />see! <br /> <strong>Further Reading</strong><br /> ●<br /> The “Compound Commands” section of the bash man page contains a full de-<br />scription of group command and subshell notations.<br /> ●<br /> The EXPANSION section of the bash man page contains a subsection of process <br />substitution.<br /> 499<br /></p>
<hr />
<p>36 – Exotica<br /> ●<br /> <em>The Advanced Bash-Scripting Guide</em> also has a discussion of process substitution:<br /><a href="http://tldp.org/LDP/abs/html/process-sub.html">http://tldp.org/LDP/abs/html/process-sub.html</a><br /> ●<br /> <em>Linux Journal</em> has two good articles on named pipes. The first, from September <br />1997:<br /><a href="http://www.linuxjournal.com/article/2156">http://www.linuxjournal.com/article/2156</a><br /> ●<br /> and the second, from March 2009:<br /><a href="http://www.linuxjournal.com/article/2156">http://www.linuxjournal.com/content/using-named-pipes-fifos-bash</a><br /> 500<br /></p>
<hr />
<p>Index<br /> <em><strong>Index</strong></em><br /> <strong>A</strong><br /> ASCII.............................77, 81, 221, 251, 263, 333<br /> a2ps command...................................................333<br /> bell character................................................157<br /> absolute pathnames................................................9<br /> carriage return..............................................267<br /> alias command.............................................50, 126<br /> collation order..............................251, 253, 387<br /> aliases.....................................................42, 50, 124<br /> control codes..................................77, 251, 327<br /> American National Standards Institute (see ANSI)<br /> groff output driver........................................320<br /> ............................................................................160<br /> linefeed character.........................................267<br /> American Standard Code for Information <br /> null character................................................221<br /> Interchange (see ASCII).......................................17<br /> printable characters......................................251<br /> anchors...............................................................247<br /> text..................................................................17<br /> anonymous FTP servers.....................................200<br /> aspell command.................................................299<br /> ANSI..................................................................160<br /> assembler............................................................341<br /> ANSI escape codes....................................160, 164<br /> assembly language.............................................341<br /> ANSI.SYS..........................................................160<br /> assignment operators..........................................467<br /> Apache web server.............................................118<br /> associative arrays.......................................485, 488<br /> apropos command................................................47<br /> asynchronous execution.....................................496<br /> apt-cache command...........................................169<br /> audio CDs...................................................180, 191<br /> apt-get command.............................................168p.<br /> AWK programming language....................299, 473<br /> aptitude command..............................................168<br />archiving............................................................230<br /> <strong>B</strong><br /> arithmetic expansion..............70, 75, 367, 456, 464<br /> back references........................................263, 294p.<br /> arithmetic expressions..................70, 453, 464, 467<br /> backslash escape sequences.................................78<br /> arithmetic operators.....................................70, 465<br /> backslash-escaped special characters.................156<br /> arithmetic truth tests...................................391, 464<br /> backups, incremental..........................................234<br /> arrays........................................................................<br /> basename command...........................................440<br /> append values to the end..............................483<br /> bash................................................................2, 124<br /> assigning values............................................479<br /> man page........................................................48<br /> associative............................................485, 488<br /> basic regular expressions 254, 262p., 292, 296, 306<br /> creating.........................................................478<br /> bc command.......................................................473<br /> deleting.........................................................484<br /> Berkeley Software Distribution.........................331<br /> determine number of elements.....................482<br /> bg command.......................................................116<br /> finding used subscripts.................................483<br /> binary.............................................93, 97, 341, 465<br /> index.............................................................478<br /> bit mask................................................................96<br /> multidimensional..........................................478<br /> bit operators.......................................................469<br /> reading variables into...................................400<br /> Bourne, Steve.....................................................2, 6<br /> sorting...........................................................484<br /> brace expansion......................................71, 75, 451<br /> subscript.......................................................478<br /> branching............................................................381<br /> two-dimensional...........................................478<br /> 501<br /></p>
<hr />
<p>Index<br /> break command..........................................412, 445<br /> documentation................................................44<br /> broken links..........................................................39<br /> executable program files........................42, 341<br /> BSD style............................................................111<br /> executing as another user...............................99<br /> buffering.............................................................182<br /> long options....................................................14<br /> bugs............................................................422, 424<br /> options............................................................14<br /> build environment..............................................346<br /> comments...........................128, 134, 298, 355, 424<br /> bzip2 command..................................................229<br /> Common Unix Printing System.................329, 339<br />comparison operators.........................................470<br />compiler.............................................................341<br /> <strong>C</strong><br /> compiling...........................................................340<br /> C programming language...........341, 453, 468, 471<br /> completions..........................................................81<br /> C++....................................................................341<br /> compound commands..............................................<br /> cal command..........................................................4<br /> case...............................................................429<br /> cancel command.................................................338<br /> for.................................................................450<br /> carriage return. .18, 77p., 157, 251p., 266, 298, 330<br /> if...................................................................381<br /> case compound command..................................429<br /> until...............................................................413<br /> case conversion..................................................462<br /> while.............................................................410<br /> cat command................................................57, 266<br /> (( ))................................................391, 406, 464<br /> cd command.....................................................9, 11<br /> [[ ]]........................................................389, 406<br /> CD-ROMs...............................................179p., 191<br /> compression algorithms.....................................227<br /> cdrecord command.............................................192<br /> conditional expressions..............................396, 420<br /> cdrtools...............................................................192<br /> configuration files..................................18, 21, 124<br /> character classes...26p., 248, 250p., 253, 257, 289, <br /> configure command...........................................346<br /> 299<br /> constants.............................................................366<br /> character ranges................................27, 249p., 299<br /> continue command.............................................412<br /> chgrp command..................................................103<br /> control characters.......................................157, 266<br /> child process.......................................................108<br /> control codes................................................77, 251<br /> chmod command..................................92, 105, 356<br /> control operators......................................................<br /> chown command........................................102, 105<br /> &amp;&amp;........................................................394, 406<br /> Chrome...............................................................361<br /> ||....................................................................394<br /> chronological sorting.........................................273<br /> controlling terminal............................................109<br /> cleartext......................................................200, 202<br /> COPYING..........................................................344<br /> client-server architecture....................................498<br /> copying and pasting.................................................<br /> COBOL programming language........................341<br /> in vim............................................................145<br /> collation order....................126, 251, 253, 289, 387<br /> on the command line......................................80<br /> ASCII...................................................253, 387<br /> with X Window System....................................3<br /> dictionary......................................................251<br /> coreutils package.........................45, 48p., 279, 303<br /> traditional.....................................................253<br /> counting words in a file........................................62<br /> comm command.................................................284<br /> cp command...................................28, 35, 131, 207<br /> command history..............................................3, 83<br /> CPU.........................................................108p., 340<br /> command line...........................................................<br /> cron job...............................................................211<br /> arguments.....................................................436<br /> crossword puzzles..............................................247<br /> editing.........................................................3, 79<br /> csplit command..................................................304<br /> expansion........................................................67<br /> CUPS..........................................................329, 339<br /> history.........................................................3, 84<br /> current working directory......................................8<br /> interfaces................................................xvii, 28<br /> cursor movement..................................................79<br /> command options.................................................14<br /> cut command..............................................276, 461<br /> command substitution............................73, 75, 451<br />commands................................................................<br /> arguments...............................................14, 436<br /> <strong>D</strong><br /> determining type.............................................43<br /> daemon programs.......................................108, 118<br /> 502<br /></p>
<hr />
<p>Index<br /> data compression................................................226<br /> dpkg command...................................................168<br /> data redundancy.................................................226<br /> du command...............................................269, 379<br /> data validation....................................................389<br /> Dynamic Host Configuration Protocol (DHCP) 199<br /> date command........................................................4<br />date formats........................................................273<br />dd command.......................................................190<br /> <strong>E</strong><br /> Debian................................................................166<br /> echo command.....................................67, 125, 362<br /> Debian Style (.deb)............................................167<br /> -e option..........................................................78<br /> debugging...................................................377, 424<br /> -n option.......................................................398<br /> declare command...............................................463<br /> edge and corner cases.........................................423<br /> defensive programming.............................420, 424<br /> EDITOR variable...............................................126<br /> delimiters..............................................76, 271, 274<br /> effective group ID................................................98<br /> dependencies..............................................168, 349<br /> effective user ID...........................................98, 109<br /> design..............................................................422p.<br /> elif statement......................................................388<br /> device drivers.............................................174, 341<br /> email...................................................................265<br /> device names......................................................182<br /> embedded systems.............................................341<br /> device nodes.........................................................20<br /> empty variables..................................................457<br /> df command...................................................4, 379<br /> encrypted tunnels...............................................206<br /> diction................................................................342<br /> encryption..........................................................290<br /> dictionary collation order...................................251<br /> end of file.....................................................59, 369<br /> diff command.....................................................284<br /> endless loop........................................................413<br /> Digital Restrictions Management (DRM)..........168<br /> enscript command..............................................336<br /> directories.................................................................<br /> environment.........................................99, 124, 404<br /> archiving.......................................................230<br /> aliases...........................................................124<br /> changing...........................................................9<br /> establishing...................................................127<br /> copying...........................................................28<br /> examining.....................................................124<br /> creating.....................................................28, 34<br /> login shell.....................................................127<br /> current working................................................8<br /> shell functions..............................................124<br /> deleting.....................................................31, 39<br /> shell variables...............................................124<br /> hierarchical.......................................................7<br /> startup files...................................................127<br /> home.................................................21, 90, 379<br /> subshells.......................................................491<br /> listing..............................................................13<br /> variables.......................................................124<br /> moving......................................................30, 36<br /> eqn command.....................................................318<br /> navigating.........................................................7<br /> executable files...................................................347<br /> OLD_PWD variable.....................................126<br /> executable program files..............................42, 341<br /> parent................................................................8<br /> executable programs................................................<br /> PATH variable..............................................126<br /> determining location.......................................43<br /> PWD variable...............................................127<br /> PATH variable..............................................126<br /> removing...................................................31, 39<br /> exit command.........................................5, 386, 407<br /> renaming...................................................30, 36<br /> exit status...................................................382, 386<br /> root...................................................................7<br /> expand command...............................................279<br /> shared...........................................................103<br /> expansions............................................................67<br /> sticky bit.........................................................98<br /> arithmetic..........................70, 75, 367, 456, 464<br /> synchronizing...............................................238<br /> brace.................................................71, 75, 451<br /> transferring over a network..........................238<br /> command substitution......................73, 75, 451<br /> viewing contents...............................................8<br /> delimiters........................................................76<br /> disk partitions.....................................................177<br /> errors resulting from.....................................418<br /> DISPLAY variable.............................................126<br /> history.......................................................84, 86<br /> Dolphin................................................................27<br /> parameter..........................72, 75, 365, 371, 456<br /> dos2unix command............................................267<br /> pathname..........................................68, 75, 451<br /> double quotes.......................................................75<br /> tilde...........................................................69, 75<br /> 503<br /></p>
<hr />
<p>Index<br /> word-splitting..............................................74p.<br /> owner..............................................................92<br /> expressions...............................................................<br /> permissions.....................................................89<br /> arithmetic........................70, 453, 464, 467, 479<br /> read access......................................................90<br /> conditional............................................396, 420<br /> regular...........................................................212<br /> ext3.....................................................................188<br /> removing...................................................31, 39<br /> extended regular expressions.............................254<br /> renaming...................................................30, 35<br /> Extensible Markup Language............................265<br /> rpm...............................................................166<br />shared library..................................................21<br />startup...........................................................127<br /> <strong>F</strong><br /> sticky bit.........................................................98<br /> false command...................................................383<br /> symbolic links..............................................212<br /> fdformat command.............................................190<br /> synchronizing...............................................238<br /> fdisk command...................................................185<br /> temporary.....................................................495<br /> fg command........................................................116<br /> text..................................................................17<br /> FIFO...................................................................498<br /> transferring over a network..........199, 235, 238<br /> file command.......................................................17<br /> truncating........................................................55<br /> file descriptor.......................................................56<br /> type.................................................................90<br /> file system corruption........................................182<br /> viewing contents.............................................17<br /> File Transfer Protocol (FTP)..............................199<br /> write access....................................................90<br /> filenames............................................................221<br /> filters....................................................................61<br /> case sensitive..................................................11<br /> find command.............................................211, 234<br /> embedded spaces in................................12, 260<br /> findutils package................................................225<br /> extensions.......................................................12<br /> Firefox................................................................361<br /> hidden.............................................................11<br /> firewalls..............................................................196<br /> files...........................................................................<br /> first-in first-out...................................................498<br /> access..............................................................89<br /> floppy disks........................................176, 183, 189<br /> archiving...............................................230, 236<br /> flow control..............................................................<br /> attributes.........................................................90<br /> branching......................................................381<br /> block special...................................................91<br /> case compound command............................429<br /> block special device.....................................212<br /> elif statement................................................388<br /> changing file mode.........................................92<br /> endless loop..................................................413<br /> changing owner and group owner................102<br /> for compound command...............................450<br /> character special.............................................91<br /> for loop.........................................................450<br /> character special device................................212<br /> function statement........................................374<br /> compression..................................................226<br /> if compound command.................................381<br /> configuration..................................18, 124, 264<br /> looping..........................................................409<br /> copying.....................................................28, 34<br /> menu-driven.................................................406<br /> copying over a network................................199<br /> multiple-choice decisions.............................429<br /> creating empty................................................55<br /> reading files with while and until loops.......414<br /> deb................................................................166<br /> terminating a loop.........................................412<br /> deleting.............................................31, 39, 218<br /> traps..............................................................493<br /> determining contents......................................17<br /> until loop......................................................413<br /> device nodes...................................................20<br /> while loop.....................................................410<br /> execution access.............................................90<br /> fmt command.....................................................309<br /> expressions...................................................384<br /> focus policy............................................................4<br /> finding..........................................................209<br /> fold command....................................................309<br /> hidden.............................................................11<br /> for compound command....................................450<br /> iso image...................................................191p.<br /> for loop...............................................................450<br /> listing..........................................................8, 13<br /> Foresight............................................................166<br /> mode...............................................................91<br /> Fortran programming language..................341, 453<br /> moving......................................................30, 35<br /> free command.................................................5, 181<br /> 504<br /></p>
<hr />
<p>Index<br /> Free Software Foundation............................xix, xxi<br /> here strings.........................................................404<br /> fsck command....................................................189<br /> hexadecimal.................................................93, 465<br /> ftp command..............................199, 207, 342, 370<br /> hidden files.....................................................11, 69<br /> FTP servers.................................................200, 370<br /> hierarchical directory structure..............................7<br /> FUNCNAME variable.......................................441<br /> high-level programming languages....................341<br /> function statement..............................................374<br /> history......................................................................<br /> expansion..................................................84, 86<br />searching.........................................................84<br /> <strong>G</strong><br /> history command..................................................84<br /> gcc......................................................................342<br /> home directories...................................................21<br /> gedit command...........................................114, 131<br /> root account....................................................22<br /> genisoimage command.......................................191<br /> /etc/passwd.....................................................90<br /> Gentoo................................................................166<br /> home directory...........................8, 11, 69, 100, 126<br /> getopts command...............................................449<br /> HOME variable..................................................126<br /> Ghostscript.........................................................329<br /> hostname............................................................157<br /> gid........................................................................89<br /> HTML........................265, 299, 319, 361, 371, 373<br /> global variables..................................................376<br /> Hypertext Markup Language.............................265<br /> globbing...............................................................26<br />GNOME...............................2, 27, 40, 95, 131, 208<br />gnome-terminal......................................................2<br /> <strong>I</strong><br /> GNU binutils package........................................452<br /> I/O redirection (see redirection)...........................53<br /> GNU C Compiler...............................................342<br /> id command..........................................................89<br /> GNU coreutils package...............45, 48p., 279, 303<br /> IDE.....................................................................183<br /> GNU findutils package......................................225<br /> if compound command......................129, 418, 429<br /> GNU Project..........14, xix, xxi, 225, 303, 342, 344<br /> IFS variable........................................................402<br /> info command.................................................48<br /> IMCP ECHO_REQUEST..................................196<br /> GNU/Linux..................................................xix, xxi<br /> incremental backups...........................................234<br /> graphical user interfaces....................................xvii<br /> info files...............................................................49<br /> grep command......................................62, 243, 403<br /> init......................................................................108<br /> groff....................................................................318<br /> init scripts...........................................................108<br /> group commands................................................487<br /> inodes...................................................................37<br /> groups...................................................................89<br /> INSTALL...........................................................344<br /> effective group ID..........................................98<br /> installation wizard..............................................167<br /> gid...................................................................89<br /> integers.....................................................................<br /> primary group ID............................................89<br /> arithmetic................................................70, 473<br /> setgid..............................................................98<br /> division...................................................71, 466<br /> GUI................................3, xvii, 27, 40, 79, 95, 127<br /> expressions...................................................388<br /> gunzip command................................................227<br /> interactivity........................................................397<br /> gzip command..............................................50, 227<br /> Internal Field Separator......................................402<br />interpreted languages.........................................341<br />interpreted programs..........................................342<br /> <strong>H</strong><br /> interpreter...........................................................341<br /> hard disks...........................................................176<br /> iso images........................................................191p.<br /> hard links..................................................24, 33, 37<br /> iso9660.......................................................180, 192<br /> creating...........................................................37<br />listing..............................................................38<br /> head command.....................................................63<br /> <strong>J</strong><br /> header files.........................................................345<br /> job control..........................................................115<br /> hello world program...........................................355<br /> job numbers........................................................115<br /> help command......................................................44<br /> jobspec................................................................116<br /> here documents..................................................369<br /> join command.....................................................281<br /> 505<br /></p>
<hr />
<p>Index<br /> Joliet extensions.................................................192<br /> Linux Filesystem Hierarchy Standard. . .19, 24, 358<br /> Joy, Bill..............................................................137<br /> Linux kernel......xvi, xixp., 46, 108, 118, 174, 183, <br />287, 350<br /> device drivers...............................................174<br /> <strong>K</strong><br /> literal characters.................................................245<br /> kate command....................................................131<br /> live CDs..............................................................xix<br /> KDE.....................................2, 27, 40, 95, 131, 208<br /> ln command....................................................33, 37<br /> kedit command...................................................131<br /> local variables....................................................376<br /> kernel...xvi, xixp., 46, 108, 118, 174, 183, 287, 350<br /> locale..........................................251, 253, 289, 387<br /> key fields............................................................271<br /> locale command.................................................253<br /> kill command......................................................117<br /> localhost.............................................................203<br /> killall command.................................................120<br /> locate command.........................................209, 261<br /> killing text............................................................80<br /> logical errors......................................................420<br /> Knuth, Donald....................................................318<br /> logical operations...............................................392<br /> Konqueror..............................................27, 95, 208<br /> logical operators.................................................214<br /> konsole...................................................................2<br /> logical relationships...................................214, 218<br /> kwrite command.........................................114, 131<br /> login prompt...................................................5, 201<br />login shell...............................................90, 99, 127<br /> <strong>L</strong><br /> long options..........................................................14<br /> LANG variable...................................126, 251, 253<br /> loopback interface..............................................199<br /> less command.................................17, 60, 238, 261<br /> looping...............................................................409<br /> lftp command.....................................................202<br /> loops...................................420, 466, 469, 486, 492<br /> libraries..............................................................341<br /> lossless compression..........................................227<br /> LibreOffice Writer..............................................xxi<br /> lossy compression..............................................227<br /> line continuation character.................................359<br /> lowercase to uppercase conversion....................463<br /> line editors..........................................................137<br /> lp command........................................................332<br /> line-continuation character.................................298<br /> lpq command......................................................337<br /> linker..................................................................341<br /> lpr command......................................................331<br /> linking................................................................341<br /> lprm command...................................................338<br /> links..........................................................................<br /> lpstat command..................................................336<br /> broken.............................................................39<br /> ls command......................................................8, 13<br /> creating...........................................................33<br /> long format.....................................................16<br /> hard...........................................................24, 33<br /> viewing file attributes.....................................90<br /> symbolic...................................................23, 34<br /> Lukyanov, Alexander.........................................202<br /> Linux community...............................................166<br /> LVM (Logical Volume Manager)...............176, 179<br /> Linux distributions.............................................166<br /> CentOS.................................................167, 336<br /> <strong>M</strong><br /> Debian...............................................166p., 340<br /> machine language...............................................340<br /> Fedora......................................xix, 89, 167, 336<br /> maintenance...............................358, 362, 364, 372<br /> Foresight.......................................................166<br /> make command..................................................347<br /> Gentoo..........................................................166<br /> Makefile.............................................................347<br /> Linspire.........................................................167<br /> man command......................................................45<br /> Mandriva......................................................167<br /> man pages.....................................................45, 319<br /> OpenSUSE............................................xix, 167<br /> markup languages......................................265, 319<br /> packaging systems........................................166<br /> memory....................................................................<br /> PCLinuxOS..................................................167<br /> assigned to each process...............................109<br /> Red Hat Enterprise Linux.............................167<br /> displaying free..................................................5<br /> Slackware.....................................................166<br /> Resident Set Size..........................................111<br /> Ubuntu........................................xix, 166p., 336<br /> segmentation violation..................................119<br /> Xandros........................................................167<br /> usage.............................................................111<br /> 506<br /></p>
<hr />
<p>Index<br /> viewing usage...............................................121<br /> Virtual Private Network................................206<br /> virtual............................................................111<br /> newline character...............................................157<br /> menu-driven programs.......................................406<br /> newlines...............................................................76<br /> meta key...............................................................81<br /> NEWS................................................................344<br /> meta sequences...................................................246<br /> nl command........................................................305<br /> metacharacters....................................................246<br /> nroff command...................................................318<br /> metadata.....................................................167, 169<br /> null character......................................................221<br /> mkdir command.............................................28, 34<br /> number bases......................................................465<br /> mkfifo command................................................498<br />mkfs command...........................................188, 190<br />mkisofs command..............................................192<br /> <strong>O</strong><br /> mktemp command..............................................496<br /> octal......................................................93, 465, 481<br /> mnemonics.........................................................341<br /> Ogg Vorbis.........................................................104<br /> modal editor.......................................................139<br /> OLD_PWD variable...........................................126<br /> monospaced fonts...............................................329<br /> OpenOffice.org Writer................................18, xxp.<br /> Moolenaar, Bram................................................137<br /> OpenSSH............................................................203<br /> more command.....................................................19<br /> operators...................................................................<br /> mount command.........................................178, 192<br /> arithmetic................................................70, 465<br /> mount points.........................................21, 178, 180<br /> assignment....................................................467<br /> mounting............................................................177<br /> binary............................................................419<br /> MP3....................................................................104<br /> comparison...................................................470<br /> multi-user systems...............................................88<br /> ternary...........................................................471<br /> multiple-choice decisions...................................429<br /> owning files..........................................................89<br /> multitasking..........................................88, 108, 496<br />mv command..................................................30, 35<br /> <strong>P<br /></strong>package files.......................................................167<br /> <strong>N</strong><br /> package maintainers...........................................167<br /> named pipes.......................................................498<br /> package management.........................................166<br /> nano command...................................................136<br /> deb................................................................166<br /> Nautilus..................................................27, 95, 208<br /> Debian Style (.deb).......................................167<br /> netstat command................................................198<br /> finding packages...........................................169<br /> networking.........................................................195<br /> high-level tools.............................................168<br /> anonymous FTP servers...............................200<br /> installing packages.......................................169<br /> default route..................................................199<br /> low-level tools..............................................168<br /> Dynamic Host Configuration Protocol (DHCP)<br /> package repositories.....................................167<br /> ......................................................................199<br /> Red Hat Style (.rpm)....................................167<br /> encrypted tunnels..........................................206<br /> removing packages.......................................170<br /> examine network settings and statistics.......198<br /> RPM.............................................................166<br /> File Transfer Protocol (FTP)........................199<br /> updating packages........................................171<br /> firewalls........................................................196<br /> packaging systems.............................................166<br /> FTP servers...................................................200<br /> page description language..................265, 320, 328<br /> Local Area Network.....................................199<br /> PAGER variable.................................................126<br /> loopback interface........................................199<br /> pagers...................................................................19<br /> man in the middle attacks.............................203<br /> parameter expansion..............................72, 75, 456<br /> routers...........................................................198<br /> parent directory......................................................8<br /> secure communication with remote hosts....203<br /> parent process.....................................................108<br /> testing if a host is alive.................................196<br /> passwd command...............................................106<br /> tracing the route to a host.............................197<br /> passwords...........................................................106<br /> transferring files...........................................238<br /> paste command...................................................280<br /> transporting files...........................................199<br /> PATA..................................................................183<br /> 507<br /></p>
<hr />
<p>Index<br /> patch command..................................................287<br /> viewing jobs.................................................337<br /> patches................................................................285<br /> process ID..........................................................109<br /> PATH variable............................126, 129, 356, 374<br /> process substitution............................................491<br /> pathname expansion...............................68, 75, 451<br /> processes............................................................108<br /> pathnames..........................................................260<br /> background...................................................115<br /> absolute.............................................................9<br /> child..............................................................108<br /> completion......................................................81<br /> controlling.....................................................113<br /> relative..............................................................9<br /> foreground....................................................115<br /> PDF............................................................321, 331<br /> interrupting...................................................114<br /> Perl programming language.42, 243, 299, 341, 473<br /> job control.....................................................115<br /> permissions........................................................354<br /> killing............................................................117<br /> PHP programming language..............................341<br /> nice...............................................................110<br /> ping command....................................................196<br /> parent............................................................108<br /> pipelines...............................................60, 404, 491<br /> PID...............................................................109<br /> in command substitution................................73<br /> process ID.....................................................109<br /> portability...........................................346, 380, 394<br /> SIGINT.........................................................494<br /> portable..............................................................380<br /> signals...........................................................117<br /> Portable Document Format........................321, 331<br /> SIGTERM....................................................494<br /> Portable Operating System Interface.................255<br /> sleeping.........................................................110<br /> positional parameters......................436, 457p., 460<br /> state...............................................................110<br /> POSIX.....................................192, 251, 254p., 394<br /> stopping........................................................116<br /> character classes.....26p., 250p., 253, 257, 289, <br /> viewing.................................................109, 111<br /> 299<br /> zombie..........................................................110<br /> PostScript...........................265, 320, 328, 333, 338<br /> production use....................................................422<br /> pr command...............................................313, 329<br /> programmable completion...................................83<br /> primary group ID.................................................89<br /> ps command.......................................................109<br /> printable characters............................................251<br /> PS1 variable...............................................126, 156<br /> printenv command.......................................73, 124<br /> PS2 variable.......................................................363<br /> printer buffers.....................................................181<br /> ps2pdf command................................................321<br /> printers.......................................................181, 183<br /> PS4 variable.......................................................426<br /> buffering output............................................181<br /> pseudocode.................................................381, 409<br /> control codes................................................327<br /> pstree command.................................................121<br /> daisy-wheel...................................................327<br /> PuTTY................................................................208<br /> device names................................................183<br /> pwd command........................................................8<br /> drivers...........................................................329<br /> PWD variable.....................................................127<br /> graphical.......................................................328<br /> Python programming language..........................341<br /> impact...........................................................327<br />laser..............................................................328<br /> printf command..........................................314, 455<br /> <strong>Q</strong><br /> printing.....................................................................<br /> quoting.................................................................74<br /> determining system status............................336<br /> double quotes..................................................75<br /> history of......................................................326<br /> escape character..............................................77<br /> Internet Printing Protocol.............................337<br /> missing quote................................................417<br /> monospaced fonts.........................................327<br /> single quotes...................................................76<br /> preparing text................................................329<br />pretty.............................................................333<br /> <strong>R</strong><br /> print queues..................................................336<br /> RAID (Redundant Array of Independent Disks)<br /> proportional fonts.........................................328<br /> ............................................................................176<br /> queue............................................................337<br /> raster image processor........................................329<br /> spooling........................................................336<br /> read command....................398, 408, 414, 422, 491<br /> terminate print jobs.......................................338<br /> 508<br /></p>
<hr />
<p>Index<br /> Readline...............................................................79<br /> Schilling,  Jorg...................................................192<br /> README.....................................................49, 344<br /> scp command.....................................................207<br /> redirection................................................................<br /> script command....................................................86<br /> blocked pipe.................................................499<br /> scripting languages.......................................42, 341<br /> group commands and subshells....................487<br /> sdiff command....................................................304<br /> here documents.............................................369<br /> searching a file for patterns..................................62<br /> here strings...................................................404<br /> searching history..................................................84<br /> standard error..................................................55<br /> Secure Shell.......................................................203<br /> standard input.........................................57, 370<br /> sed command.....................................290, 322, 461<br /> standard output...............................................54<br /> set command..............................................124, 425<br /> redirection operators................................................<br /> setgid....................................................................98<br /> &amp;&gt;...................................................................57<br /> setuid............................................................98, 385<br /> &amp;&gt;&gt;................................................................57<br /> Seward, Julian....................................................229<br /> &lt;......................................................................59<br /> sftp command.....................................................207<br /> &lt;(list)............................................................491<br /> shared libraries.............................................21, 168<br /> &lt;&lt;..............................................................369p.<br /> shebang......................................................355, 360<br /> &lt;&lt;-................................................................370<br /> shell builtins.........................................................42<br /> &lt;&lt;&lt;...............................................................404<br /> shell functions..............................42, 124, 374, 440<br /> &gt;......................................................................54<br /> shell prompts 2, 9, 85, 100, 114, 126, 156, 204, 363<br /> &gt;(list)............................................................491<br /> shell scripts.........................................................354<br /> &gt;&gt;...................................................................55<br /> SHELL variable.................................................126<br /> |.......................................................................60<br /> shell variables.....................................................124<br /> regular expressions...............62, 243, 295, 389, 403<br /> shift command............................................439, 444<br /> anchors.........................................................247<br /> SIGINT..............................................................494<br /> back references..................................263, 294p.<br /> signals................................................................493<br /> basic...........................254, 262p., 292, 296, 306<br /> single quotes.........................................................76<br /> extended.......................................................254<br /> Slackware...........................................................166<br /> relational databases............................................281<br /> sleep command...................................................411<br /> relative pathnames.................................................9<br /> soft link................................................................23<br /> release early, release often.................................422<br /> sort command...............................................61, 267<br /> removing duplicate lines in a file.........................61<br /> sort keys.............................................................271<br /> REPLY variable..........................................398, 491<br /> source code..............................166p., 174, 265, 340<br /> report generator..................................................361<br /> source command........................................135, 357<br /> repositories.........................................................167<br /> source tree..........................................................343<br /> return command.........................................375, 386<br /> special parameters......................................441, 458<br /> reusable..............................................................380<br /> split command....................................................304<br /> RIP.....................................................................329<br /> SSH....................................................................203<br /> rlogin command.................................................202<br /> ssh command..............................................203, 235<br /> rm command........................................................31<br /> ssh program..........................................................88<br /> Rock Ridge extensions.......................................192<br /> Stallman, Richard.........xvi, xix, xxi, 131, 255, 342<br /> roff......................................................................318<br /> standard error..............................................53p., 56<br /> ROT13 encoding................................................290<br /> disposing of....................................................57<br /> RPM...................................................................166<br /> redirecting to a file.........................................55<br /> rpm command....................................................169<br /> standard input.......................................53, 370, 398<br /> rsync command..................................................238<br /> redirecting.......................................................57<br /> rsync remote-update protocol............................238<br /> standard output.....................................................53<br /> Ruby programming language.............................341<br /> appending to a file..........................................55<br />disposing of....................................................57<br />redirecting standard error to...........................56<br /> <strong>S</strong><br /> redirecting to a file.........................................54<br /> scalar variables...................................................478<br /> startup files.........................................................127<br /> 509<br /></p>
<hr />
<p>Index<br /> stat command.....................................................223<br /> targets.................................................................347<br /> sticky bit...............................................................98<br /> Task Manager.....................................................113<br /> storage devices...................................................176<br /> Tatham, Simon...................................................208<br /> audio CDs.............................................180, 191<br /> tbl command...............................................318, 322<br /> CD-ROMs.........................................179p., 191<br /> tee command........................................................64<br /> creating file systems.....................................185<br /> Teletype..............................................................109<br /> device names................................................182<br /> telnet command..................................................202<br /> disk partitions...............................................177<br /> TERM variable...................................................127<br /> FAT32...........................................................185<br /> terminal emulators.................................................2<br /> floppy disks..........................................183, 189<br /> terminal sessions......................................................<br /> formatting.....................................................185<br /> controlling terminal......................................109<br /> LVM (Logical Volume Manager).................179<br /> effect of .bashrc............................................357<br /> mount points.........................................178, 180<br /> environment....................................................99<br /> partitions.......................................................185<br /> exiting...............................................................5<br /> reading and writing directly.........................190<br /> login shell...............................................99, 127<br /> repairing file systems...................................189<br /> TERM variable.............................................127<br /> unmounting...................................................181<br /> using named pipes........................................499<br /> USB flash drives...........................................190<br /> virtual...............................................................5<br /> stream editor.......................................................290<br /> with remote systems.......................................88<br /> strings.......................................................................<br /> terminals..............................81, 87p., 160, 318, 327<br /> expressions...................................................387<br /> ternary operator..................................................471<br /> extract a portion of.......................................459<br /> test cases.............................................................423<br /> length of........................................................459<br /> test command.............................384, 389, 410, 419<br /> perform search and replace upon.................461<br /> test coverage.......................................................423<br /> remove leading portion of............................460<br /> testing..............................................................422p.<br /> remove trailing portion of............................460<br /> TEX....................................................................318<br /> ${parameter:offset:length}...........................459<br /> text........................................................................17<br /> ${parameter:offset}......................................459<br /> adjusting line length.....................................309<br /> strings command................................................452<br /> ASCII.............................................................17<br /> stubs...........................................................377, 422<br /> carriage return..............................................267<br /> style....................................................................345<br /> comparing.....................................................283<br /> su command.........................................................99<br /> converting MS-DOS to Unix........................289<br /> subshells.....................................................404, 487<br /> counting words...............................................62<br /> sudo command.............................................99, 101<br /> cutting...........................................................276<br /> Sun Microsystems..............................................137<br /> deleting duplicate lines.................................275<br /> superuser..........................................2, 90, 100, 120<br /> deleting multiple blank lines........................267<br /> symbolic links..........................................23, 34, 38<br /> detecting differences.....................................284<br /> creating.....................................................38, 40<br /> displaying common lines..............................284<br /> listing..............................................................38<br /> displaying control characters........................266<br /> symlink.................................................................23<br /> DOS format..................................................267<br /> syntax errors.......................................................416<br /> EDITOR variable.........................................126<br /> syntax highlighting.....................................354, 359<br /> editors...................................................130, 264<br />expanding tabs..............................................279<br />files.................................................................17<br /> <strong>T</strong><br /> filtering...........................................................61<br /> tables..................................................................281<br /> folding..........................................................309<br /> tabular data.................................................271, 317<br /> formatting.....................................................305<br /> tail command........................................................63<br /> formatting for typesetters.............................318<br /> tape archive........................................................230<br /> formatting tables...........................................322<br /> tar command.......................................................230<br /> joining...........................................................281<br /> tarballs................................................................343<br /> linefeed character.........................................267<br /> 510<br /></p>
<hr />
<p>Index<br /> lowercase to uppercase conversion..............289<br /> <strong>U</strong><br /> numbering lines....................................267, 305<br /> Ubuntu..................................89, 102, 166, 250, 357<br /> paginating.....................................................313<br /> umask command..........................................96, 105<br /> pasting..........................................................280<br /> umount command...............................................181<br /> preparing for printing...................................329<br /> unalias command.................................................51<br /> removing duplicate lines................................61<br /> unary operator expected.....................................419<br /> rendering in PostScript.................................320<br /> unary operators...................................................465<br /> ROT13 encoded............................................290<br /> unexpand command...........................................279<br /> searching for patterns.....................................62<br /> unexpected token...............................................418<br /> sorting.....................................................61, 267<br /> uniq command..............................................61, 275<br /> spell checking...............................................299<br /> Unix...................................................................xvii<br /> substituting...................................................294<br /> Unix System V...................................................331<br /> substituting tabs for spaces...........................279<br /> unix2dos command............................................267<br /> tab-delimited.................................................278<br /> unset command..................................................484<br /> transliterating characters..............................288<br /> until compound command..................................413<br /> Unix format..................................................267<br /> until loop............................................................413<br /> viewing with less......................................17, 60<br /> unzip command..................................................236<br /> text editors..........................................130, 264, 288<br /> updatedb command............................................211<br /> emacs............................................................131<br /> upstream providers.............................................167<br /> for writing shell scripts.................................354<br /> uptime................................................................373<br /> gedit......................................................131, 354<br /> uptime command................................................379<br /> interactive.....................................................288<br /> USB flash drives........................................176, 190<br /> kate.......................................................131, 354<br /> Usenet................................................................290<br /> kedit..............................................................131<br /> USER variable...........................................125, 127<br /> kwrite............................................................131<br /> users.........................................................................<br /> line................................................................137<br /> accounts..........................................................89<br /> nano......................................................131, 136<br /> changing identity............................................99<br /> pico...............................................................131<br /> changing passwords......................................106<br /> stream...........................................................290<br /> effective user ID.....................................98, 109<br /> syntax highlighting...............................354, 359<br /> home directory................................................90<br /> vi...................................................................131<br /> identity............................................................89<br /> vim................................................131, 354, 359<br /> password.........................................................90<br /> visual............................................................137<br /> setting default permissions.............................96<br /> tilde expansion...............................................69, 75<br /> setuid..............................................................98<br /> tload command...................................................121<br /> superuser..................................90, 92, 98p., 107<br /> top command......................................................111<br /> /etc/passwd.....................................................90<br /> top-down design.................................................372<br /> /etc/shadow.....................................................90<br /> Torvalds, Linus............................................xvi, xxi<br />touch command.......................222p., 239, 349, 446<br />tr command........................................................288<br /> <strong>V</strong><br /> traceroute command...........................................197<br /> validating input..................................................404<br /> tracing................................................................425<br /> variables...............................................72, 364, 456<br /> transliterating characters....................................288<br /> assigning values....................................367, 467<br /> traps....................................................................493<br /> constants.......................................................366<br /> troff command....................................................318<br /> declaring...............................................364, 367<br /> true command.....................................................383<br /> environment..................................................124<br /> TTY....................................................................109<br /> global............................................................376<br /> type command......................................................43<br /> local..............................................................376<br /> typesetters..................................................318, 328<br /> names....................................................366, 459<br /> TZ variable.........................................................127<br /> scalar.............................................................478<br />shell..............................................................124<br /> 511<br /></p>
<hr />
<p>Index<br /> vfat.....................................................................188<br /> .bash_login.........................................................127<br /> vi command........................................................136<br /> .bash_profile.......................................................127<br /> vim command.............................................263, 359<br /> .bashrc................................128, 130, 357, 380, 441<br /> virtual consoles......................................................5<br /> .profile................................................................127<br /> Virtual Private Network.....................................206<br /> .ssh/known_hosts...............................................205<br /> virtual terminals.....................................................5<br />visual editors......................................................137<br />vmstat command................................................121<br /> <strong>(<br /></strong>(( )) compound command...........................464, 470<br /> <strong>W<br /></strong>wait command....................................................496<br /> <strong>[</strong><br /> wc command........................................................62<br /> [ command.........................................................418<br /> web pages...........................................................265<br />wget command...................................................202<br /> <strong>/</strong><br /> What You See Is What You Get.........................327<br /> /............................................................................20<br /> whatis command..................................................47<br /> /bin.......................................................................20<br /> which command.............................................43, 73<br /> /boot.....................................................................20<br /> while compound command................................410<br /> /boot/grub/grub.conf............................................20<br /> wildcards..................................26, 58, 67, 243, 250<br /> /boot/vmlinuz.......................................................20<br /> wodim command................................................193<br /> /dev.......................................................................20<br /> word-splitting..................................................74pp.<br /> /dev/cdrom.........................................................183<br /> world....................................................................89<br /> /dev/dvd..............................................................183<br /> WYSIWYG........................................................327<br /> /dev/floppy.........................................................183<br />/dev/null...............................................................57<br /> <strong>X</strong><br /> /etc........................................................................21<br /> X Window System...................................3, 88, 206<br /> /etc/bash.bashrc..................................................128<br /> xargs command..................................................220<br /> /etc/crontab...........................................................21<br /> xload command..................................................121<br /> /etc/fstab...............................................21, 177, 189<br /> xlogo command..................................................114<br /> /etc/group.............................................................90<br /> XML...................................................................265<br /> /etc/passwd.............................21, 90, 274, 279, 403<br />/etc/profile..................................................127, 129<br />/etc/shadow..........................................................90<br /> <strong>Y</strong><br /> /etc/sudoers..........................................................99<br /> yanking text..........................................................80<br /> /lib........................................................................21<br /> yum command....................................................169<br /> /lost+found...........................................................21<br />/media...................................................................21<br />/mnt......................................................................21<br /> <strong>Z</strong><br /> /opt.......................................................................21<br /> zgrep command..................................................263<br /> /proc.....................................................................22<br /> zip command......................................................236<br /> /root..............................................................22, 100<br /> zless command.....................................................50<br /> /sbin......................................................................22<br />/tmp..............................................................22, 496<br /> <strong>-</strong><br /> /usr........................................................................22<br /> --help option.........................................................45<br /> /usr/bin.................................................................22<br />/usr/lib..................................................................22<br />/usr/local...............................................................22<br /> <strong>.</strong><br /> /usr/local/bin........................................22, 350, 358<br /> ./configure..........................................................346<br /> /usr/local/sbin.....................................................358<br /> .bash_history........................................................83<br /> /usr/sbin................................................................22<br /> 512<br /></p>
<hr />
<p>Index<br /> /usr/share..............................................................22<br /> ${parameter:-word}...........................................457<br /> /usr/share/dict.....................................................247<br /> ${parameter:?word}...........................................458<br /> /usr/share/doc.................................................22, 49<br /> ${parameter:+word}..........................................458<br /> /var.......................................................................23<br /> ${parameter:=word}..........................................457<br /> /var/log.................................................................23<br /> ${parameter//pattern/string}..............................461<br /> /var/log/messages...................................23, 64, 183<br /> ${parameter/#pattern/string}.............................461<br /> /var/log/syslog..............................................64, 183<br /> ${parameter/%pattern/string}............................461<br />${parameter/pattern/string}...............................461<br />${parameter##pattern}.......................................460<br /> <strong>$</strong><br /> ${parameter#pattern}.........................................460<br /> $!................................................................442, 497<br /> ${parameter%%pattern}....................................460<br /> $((expression))...................................................464<br /> ${parameter%pattern}.......................................460<br /> ${!array[@]}......................................................483<br /> ${parameter^}....................................................463<br /> ${!array[*]}........................................................483<br /> ${parameter^^}..................................................463<br /> ${!prefix@}.......................................................459<br /> $@..............................................................441, 449<br /> ${!prefix*}.........................................................459<br /> $*................................................................441, 449<br /> ${#parameter}....................................................459<br /> $#........................................................................437<br /> ${parameter,,}....................................................463<br /> $0........................................................................441<br /> ${parameter,}.....................................................463<br /> 513<br /></p>
<hr />
<h1>Document Outline</h1>
<ul>
<li><a href="news.html#18">Introduction</a>
<ul>
<li><a href="news.html#18">Why Use The Command Line?</a></li>
<li><a href="news.html#19">What This Book Is About</a></li>
<li><a href="news.html#19">Who Should Read This Book</a></li>
<li><a href="news.html#20">What's In This Book</a></li>
<li><a href="news.html#20">How To Read This Book</a>
<ul>
<li><a href="news.html#21">Prerequisites</a></li>
</ul></li>
<li><a href="news.html#22">Acknowledgments</a></li>
<li><a href="news.html#22">Your Feedback Is Needed!</a></li>
<li><a href="news.html#23">What's New In The Second Internet Edition</a></li>
<li><a href="news.html#23">Further Reading</a></li>
<li><a href="news.html#23">Colophon</a></li>
</ul></li>
<li><a href="news.html#25">Part 1 – Learning The Shell</a>
<ul>
<li><a href="news.html#26">1 – What Is The Shell?</a>
<ul>
<li><a href="news.html#26">Terminal Emulators</a></li>
<li><a href="news.html#26">Your First Keystrokes</a>
<ul>
<li><a href="news.html#27">Command History</a></li>
<li><a href="news.html#27">Cursor Movement</a></li>
</ul></li>
<li><a href="news.html#28">Try Some Simple Commands</a></li>
<li><a href="news.html#29">Ending A Terminal Session</a></li>
<li><a href="news.html#29">Summing Up</a></li>
<li><a href="news.html#30">Further Reading</a></li>
</ul></li>
<li><a href="news.html#31">2 – Navigation</a>
<ul>
<li><a href="news.html#31">Understanding The File System Tree</a></li>
<li><a href="news.html#31">The Current Working Directory</a></li>
<li><a href="news.html#32">Listing The Contents Of A Directory</a></li>
<li><a href="news.html#33">Changing The Current Working Directory</a>
<ul>
<li><a href="news.html#33">Absolute Pathnames</a></li>
<li><a href="news.html#33">Relative Pathnames</a></li>
<li><a href="news.html#35">Some Helpful Shortcuts</a></li>
</ul></li>
<li><a href="news.html#36">Summing Up</a></li>
</ul></li>
<li><a href="news.html#37">3 – Exploring The System</a>
<ul>
<li><a href="news.html#37">More Fun With ls</a>
<ul>
<li><a href="news.html#38">Options And Arguments</a></li>
<li><a href="news.html#40">A Longer Look At Long Format</a></li>
</ul></li>
<li><a href="news.html#41">Determining A File's Type With file</a></li>
<li><a href="news.html#41">Viewing File Contents With less</a></li>
<li><a href="news.html#43">A Guided Tour</a></li>
<li><a href="news.html#47">Symbolic Links</a></li>
<li><a href="news.html#48">Hard Links</a></li>
<li><a href="news.html#48">Summing Up</a></li>
<li><a href="news.html#48">Further Reading</a></li>
</ul></li>
<li><a href="news.html#49">4 – Manipulating Files And Directories</a>
<ul>
<li><a href="news.html#49">Wildcards</a></li>
<li><a href="news.html#52">mkdir – Create Directories</a></li>
<li><a href="news.html#52">cp – Copy Files And Directories</a>
<ul>
<li><a href="news.html#53">Useful Options And Examples</a></li>
</ul></li>
<li><a href="news.html#54">mv – Move And Rename Files</a>
<ul>
<li><a href="news.html#54">Useful Options And Examples</a></li>
</ul></li>
<li><a href="news.html#55">rm – Remove Files And Directories</a>
<ul>
<li><a href="news.html#55">Useful Options And Examples</a></li>
</ul></li>
<li><a href="news.html#57">ln – Create Links</a>
<ul>
<li><a href="news.html#57">Hard Links</a></li>
<li><a href="news.html#57">Symbolic Links</a></li>
</ul></li>
<li><a href="news.html#58">Let's Build A Playground</a>
<ul>
<li><a href="news.html#58">Creating Directories</a></li>
<li><a href="news.html#58">Copying Files</a></li>
<li><a href="news.html#59">Moving And Renaming Files</a></li>
<li><a href="news.html#61">Creating Hard Links</a></li>
<li><a href="news.html#62">Creating Symbolic Links</a></li>
<li><a href="news.html#63">Removing Files And Directories</a></li>
</ul></li>
<li><a href="news.html#65">Summing Up</a></li>
<li><a href="news.html#65">Further Reading</a></li>
</ul></li>
<li><a href="news.html#66">5 – Working With Commands</a>
<ul>
<li><a href="news.html#66">What Exactly Are Commands?</a></li>
<li><a href="news.html#67">Identifying Commands</a>
<ul>
<li><a href="news.html#67">type – Display A Command's Type</a></li>
<li><a href="news.html#67">which – Display An Executable's Location</a></li>
</ul></li>
<li><a href="news.html#68">Getting A Command's Documentation</a>
<ul>
<li><a href="news.html#68">help – Get Help For Shell Builtins</a></li>
<li><a href="news.html#69">--help – Display Usage Information</a></li>
<li><a href="news.html#69">man – Display A Program's Manual Page</a></li>
<li><a href="news.html#71">apropos – Display Appropriate Commands</a></li>
<li><a href="news.html#71">whatis – Display A Very Brief Description Of A Command</a></li>
<li><a href="news.html#72">info – Display A Program's Info Entry</a></li>
<li><a href="news.html#73">README And Other Program Documentation Files</a></li>
</ul></li>
<li><a href="news.html#74">Creating Your Own Commands With alias</a></li>
<li><a href="news.html#76">Summing Up</a></li>
<li><a href="news.html#76">Further Reading</a></li>
</ul></li>
<li><a href="news.html#77">6 – Redirection</a>
<ul>
<li><a href="news.html#77">Standard Input, Output, And Error</a></li>
<li><a href="news.html#78">Redirecting Standard Output</a></li>
<li><a href="news.html#79">Redirecting Standard Error</a>
<ul>
<li><a href="news.html#80">Redirecting Standard Output And Standard Error To One File</a></li>
<li><a href="news.html#81">Disposing Of Unwanted Output</a></li>
</ul></li>
<li><a href="news.html#81">Redirecting Standard Input</a>
<ul>
<li><a href="news.html#81">cat – Concatenate Files</a></li>
</ul></li>
<li><a href="news.html#83">Pipelines</a>
<ul>
<li><a href="news.html#85">Filters</a></li>
<li><a href="news.html#85">uniq - Report Or Omit Repeated Lines</a></li>
<li><a href="news.html#86">wc – Print Line, Word, And Byte Counts</a></li>
<li><a href="news.html#86">grep – Print Lines Matching A Pattern</a></li>
<li><a href="news.html#87">head / tail – Print First / Last Part Of Files</a></li>
<li><a href="news.html#88">tee – Read From Stdin And Output To Stdout And Files</a></li>
</ul></li>
<li><a href="news.html#89">Summing Up</a></li>
</ul></li>
<li><a href="news.html#91">7 – Seeing The World As The Shell Sees It</a>
<ul>
<li><a href="news.html#91">Expansion</a>
<ul>
<li><a href="news.html#92">Pathname Expansion</a></li>
<li><a href="news.html#93">Tilde Expansion</a></li>
<li><a href="news.html#94">Arithmetic Expansion</a></li>
<li><a href="news.html#95">Brace Expansion</a></li>
<li><a href="news.html#96">Parameter Expansion</a></li>
<li><a href="news.html#97">Command Substitution</a></li>
</ul></li>
<li><a href="news.html#98">Quoting</a>
<ul>
<li><a href="news.html#99">Double Quotes</a></li>
<li><a href="news.html#100">Single Quotes</a></li>
<li><a href="news.html#101">Escaping Characters</a></li>
</ul></li>
<li><a href="news.html#102">Summing Up</a></li>
<li><a href="news.html#102">Further Reading</a></li>
</ul></li>
<li><a href="news.html#103">8 – Advanced Keyboard Tricks</a>
<ul>
<li><a href="news.html#103">Command Line Editing</a>
<ul>
<li><a href="news.html#103">Cursor Movement</a></li>
<li><a href="news.html#104">Modifying Text</a></li>
<li><a href="news.html#104">Cutting And Pasting (Killing And Yanking) Text</a></li>
</ul></li>
<li><a href="news.html#105">Completion</a></li>
<li><a href="news.html#107">Using History</a>
<ul>
<li><a href="news.html#108">Searching History</a></li>
<li><a href="news.html#110">History Expansion</a></li>
</ul></li>
<li><a href="news.html#110">Summing Up</a></li>
<li><a href="news.html#111">Further Reading</a></li>
</ul></li>
<li><a href="news.html#112">9 – Permissions</a>
<ul>
<li><a href="news.html#113">Owners, Group Members, And Everybody Else</a></li>
<li><a href="news.html#114">Reading, Writing, And Executing</a>
<ul>
<li><a href="news.html#116">chmod – Change File Mode</a></li>
<li><a href="news.html#119">Setting File Mode With The GUI</a></li>
<li><a href="news.html#120">umask – Set Default Permissions</a></li>
</ul></li>
<li><a href="news.html#123">Changing Identities</a>
<ul>
<li><a href="news.html#123">su – Run A Shell With Substitute User And Group IDs</a></li>
<li><a href="news.html#125">sudo – Execute A Command As Another User</a></li>
<li><a href="news.html#126">chown – Change File Owner And Group</a></li>
<li><a href="news.html#127">chgrp – Change Group Ownership</a></li>
</ul></li>
<li><a href="news.html#127">Exercising Our Privileges</a></li>
<li><a href="news.html#130">Changing Your Password</a></li>
<li><a href="news.html#131">Summing Up</a></li>
<li><a href="news.html#131">Further Reading</a></li>
</ul></li>
<li><a href="news.html#132">10 – Processes</a>
<ul>
<li><a href="news.html#132">How A Process Works</a></li>
<li><a href="news.html#133">Viewing Processes</a>
<ul>
<li><a href="news.html#135">Viewing Processes Dynamically With top</a></li>
</ul></li>
<li><a href="news.html#137">Controlling Processes</a>
<ul>
<li><a href="news.html#138">Interrupting A Process</a></li>
<li><a href="news.html#138">Putting A Process In The Background</a></li>
<li><a href="news.html#139">Returning A Process To The Foreground</a></li>
<li><a href="news.html#140">Stopping (Pausing) A Process</a></li>
</ul></li>
<li><a href="news.html#141">Signals</a>
<ul>
<li><a href="news.html#141">Sending Signals To Processes With kill</a></li>
<li><a href="news.html#144">Sending Signals To Multiple Processes With killall</a></li>
</ul></li>
<li><a href="news.html#144">More Process Related Commands</a></li>
<li><a href="news.html#145">Summing Up</a></li>
</ul></li>
</ul></li>
<li><a href="news.html#147">Part 2 – Configuration And The Environment</a>
<ul>
<li><a href="news.html#148">11 – The Environment</a>
<ul>
<li><a href="news.html#148">What Is Stored In The Environment?</a>
<ul>
<li><a href="news.html#148">Examining The Environment</a></li>
<li><a href="news.html#150">Some Interesting Variables</a></li>
</ul></li>
<li><a href="news.html#151">How Is The Environment Established?</a>
<ul>
<li><a href="news.html#152">What's In A Startup File?</a></li>
</ul></li>
<li><a href="news.html#154">Modifying The Environment</a>
<ul>
<li><a href="news.html#154">Which Files Should We Modify?</a></li>
<li><a href="news.html#154">Text Editors</a></li>
<li><a href="news.html#155">Using A Text Editor</a></li>
<li><a href="news.html#159">Activating Our Changes</a></li>
</ul></li>
<li><a href="news.html#159">Summing Up</a></li>
<li><a href="news.html#159">Further Reading</a></li>
</ul></li>
<li><a href="news.html#160">12 – A Gentle Introduction To vi</a>
<ul>
<li><a href="news.html#160">Why We Should Learn vi</a></li>
<li><a href="news.html#161">A Little Background</a></li>
<li><a href="news.html#161">Starting And Stopping vi</a></li>
<li><a href="news.html#163">Editing Modes</a>
<ul>
<li><a href="news.html#164">Entering Insert Mode</a></li>
<li><a href="news.html#164">Saving Our Work</a></li>
</ul></li>
<li><a href="news.html#165">Moving The Cursor Around</a></li>
<li><a href="news.html#166">Basic Editing</a>
<ul>
<li><a href="news.html#166">Appending Text</a></li>
<li><a href="news.html#167">Opening A Line</a></li>
<li><a href="news.html#168">Deleting Text</a></li>
<li><a href="news.html#169">Cutting, Copying, And Pasting Text</a></li>
<li><a href="news.html#171">Joining Lines</a></li>
</ul></li>
<li><a href="news.html#171">Search-And-Replace</a>
<ul>
<li><a href="news.html#171">Searching Within A Line</a></li>
<li><a href="news.html#171">Searching The Entire File</a></li>
<li><a href="news.html#172">Global Search-And-Replace</a></li>
</ul></li>
<li><a href="news.html#174">Editing Multiple Files</a>
<ul>
<li><a href="news.html#175">Switching Between Files</a></li>
<li><a href="news.html#175">Opening Additional Files For Editing</a></li>
<li><a href="news.html#176">Copying Content From One File Into Another</a></li>
<li><a href="news.html#177">Inserting An Entire File Into Another</a></li>
</ul></li>
<li><a href="news.html#178">Saving Our Work</a></li>
<li><a href="news.html#179">Summing Up</a></li>
<li><a href="news.html#179">Further Reading</a></li>
</ul></li>
<li><a href="news.html#180">13 – Customizing The Prompt</a>
<ul>
<li><a href="news.html#180">Anatomy Of A Prompt</a></li>
<li><a href="news.html#182">Trying Some Alternative Prompt Designs</a></li>
<li><a href="news.html#183">Adding Color</a></li>
<li><a href="news.html#186">Moving The Cursor</a></li>
<li><a href="news.html#187">Saving The Prompt</a></li>
<li><a href="news.html#188">Summing Up</a></li>
<li><a href="news.html#188">Further Reading</a></li>
</ul></li>
</ul></li>
<li><a href="news.html#189">Part 3 – Common Tasks And Essential Tools</a>
<ul>
<li><a href="news.html#190">14 – Package Management</a>
<ul>
<li><a href="news.html#190">Packaging Systems</a></li>
<li><a href="news.html#191">How A Package System Works</a>
<ul>
<li><a href="news.html#191">Package Files</a></li>
<li><a href="news.html#191">Repositories</a></li>
<li><a href="news.html#192">Dependencies</a></li>
<li><a href="news.html#192">High And Low-level Package Tools</a></li>
</ul></li>
<li><a href="news.html#193">Common Package Management Tasks</a>
<ul>
<li><a href="news.html#193">Finding A Package In A Repository</a></li>
<li><a href="news.html#193">Installing A Package From A Repository</a></li>
<li><a href="news.html#194">Installing A Package From A Package File</a></li>
<li><a href="news.html#194">Removing A Package</a></li>
<li><a href="news.html#195">Updating Packages From A Repository</a></li>
<li><a href="news.html#195">Upgrading A Package From A Package File</a></li>
<li><a href="news.html#196">Listing Installed Packages</a></li>
<li><a href="news.html#196">Determining If A Package Is Installed</a></li>
<li><a href="news.html#197">Displaying Info About An Installed Package</a></li>
<li><a href="news.html#197">Finding Which Package Installed A File</a></li>
</ul></li>
<li><a href="news.html#197">Summing Up</a></li>
<li><a href="news.html#199">Further Reading</a></li>
</ul></li>
<li><a href="news.html#200">15 – Storage Media</a>
<ul>
<li><a href="news.html#200">Mounting And Unmounting Storage Devices</a>
<ul>
<li><a href="news.html#202">Viewing A List Of Mounted File Systems</a></li>
<li><a href="news.html#206">Determining Device Names</a></li>
</ul></li>
<li><a href="news.html#209">Creating New File Systems</a>
<ul>
<li><a href="news.html#209">Manipulating Partitions With fdisk</a></li>
<li><a href="news.html#212">Creating A New File System With mkfs</a></li>
</ul></li>
<li><a href="news.html#213">Testing And Repairing File Systems</a></li>
<li><a href="news.html#213">Formatting Floppy Disks</a></li>
<li><a href="news.html#214">Moving Data Directly To/From Devices</a></li>
<li><a href="news.html#215">Creating CD-ROM Images</a>
<ul>
<li><a href="news.html#215">Creating An Image Copy Of A CD-ROM</a></li>
<li><a href="news.html#215">Creating An Image From A Collection Of Files</a></li>
</ul></li>
<li><a href="news.html#216">Writing CD-ROM Images</a>
<ul>
<li><a href="news.html#216">Mounting An ISO Image Directly</a></li>
<li><a href="news.html#217">Blanking A Re-Writable CD-ROM</a></li>
<li><a href="news.html#217">Writing An Image</a></li>
</ul></li>
<li><a href="news.html#217">Summing Up</a></li>
<li><a href="news.html#217">Further Reading</a></li>
<li><a href="news.html#217">Extra Credit</a></li>
</ul></li>
<li><a href="news.html#219">16 – Networking</a>
<ul>
<li><a href="news.html#220">Examining And Monitoring A Network</a>
<ul>
<li><a href="news.html#220">ping</a></li>
<li><a href="news.html#221">traceroute</a></li>
<li><a href="news.html#222">netstat</a></li>
</ul></li>
<li><a href="news.html#223">Transporting Files Over A Network</a>
<ul>
<li><a href="news.html#223">ftp</a></li>
<li><a href="news.html#226">lftp – A Better ftp</a></li>
<li><a href="news.html#226">wget</a></li>
</ul></li>
<li><a href="news.html#226">Secure Communication With Remote Hosts</a>
<ul>
<li><a href="news.html#227">ssh</a></li>
<li><a href="news.html#231">scp And sftp</a></li>
</ul></li>
<li><a href="news.html#232">Summing Up</a></li>
<li><a href="news.html#232">Further Reading</a></li>
</ul></li>
<li><a href="news.html#233">17 – Searching For Files</a>
<ul>
<li><a href="news.html#233">locate – Find Files The Easy Way</a></li>
<li><a href="news.html#235">find – Find Files The Hard Way</a>
<ul>
<li><a href="news.html#236">Tests</a></li>
<li><a href="news.html#238">Operators</a></li>
<li><a href="news.html#241">Predefined Actions</a></li>
<li><a href="news.html#243">User-Defined Actions</a></li>
<li><a href="news.html#244">Improving Efficiency</a></li>
<li><a href="news.html#244">xargs</a></li>
<li><a href="news.html#245">A Return To The Playground</a></li>
<li><a href="news.html#248">Options</a></li>
</ul></li>
<li><a href="news.html#249">Summing Up</a></li>
<li><a href="news.html#249">Further Reading</a></li>
</ul></li>
<li><a href="news.html#250">18 – Archiving And Backup</a>
<ul>
<li><a href="news.html#250">Compressing Files</a>
<ul>
<li><a href="news.html#251">gzip</a></li>
<li><a href="news.html#253">bzip2</a></li>
</ul></li>
<li><a href="news.html#254">Archiving Files</a>
<ul>
<li><a href="news.html#254">tar</a></li>
<li><a href="news.html#260">zip</a></li>
</ul></li>
<li><a href="news.html#262">Synchronizing Files And Directories</a>
<ul>
<li><a href="news.html#264">Using rsync Over A Network</a></li>
</ul></li>
<li><a href="news.html#265">Summing Up</a></li>
<li><a href="news.html#265">Further Reading</a></li>
</ul></li>
<li><a href="news.html#267">19 – Regular Expressions</a>
<ul>
<li><a href="news.html#267">What Are Regular Expressions?</a></li>
<li><a href="news.html#267">grep</a></li>
<li><a href="news.html#269">Metacharacters And Literals</a></li>
<li><a href="news.html#270">The Any Character</a></li>
<li><a href="news.html#271">Anchors</a></li>
<li><a href="news.html#272">Bracket Expressions And Character Classes</a>
<ul>
<li><a href="news.html#272">Negation</a></li>
<li><a href="news.html#273">Traditional Character Ranges</a></li>
<li><a href="news.html#274">POSIX Character Classes</a></li>
</ul></li>
<li><a href="news.html#278">POSIX Basic Vs. Extended Regular Expressions</a></li>
<li><a href="news.html#279">Alternation</a></li>
<li><a href="news.html#280">Quantifiers</a>
<ul>
<li><a href="news.html#280">? - Match An Element Zero Or One Time</a></li>
<li><a href="news.html#281">* - Match An Element Zero Or More Times</a></li>
<li><a href="news.html#282">+ - Match An Element One Or More Times</a></li>
<li><a href="news.html#282">{ } - Match An Element A Specific Number Of Times</a></li>
</ul></li>
<li><a href="news.html#283">Putting Regular Expressions To Work</a>
<ul>
<li><a href="news.html#283">Validating A Phone List With grep</a></li>
<li><a href="news.html#284">Finding Ugly Filenames With find</a></li>
<li><a href="news.html#285">Searching For Files With locate</a></li>
<li><a href="news.html#285">Searching For Text With less And vim</a></li>
</ul></li>
<li><a href="news.html#287">Summing Up</a></li>
<li><a href="news.html#287">Further Reading</a></li>
</ul></li>
<li><a href="news.html#288">20 – Text Processing</a>
<ul>
<li><a href="news.html#288">Applications Of Text</a>
<ul>
<li><a href="news.html#289">Documents</a></li>
<li><a href="news.html#289">Web Pages</a></li>
<li><a href="news.html#289">Email</a></li>
<li><a href="news.html#289">Printer Output</a></li>
<li><a href="news.html#289">Program Source Code</a></li>
</ul></li>
<li><a href="news.html#289">Revisiting Some Old Friends</a>
<ul>
<li><a href="news.html#290">cat</a></li>
<li><a href="news.html#291">sort</a></li>
<li><a href="news.html#299">uniq</a></li>
</ul></li>
<li><a href="news.html#300">Slicing And Dicing</a>
<ul>
<li><a href="news.html#300">cut</a></li>
<li><a href="news.html#304">paste</a></li>
<li><a href="news.html#305">join</a></li>
</ul></li>
<li><a href="news.html#307">Comparing Text</a>
<ul>
<li><a href="news.html#308">comm</a></li>
<li><a href="news.html#308">diff</a></li>
<li><a href="news.html#311">patch</a></li>
</ul></li>
<li><a href="news.html#312">Editing On The Fly</a>
<ul>
<li><a href="news.html#312">tr</a></li>
<li><a href="news.html#314">sed</a></li>
<li><a href="news.html#323">aspell</a></li>
</ul></li>
<li><a href="news.html#327">Summing Up</a></li>
<li><a href="news.html#327">Further Reading</a></li>
<li><a href="news.html#328">Extra Credit</a></li>
</ul></li>
<li><a href="news.html#329">21 – Formatting Output</a>
<ul>
<li><a href="news.html#329">Simple Formatting Tools</a>
<ul>
<li><a href="news.html#329">nl – Number Lines</a></li>
<li><a href="news.html#333">fold – Wrap Each Line To A Specified Length</a></li>
<li><a href="news.html#333">fmt – A Simple Text Formatter</a></li>
<li><a href="news.html#337">pr – Format Text For Printing</a></li>
<li><a href="news.html#338">printf – Format And Print Data</a></li>
</ul></li>
<li><a href="news.html#341">Document Formatting Systems</a>
<ul>
<li><a href="news.html#342">groff</a></li>
</ul></li>
<li><a href="news.html#348">Summing Up</a></li>
<li><a href="news.html#348">Further Reading</a></li>
</ul></li>
<li><a href="news.html#350">22 – Printing</a>
<ul>
<li><a href="news.html#350">A Brief History Of Printing</a>
<ul>
<li><a href="news.html#350">Printing In The Dim Times</a></li>
<li><a href="news.html#351">Character-based Printers</a></li>
<li><a href="news.html#352">Graphical Printers</a></li>
</ul></li>
<li><a href="news.html#353">Printing With Linux</a></li>
<li><a href="news.html#353">Preparing Files For Printing</a>
<ul>
<li><a href="news.html#353">pr – Convert Text Files For Printing</a></li>
</ul></li>
<li><a href="news.html#355">Sending A Print Job To A Printer</a>
<ul>
<li><a href="news.html#355">lpr – Print Files (Berkeley Style)</a></li>
<li><a href="news.html#356">lp – Print Files (System V Style)</a></li>
<li><a href="news.html#357">Another Option: a2ps</a></li>
</ul></li>
<li><a href="news.html#360">Monitoring And Controlling Print Jobs</a>
<ul>
<li><a href="news.html#360">lpstat – Display Print System Status</a></li>
<li><a href="news.html#361">lpq – Display Printer Queue Status</a></li>
<li><a href="news.html#362">lprm / cancel – Cancel Print Jobs</a></li>
</ul></li>
<li><a href="news.html#362">Summing Up</a></li>
<li><a href="news.html#362">Further Reading</a></li>
</ul></li>
<li><a href="news.html#364">23 – Compiling Programs</a>
<ul>
<li><a href="news.html#364">What Is Compiling?</a>
<ul>
<li><a href="news.html#365">Are All Programs Compiled?</a></li>
</ul></li>
<li><a href="news.html#366">Compiling A C Program</a>
<ul>
<li><a href="news.html#366">Obtaining The Source Code</a></li>
<li><a href="news.html#368">Examining The Source Tree</a></li>
<li><a href="news.html#370">Building The Program</a></li>
<li><a href="news.html#374">Installing The Program</a></li>
</ul></li>
<li><a href="news.html#374">Summing Up</a></li>
<li><a href="news.html#374">Further Reading</a></li>
</ul></li>
</ul></li>
<li><a href="news.html#377">Part 4 – Writing Shell Scripts</a>
<ul>
<li><a href="news.html#378">24 – Writing Your First Script</a>
<ul>
<li><a href="news.html#378">What Are Shell Scripts?</a></li>
<li><a href="news.html#378">How To Write A Shell Script</a></li>
<li><a href="news.html#379">Script File Format</a></li>
<li><a href="news.html#380">Executable Permissions</a></li>
<li><a href="news.html#380">Script File Location</a>
<ul>
<li><a href="news.html#382">Good Locations For Scripts</a></li>
</ul></li>
<li><a href="news.html#382">More Formatting Tricks</a>
<ul>
<li><a href="news.html#382">Long Option Names</a></li>
<li><a href="news.html#382">Indentation And line-continuation</a></li>
</ul></li>
<li><a href="news.html#384">Summing Up</a></li>
<li><a href="news.html#384">Further Reading</a></li>
</ul></li>
<li><a href="news.html#385">25 – Starting A Project</a>
<ul>
<li><a href="news.html#385">First Stage: Minimal Document</a></li>
<li><a href="news.html#387">Second Stage: Adding A Little Data</a></li>
<li><a href="news.html#388">Variables And Constants</a>
<ul>
<li><a href="news.html#391">Assigning Values To Variables And Constants</a></li>
</ul></li>
<li><a href="news.html#392">Here Documents</a></li>
<li><a href="news.html#395">Summing Up</a></li>
<li><a href="news.html#395">Further Reading</a></li>
</ul></li>
<li><a href="news.html#396">26 – Top-Down Design</a>
<ul>
<li><a href="news.html#397">Shell Functions</a></li>
<li><a href="news.html#400">Local Variables</a></li>
<li><a href="news.html#401">Keep Scripts Running</a></li>
<li><a href="news.html#404">Summing Up</a></li>
<li><a href="news.html#404">Further Reading</a></li>
</ul></li>
<li><a href="news.html#405">27 – Flow Control: Branching With if</a>
<ul>
<li><a href="news.html#405">if</a></li>
<li><a href="news.html#406">Exit Status</a></li>
<li><a href="news.html#408">test</a>
<ul>
<li><a href="news.html#408">File Expressions</a></li>
<li><a href="news.html#411">String Expressions</a></li>
<li><a href="news.html#412">Integer Expressions</a></li>
</ul></li>
<li><a href="news.html#413">A More Modern Version Of test</a></li>
<li><a href="news.html#415">(( )) - Designed For Integers</a></li>
<li><a href="news.html#416">Combining Expressions</a></li>
<li><a href="news.html#418">Control Operators: Another Way To Branch</a></li>
<li><a href="news.html#419">Summing Up</a></li>
<li><a href="news.html#420">Further Reading</a></li>
</ul></li>
<li><a href="news.html#421">28 – Reading Keyboard Input</a>
<ul>
<li><a href="news.html#422">read – Read Values From Standard Input</a>
<ul>
<li><a href="news.html#424">Options</a></li>
<li><a href="news.html#426">IFS</a></li>
</ul></li>
<li><a href="news.html#428">Validating Input</a></li>
<li><a href="news.html#430">Menus</a></li>
<li><a href="news.html#431">Summing Up</a>
<ul>
<li><a href="news.html#431">Extra Credit</a></li>
</ul></li>
<li><a href="news.html#432">Further Reading</a></li>
</ul></li>
<li><a href="news.html#433">29 – Flow Control: Looping With while / until</a>
<ul>
<li><a href="news.html#433">Looping</a>
<ul>
<li><a href="news.html#433">while</a></li>
</ul></li>
<li><a href="news.html#436">Breaking Out Of A Loop</a>
<ul>
<li><a href="news.html#437">until</a></li>
</ul></li>
<li><a href="news.html#438">Reading Files With Loops</a></li>
<li><a href="news.html#439">Summing Up</a></li>
<li><a href="news.html#439">Further Reading</a></li>
</ul></li>
<li><a href="news.html#440">30 – Troubleshooting</a>
<ul>
<li><a href="news.html#440">Syntactic Errors</a>
<ul>
<li><a href="news.html#441">Missing Quotes</a></li>
<li><a href="news.html#441">Missing Or Unexpected Tokens</a></li>
<li><a href="news.html#442">Unanticipated Expansions</a></li>
</ul></li>
<li><a href="news.html#444">Logical Errors</a>
<ul>
<li><a href="news.html#444">Defensive Programming</a></li>
<li><a href="news.html#446">Verifying Input</a></li>
</ul></li>
<li><a href="news.html#446">Testing</a>
<ul>
<li><a href="news.html#447">Test Cases</a></li>
</ul></li>
<li><a href="news.html#448">Debugging</a>
<ul>
<li><a href="news.html#448">Finding The Problem Area</a></li>
<li><a href="news.html#448">Tracing</a></li>
<li><a href="news.html#451">Examining Values During Execution</a></li>
</ul></li>
<li><a href="news.html#451">Summing Up</a></li>
<li><a href="news.html#452">Further Reading</a></li>
</ul></li>
<li><a href="news.html#453">31 – Flow Control: Branching With case</a>
<ul>
<li><a href="news.html#453">case</a>
<ul>
<li><a href="news.html#455">Patterns</a></li>
<li><a href="news.html#457">Performing Multiple Actions</a></li>
</ul></li>
<li><a href="news.html#458">Summing Up</a></li>
<li><a href="news.html#458">Further Reading</a></li>
</ul></li>
<li><a href="news.html#460">32 – Positional Parameters</a>
<ul>
<li><a href="news.html#460">Accessing The Command Line</a>
<ul>
<li><a href="news.html#461">Determining The Number of Arguments</a></li>
<li><a href="news.html#462">shift – Getting Access To Many Arguments</a></li>
<li><a href="news.html#463">Simple Applications</a></li>
<li><a href="news.html#464">Using Positional Parameters With Shell Functions</a></li>
</ul></li>
<li><a href="news.html#465">Handling Positional Parameters En Masse</a></li>
<li><a href="news.html#467">A More Complete Application</a></li>
<li><a href="news.html#470">Summing Up</a></li>
<li><a href="news.html#473">Further Reading</a></li>
</ul></li>
<li><a href="news.html#474">33 – Flow Control: Looping With for</a>
<ul>
<li><a href="news.html#474">for: Traditional Shell Form</a></li>
<li><a href="news.html#477">for: C Language Form</a></li>
<li><a href="news.html#478">Summing Up</a></li>
<li><a href="news.html#479">Further Reading</a></li>
</ul></li>
<li><a href="news.html#480">34 – Strings And Numbers</a>
<ul>
<li><a href="news.html#480">Parameter Expansion</a>
<ul>
<li><a href="news.html#480">Basic Parameters</a></li>
<li><a href="news.html#481">Expansions To Manage Empty Variables</a></li>
<li><a href="news.html#483">Expansions That Return Variable Names</a></li>
<li><a href="news.html#483">String Operations</a></li>
<li><a href="news.html#486">Case Conversion</a></li>
</ul></li>
<li><a href="news.html#488">Arithmetic Evaluation And Expansion</a>
<ul>
<li><a href="news.html#489">Number Bases</a></li>
<li><a href="news.html#489">Unary Operators</a></li>
<li><a href="news.html#489">Simple Arithmetic</a></li>
<li><a href="news.html#491">Assignment</a></li>
<li><a href="news.html#493">Bit Operations</a></li>
<li><a href="news.html#494">Logic</a></li>
</ul></li>
<li><a href="news.html#497">bc – An Arbitrary Precision Calculator Language</a>
<ul>
<li><a href="news.html#498">Using bc</a></li>
<li><a href="news.html#499">An Example Script</a></li>
</ul></li>
<li><a href="news.html#500">Summing Up</a></li>
<li><a href="news.html#500">Extra Credit</a></li>
<li><a href="news.html#500">Further Reading</a></li>
</ul></li>
<li><a href="news.html#502">35 – Arrays</a>
<ul>
<li><a href="news.html#502">What Are Arrays?</a></li>
<li><a href="news.html#502">Creating An Array</a></li>
<li><a href="news.html#503">Assigning Values To An Array</a></li>
<li><a href="news.html#504">Accessing Array Elements</a></li>
<li><a href="news.html#506">Array Operations</a>
<ul>
<li><a href="news.html#506">Outputting The Entire Contents Of An Array</a></li>
<li><a href="news.html#506">Determining The Number Of Array Elements</a></li>
<li><a href="news.html#507">Finding The Subscripts Used By An Array</a></li>
<li><a href="news.html#507">Adding Elements To The End Of An Array</a></li>
<li><a href="news.html#508">Sorting An Array</a></li>
<li><a href="news.html#508">Deleting An Array</a></li>
</ul></li>
<li><a href="news.html#509">Associative Arrays</a></li>
<li><a href="news.html#510">Summing Up</a></li>
<li><a href="news.html#510">Further Reading</a></li>
</ul></li>
<li><a href="news.html#511">36 – Exotica</a>
<ul>
<li><a href="news.html#511">Group Commands And Subshells</a>
<ul>
<li><a href="news.html#515">Process Substitution</a></li>
</ul></li>
<li><a href="news.html#517">Traps</a></li>
<li><a href="news.html#520">Asynchronous Execution</a>
<ul>
<li><a href="news.html#520">wait</a></li>
</ul></li>
<li><a href="news.html#522">Named Pipes</a>
<ul>
<li><a href="news.html#522">Setting Up A Named Pipe</a></li>
<li><a href="news.html#523">Using Named Pipes</a></li>
</ul></li>
<li><a href="news.html#523">Summing Up</a></li>
<li><a href="news.html#523">Further Reading</a></li>
</ul></li>
<li><a href="news.html#525">Index</a></li>
</ul></li>
</ul>
<hr />
